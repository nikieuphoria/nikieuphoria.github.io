<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>薛定谔，你在吗？</title>
      <link href="/2025/08/05/%E8%96%9B%E5%AE%9A%E8%B0%94%EF%BC%8C%E4%BD%A0%E5%9C%A8%E5%90%97%EF%BC%9F/"/>
      <url>/2025/08/05/%E8%96%9B%E5%AE%9A%E8%B0%94%EF%BC%8C%E4%BD%A0%E5%9C%A8%E5%90%97%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<p>最近的新闻频繁上演诡谲的话题：宛如《哭悲》里面异化的世界。</p><p>极端的焦虑、不安、困惑和痛苦，我想要呕吐，恐惧自己马上成为刀刃下的腐骨，更恐惧的是我甚至发不出愤怒的声音，就此寂静下去。</p><p>当然，这是一篇2025过半的回顾，我控制自己不要呕吐出太多负面的情绪。</p><hr><p>打字的时候是八月，年中已经过去了整整两个月，我却几乎毫无察觉。身体还滞留在年初的某个时间点。<br>工作后一个问题产生了：<br><strong>把成长感和价值感全押在工作上，是不是一种错？  工作是不是就该只是一个赚钱的工具？</strong><br>从更换项目以来，这个疑问宛如缠绕我的恶鬼，时时刻刻将我逼迫到崩溃的边缘。</p><p>说实话，我的第一个项目环境挺轻松，领导同事也都很好。但就算这样，我还是能从中榨出一些痛苦，那种现在看来已经算奢侈的痛苦：比如工作一段时间后就觉得自己学习的速度减慢了，不再像刚入职那样快速吸收新东西。<br>但那个项目起码流程清晰、可追溯、标准化，领导给的权限是有限但稳定的。更重要的是，同事的工作方式彻底改变了我对技术的理解和看法。</p><p>可惜，当时我也开始感到不安。生活很美好，甚至可以说无聊，而我却因此感到恐惧：<br>“要是一直这样，我是不是就停滞不前了？是不是成长得太慢了？”</p><p>于是我去了另一个项目。搬家的琐碎、通勤时间成本增加、生活成本增加、居住环境质量下降、新环境、新同事……</p><p>决定的时候很纠结。但对我来说，“纠结”往往不是因为我不知道选哪条路，而是我心里已经有答案了，但需要一些成熟的逻辑和可信任的理论来支撑。</p><p>第一天我就有即将不幸的预感，如同宿命论的舞台上最后一幕的雨，象征着悲剧。<br>第一周我就开始不安。<br>第一个半月我崩溃了。</p><p>然后前文所说的疑问就开始唱歌，无时无刻我质询自己，观察别人，试图获得答案。<br>我还开始写职场七宗罪，^ ^<br>叙述那些经历和感受都是一种痛，跳过。</p><p>疑问没有答案。<br>为了不把自己拖死，我开始自我保护，也就是彻底摆烂。上班带上耳机听犯罪播客，看罪案（倾情推荐xinklings，我超喜欢的一个写罪案的女博主）。<br>我不再提出疑问，不再思考如何更好解决工作中出现的问题，不再积极跟进问题。甲领导说A好，我就照着A做，即使A根本没有道理。</p><p>就这样摆烂了一个月。<br>我和领导五月argue过，直到八月才调整工作重点。<br><img src="/images/sky.jpg" alt="EC2"><br>漫长的时间里，对工作本体的不满已经蔓延升维成为对领导能力、甲方、客户、公司制度、公司属性的多面一体不满了。<br>工作一步一步侵占我的自由，管理者满不在乎：“不就几分钟嘛，到底是有多难？”<br>打卡，日报，周报，工作量汇总，服装，工牌……<br>一切永无止境。</p><p>疑问还是没有答案，我还是时常愤怒和痛苦，目前还在寻找解决方式。<br>顺便一提，职场七宗罪已经写道第六条了。</p><blockquote><p>任何一个在普世登本位里给上级打工的feminist，基本上没有不反思自己、不为工作的组织框架下被管理、被训诫、被规训而痛苦的。</p></blockquote><hr><p>第一个问题浮现后，第二个也紧随其后：我是否真的适合做技术工作。<br>有时候过渡思考某个问题会陷入深渊。</p><p>我的解决方式是：</p><blockquote><p>不要在不会某件事情的时候断言自己不喜欢不适合。<br><img src="/images/tree.jpg" alt="EC2"></p></blockquote><hr><p>今年搬家后，我和这个城市遇到的一个同期同事，成为了朋友，我们一起过了生日。</p><p>灵感终于落实成文字，虽然因为工作中断了，但至少5W字了。</p><p>本来年初写下阅读目标是30本，现在已经读完24本，得益于每天通勤时间的变长。</p><p>开始建设自己的Linkedin，封了两次号，现在终于正常运行。</p><p>有了第一个文身。</p><p>公众号邀请我写了技术分享文章</p><p>虽然还是没有去学自由泳。&gt;_&lt;</p><p>奇怪，怎么写得像是年终总结。工作，你毁了我！！！<br><img src="/images/w1.jpg" alt="EC2"></p><p>所谓“时代变局”不只是新闻用语，它正在一点点渗进我的日常。<br>命运的诡谲之处就在于，没有是非题，只要我骗过自己，就能皆大欢喜。<br>可我并不想欺骗自己：我过得幸福。</p><p>我忍不住朝虚空大喊：“薛定谔，你在吗？”<br><img src="/images/xde.jpg" alt="EC2"><br>可事实上，在盒子里我注定只是工具，想要摆脱黑暗，只能逃出去，顺便咬薛定谔一口。</p><p><img src="/images/taluo.jpg" alt="EC2"></p>]]></content>
      
      
      <categories>
          
          <category> flee as a bird to your mountain </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2025/07/15/K8S-/"/>
      <url>/2025/07/15/K8S-/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>AWS-SAA认证全攻略</title>
      <link href="/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/"/>
      <url>/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<p>此篇文章源自我在WomenStack 百栈百胜公众号的一次分享，公众号文章链接附下，欢迎大家关注微信公众号WomenStack 百栈百胜<br><a href="https://mp.weixin.qq.com/s?__biz=Mzk4ODQ2NzkxOQ==&mid=2247485911&idx=1&sn=82f2435d9600c3b4be6aa200df2c1d7a&chksm=c4d61b2fafa6e6642660c64001f4dd53009cd7a998e79f94e9ff68accda2572c47d9ea51f575&mpshare=1&scene=1&srcid=0729ZToFy994c5rHOusSlaqM&sharer_shareinfo=8993ec30eec70b4e1b042681f1ed1f18&sharer_shareinfo_first=cc8c545add2d44d6f5095cb1a0818068#rd">https://mp.weixin.qq.com/s?__biz=Mzk4ODQ2NzkxOQ==&amp;mid=2247485911&amp;idx=1&amp;sn=82f2435d9600c3b4be6aa200df2c1d7a&amp;chksm=c4d61b2fafa6e6642660c64001f4dd53009cd7a998e79f94e9ff68accda2572c47d9ea51f575&amp;mpshare=1&amp;scene=1&amp;srcid=0729ZToFy994c5rHOusSlaqM&amp;sharer_shareinfo=8993ec30eec70b4e1b042681f1ed1f18&amp;sharer_shareinfo_first=cc8c545add2d44d6f5095cb1a0818068#rd</a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我学云计算的第一步，是靠考下 <strong>AWS Certified Solutions Architect – Associate（简称 SAA</strong><strong>）</strong> 完成的。</p><p>AWS（Amazon Web Services）是亚马逊（Amazon）旗下的云计算平台，与 Microsoft Azure、Google Cloud Platform（GCP）并称全球三大云服务商。 国内则有阿里巴巴、腾讯、华为等公司提供各自的云服务，分别是阿里云、腾讯云和华为云。</p><p>虽然各家厂商均推出自有认证体系，但AWS的很多架构与服务都是云计算的行业标准。即便考完很久，大部分知识都忘记了，但现在无论使用哪家厂商的云服务，我都能将其对应到 AWS 的服务。</p><p>这并不意味着考试万能，对我的职业路径也没有巨大增益，但在学习过程中，通过将零散的服务组件系统性地整合为完整的架构体系，重新审视并理解传统IT架构的本质特征与运行逻辑，这些对我而言是非常宝贵的经历。</p><p>我学习到的，<strong>不只是“该用哪个服务”，而是“如何思考”。<strong>它帮我建立了</strong>云原生****的思维方式</strong>，让我在后续的实际项目、技术决策中，能更清晰地分析问题、设计架构。</p><p>AWS提供非常多的认证，可以通过官网查看。大致分为入门、助理、专业、专项。详细认证信息可通过文末链接[2]查看。</p><p>作为初学者，应该选择<strong>入门级</strong>的Cloud Practitioner还是<strong>助理级</strong>的Solutions Architect Associate呢？</p><p>Cloud Practitioner（云计算从业者）更加关注云服务本身，适合没有技术背景的人员，需要知道有哪些产品、能做什么、大概怎么用即可，无需深究架构原理。</p><p>Solutions Architect Associate（解决方案架构师助理级）适合开发者、运维工程师、系统工程师，更加侧重云服务在架构中如何发挥作用，更要掌握它们如何组合成高可用、可扩展、成本优化的整体解决方案。</p><p>我本身是计算机专业背景，玩过虚拟机、搭过服务，对 Linux 、计算机网络不陌生，但不了解云原生云计算，当时的职业规划也更倾向于建立系统的云架构设计能力，所以选择SAA而非CP（Cloud Practitioner）。当然，国内的云认证更方便，如阿里云的ACP（阿里云云计算高级工程师Alibaba Cloud Certified Professional - Cloud Computing），资源更加好获取，语言也没有门槛，怎么选看个人倾向。</p><p>本文主要分享AWS-SAA（解决方案架构师助理级）的认证经验。</p><h1 id="个人情况"><a href="#个人情况" class="headerlink" title="个人情况"></a>个人情况</h1><p>背景：计算机专业，对云服务完全不了解</p><p>备考时长时间：48天左右</p><ul><li>学习：35天，每天有效学习时长3~5小时（其中可能有1-3天去玩了）</li><li>刷题：13天</li></ul><p>刷题来源：ExamTopics</p><h1 id="关于-AWS-SAA-考试："><a href="#关于-AWS-SAA-考试：" class="headerlink" title="关于 AWS SAA 考试："></a>关于 AWS SAA 考试：</h1><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>SAA-C03 是 <strong>AWS SAA</strong> 认证考试的最新版本代码，于 2022 年 8 月 30 日正式启用，替代旧版 SAA-C02。在获取资料、学习、刷题过程中请认准最新代码。</li><li>认证常见问题（重考政策等）见文末[3]。</li><li>考前、考中和考后的流程与要求见文末[4]。</li></ul><h2 id="折扣与报名"><a href="#折扣与报名" class="headerlink" title="折扣与报名"></a>折扣与报名</h2><ul><li>官方价格150 USD（约1085元），AWS官方提供多种活动获取折扣优惠。此外，通过任何一项认证后能够领取五折优惠券。</li><li>考试方式：线下考试中心或在线监考考试。</li><li>考试语言：推荐选<strong>中文</strong>，因为选了中文之后也可以查看英文考题，反之则不行。</li><li>提前 1 周预约即可，如果需要更改预约时间，在<strong>考试时间至少 24 小时之前</strong>取消或重新预约。</li><li>报考链接见文末[5]。</li></ul><hr><h2 id="题目结构"><a href="#题目结构" class="headerlink" title="题目结构"></a>题目结构</h2><ul><li>一共 <strong>65 道题。</strong></li><li>其中有15道为不计分试题。AWS 收集这些不计分试题的 答题情况以进行评估，以便将来将这些试题作为计分试题。在考试中不会标明不计分试题。</li><li>全部为 <strong>单选 &#x2F; 多选。</strong></li><li>题目比较长，包含场景描述、业务背景、架构限制等。</li></ul><hr><h2 id="考试时间与结果"><a href="#考试时间与结果" class="headerlink" title="考试时间与结果"></a>考试时间与结果</h2><ul><li>考试时长：130 分钟，非英语母语者申请 Exam Accommodations将考试时间延长 30 分钟。</li><li>考试结果换算分数为 100 – 1000 分。最低及格分数为 720 分。</li><li>完成考试后，不会立马在屏幕上看到考试结果。</li><li>未通过考试，需要 14 天后才能重考。重考次数没有限制，但每次重考都必须全额支付报名费。</li></ul><h1 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h1><h2 id="官方学习资料——AWS-白皮书"><a href="#官方学习资料——AWS-白皮书" class="headerlink" title="官方学习资料——AWS 白皮书"></a>官方学习资料——AWS 白皮书</h2><p>白皮书提供非常详细的文档支持，大部分疑问都可以得到答案。学会熟练查阅白皮书，从官方文档获取最全面的云产品信息。白皮书链接见文末[6]。</p><h2 id="考点知识大纲"><a href="#考点知识大纲" class="headerlink" title="考点知识大纲"></a>考点知识大纲</h2><p>AWS目前有近百项服务，不过如果想通过AWS的助理级认证，只需要熟悉掌握主要的服务即可。对其他服务只需要明白其使用场景以及一些应用限制。官方提供的大纲更加详细，但是以<strong>设计架构</strong>的角度出发。官方大纲pdf可通过文末[7]获取。</p><p>我的大纲是从学习者角度出发整理的，这里只作为补充参考。一部分内容如机器学习几乎不占比重，不是考试重点，但偶尔也会出现在考题中，你只需要大概知道即可。</p><ol><li>计算服务（Compute）<br> EC2：需掌握启动、配置、安全组、弹性 IP、Auto Scaling<br> Lambda：事件驱动的无服务器计算服务<br> Elastic Beanstalk：自动化部署与管理<br> ECS &#x2F; EKS（容器服务）</li><li>存储服务（Storage）<br> S3：存储桶、存储类别、生命周期管理、版本控制、加密等<br> EBS：卷类型（gp3、io2）、快照、加密<br> EFS：适用于多个 EC2 实例共享访问的文件存储<br> FSx：适用于 Windows 文件服务器或高性能计算（Lustre）</li><li>数据库服务（Database）：<br> RDS：托管版数据库</li></ol><p>Aurora：兼容 MySQL&#x2F;PostgreSQL，比 RDS 更快更贵</p><p>DynamoDB：NoSQL 数据库</p><p>ElastiCache：托管版 Redis 或 Memcached</p><p>Redshift：数据仓库，跑大规模分析 SQL，适合 BI 报表</p><p>Transfer Family：用 SFTP&#x2F;FTP&#x2F;FTPS 把数据安全地迁到 AWS 上</p><p>Snow Family：实体硬件设备，用来物理迁移海量数据进云</p><ol start="4"><li>网络（Networking）<br> VPC：包含子网（公有&#x2F;私有）、路由表、安全组（SG）与网络ACL<br> IGW NAT Gateway：分别用于公网访问与私网出站访问<br> Bastion Host：跳板机，用于安全访问私有子网<br> Route 53：DNS 服务<br> CloudFront：CDN 加速服务<br> Direct Connect &#x2F; Transit Gateway</li><li>Serverless 、应用解耦与集成<br> Lambda + API Gateway<br> Kinesis<br> SNS（发布&#x2F;订阅）<br> SQS（消息队列）<br> EventBridge：事件总线，支持跨服务事件驱动架构<br> Step Functions：状态管理 + 工作流编排</li><li>灾难恢复与数据迁移（DR &amp; Migration）<br> 灾难恢复方案<br> 数据迁移工具<br> 备份策略</li><li>安全与权限控制（Security &amp; Identity）<br> IAM：身份与访问管理（用户、组、角色、策略）<br> Organizations &#x2F; SCP：多账户管理与集中策略控制<br> KMS：密钥管理服务（对数据加密解密）<br> CloudTrail &#x2F; Config：操作记录审计与合规性监控<br> CloudWatch：监控服务，含日志、指标、报警、仪表板</li></ol><h2 id="Udemy课程"><a href="#Udemy课程" class="headerlink" title="Udemy课程"></a>Udemy课程</h2><p>Udemy平台Stephane Maarek的《Ultimate AWS Certified Solutions Architect Associate》，官方链接见文末[8]。</p><p>该课程面向初学者，无需了解任何 AWS 知识，提供完整的学习路径，包括：</p><ul><li>完整的模拟考试，包括解释！</li><li>所有 800 多张幻灯片均以可下载的 PDF 形式提供</li><li>实操部分的详细讲解，包括Troubleshooting</li><li>了解 AWS 基础知识：计算服务（EC2&#x2F;Lambda&#x2F;EKS、存储体系（S3&#x2F;EBS&#x2F;EFS）、 网络架构（VPC&#x2F;Route53&#x2F;CloudFront）、数据库服务（RDS&#x2F;DynamoDB&#x2F;ElastiCache）</li><li>解决方案架构：架构设计原则、高性能架构、安全合规、成本优化</li></ul><p>最重要的几个产品讲解得非常细，搭配动手操作。对于云计算小白来说很不错，加深理解，巩固记忆。课程为英文，前期我挂了翻译，我后期基本就不需要翻译也能够看懂。</p><h1 id="学习路径"><a href="#学习路径" class="headerlink" title="学习路径"></a>学习路径</h1><h2 id="动手实践——理论与实操相结合"><a href="#动手实践——理论与实操相结合" class="headerlink" title="动手实践——理论与实操相结合"></a>动手实践——理论与实操相结合</h2><p>注册 AWS <strong>全球区</strong>账号，绑定信用卡即可激活一年的 Free Tier。免费额度覆盖大部分备考所需资源。</p><p>针对重要服务可以多练手，如EC2，S3，网络部分的服务。例如：</p><ul><li>启动EC2实例、配置安全组、SSH 连接、安装 web server；</li><li>S3： 上传下载对象、设置 bucket policy、版本控制等 ；</li><li>VPC + EC2 + S3 组合</li></ul><h2 id="高效笔记策略——记录与知识内化"><a href="#高效笔记策略——记录与知识内化" class="headerlink" title="高效笔记策略——记录与知识内化"></a>高效笔记策略——记录与知识内化</h2><p>入门阶段，你会被大量缩写词包围，各个云厂商的命名也不尽相同。例如，AWS 把云服务器叫作 EC2（Elastic Compute Cloud），阿里云则叫 ECS（Elastic Compute Service）。</p><p>网上中英文备考笔记俯拾皆是，官方白皮书更是全面，Stephane Maarek课程所提供的PPT干货满满。</p><p>但我仍强烈建议——<strong>用自己的话再写一遍</strong>。把别人的知识先嚼碎，再用自己的逻辑吐出来，记忆最深，理解也最透彻。</p><p>每个人的习惯不同，我习惯抓住几个点进行衍射：</p><h3 id="服务理解"><a href="#服务理解" class="headerlink" title="服务理解"></a>服务理解</h3><ul><li>是什么，有什么用？</li><li>在传统架构中对应什么服务？（这一步只是在初期帮助小白建立云原生的基础认知，后期应建立纯粹的云原生思维就不需要这一步骤了）</li><li>和别的服务如何组合，和其他服务的区别是什么？</li></ul><p>比如<strong>EC2</strong></p><ul><li>是什么：服务器，不过是在云上的服务器，你不需要再关注传统服务器的硬件等问题。</li><li>有什么用：跑网站、跑脚本、部署程序，物理服务器能干的它就能，物理服务器不能干的它也能，而且更加灵活。</li><li>之后再衍生到EC2的细节。</li></ul><h3 id="结构化记录"><a href="#结构化记录" class="headerlink" title="结构化记录"></a>结构化记录</h3><p>阶段性整理笔记，填充到学习大纲中。</p><h3 id="可视化输出"><a href="#可视化输出" class="headerlink" title="可视化输出"></a>可视化输出</h3><p>用一张图理清架构，用一张表分清差异</p><p>等你大致知道每个服务“干啥用”的时候，就要开始想它们<strong>怎么组合</strong>，以及两个相似产品的<strong>差异</strong>。 这里推荐draw.io绘制架构图，它提供了很多厂商的图标，如AWS、Cisco、Azure、Google等。</p><p>当你学习到网络这一部分时：</p><p>怎样做才能实现私有子网的 Internet 访问？</p><p>VPC和Internet之间相互通信可以用什么服务？</p><p>区域到区域、 可用区到可用区、私有到公有间的通信方式？</p><p>这时候，你可以通过架构图来帮助自己理解。</p><p><img src="/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/AWS-%E7%BD%91png.png" title="null"><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744653217-7fd7970f-3bd9-4e4c-bd8d-233e0d4504ba.png" title="我绘制的网络部分架构图"></p><p>那SG和NACL有什么区别，你可以通过表格来直观感受他们的相似和不同：</p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>特点 &#x2F; 注意事项</td><td>安全组 (SG)</td><td>网络访问控制列表 (NACL)</td></tr><tr><td>类型</td><td>instance级别防火墙</td><td>subnet级别防火墙</td></tr><tr><td>方向</td><td>可以配置入站和出站规则</td><td><strong>必须</strong>同时配置入站和出站规则</td></tr><tr><td>默认规则</td><td>拒绝所有流量</td><td>允许所有流量</td></tr><tr><td>有状态性</td><td>有状态，自动允许相关回复流量</td><td>无状态，入站和出站流量的状态是分开维护</td></tr><tr><td>数量限制</td><td>一个实例可以关联多个SG</td><td>一个子网只能关联一个NACL</td></tr><tr><td>功能</td><td>简单，易于使用</td><td>较为复杂，可用于更细粒度的控制</td></tr></tbody></table><h2 id="刷题"><a href="#刷题" class="headerlink" title="刷题"></a>刷题</h2><p><strong>懂产品 ≠ 会做题</strong>。传统选择题往往是选择正确答案，但AWS-SAA认证中，题干往往是：</p><ul><li>哪个服务在特定场景下最合适？</li><li>哪种方案最安全 &#x2F; 最省钱 &#x2F; 最少运维？</li></ul><p>许多考生常陷入一个认知误区：认为掌握AWS产品功能就等同于具备通过认证考试的能力。实际上，AWS认证考核的是一种更高阶的架构思维。考试设计的深层逻辑：</p><ul><li>场景化决策</li><li>可能没有绝对”正确”的答案，只有针对特定约束条件的”最优解”</li></ul><h3 id="刷题资源"><a href="#刷题资源" class="headerlink" title="刷题资源"></a>刷题资源</h3><p>主要使用 <strong>ExamTopics</strong>，官方目前题量超 1000 题。官方链接见文末[9]。</p><ul><li><strong>优点</strong>：<br>  题目质量接近考试真实难度，命中率高，国内大多数人选择该题库。我实际考试中碰到好几道原题。即使只刷了约 400 题精选题，收获也很大。国内也很容易找到整理好的中英双语版本，包括高频精选题、各种格式的 PDF 或表格，获取成本不高。</li><li><strong>缺点</strong>：<br>  个别题目存在答案争议，站内讨论和 AI 解读也无法统一。好在这类题占比极低，影响不大。</li></ul><p><strong>其他来源</strong><br>Udemy 的Practice Exams ：难度普遍高于真题，我评估后没有采用；</p><p>Whizlabs &#x2F; Tutorial Dojo（TD）： 解释详细，命中率略低于 ExamTopics ；</p><p>Ping-T：日语；</p><h3 id="刷题策略：高效规划你的学习路径"><a href="#刷题策略：高效规划你的学习路径" class="headerlink" title="刷题策略：高效规划你的学习路径"></a>刷题策略：高效规划你的学习路径</h3><p>个人刷题方法：每天 50 题左右，不求多但求精。做完一定会提炼每题的关键考点，错题或我觉得有意义的题进行归档，标注错因与正确思路；把相关知识点再复习一遍。我选择的是最适合自己的方式，也有很多人选择背题备考，速度更快。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1753077463133-334e4d8b-3d34-4e65-89f7-106b9cc09867.png" title="当时的做题记录"></p><h3 id="刷题精髓：掌握这些技巧让效率倍增"><a href="#刷题精髓：掌握这些技巧让效率倍增" class="headerlink" title="刷题精髓：掌握这些技巧让效率倍增"></a>刷题精髓：掌握这些技巧让效率倍增</h3><p><strong>使用 AI 辅助学习：</strong><br>当你学完课程开始做题，最开始可能完全看不懂题干。不用担心，这很正常。此时你可以借助AI，让它向你解释。你需要10-20题的适应期来理解出题逻辑。</p><p><strong>适当总结记忆：</strong></p><ul><li><p>EBS 加密 → 想到 <strong>KMS</strong></p></li><li><p>移动&#x2F;网络应用程序身份验证 → 想到 <strong>Cognito</strong> 和 <strong>MFA</strong></p></li><li><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1753112096433-c0311260-b1ca-4687-9dfb-1df87d8f04f0.png" title="不同服务的延迟时间"></p></li></ul><p><strong>关键词识别技巧：</strong><br>当题目中出现 <strong>“细粒度”</strong> 时，要特别关注：</p><ul><li>是否仅授予特定实体（用户、角色、服务）<strong>最小必要权限</strong></li><li>是否限定权限只作用于<strong>特定资源</strong>，而不是整块服务或整个 bucket</li></ul><h3 id="实例解析：手把手教你做题"><a href="#实例解析：手把手教你做题" class="headerlink" title="实例解析：手把手教你做题"></a>实例解析：手把手教你做题</h3><p>一家公司使用在 Amazon EC2 实例上运行的 RESTful Web 服务应用程序从数千个远程设备收集数据。 EC2 实例接收原始数据，转换原始数据，并将所有数据存储在 Amazon S3存储桶中。远程设备的数量很快将增加到数百万。该公司需要一个<strong>高度可扩展</strong>的解决方案，<strong>最大限度地减少运维开销</strong>。</p><p>解决方案架构师应该采取哪些步骤<strong>组合</strong>来满足这些要求？ （选择两个。）</p><p>A. 使用 AWS Glue 处理 Amazon S3 中的原始数据。</p><p>B. 使用 Amazon Route 53 将流量路由到不同的 EC2 实例。</p><p>C. 添加更多 EC2 实例以适应不断增加的传入数据量。</p><p>D. 将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。</p><p>E. 使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流。配置 Amazon Kinesis Data Firehose 以使用数据流作为源将数据传输到 Amazon S3</p><p>简单来说就是有家公司将 Web 服务部署在 EC2 （云服务器）上，它会接收大量数据，然后做些处理，最后把结果存到 S3（一个对象存储服务），现在数据开始变多。</p><p>等你开始学习课程，你一定会捕捉到题干中很关键的两点：</p><ul><li><strong>高度可扩展， highly scalable,：需要能自动扩容的架构</strong></li><li><strong>减少运维开销：优先选择Serverless（无服务器）方案</strong></li></ul><p>目前业务架构：EC2 接收数据，EC2 处理数据，EC2 存入 S3</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744723175-04471ffc-e54e-490b-a6f1-3a1c98e45993.png" title="公司当前的业务架构"></p><p>接着我们了解一下选项中的服务：</p><ul><li>AWS Glue ：集成、转换和加载数据的服务。scalable，severless</li><li>Amazon Route 53：DNS 服务，用来解析域名</li><li>Amazon SQS：消息队列服务，缓冲流量、解耦系统。 scalable，severless</li><li>Amazon API Gateway：并将不同的后端服务整合到一个统一的接口中。自动扩容能力，无需关心并发数severless</li><li>Amazon Kinesis：<strong>完全托管</strong>的流数据处理服务。 scalable，severless</li></ul><p>这时候我们需要考虑，如何高效接收海量数据，如何处理这些数据。</p><ul><li><p>B选项：使用 Amazon Route 53 将流量路由到不同的 EC2 实例。</p></li><li><p>Amazon Route 53是 DNS 路由服务，不能直接处理请求或做负载均衡</p></li><li><p>C选项： 添加更多 EC2 实例以适应不断增加的传入数据量。</p></li><li><p>可扩展是可扩展，但搭 Auto Scaling之后，管理大量 EC2 实例会带来高昂的运维成本</p></li><li><p>D选项：将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。</p></li><li><p>SQS虽然解耦了流量，但仍然要运维 EC2实例</p></li></ul><p>现在我们来看一下选择AE之后，业务架构变成下图：</p><p><img src="/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/question.drawio.png" title="null"><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744740911-0f5b4518-68d2-4203-ba5e-2856a6dd92c6.png" title="AE选项组合后的业务架构"></p><p>这时候，API Gateway 作为流量入口，<strong>动态应对高并发</strong>；</p><p>Kinesis Data Stream可<strong>动态扩展</strong>应对激增的请求量；</p><p>Firehose 从数据流中读取数据，然后写入 S3，<strong>无需人工干预，全自动交付</strong>；</p><p>S3存储原始数据，AWS Glue处理数据，<strong>完全托管无需运维</strong>。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>以上内容都是我的个人经验分享，不具备权威性，也可能因时间推移而有所滞后，仅供参考。</p><p>最后私心放上Stephane Maarek的几句话：</p><p>当开始学习并使用云服务时，你会遇到一些困难，你会尖叫：</p><p>Nothing is working - “aaaahhhhhh”</p><p>Don’t panic.</p><p>If you still don’t understand it, no worries, this is not a blocker for the course.</p><p>Keep on going, and come back to this concept towards the end.</p><p>这不仅是我入门云原生的起点，更让我切实感受到学习的快乐、魅力，还有一种近乎狂喜的兴奋。希望你也能够获得！</p><p>Happy learning!</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p>[1]AWS官网</p><p>aws.amazon.com</p><p>[2]AWS的认证信息</p><p><a href="https://aws.amazon.com/cn/certification/?nc2=h_ql_le_tc_c&ams%23interactive-card-vertical%23pattern-data.filter=%257B%2522filters%2522%253A%255B%255D%257D">https://aws.amazon.com/cn/certification/?nc2=h_ql_le_tc_c&amp;ams%23interactive-card-vertical%23pattern-data.filter=%257B%2522filters%2522%253A%255B%255D%257D</a></p><p>[3]AWS认证常见问题（包括重考政策，考试更新频率等）</p><p><a href="https://aws.amazon.com/cn/certification/faqs/">https://aws.amazon.com/cn/certification/faqs/</a></p><p>[4]考前、考中和考后的流程与要求</p><p><a href="https://aws.amazon.com/cn/certification/policies/">https://aws.amazon.com/cn/certification/policies/</a></p><p>[5]AWS-SAA的报考链接</p><p><a href="https://aws.amazon.com/cn/certification/certified-solutions-architect-associate/">https://aws.amazon.com/cn/certification/certified-solutions-architect-associate/</a></p><p>[6]AWS白皮书文档</p><p><a href="https://docs.aws.amazon.com/zh_cn/">https://docs.aws.amazon.com/zh_cn/</a></p><p>[7]官方提供的大纲（链接可直接下载PDF）</p><p><a href="https://d1.awsstatic.com/zh_CN/training-and-certification/docs-sa-assoc/">https://d1.awsstatic.com/zh_CN/training-and-certification/docs-sa-assoc/</a></p><p>[8]demy平台Stephane Maarek的《Ultimate AWS Certified Solutions Architect Associate》课程链接</p><p><a href="https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03/?couponCode=KEEPLEARNING">https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03/?couponCode=KEEPLEARNING</a></p><p>[9]examtopics链接</p><p><a href="https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/">https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/</a></p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8S-day1-初始化安装k8s集群的环境</title>
      <link href="/2025/07/15/K8S-day1-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E7%9A%84%E7%8E%AF%E5%A2%83/"/>
      <url>/2025/07/15/K8S-day1-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E7%9A%84%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="初始化安装k8s集群的环境"><a href="#初始化安装k8s集群的环境" class="headerlink" title="初始化安装k8s集群的环境"></a>初始化安装k8s集群的环境</h1><h2 id="环境与注意事项"><a href="#环境与注意事项" class="headerlink" title="环境与注意事项"></a>环境与注意事项</h2><table><thead><tr><th>主机名</th><th>ip地址</th></tr></thead><tbody><tr><td>master</td><td>172.20.196.17</td></tr><tr><td>node1</td><td>172.20.196.18</td></tr><tr><td>node2</td><td>172.20.196.19</td></tr></tbody></table><ul><li>我用的是云服务器，故一部分操作不需要做。<br><img src="/images/ecs.png" alt="EC2"></li><li>操作过程可以通过ansible减少重复操作。</li><li>在每台机器安装基础软件包</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y device-mapper-persistent-data lvm2 wget net-tools nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel  python-devel epel-release openssh-server socat  ipvsadm conntrack telnet ipvsadm</span><br></pre></td></tr></table></figure><h2 id="1-配置静态ip地址"><a href="#1-配置静态ip地址" class="headerlink" title="1.  配置静态ip地址"></a>1.  配置静态ip地址</h2><p>  修改配置文件后重启网络服务</p><h2 id="2-修改主机名"><a href="#2-修改主机名" class="headerlink" title="2. 修改主机名"></a>2. 修改主机名</h2><p>分别修改三台主机名称</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname master &amp;&amp; bash </span><br></pre></td></tr></table></figure><h2 id="3-配置hosts文件"><a href="#3-配置hosts文件" class="headerlink" title="3. 配置hosts文件"></a>3. 配置hosts文件</h2><p><strong>配置主机hosts文件，相互之间通过主机名互相访问</strong><br>分别修改每台机器的&#x2F;etc&#x2F;hosts文件增加如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.20.196.17 master</span><br><span class="line">172.20.196.18 node1</span><br><span class="line">172.20.196.19 node2</span><br></pre></td></tr></table></figure><h2 id="4-免密登录"><a href="#4-免密登录" class="headerlink" title="4. 免密登录"></a>4. 免密登录</h2><p><strong>方便相互之前传文件</strong><br>生成密钥</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">一路回车</span><br></pre></td></tr></table></figure><p>传输公钥（master传给node-1，node-2，other。依次传给初自己外的机器）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id node1</span><br></pre></td></tr></table></figure><p>测试登录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# ssh node1</span><br><span class="line">Last login: Tue Jul 15 16:58:01 2025 from 120.238.191.115</span><br><span class="line"></span><br><span class="line">Welcome to Alibaba Cloud Elastic Compute Service !</span><br></pre></td></tr></table></figure><h2 id="5-关闭selinux"><a href="#5-关闭selinux" class="headerlink" title="5. 关闭selinux"></a>5. 关闭selinux</h2><p><strong>为什么要关闭selinux？</strong><br><strong>SELinux 是 Linux 系统的一种安全机制，可以限制系统资源（如文件、网络等）的访问，提高系统的安全性。在 Kubernetes 运行过程中，需要访问系统资源，但 SELinux 可能会限制访问，从而影响 Kubernetes 的运行。因此，在安装 Kubernetes 时，需要关闭 SELinux，以避免它对 Kubernetes 的影响。</strong></p><p>修改&#x2F;etc&#x2F;selinux&#x2F;config</p><h2 id="6-关闭swap分区"><a href="#6-关闭swap分区" class="headerlink" title="6. 关闭swap分区"></a>6. 关闭swap分区</h2><p>**Swap交换分区是一种在计算机中使用的虚拟内存技术。当物理内存不足以容纳当前运行的程序时，操作系统将会把一部分内存空间暂时转移到硬盘上，以便为当前程序提供运行所需的内存空间。这个过程就称为交换。**<strong>交换分区（Swap Partition）就是硬盘上专门预留给操作系统进行交换的一块空间。</strong></p><p><strong>交换分区的使用可以有效避免程序因为内存不足而崩溃或运行缓慢的问题，但是硬盘的读写速度比内存要慢得多，因此交换分区的使用会对系统的性能产生一定的影响。</strong></p><p><strong>在 Kubernetes 运行过程中，需要频繁地使用内存和磁盘等系统资源。如果使用了交换分区，会导致 Kubernetes 的运行速度变慢，从而影响整个集群的性能。因此，在安装 Kubernetes 时，通常会建议关闭交换分区。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# swapoff -a</span><br><span class="line"></span><br><span class="line">#永久关闭：注释swap挂载，给swap这行开头加注释</span><br><span class="line">[root@master ~]# vim /etc/fstab </span><br><span class="line">#/dev/mapper/centos-swap swap      swap    defaults        0 0</span><br></pre></td></tr></table></figure><h2 id="7-修改机器内核参数"><a href="#7-修改机器内核参数" class="headerlink" title="7. 修改机器内核参数"></a>7. 修改机器内核参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">#modprobe br_netfilter 的作用是将 br_netfilter 模块添加到 Linux 内核中。这个模块是 Linux 网桥的核心模块，它提供了网络包转发和过滤的功能</span><br><span class="line"></span><br><span class="line">[root@master ~]# vim /etc/sysctl.d/k8s.conf </span><br><span class="line">输入如下内容：</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1    #启用ipv6数据包的过滤和处理</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1   #启用ipv4数据包的过滤和处理</span><br><span class="line">net.ipv4.ip_forward = 1   #启用了  IP 转发功能</span><br><span class="line"></span><br><span class="line">[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf</span><br></pre></td></tr></table></figure><h2 id="8-关闭防火墙"><a href="#8-关闭防火墙" class="headerlink" title="8. 关闭防火墙"></a>8. 关闭防火墙</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# systemctl stop firewalld</span><br><span class="line">[root@master ~]# systemctl disable firewalld</span><br></pre></td></tr></table></figure><h2 id="9-配置repo源"><a href="#9-配置repo源" class="headerlink" title="9. 配置repo源"></a>9. 配置repo源</h2><h2 id="10-时间同步"><a href="#10-时间同步" class="headerlink" title="10. 时间同步"></a>10. 时间同步</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#安装ntpdate命令</span><br><span class="line">[root@master ~]# yum install ntpdate -y</span><br><span class="line">#跟网络时间做同步</span><br><span class="line">[root@master ~]# ntpdate cn.pool.ntp.org</span><br><span class="line">#把时间同步做成计划任务</span><br><span class="line">[root@master ~]# crontab -e</span><br><span class="line">* *  * * * /usr/sbin/ntpdate   cn.pool.ntp.org</span><br><span class="line">[root@master ~]# systemctl restart crond</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> k8s </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubenates </tag>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSL-Windows Subsystem for Linux</title>
      <link href="/2025/05/06/WSL/"/>
      <url>/2025/05/06/WSL/</url>
      
        <content type="html"><![CDATA[<h1 id="WSL-Windows-Subsystem-for-Linux"><a href="#WSL-Windows-Subsystem-for-Linux" class="headerlink" title="WSL-Windows Subsystem for Linux"></a>WSL-Windows Subsystem for Linux</h1><h4 id="wsl是什么？"><a href="#wsl是什么？" class="headerlink" title="wsl是什么？"></a>wsl是什么？</h4><p>适用于Windows的Linux子系统，可以在windows下运行linux操作系统。</p><ol><li>轻量：不像虚拟机那样吃内存，不跑完整 Linux 系统，运行速度快，资源占用少</li><li>无缝：能和 Windows 系统共享文件、剪贴板、网络</li><li>无需虚拟机：不需要装 VMware、VirtualBox，也不用重启，直接在 Win 下跑 Linux</li><li>开发友好：支持绝大多数 Linux 工具链（如 apt、git、docker、conda 等），尤其适合开发者</li></ol><h4 id="wsl用来干什么"><a href="#wsl用来干什么" class="headerlink" title="wsl用来干什么"></a>wsl用来干什么</h4><h4 id="安装教程"><a href="#安装教程" class="headerlink" title="安装教程"></a>安装教程</h4><p><a href="https://blog.csdn.net/u011119817/article/details/130745551?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522ae299346a694700a68e917c31739a4f5%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=ae299346a694700a68e917c31739a4f5&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-130745551-null-null.142%5Ev102%5Epc_search_result_base3&utm_term=wsl%E5%AE%89%E8%A3%85&spm=1018.2226.3001.4187">windows11 安装WSL2全流程_wsl2安装-CSDN博客</a></p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>a glass of Baileys</title>
      <link href="/2025/05/06/a%20glass%20of%20Baileys/"/>
      <url>/2025/05/06/a%20glass%20of%20Baileys/</url>
      
        <content type="html"><![CDATA[<p>The Labor Day holiday ended.<br>I was on a delayed flight back to Guangzhou when I saw the news—Joan had passed away.<br>She chose to leave before summer even began.</p><p>The meaninglessness of work, of career, of life itself—and the grief of her death—<strong>haunt me.</strong></p><p>A line from a movie has been echoing in my head:</p><blockquote><p><em>Is life always this hard, or is it just when you’re a kid?</em><br><em>Always like this.</em></p></blockquote><p>I rewrote it into something that belongs to me now:</p><blockquote><p><em>Is work always this hard, or is it just because I’m in this place?</em></p></blockquote><p>I’ve been enduring.<br>Enduring the performance of working life.<br>Enduring the unspoken rule that <em>if you’re not exhausted, you’re not working hard enough.</em><br>I’m anxious. I’m overwhelmed. I’m becoming unrecognizable to myself.</p><p>And still, people keep telling me,</p><blockquote><p><em>“You’re already so lucky.”</em></p></blockquote><p>Just like the comments under Joan’s old videos:</p><blockquote><p><em>“You’re so beautiful, so talented, so brilliant.”</em></p></blockquote><p>But none of those words can save you.<br>They can’t protect you from the quiet truth that <strong>some of us simply can’t live in blurred, diluted versions of life.</strong><br>That clarity—too much of it—hurts.</p><p>Sometimes I wonder:<br>Is it naïve to still want growth, meaning, and selfhood through work?</p><p>I don’t know.</p><p>But I do know this:</p><p>This job, this system, this culture—<br>is not where my soul belongs.</p><p>Summer has come, Joan<br>And I want to drink a glass of Baileys </p>]]></content>
      
      
      <categories>
          
          <category> flee as a bird to your mountain </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git</title>
      <link href="/2025/02/08/git-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"/>
      <url>/2025/02/08/git-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Git-是分布式版本控制系统。"><a href="#Git-是分布式版本控制系统。" class="headerlink" title="Git 是分布式版本控制系统。"></a>Git 是分布式版本控制系统。</h1><p><img src="/images/git.png" alt="Untitled"></p><h1 id="版本控制-Revision-control"><a href="#版本控制-Revision-control" class="headerlink" title="版本控制-Revision control"></a>版本控制-Revision control</h1><p>在开发的过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份以便恢复以前的版本的软件工程技术。</p><p>主流的版本控制器有如下这些：</p><ul><li><strong>Git</strong></li><li><strong>SVN</strong>（Subversion）</li><li><strong>CVS</strong>（Concurrent Versions System）</li><li><strong>VSS</strong>（Micorosoft Visual SourceSafe）</li><li><strong>TFS</strong>（Team Foundation Server）</li><li>Visual Studio Online</li></ul><h2 id="版本控制分类"><a href="#版本控制分类" class="headerlink" title="版本控制分类"></a>版本控制分类</h2><h3 id="1、本地版本控制"><a href="#1、本地版本控制" class="headerlink" title="1、本地版本控制"></a><strong>1、本地版本控制</strong></h3><p>记录文件每次的更新，可以对每个版本做一个快照，或是记录补丁文件，适合个人用，如RCS。</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0Dg3fHrbPqbNEOMO9GTjFhVaukMZWx54icS7eS2x8A7BEu0VB9ibwEhzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0Dg3fHrbPqbNEOMO9GTjFhVaukMZWx54icS7eS2x8A7BEu0VB9ibwEhzQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><h3 id="2、集中版本控制-SVN"><a href="#2、集中版本控制-SVN" class="headerlink" title="2、集中版本控制  SVN"></a><strong>2、集中版本控制  SVN</strong></h3><p>所有的版本数据都保存在服务器上，协同开发者从服务器上同步更新或上传自己的修改</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p00V4uLaibxtZI9RLpq7tkSdlWiaF92AVeZ0ib9DicqBkS2poo5u8sEU2mCQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p00V4uLaibxtZI9RLpq7tkSdlWiaF92AVeZ0ib9DicqBkS2poo5u8sEU2mCQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><p>所有的版本数据都存在服务器上，用户的本地只有自己以前所同步的版本，如果不连网的话，用户就看不到历史版本，也无法切换版本验证问题，或在不同分支工作。</p><p>而且，所有数据都保存在单一的服务器上，有很大的风险这个服务器会损坏，这样就会丢失所有的数据，当然可以定期备份。代表产品：SVN、CVS、VSS</p><h3 id="3、分布式版本控制-Git"><a href="#3、分布式版本控制-Git" class="headerlink" title="3、分布式版本控制 Git"></a><strong>3、分布式版本控制 Git</strong></h3><h3 id="服务器断网也可以开发，且每个客户端都保存着完整代码"><a href="#服务器断网也可以开发，且每个客户端都保存着完整代码" class="headerlink" title="服务器断网也可以开发，且每个客户端都保存着完整代码"></a>服务器断网也可以开发，且每个客户端都保存着完整代码</h3><p>每个人都拥有全部的代码！安全隐患！</p><p>所有版本信息仓库全部同步到本地的每个用户，这样就可以在本地查看所有版本历史，可以离线在本地提交，只需在连网时push到相应的服务器或其他用户那里。由于每个用户那里保存的都是所有的版本数据，只要有一个用户的设备没有问题就可以恢复所有的数据，但这增加了本地存储空间的占用。</p><p>不会因为服务器损坏或者网络问题，造成不能工作的情况！</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0ev8Q7qXjsTfeSwFexdA4tGjFAiaVEKQzAHdGcINXILKflI2cfk9BiawQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0ev8Q7qXjsTfeSwFexdA4tGjFAiaVEKQzAHdGcINXILKflI2cfk9BiawQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h1><h2 id="三个区域"><a href="#三个区域" class="headerlink" title="三个区域"></a>三个区域</h2><ul><li><p><strong>工作区（Working Directory或Workspace）</strong>：看到的目录，平时存放项目代码的地方</p></li><li><p><strong>暂存区（Stage&#x2F;Index）</strong>：英文名stage或者index，用于准备提交的文件区域。</p><ul><li>一般存放在**<code>.git</code>**目录下index文件中，所以也称为索引index</li></ul></li><li><p><strong>仓库（Repository或Git Directory）</strong>：用于存储项目的所有文件和历史记录。</p><ul><li>通常存储在项目根目录的 <strong><code>.git</code></strong> 子目录中。</li><li>其中**<code>HEAD</code>**指向最新放入仓库的版本</li></ul><p>  <img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/627d280e-15d4-47b3-997b-8a0ec484a12d/Untitled.png" alt="Untitled"></p></li></ul><p>**远程的git仓库(Remote Directory)：**存储在远程服务器上的仓库副本，用于多人协作和备份。你可以使用 <strong><code>git push</code></strong> 命令将本地仓库的内容推送到远程仓库，也可以使用 <strong><code>git pull</code></strong> 命令从远程仓库拉取最新的更改。</p><h2 id="git-工作流程"><a href="#git-工作流程" class="headerlink" title="git 工作流程"></a>git <strong>工作流程</strong></h2><ul><li><p><strong>工作区 -&gt; 暂存区 -&gt; 本地仓库 -&gt; 远程仓库</strong></p></li><li><p>工作区：代码存放的位置。在工作区可以修改代码，且没有历史记录；</p></li><li><p>暂存区：将工作区的代码 添加(<code>git add</code>) 到暂存区，也可以修改代码并且没有历史记录；</p></li><li><p>本地库：将暂存区的代码提交 (<code>git commit</code>) 到本地库，就会生成历史版本。在本地库的版本不能修改。若发现代码不尽人意，只能在工作区修改后再次提交，此时本地库同时存在这两个版本。例如，先提交了 v1 版本，发现不好，则只能在 v1 版本基础上修改然后提交为 v2；</p></li><li><p>代码托管中心（远程库）：将本地库的代码推送 (<code>git push</code>) 至远程库。</p><p>  <img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/108604d8-e083-4eee-87e5-aae75338e618/Untitled.png" alt="Untitled"></p></li></ul><p>文件在这四个区域之间的转换关系如下：</p><h2 id="git-文件状态"><a href="#git-文件状态" class="headerlink" title="git 文件状态"></a>git 文件状态</h2><p><strong>查看工作区的文件状态</strong><code>git status</code></p><ol><li><strong>未追踪（Untracked）</strong>：<ul><li>这是指在Git仓库中没有记录的文件。这些文件存在于工作区中，但尚未被添加到Git的版本控制中。</li></ul></li><li><strong>已暂存（Staged）</strong>：<ul><li>这是指将工作区中的文件添加到了暂存区（也叫索引）中，表示你打算在下一次提交中包括这些更改。</li></ul></li><li><strong>已修改（Modified）</strong>：<ul><li>这是指已经修改了某个文件，但尚未将这些更改添加到暂存区。</li></ul></li><li><strong>已提交（Committed）</strong>：<ul><li>这是指已经将文件的更改保存到了本地版本库中。</li></ul></li></ol><h2 id="git分支-Branch"><a href="#git分支-Branch" class="headerlink" title="git分支-Branch"></a>git<strong>分支-Branch</strong></h2><p>分支（Branch）是用来开发新功能或修复错误的独立工作流。它允许你将工作从主线（通常是**<code>master</code>**分支）中分离出来，以便不会影响到主线上的其他开发工作。</p><p>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作</p><p>工作一般情况下在新建的dev分支上工作，dev分支代码稳定后可以合并到主分支master上来。</p><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/38ae47d3-468a-4d9a-9bda-71a05d71ccfa/Untitled.png" alt="Untitled"></p><p>多个分支：用户分支，测试分支，开发分支…… 不同分支互不干扰，可以同时推进，完成开发后就可以进行分支合并（在用户看来就是更新）。分支底层就是指针的引用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出所有本地分支</span></span><br><span class="line">git branch</span><br><span class="line"><span class="comment">#这会列出所有可用的分支，并用一个**星号标记当前所在的分支**。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有远程分支</span></span><br><span class="line">git branch -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支</span></span><br><span class="line">git branch [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，并切换到该分支</span></span><br><span class="line">git checkout -b [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment">#切换分支</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并指定分支到当前分支</span></span><br><span class="line">$ git merge [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将dev分支合并到master分支</span></span><br><span class="line">git merge dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除分支</span></span><br><span class="line">$ git branch -d [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">$ git push origin --delete [branch-name]</span><br><span class="line">$ git branch -dr [remote/branch]</span><br></pre></td></tr></table></figure><h2 id="解决冲突"><a href="#解决冲突" class="headerlink" title="解决冲突"></a><strong>解决冲突</strong></h2><ul><li>在合并分支时，如果Git无法自动合并，会产生冲突。需要手动解决冲突后再提交。</li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="创建仓库"><a href="#创建仓库" class="headerlink" title="创建仓库"></a>创建仓库</h3><ol><li><p>本地仓库搭建</p></li><li><p>克隆远程仓库：克隆远程目录，由于是将远程服务器上的仓库完全镜像一份至本地</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1.初始化</span><br><span class="line"></span><br><span class="line">git init <span class="comment"># 初始化仓库</span></span><br><span class="line">git <span class="built_in">clone</span> <span class="comment"># 拷贝一份远程仓库，也就是下载一个项目</span></span><br><span class="line"></span><br><span class="line">git init --bare shell.git</span><br><span class="line">git init 是 Git 的一个命令，用于初始化一个新的 Git 仓库。</span><br><span class="line">--bare 是一个选项，它告诉 Git 创建一个裸仓库</span><br><span class="line">  也就是不包含工作区（Working Directory）的仓库。**裸仓库只包含版本历史记录。**</span><br><span class="line">shell.git 是你为新仓库选择的名称，实际上就是仓库的目录名。</span><br><span class="line"></span><br><span class="line">2.克隆</span><br><span class="line">git <span class="built_in">clone</span> &lt;https://github.com/repository.git&gt;</span><br><span class="line"><span class="comment">#URL克隆</span></span><br><span class="line">git <span class="built_in">clone</span> git@github.com:username/repository.git</span><br><span class="line"><span class="comment">#SSH协议来进行克隆</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="提交与修改"><a href="#提交与修改" class="headerlink" title="提交与修改"></a>提交与修改</h3><p>在工作区commit</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">git add <span class="comment"># 添加文件到暂存区</span></span><br><span class="line">git status <span class="comment"># 查看仓库当前的状态，显示有变更的文件</span></span><br><span class="line"></span><br><span class="line">git diff <span class="comment"># 比较文件的不同，即暂存区和工作区的差异</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">&quot;commit message&quot;</span> <span class="comment"># 提交暂存区到本地仓库</span></span><br><span class="line"></span><br><span class="line">git reset <span class="comment"># 回退版本</span></span><br><span class="line">git <span class="built_in">rm</span> <span class="comment"># 删除工作区文件</span></span><br><span class="line">git <span class="built_in">mv</span> <span class="comment"># 移动或重命名工作区文件</span></span><br></pre></td></tr></table></figure><p>提交日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> <span class="comment"># 查看历史提交记录</span></span><br><span class="line">git blame&lt;file&gt; <span class="comment"># 以列表形式查看指定文件的历史修改记录</span></span><br><span class="line">远程操作</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux 内核--Cgroup与namespace</title>
      <link href="/2025/02/08/Linux%20%E5%86%85%E6%A0%B8--Cgroup%E4%B8%8Enamespace/"/>
      <url>/2025/02/08/Linux%20%E5%86%85%E6%A0%B8--Cgroup%E4%B8%8Enamespace/</url>
      
        <content type="html"><![CDATA[<h2 id="容器-cgroup-namespace-rootfs-容器引擎"><a href="#容器-cgroup-namespace-rootfs-容器引擎" class="headerlink" title="容器 &#x3D; cgroup + namespace + rootfs + 容器引擎"></a>容器 &#x3D; cgroup + namespace + rootfs + 容器引擎</h2><p>容器的核心技术是 <strong>Cgroup</strong> + <strong>Namespace</strong></p><ul><li>​Cgroup： 资源控制 </li><li>​namespace： 访问隔离</li><li>​rootfs：文件系统隔离。镜像的本质就是一个rootfs文件</li><li>​容器引擎：生命周期控制</li></ul><p><strong>cgroup（控制组）和namespace（命名空间）</strong> 是 Linux 内核中的两个核心技术，主要用于实现<strong>资源管理</strong>和<strong>环境隔离</strong>，它们是容器技术（如 Docker）的底层基础。</p><hr><h3 id="cgroup（控制组）："><a href="#cgroup（控制组）：" class="headerlink" title="cgroup（控制组）："></a><strong>cgroup（控制组）：</strong></h3><p><strong>核心作用</strong>：<strong>限制、分配和监控进程的资源使用</strong>，比如 CPU、内存、磁盘 I&#x2F;O 等。</p><ul><li><strong>作用：</strong> 通过cgroup，系统管理员可以为一组进程分配资源，并限制它们对系统资源的使用。这对于实现资源隔离和管理是很有用的，特别是在容器化环境中，可以确保容器之间不会相互干扰，同时允许对资源进行有效的分配和控制。</li></ul><h3 id="namespace（命名空间）："><a href="#namespace（命名空间）：" class="headerlink" title="namespace（命名空间）："></a><strong>namespace（命名空间）：</strong></h3><p>命名空间是 Linux 内核提供的一种隔离机制，用于<strong>隔离</strong>容器的进程和文件系统等。</p><ul><li><strong>作用：</strong> 命名空间提供了一种隔离的手段，使得进程可以在一个独立的环境中运行，与其他命名空间中的进程隔离开。常用的命名空间包括 PID（进程 ID）、NET（网络）、UTS（主机名和域名）、IPC（进程间通信）、MNT（挂载点）等。在容器技术中，命名空间是实现容器隔离的基础，使得容器内的进程和资源与主机及其他容器隔离开。</li></ul><hr><h3 id="cgroup-vs-namespace-的区别"><a href="#cgroup-vs-namespace-的区别" class="headerlink" title="cgroup vs namespace 的区别"></a>cgroup vs namespace 的区别</h3><table><thead><tr><th><strong>特性</strong></th><th><strong>cgroup</strong></th><th><strong>namespace</strong></th></tr></thead><tbody><tr><td><strong>核心目标</strong></td><td>限制资源用量（如 CPU、内存）</td><td>隔离资源视图（如进程、网络）</td></tr><tr><td><strong>关注点</strong></td><td><strong>资源控制</strong></td><td><strong>环境隔离</strong></td></tr><tr><td><strong>类比</strong></td><td>给进程分配“资源配额”</td><td>给进程创造一个“独立房间”</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> linux </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SElinux-安全上下文</title>
      <link href="/2025/01/21/SElinux-%E5%AE%89%E5%85%A8%E4%B8%8A%E4%B8%8B%E6%96%87/"/>
      <url>/2025/01/21/SElinux-%E5%AE%89%E5%85%A8%E4%B8%8A%E4%B8%8B%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h2 id="SElinux-Security-Enhanced-Linux-安全增强型-linux"><a href="#SElinux-Security-Enhanced-Linux-安全增强型-linux" class="headerlink" title="SElinux-Security-Enhanced Linux 安全增强型 linux"></a>SElinux-Security-Enhanced Linux 安全增强型 linux</h2><p>Linux系统安全的强制访问控制体系</p><h3 id="三种配置模式"><a href="#三种配置模式" class="headerlink" title="三种配置模式"></a>三种配置模式</h3><ol><li>selinux的配置文件：&#x2F;etc&#x2F;sysconfig&#x2F;selinux</li></ol><table><thead><tr><th>状态</th><th>含义</th></tr></thead><tbody><tr><td>enforcing</td><td>级别为强制</td></tr><tr><td>permissive</td><td>级别为警告</td></tr><tr><td>disable</td><td>关闭</td></tr></tbody></table><ol start="2"><li>模式管理</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看当前工作模式</span></span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line"></span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Enforcing</span><br><span class="line"><span class="comment"># 临时关闭进入宽容模式</span></span><br><span class="line">[root@server ~]# setenforce  0  </span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Permissive</span><br><span class="line"> <span class="comment"># 临时开启</span></span><br><span class="line">[root@server ~]# setenforce  1 </span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Enforcing</span><br><span class="line"></span><br><span class="line"><span class="comment">#永久性关闭</span></span><br><span class="line">[root@server ~]# vim  /etc/selinux/config </span><br><span class="line">SELINUX=disabled    </span><br></pre></td></tr></table></figure><p><code>注意</code>：enforceing与permissive二者可以直接进行切换，但是关闭selinux（disabled）进行切换时要重启reboot</p><h3 id="安全上下文（security-context）"><a href="#安全上下文（security-context）" class="headerlink" title="安全上下文（security context）"></a><strong>安全上下文（security context）</strong></h3><ul><li>所有进程、文件和目录都有自己的安全上下文</li><li>进程是否能够访问文件或目录，就要其安全上下文是否匹配</li></ul><p><strong>安全上下文用冒号分为四个字段：Identify：role：type：</strong></p><ul><li>身份标识（Identify）：相当于账号方面的身份标识，主要有以下三种常见的类型：<ul><li>root：表示root的账号身份；</li><li>system_u：表示程序方面的标识，通常就是进程</li><li>unconfined_u：代表的是一般用户账号相关的身份。</li></ul></li><li>角色（role）：通过角色字段，可知道这个数据是属于程序、文件资源还是代表用户。一般角色有：<ul><li>object_r：代表的是文件或目录等文件资源；</li><li>system_r：代表的是进程。</li></ul></li><li><strong>类型（type）：</strong><ul><li>type：在文件资源上面称为类型。</li><li>domain：在主体程序中则称为域。domain需要与type搭配，则该程序才能够顺利读取文件资源。</li></ul></li><li>最后一个字段是和MLS和MCS相关的东西，代表灵敏度，一般用s0、s1、s2来命名，数字代表灵敏度的分级。数值越大、灵敏度越高。</li></ul><p><strong>查看安全上下文</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> -Z</span><br></pre></td></tr></table></figure><p><strong>chcon手动修改文件的SELinux类型</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chcon</span> [-R] [-t <span class="built_in">type</span>] [-u user] [-r role] 文件</span><br><span class="line"><span class="built_in">chcon</span> [-R] --reference=范例文件 文件</span><br><span class="line">选项：</span><br><span class="line">-R：连同该目录下的子目录也同时修改</span><br><span class="line">-t：后面接安全上下文的类型栏位，例如httpd_sys_content_t</span><br><span class="line">-u：后面接身份识别，例如system_u</span><br><span class="line">-r：后面接角色，例如 system_r</span><br><span class="line">-v：若有变化成功，请将变动的结果列出来</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>restorecon让文件恢复正确的SELinux类型</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">restorecon [-Rv] 文件目录</span><br><span class="line">选项：</span><br><span class="line">-R：连同子目录一起修改</span><br><span class="line">-v：将过程显示到屏幕</span><br></pre></td></tr></table></figure><p><strong>semanage默认目录的安全上下文查询与修改</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# yum -y install policycoreutils-python semanage</span><br><span class="line"></span><br><span class="line">semanage 选项 参数  文件</span><br><span class="line"></span><br><span class="line">选项：</span><br><span class="line">login</span><br><span class="line">user</span><br><span class="line">port</span><br><span class="line">interface</span><br><span class="line">fcontext  <span class="comment">#注意：fcontext查询默认安全上下文（重要）</span></span><br><span class="line">translation</span><br><span class="line">boolean</span><br><span class="line">参数：</span><br><span class="line"> -l :查询；</span><br><span class="line"> -a :添加</span><br><span class="line"> -m :修改</span><br><span class="line"> -d :删除</span><br><span class="line"> -t :类型</span><br><span class="line"> -r :角色</span><br><span class="line"> -s :用户</span><br><span class="line"> -f :文件</span><br><span class="line">文件：</span><br><span class="line">文件或目录</span><br><span class="line"></span><br><span class="line">semanage  fcontext  -l |  grep  文件名</span><br><span class="line">semanage  port  -l  |  grep  协议</span><br><span class="line">semanage port -a -t http_port_t  -p  tcp  7777 <span class="comment"># 添加新端口</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例1 查询一下/etc/  /etc/cron.d默认的SELinux类型是什么</span></span><br><span class="line">[root@chenshiren ~]# semanage  fcontext -l |grep -E <span class="string">&#x27;^/etc|^/etc/cron&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>实验1</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文件系统与磁盘管理</title>
      <link href="/2025/01/21/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"/>
      <url>/2025/01/21/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><strong>disk -&gt; partition -&gt; PV -&gt; VG -&gt; LV -&gt; fs</strong></p><p><strong>磁盘-&gt;分区-&gt;物理卷-&gt;卷组-&gt;逻辑卷-&gt;文件系统。</strong><br>![[&#x2F;images&#x2F;disk.drawio.png]]</p><h4 id="文件系统-File-System"><a href="#文件系统-File-System" class="headerlink" title="文件系统 File System"></a>文件系统 <strong>File System</strong></h4><ol><li>EXT4：EXT4是Linux默认文件系统</li><li>XFS</li><li><strong>SWAP</strong>：交换文件系统，相当于虚拟内存</li></ol><h4 id="df"><a href="#df" class="headerlink" title="df"></a>df</h4><p>列出文件系统的整体磁盘使用量</p><p>df -h</p><h4 id="du"><a href="#du" class="headerlink" title="du"></a>du</h4><p>检查磁盘空间使用量</p><h4 id="lsblk"><a href="#lsblk" class="headerlink" title="lsblk"></a>lsblk</h4><ul><li>列出块设备的信息，包括磁盘和分区。它以树状结构显示</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出当前系统所有磁盘与磁盘内的分区信息</span></span><br><span class="line">[root@master ~]# lsblk</span><br><span class="line">NAME              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                 8:0    0   20G  0 disk</span><br><span class="line">├─sda1              8:1    0    1G  0 part /boot</span><br><span class="line">└─sda2              8:2    0   19G  0 part</span><br><span class="line">  ├─centos-root   253:0    0   17G  0 lvm  /</span><br><span class="line">  └─centos-swap   253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">sdb                 8:16   0  100G  0 disk</span><br><span class="line">├─datavg-data1_lv 253:2    0   45G  0 lvm</span><br><span class="line">└─datavg-data2_lv 253:3    0  200M  0 lvm</span><br><span class="line">sr0                11:0    1  9.5G  0 rom</span><br><span class="line"></span><br><span class="line"><span class="comment">#sda1：sd代表SCSI磁盘，a代表第一块磁盘，1代表第一个分区</span></span><br><span class="line"><span class="comment">#sdb：sd代表SCSI磁盘，b代表第二块磁盘，1代表第一个分区</span></span><br><span class="line"><span class="comment">#解释：</span></span><br><span class="line">NAME <span class="comment">#设备名称</span></span><br><span class="line">MAJ:MIN <span class="comment">#主设备号:次设备号，内核通过主次设备号识别磁盘</span></span><br><span class="line">RM <span class="comment">#是否为可卸载设备，1可卸载，0不可卸载</span></span><br><span class="line">SIZE <span class="comment">#设备的容量大小</span></span><br><span class="line">RO <span class="comment">#表示设备是否为只读，0非只读设备，1只读设备</span></span><br><span class="line">TYPE <span class="comment">#表示设备类型（disk为磁盘，part为分区，lvm逻辑卷，rom只读）</span></span><br><span class="line">MOUNTPOINT <span class="comment">#设备挂载点（SWAP没有挂载点）</span></span><br><span class="line"></span><br><span class="line">lsblk -f <span class="comment">##列出所有磁盘分区内使用的文件系统类型</span></span><br></pre></td></tr></table></figure><h2 id="磁盘分区"><a href="#磁盘分区" class="headerlink" title="磁盘分区"></a>磁盘分区</h2><ul><li>**分区过程：**添加新硬盘–分区–格式化文件系统–挂载使用</li></ul><h3 id="1-fdisk-磁盘分区"><a href="#1-fdisk-磁盘分区" class="headerlink" title="1.fdisk-磁盘分区"></a>1.fdisk-磁盘分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br><span class="line">**m <span class="comment">#获取命令帮助 ※**</span></span><br><span class="line">**p <span class="comment">#显示磁盘分区表 ※**</span></span><br><span class="line">**n <span class="comment">#新增加一个分区 ※**</span></span><br><span class="line">q <span class="comment">#不保存分区退出 ※</span></span><br><span class="line">d <span class="comment">#删除一个分区 ※</span></span><br><span class="line">**w <span class="comment">#保存分区退出 ※  记得保存**   </span></span><br><span class="line">a <span class="comment">#设置可引导标记</span></span><br><span class="line">b <span class="comment">#编辑bsd磁盘标签</span></span><br><span class="line">c <span class="comment">#设置DOS操作系统兼容标记</span></span><br><span class="line">l <span class="comment">#显示已知的文件系统类型，82为swap交换分区，83为Linux分区</span></span><br><span class="line">o <span class="comment">#建立空白DOS分区表</span></span><br><span class="line">s <span class="comment">#新建空白SUN磁盘标签</span></span><br><span class="line">t <span class="comment">#改变分区的系统ID</span></span><br><span class="line">u <span class="comment">#改变显示记录单位</span></span><br><span class="line">v <span class="comment">#验证分区表</span></span><br><span class="line">x <span class="comment">#附加功能</span></span><br></pre></td></tr></table></figure><ul><li><p>示例</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# fdisk /dev/sdb   **#*对sdb进行分区***   </span><br><span class="line">Welcome to fdisk (util-linux 2.23.2).</span><br><span class="line"></span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, <span class="keyword">until</span> you decide to write them.</span><br><span class="line">Be careful before using the write <span class="built_in">command</span>.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n  **#增加分区**  </span><br><span class="line">Partition <span class="built_in">type</span>:</span><br><span class="line">   p   primary (2 primary, 0 extended, 2 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p):  <span class="comment">#**回车选择默认主分区**    </span></span><br><span class="line">Using default response p</span><br><span class="line">Partition number (2,4, default 2): 2   **#输入分区号为2**    </span><br><span class="line">First sector (4097-209715199, default 26624):  **#回车选择默认起始位置**   </span><br><span class="line">Using default value 26624</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (26624-209715199, default 209715199): 409600</span><br><span class="line"><span class="comment">#**输入磁柱结束位置**  </span></span><br><span class="line">Partition 2 of <span class="built_in">type</span> Linux and of size 187 MiB is <span class="built_in">set</span></span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): </span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0xbf03ef25</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048        4096        1024+  83  Linux</span><br><span class="line">/dev/sdb2           26624      409600      191488+  83  Linux</span><br><span class="line">/dev/sdb3            6144       24689        9273   83  Linux</span><br><span class="line"></span><br><span class="line">Partition table entries are not <span class="keyword">in</span> disk order</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w   **#保存分区并退出**    </span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br><span class="line">[root@master ~]# lsblk   **#查看磁盘信息，sdb分区2已经创建**    </span><br><span class="line">NAME              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                 8:0    0   20G  0 disk</span><br><span class="line">├─sda1              8:1    0    1G  0 part /boot</span><br><span class="line">└─sda2              8:2    0   19G  0 part</span><br><span class="line">  ├─centos-root   253:0    0   17G  0 lvm  /</span><br><span class="line">  └─centos-swap   253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">sdb                 8:16   0  100G  0 disk</span><br><span class="line">├─sdb1              8:17   0    1M  0 part</span><br><span class="line">├─sdb2              8:18   0  187M  0 part</span><br><span class="line">├─sdb3              8:19   0  9.1M  0 part</span><br><span class="line">├─datavg-data1_lv 253:2    0   45G  0 lvm</span><br><span class="line">└─datavg-data2_lv 253:3    0  200M  0 lvm</span><br><span class="line">sr0                11:0    1  9.5G  0 rom</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="2-mkxfs格式化分区为文件系统"><a href="#2-mkxfs格式化分区为文件系统" class="headerlink" title="2.mkxfs格式化分区为文件系统"></a>2.mkxfs<strong>格式化分区为文件系统</strong></h3><ul><li>mkfs命令用于在分区上建立文件系统</li><li>常用文件系统类型：ext4，xfs</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkfs -t 文件系统格式 /dev/sdb1</span><br><span class="line">mkfs.文件格式 /dev/sdb1  </span><br></pre></td></tr></table></figure><h3 id="3-mount挂载分区"><a href="#3-mount挂载分区" class="headerlink" title="3.mount挂载分区"></a>3.mount挂载分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建挂载点目录</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">mkdir</span> /mybak</span><br><span class="line"></span><br><span class="line"><span class="comment">#挂载文件系统</span></span><br><span class="line">[root@localhost ~]# mount /dev/sdb1 /mybak</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看正在使用中的分区信息</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">df</span> -Th</span><br></pre></td></tr></table></figure><h3 id="4-永久挂载"><a href="#4-永久挂载" class="headerlink" title="4.永久挂载"></a>4.永久挂载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">5. **永久挂载：** 更新 /etc/fstab 文件，以确保在系统重新启动时分区会自动挂载</span><br><span class="line"></span><br><span class="line"><span class="comment">#开机自动挂载</span></span><br><span class="line">[root@localhost ~]# vim /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment">#末行 添加  </span></span><br><span class="line">/dev/sdc1 /mnt/sdc_drive ext4 defaults 0 0</span><br><span class="line"><span class="comment">#设备 挂载点 文件类型 defaults 0 0    </span></span><br></pre></td></tr></table></figure><h2 id="SWAP"><a href="#SWAP" class="headerlink" title="SWAP"></a>SWAP</h2><p>在物理内存空间不足时，可以将物理内存中的一些不重要数据拷贝到磁盘的 swap 分区中，从而让出内存空间，并且在需要那些已被拷出数据时再从 swap 分区中拷回到内存。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看内存及swap</span></span><br><span class="line">free</span><br><span class="line">free -h</span><br><span class="line">free -m</span><br></pre></td></tr></table></figure><h3 id="增加swap分区"><a href="#增加swap分区" class="headerlink" title="增加swap分区"></a>增加swap分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">**方法一**</span><br><span class="line"><span class="comment">#创建分区</span></span><br><span class="line">[root@node2 ~]# fdisk /dev/vdb</span><br><span class="line"><span class="comment">#格式化为文件系统</span></span><br><span class="line">[root@node2 ~]# mkswap /dev/vdb3</span><br><span class="line"><span class="comment">#保存设置使其永久生效</span></span><br><span class="line">[root@node2 ~]# vim /etc/fstab</span><br><span class="line">/dev/vdb3 swap swap defaults 0 0</span><br><span class="line"><span class="comment"># 激活SWAP文件</span></span><br><span class="line">swapon -a</span><br><span class="line"><span class="comment">#查看交换分区组成</span></span><br><span class="line">swapon -s</span><br><span class="line">free -h</span><br><span class="line"></span><br><span class="line">**方法二**</span><br><span class="line"><span class="comment"># 在根目录创建分区路径</span></span><br><span class="line">$ <span class="built_in">mkdir</span> -p /swap/</span><br><span class="line"><span class="comment"># 设置分区的大小</span></span><br><span class="line"><span class="comment"># bs=64M是块大小，count=64是块数量，所以swap空间大小是bs*count=4096MB=4GB</span></span><br><span class="line">$ <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=/swap/swap0 bs=64M count=64</span><br><span class="line"><span class="comment"># 设置该目录权限</span></span><br><span class="line">$ <span class="built_in">chmod</span> 0600 /swap/swap0</span><br><span class="line"><span class="comment"># 创建SWAP文件</span></span><br><span class="line">$ mkswap /swap/swap0</span><br><span class="line"><span class="comment"># 激活SWAP文件</span></span><br><span class="line">$ swapon /swap/swap0</span><br><span class="line"><span class="comment"># 查看SWAP信息是否正确</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a>LVM</h2><table><thead><tr><th>PV</th><th>物理卷physical volume</th></tr></thead><tbody><tr><td>VG</td><td>卷组Volume Group</td></tr><tr><td>LV</td><td>逻辑卷logical volume</td></tr></tbody></table><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/94a1f2ee-e740-44cf-bd2c-a6c21df5515a/image.png" alt="image.png"></p><h3 id="pv-物理卷"><a href="#pv-物理卷" class="headerlink" title="pv-物理卷"></a>pv-物理卷</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# pvcreate /dev/sdb1  /dev/sbd2</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看物理卷</span></span><br><span class="line">[root@newrain ~]# pvs</span><br></pre></td></tr></table></figure><h3 id="vg-卷组"><a href="#vg-卷组" class="headerlink" title="vg-卷组"></a>vg-卷组</h3><p>将创建好的物理卷组成卷组</p><p>直接创建卷组(系统会先将分区或磁盘创建为PV再创建卷组）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vgcreate vg1 /dev/sdb1</span><br><span class="line"> Volume group <span class="string">&quot;vg1&quot;</span> successfully created</span><br><span class="line">  </span><br><span class="line"> vgcreate -s [PE大小] </span><br><span class="line">  </span><br><span class="line">[root@localhost ~]# vgs</span><br></pre></td></tr></table></figure><h3 id="lv-逻辑卷"><a href="#lv-逻辑卷" class="headerlink" title="lv-逻辑卷"></a>lv-逻辑卷</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#创建逻辑卷</span></span><br><span class="line">[root@localhost ~]# lvcreate -L 10G -n mylv vg1</span><br><span class="line">Logical volume <span class="string">&quot;mylv&quot;</span> created.</span><br><span class="line"></span><br><span class="line">-L：指定逻辑卷的大小，如 -L 10G 表示 10GB。</span><br><span class="line">-l [PE个数] PE物理拓展块</span><br><span class="line"></span><br><span class="line">查看逻辑卷信息：</span><br><span class="line">lvs       //显示有关逻辑卷的信息</span><br><span class="line">lvscan     //扫描并显示LVM逻辑卷</span><br><span class="line">lvdisplay   //显示LVM逻辑卷属性</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="格式化并挂载使用"><a href="#格式化并挂载使用" class="headerlink" title="格式化并挂载使用"></a><strong>格式化并挂载使用</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#格式化文件系统</span></span><br><span class="line">[root@localhost ~]# mkfs.xfs /dev/vg1/mylv</span><br><span class="line"></span><br><span class="line"><span class="comment">#挂载使用</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">mkdir</span> /mount</span><br><span class="line">[root@localhost ~]# mount /dev/vg1/mylv /mount</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="拓展空间"><a href="#拓展空间" class="headerlink" title="拓展空间"></a>拓展空间</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#拓展卷组  </span></span><br><span class="line">[root@localhost ~]# vgextend vg1 /dev/sdb5 </span><br><span class="line"></span><br><span class="line"><span class="comment">#扩容逻辑卷</span></span><br><span class="line">[root@localhost ~]# lvextend -L +9G /dev/vg1/mylv</span><br><span class="line"></span><br><span class="line">扩展文件系统：当逻辑卷扩大以后，也需要对逻辑卷的文件系统进行扩展</span><br><span class="line">扩展文件系统容量：</span><br><span class="line">xfs_growfs <span class="comment">#用于扩容XFS设备</span></span><br><span class="line">resize2fs <span class="comment">#用于扩容EXT3/EXT4设备</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#扩展文件系统</span></span><br><span class="line"> xfs_growfs /dbbak</span><br><span class="line"> resize2fs /dev/myvol/vo</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux-文件的访问控制列表facl</title>
      <link href="/2025/01/21/%E6%96%87%E4%BB%B6%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E5%88%97%E8%A1%A8facl/"/>
      <url>/2025/01/21/%E6%96%87%E4%BB%B6%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E5%88%97%E8%A1%A8facl/</url>
      
        <content type="html"><![CDATA[<p><code>setfacl</code>工具： 设置和修改文件或目录的访问控制列表（ACLs）的命令行工具。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -m option:name[:permission] file</span><br></pre></td></tr></table></figure><ul><li><code>-m</code> 表示修改现有的 ACL 条目。</li><li><code>option</code> 可以是 <code>u</code>（用户）、<code>g</code>（组）、<code>o</code>（其他）、<code>d</code>（默认）、<code>-</code>（掩码，用于限制通过 ACL 授予的权限）。</li><li><code>name</code> 是用户或组的名称。</li><li><code>permission</code> 是逗号分隔的权限列表，可以是 <code>r</code>（读）、<code>w</code>（写）、<code>x</code>（执行）、<code>R</code>（读，但不允许执行）、<code>W</code>（写，但不允许执行）、<code>X</code>（执行，但不允许写）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible</title>
      <link href="/2024/10/30/ansible/"/>
      <url>/2024/10/30/ansible/</url>
      
        <content type="html"><![CDATA[<h1 id="一、安装与配置"><a href="#一、安装与配置" class="headerlink" title="一、安装与配置"></a><span style>一、安装与配置</span></h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#yum安装</span></span><br><span class="line">yum install epel-release -y</span><br><span class="line">yum install ansible –y</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看ansible版本</span></span><br><span class="line">ansible --version</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-管理节点与被管理节点建⽴SSH信任关系"><a href="#2-管理节点与被管理节点建⽴SSH信任关系" class="headerlink" title="2.管理节点与被管理节点建⽴SSH信任关系"></a>2.管理节点与被管理节点建⽴SSH信任关系</h2><pre><code>2.1.生成私钥[root@server ~]# ssh-keygen   2.2.向主机分发私钥[root@server ~]# ssh-copy-id root@192.168.37.122[root@server ~]# ssh-copy-id root@192.168.37.133</code></pre><h2 id="3-ansible配置文件"><a href="#3-ansible配置文件" class="headerlink" title="3. ansible配置文件"></a>3. ansible配置文件</h2><p>修改配置文件，创建主机清单文件 ：写在[]里的是组名，[ ]下面的是组内的主机名<br>[root@server ~]# vim &#x2F;etc&#x2F;ansible&#x2F;hosts<br>[web]<br>192.168.37.122<br>192.168.37.133</p><h1 id="二、核心组件"><a href="#二、核心组件" class="headerlink" title="二、核心组件"></a>二、核心组件</h1><p>主机清单（Inventory）<br>模块（Modules）<br>任务（Tasks）和剧本（Playbooks）<br>角色（Roles）</p><h1 id="三、ansible-doc-命令行模块"><a href="#三、ansible-doc-命令行模块" class="headerlink" title=" 三、ansible-doc 命令行模块"></a><span style> 三、ansible-doc 命令行模块</span></h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ansible &lt;ip组&gt; -m &lt;模块&gt; -a &lt;argument参数&gt; [options]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ansible dev,<span class="built_in">test</span>,prod -a <span class="string">&#x27;getenforce&#x27;</span> </span><br></pre></td></tr></table></figure><p>命令的工作目录默认是远程用户的主目录（~），command 模块不会保留shell的环境状态（包括当前工作目录）</p><p> ansible-doc -l  #列出当前系统中ansible的所有模块<br>ansible-doc  -s  模块名   #查看模块的参数<br>ansible-doc  模块名   #查看模块的详细信息包括用法</p><h3 id="1-ping模块"><a href="#1-ping模块" class="headerlink" title="1.ping模块"></a>1.ping模块</h3><p><code>ansible all -m ping</code></p><h3 id="2-command模块"><a href="#2-command模块" class="headerlink" title="2.command模块"></a>2.command模块</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chdir=/etc/sysconfig  ---执行命令前先切换到指定目录</span><br><span class="line">creates=/doc/1.txt：判断指定文件是否存在，如果存在，不执行后面的操作</span><br><span class="line">removes：判断指定文件是否存在，如果存在，执行后面的操作</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>注意，该命令不支持&#x3D;&#x3D;<code>| 管道命令</code>&#x3D;&#x3D;。</li></ul><p><code>ansible all -m command -a ‘removes=/etc/sysconfig/network-scripts/ifcfg-ens33 ip addr ’</code></p><h3 id="3-shell模块"><a href="#3-shell模块" class="headerlink" title="3.shell模块"></a>3.shell模块</h3><p>ansible all -m shell -a ‘echo “niki_ansible” |cat &gt;&gt;1.txt&#96;</p><p>ansible webservers -m shell -a ‘ifconfig | grep ens33’</p><p>ansible webservers -m shell -a ‘ifconfig &gt; &#x2F;opt&#x2F;kx.txt’</p><h3 id="4-file模块"><a href="#4-file模块" class="headerlink" title="4.file模块"></a>4.file模块</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">state　　#状态，有以下选项：</span><br><span class="line"></span><br><span class="line">directory：如果目录不存在，就创建目录</span><br><span class="line">file：文件不存在，不会被创建</span><br><span class="line">touch：文件不存在，创建新文件，如果文件或目录已存在，则更新其最后修改时间</span><br><span class="line">absent：删除目录、文件或者取消链接文件</span><br><span class="line">link：创建软链接，hard：创建硬链接</span><br></pre></td></tr></table></figure><p><code>ansible web -m file -a &#39;path=/data/app state=directory’</code>   创建目录</p><p><code>ansible web -m file -a &#39;path=/data/a state=absent’</code>      删除文件</p><p><code>ansible dbservers -m file -a &#39; group=root mode=644 path=/opt/host_ansible&#39;</code> #修改文件的属主属组权限等</p><h3 id="5-copy模块-将文件复制到远程主机"><a href="#5-copy模块-将文件复制到远程主机" class="headerlink" title="5.copy模块-将文件复制到远程主机"></a>5.copy模块-将文件复制到远程主机</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">src　　　　<span class="comment">#被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于&quot;rsync&quot;</span></span><br><span class="line">content　　　<span class="comment">#用于替换&quot;src&quot;，可以直接指定文件的值</span></span><br><span class="line">dest　　　　<span class="comment">#必选项，将源文件复制到的远程主机的绝对路径</span></span><br><span class="line">backup　　　<span class="comment">#当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息</span></span><br><span class="line">directory_mode　　　　<span class="comment">#递归设定目录的权限，默认为系统默认权限</span></span><br></pre></td></tr></table></figure><p> <code>ansible web -m copy -a &#39;src=~/hello dest=/data/hello&#39;</code> </p><p><code>ansible web -m copy -a &#39;content=&quot;I am keer\n&quot; dest=/data/name mode=666’</code></p><h3 id="6-fetch-模块-从远程主机获取文件到本地"><a href="#6-fetch-模块-从远程主机获取文件到本地" class="headerlink" title="6.fetch 模块-从远程主机获取文件到本地"></a>6.<strong>fetch 模块-从远程主机获取文件到本地</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dest：用来存放文件的目录</span><br><span class="line">src：在远程拉取的文件，**并且必须是一个file**，不能是目录</span><br></pre></td></tr></table></figure><p><code>ansible web -m fetch -a &#39;src=/data/hello dest=/data&#39;</code>  </p><h3 id="7-yum-apt-模块"><a href="#7-yum-apt-模块" class="headerlink" title="7.yum&#x2F;apt 模块"></a>7.<strong>yum&#x2F;apt 模块</strong></h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">name：要管理的包名</span></span><br><span class="line"><span class="string">state：#present---&gt;安装</span> <span class="string">latest---&gt;安装最新的,</span> <span class="string">absent---&gt;</span> <span class="string">卸载软件。</span></span><br></pre></td></tr></table></figure><hr><h3 id="8-service-模块"><a href="#8-service-模块" class="headerlink" title="8. service 模块"></a>8. service 模块</h3><p>　　该模块用于服务程序的管理。<br>　　其主要选项如下：</p><blockquote><p><code>arguments</code> #命令行提供额外的参数<br><code>enabled</code> #设置开机启动。<br><code>name=</code> #服务名称<br><code>runlevel</code> #开机启动的级别，一般不用指定。<br><code>sleep</code> #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)<br><code>state</code> #有四种状态，分别为：<code>started</code>—&gt;启动服务， <code>stopped</code>—&gt;停止服务， <code>restarted</code>—&gt;重启服务， <code>reloaded</code>—&gt;重载配置</p></blockquote><p>　　下面是一些例子：<br><strong>① 开启服务并设置自启动</strong></p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@server</span> ~]# ansible web -m service -a <span class="string">&#x27;name=nginx state=started enabled=true&#x27;</span> </span><br><span class="line"><span class="number">192.168</span>.<span class="number">37.122</span> | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">&quot;changed&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;enabled&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;nginx&quot;</span>, </span><br><span class="line">    <span class="string">&quot;state&quot;</span>: <span class="string">&quot;started&quot;</span>, </span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br><span class="line"><span class="number">192.168</span>.<span class="number">37.133</span> | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">&quot;changed&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;enabled&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;nginx&quot;</span>, </span><br><span class="line">    <span class="string">&quot;state&quot;</span>: <span class="string">&quot;started&quot;</span>, </span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="firewalld-模块"><a href="#firewalld-模块" class="headerlink" title="firewalld 模块"></a>firewalld 模块</h2><p>一个动态防火墙管理工具<br><strong>1. <strong>state</strong>：设置规则的状态。<br>    - <code>enabled</code>：启用规则。<br>    - <code>disabled</code>：禁用规则。<br>2. <strong>permanent</strong>：设置规则是否永久生效。<br>    - <code>yes</code>：规则永久生效，重启后依然有效。<br>    - <code>no</code>：规则临时生效，重启后失效。<br>3. <strong>immediate</strong>：是否立即应用规则变更。<br>    - <code>yes</code>：立即应用规则变更。<br>    - <code>no</code>：规则变更将在下一次 <code>firewalld</code> 重启时生效。<br>4. <strong>service</strong>：指定要允许或拒绝的服务名称，例如 <code>http</code>、<code>https</code>、<code>ssh</code> 等。<br>5. <strong>port</strong>：指定要允许或拒绝的端口，可以是单个端口（如 <code>8080/tcp</code>）或端口范围（如 <code>1024-2048/tcp</code>）。</strong></p><pre><code><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#启动 firewalld 服务**：</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Start</span> <span class="string">firewalld</span> <span class="string">service</span></span><br><span class="line">  <span class="attr">ansible.builtin.firewalld:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">    <span class="string">enabled：</span> <span class="literal">yes</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#添加允许规则：</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Open</span> <span class="string">port</span> <span class="number">80</span> <span class="string">in</span> <span class="string">firewalld</span></span><br><span class="line">  <span class="attr">ansible.builtin.firewalld:</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">permanent:</span> <span class="literal">yes</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">enabled</span></span><br><span class="line">    <span class="attr">immediate:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></code></pre><h2 id="Setup模块"><a href="#Setup模块" class="headerlink" title="Setup模块"></a>Setup模块</h2><p>使用<strong>setup模块</strong>获取被管理主机的所有facts信息，可以使用filter来查看指定的信息。setup模块获取的整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最外层的值。我们可以通过以下Ansible Ad-Hoc命令查看facts信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m setup | grep hostname</span><br><span class="line"></span><br><span class="line"> ansible all -m setup -a &#x27;filter=&quot;ansible_nodename&quot;&#x27;   </span><br></pre></td></tr></table></figure><h1 id="四、playbook-剧本"><a href="#四、playbook-剧本" class="headerlink" title="四、playbook-剧本"></a>四、playbook-剧本</h1><h3 id="playbook格式"><a href="#playbook格式" class="headerlink" title="playbook格式"></a>playbook格式</h3><p><strong>playbook 是 ansible 用于配置，部署，和管理被控节点的剧本。</strong><code>类似于脚本</code></p><ol><li><code>-</code>和<code>:</code>后必须<font color="#ff0000">空一格</font></li><li>大小写敏感,使用缩进表示层级关系</li><li>缩进时不允许使用tab键、只允许使用空格</li><li>缩进的空格数目不重要，只要相同层级的元素左侧对齐即可</li><li><strong>任务列表</strong>：每个任务前使用<code>-</code> 表示一个新的任务。</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---   </span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">playbook</span>  </span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">web：test</span>  <span class="comment"># 指定此 Play 将在哪些主机上运行</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  </span><br><span class="line">  <span class="attr">tasks:</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">connect</span> <span class="string">test</span>  </span><br><span class="line">      <span class="attr">ping:</span>    </span><br><span class="line">  </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">new</span> <span class="string">file</span>  </span><br><span class="line">      <span class="attr">file:</span> </span><br><span class="line">        <span class="attr">group:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">mode:</span> <span class="number">744</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/niki1/file1</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">touch</span> </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="comment">#以上为普通形式，行数较多，但更容易操作。任务的关键字垂直堆叠，更容易区分。</span></span><br><span class="line">    <span class="comment">#以下可以运行但不推荐</span></span><br><span class="line">    <span class="attr">tasks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shorthand</span> <span class="string">form</span></span><br><span class="line">        <span class="attr">service:</span> <span class="string">name=httpd</span> <span class="string">enabled=true</span> <span class="string">state=started</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure><h3 id="运行剧本"><a href="#运行剧本" class="headerlink" title="运行剧本"></a>运行剧本</h3><p>空运行 <code>ansible-playbook -C pb.yml</code></p><p>直接运行 <code>ansible-playbook pb.yml</code></p><p>语法验证 <strong><code>ansible-playbook --syntax-check pb.yml</code></strong></p><p>指定从某个task开始运行<code>ansible-playbook pb.yml --start-at-task=&#39;xxx&#39;</code>  </p><p><font color="#00b050">| 绿色代表执行成功，系统保持原样</font></p><p><font color="#ffff00">| 黄色代表系统代表系统状态发生改变</font></p><p><font color="#ff0000">| 红色代表执行失败，显示错误输出</font></p><h4 id="ansible-navigator容器中运行剧本"><a href="#ansible-navigator容器中运行剧本" class="headerlink" title="ansible-navigator容器中运行剧本"></a>ansible-navigator容器中运行剧本</h4><p>ansible-navigator 利用容器化的执行环境，用于与 Ansible Playbooks、Roles、Collections 等交互。<br>ansible-navigator run playbook.yml <span style="background:rgba(173, 239, 239, 0.55)">-m stdout</span><br>-<code>-m stdout</code>：这个选项指定输出模式为 <code>stdout</code>，即将执行结果输出到标准输出（终端），而不是使用交互式界面。</p><h3 id="Handler-notify-触发器"><a href="#Handler-notify-触发器" class="headerlink" title="Handler+notify-触发器"></a><strong>Handler+notify-触发器</strong></h3><p>在特定条件下触发；接收到其它任务的通知<code>notify</code>时被触发</p><p>Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了.</p><h3 id="Tag-标签"><a href="#Tag-标签" class="headerlink" title="Tag-标签"></a>Tag-标签</h3><p>为tasks或play添加标记，选择性地执行playbook的特定部分。</p><h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>如果命令或脚本的退出码不为零，可以使用如下方式替代</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line">  <span class="string">-name:</span> <span class="string">run</span> <span class="string">this</span> <span class="string">command</span> <span class="string">and</span> <span class="string">ignore</span> <span class="string">the</span> <span class="string">result</span></span><br><span class="line">   <span class="attr">shell:</span> <span class="string">/usr/bin/somecommand</span> <span class="string">||</span> <span class="string">/bin/true</span></span><br><span class="line"><span class="string">转错为正</span> <span class="string">如果命令失败则执行</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="string">或者使用ignore_errors来忽略错误信息</span></span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line"><span class="string">-name:</span> <span class="string">run</span> <span class="string">this</span> <span class="string">command</span> <span class="string">and</span> <span class="string">ignore</span> <span class="string">the</span> <span class="string">result</span></span><br><span class="line"> <span class="attr">shell:</span> <span class="string">/usr/bin/somecommand</span></span><br><span class="line"> <span class="attr">ignore_errors:</span> <span class="literal">True</span> <span class="string">忽略错误</span></span><br></pre></td></tr></table></figure><h3 id="Variable-变量"><a href="#Variable-变量" class="headerlink" title="Variable-变量"></a><strong>Variable-变量</strong></h3><p>变量名：仅能由字母、数字和下划线组成，且只能以字母开头<br>变量定义：直接定义  key&#x3D;value<br>根据变量的作⽤范围⼤体的将变量分为:</p><pre><code>全局变量剧本变量资产变量内置变量:内置变量⼏乎都是以 ansible_ 为前缀。系统自带事实变量facts：ansible setup模块   </code></pre><p>  ansible all -m setup -a ‘filter&#x3D;”ansible_nodename”‘     #查询主机名</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="string">.系统自带事实变量facts：ansible</span> <span class="string">setup模块</span>   </span><br><span class="line">  <span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">setup</span> <span class="string">-a</span> <span class="string">&#x27;filter=&quot;ansible_nodename&quot;&#x27;</span>     <span class="comment">#查询主机名</span></span><br><span class="line">  </span><br><span class="line"><span class="number">2</span><span class="string">./etc/ansible/hosts(主机清单)中定义变量</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span><span class="string">.在playbook中定义</span></span><br><span class="line">       <span class="attr">vars:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">var1:</span> <span class="string">value1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">var2:</span> <span class="string">value2</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span><span class="string">.在独立的变量YAML文件中定义</span></span><br><span class="line"><span class="string">vim</span> <span class="string">vars.yml</span></span><br><span class="line"><span class="attr">pack:</span> <span class="string">vsftpd</span></span><br><span class="line"><span class="attr">service:</span> <span class="string">vsftpd</span></span><br><span class="line"></span><br><span class="line"><span class="string">引用变量文件</span></span><br><span class="line"><span class="attr">vars_files:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">vars.yml</span></span><br><span class="line">  </span><br></pre></td></tr></table></figure><p>变量调用：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">通过&#123;&#123;</span> <span class="string">variable_name</span> <span class="string">&#125;&#125;</span> <span class="string">调用变量</span></span><br><span class="line"><span class="string">通过-e指定</span>  </span><br><span class="line"><span class="string">ansible-playbook</span> <span class="string">test.yml</span> <span class="string">-e</span> <span class="string">&quot;hosts=123&quot;</span></span><br></pre></td></tr></table></figure><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用变量文件   </span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vars_log</span> <span class="string">file</span></span><br><span class="line">  <span class="attr">vars_files:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">/niki2/vars.yml</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">new</span> <span class="string">file</span></span><br><span class="line">      <span class="attr">file:</span></span><br><span class="line">         <span class="attr">path:</span> <span class="string">/niki1/&#123;&#123;</span> <span class="string">name1</span> <span class="string">&#125;&#125;_log.txt</span></span><br><span class="line">         <span class="attr">mode:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; mode1 &#125;&#125;</span>&quot;</span></span><br><span class="line">         <span class="attr">state:</span> <span class="string">touch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Template-模板"><a href="#Template-模板" class="headerlink" title="Template-模板"></a><strong>Template-模板</strong></h3><p>根据模板文件<strong>动态</strong>生成对应的配置文件，命名必须以 <strong>.j2</strong> 结尾（<code>Jinja2</code>：Jinja2是python的一种模板语言）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">nginx</span>  <span class="comment">#安装nginx，若为centos7需要启用 EPEL 仓库</span></span><br><span class="line">      <span class="attr">yum:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">template</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">src:</span> <span class="string">/etc/ansible/templates/nginx.conf.j2</span> </span><br><span class="line">        <span class="comment">#nginx.conf.j2模板设置worker_processes 的值为   &#123;&#123; ansible_processor_vcpus*2&#125;&#125;;</span></span><br><span class="line">        <span class="attr">dest:</span> <span class="string">/etc/nginx/nginx.conf</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">service</span></span><br><span class="line">      </span><br><span class="line">     </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service</span> <span class="string">start</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">yes</span> <span class="comment">#开机自启</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">service</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">restarted</span></span><br></pre></td></tr></table></figure><h3 id="条件测试when与循环迭代-with-items"><a href="#条件测试when与循环迭代-with-items" class="headerlink" title="条件测试when与循环迭代  with_items"></a>条件测试when与循环迭代  with_items</h3><ul><li><p>when语句：在task中使用</p></li><li><p>循环：迭代，需要重复执行的任务；</p><p>  对迭代项的引用，固定变量名为”item”，而后，要在task中使用with_items给定要迭代的元素列表；</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">add</span> <span class="string">groups</span></span><br><span class="line">      <span class="attr">group:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item &#125;&#125;</span>&quot;</span></span><br><span class="line">      <span class="attr">with_items:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group2</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group3</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">add</span> <span class="string">users</span></span><br><span class="line">      <span class="attr">user:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item.name &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">group:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item.group &#125;&#125;</span>&quot;</span></span><br><span class="line">      <span class="attr">with_items:</span></span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u1&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group1&#x27;</span>&#125;</span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u2&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group2&#x27;</span>&#125;</span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u3&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group3&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="五、roles-角色"><a href="#五、roles-角色" class="headerlink" title="五、roles-角色"></a>五、roles-角色</h1><p>用于<strong>层次性，结构化</strong>地组织playbook<br>roles通过分别将变量(vars)、文件(file)、任务(tasks)、模块(modules)及处理器(handlers)放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中。 </p><h3 id="创建role"><a href="#创建role" class="headerlink" title="创建role"></a>创建role</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible-galaxy init my_role</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="安装roels"><a href="#安装roels" class="headerlink" title="安装roels"></a>安装roels</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">直接从galaxy安装</span></span><br><span class="line">ansible-galaxy install &lt;role_name&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">从 requirements.yml 文件安装多个角色</span></span><br><span class="line">vim requirements.yml</span><br><span class="line"></span><br><span class="line">- src: geerlingguy.apache</span><br><span class="line">- src: geerlingguy.mysql</span><br><span class="line">- </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装</span></span><br><span class="line">ansible-galaxy install -r requirements.yml</span><br><span class="line">---</span><br><span class="line"> - name: webservers role</span><br><span class="line">   hosts: webservers</span><br><span class="line">   roles:</span><br><span class="line"> - apache</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="六、collection-集合"><a href="#六、collection-集合" class="headerlink" title="六、collection-集合"></a>六、collection-集合</h1><p>Collection 是一个更高级的封装，包含多个 Roles、模块、插件等，允许用户更全面地共享和分发自动化内容。它可以包含多个功能模块，适用于更复杂的项目。</p><h2 id="如何使用-Ansible-Collections"><a href="#如何使用-Ansible-Collections" class="headerlink" title="如何使用 Ansible Collections"></a>如何使用 Ansible Collections</h2><h3 id="1、安装-Collection"><a href="#1、安装-Collection" class="headerlink" title="1、安装 Collection"></a>1、安装 Collection</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可以从 Ansible Galaxy 或其他来源安装 Collection：</span></span><br><span class="line">ansible-galaxy collection install &lt;namespace&gt;.&lt;collection_name&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">也可以从本地目录或通过 requirements.yml 文件安装collection：</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2、Playbook-中使用-Collection"><a href="#2、Playbook-中使用-Collection" class="headerlink" title="2、Playbook 中使用 Collection"></a>2、Playbook 中使用 Collection</h3><p>在你的 playbook.yml 文件中，你可以指定要使用的 Collection：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">Playbook</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">collections:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">my_namespace.my_collection</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">task</span></span><br><span class="line">      <span class="attr">my_namespace.my_collection.my_module:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">example</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br></pre></td></tr></table></figure><h3 id="3、管理-Collection"><a href="#3、管理-Collection" class="headerlink" title="3、管理 Collection"></a>3、管理 Collection</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">列出已安装的 Collection：</span></span><br><span class="line">ansible-galaxy collection list</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载 Collection：</span></span><br><span class="line">ansible-galaxy collection uninstall my_namespace.my_collection</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用-requirements-yml-文件管理-Collection"><a href="#使用-requirements-yml-文件管理-Collection" class="headerlink" title="使用 requirements.yml 文件管理 Collection"></a>使用 requirements.yml 文件管理 Collection</h3><blockquote><p>[!success] Title<br>创建一个 requirements.yml 文件来管理 Collection </p><p>collections模块中name通常为集合名字。<strong>如果直接提供 URL，格式为完整的链接。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">collections:</span><br><span class="line">  - name: my_namespace.my_collection</span><br><span class="line">    source: https://my.custom.repo/path/to/collection/</span><br><span class="line">    version: 1.0.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">然后使用以下命令安装所有 Collection：</span></span><br><span class="line">ansible-galaxy collection install -r requirements.yml </span><br><span class="line"></span><br><span class="line">-r, --requirements</span><br><span class="line">从指定的 requirements 文件中安装 Collections。</span><br><span class="line"></span><br><span class="line">-p, --collections-path</span><br><span class="line">指定安装 Collections 的目录。如果没有指定，默认安装到系统的 Ansible Collections 路径。</span><br></pre></td></tr></table></figure><h1 id="七、ansible-galaxy"><a href="#七、ansible-galaxy" class="headerlink" title="七、ansible galaxy"></a>七、ansible galaxy</h1><p><a href="https://galaxy.ansible.com/ui/search/">https://galaxy.ansible.com/ui/search/</a><br>Ansible Galaxy 是一个在线平台，提供一个广泛的 Ansible 资源库，包括 <strong>角色（roles）</strong>、<strong>集合（collections）</strong> 和其他自动化内容。用户可以通过 Galaxy 搜索、下载和分享这些资源。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装角色</span></span><br><span class="line">ansible-galaxy role install &lt;role_name&gt;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">列出已安装的角色或集合：</span></span><br><span class="line">ansible-galaxy role list</span><br></pre></td></tr></table></figure><h1 id="八、debug-msg"><a href="#八、debug-msg" class="headerlink" title="八、debug  msg"></a>八、debug  msg</h1><p>在Ansible中，<code>debug</code>模块是一个非常有用的工具，它允许你在执行任务时输出变量的值或执行过程中的信息。这对于调试和理解你的Ansible playbooks的执行流程非常有用。</p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ol><li><p><strong>基本用法</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">a</span> <span class="string">debug</span> <span class="string">message</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;This is a debug message&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>输出变量</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">the</span> <span class="string">value</span> <span class="string">of</span> <span class="string">a</span> <span class="string">variable</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;The value of my_var is <span class="template-variable">&#123;&#123; my_var &#125;&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>条件输出</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">a</span> <span class="string">message</span> <span class="string">if</span> <span class="string">a</span> <span class="string">condition</span> <span class="string">is</span> <span class="string">met</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;This will only print if the condition is true&quot;</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">my_condition</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">my_condition</span></span><br></pre></td></tr></table></figure></li><li><p><strong>输出变量内容</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">the</span> <span class="string">content</span> <span class="string">of</span> <span class="string">a</span> <span class="string">variable</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">var:</span> <span class="string">my_var</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="调试技巧"><a href="#调试技巧" class="headerlink" title="调试技巧"></a>调试技巧</h3><ul><li><strong>在每个任务后添加debug模块</strong>: 这可以帮助你跟踪变量的值和任务的执行状态。</li><li><strong>使用<code>when</code>条件</strong>: 只在特定条件下输出信息，避免不必要的输出。</li><li><strong>使用<code>verbosity</code></strong>: 通过增加verbosity级别，可以输出更多的调试信息。在命令行中使用<code>-v</code>或<code>-vv</code>参数。</li></ul><h1 id="九、ansible-vault"><a href="#九、ansible-vault" class="headerlink" title="九、ansible-vault"></a>九、ansible-vault</h1><p><code>ansible-vault</code> 是一个用于加密和解密敏感数据的工具。它允许你以加密的形式存储敏感信息，如密码、密钥或任何其他敏感数据，以确保这些信息在Playbooks和变量文件中不会被暴露。</p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 运维 </tag>
            
            <tag> #Automation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux用户与组管理</title>
      <link href="/2024/07/20/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%201/"/>
      <url>/2024/07/20/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%201/</url>
      
        <content type="html"><![CDATA[<h2 id="用户与组管理"><a href="#用户与组管理" class="headerlink" title="用户与组管理"></a>用户与组管理</h2><h3 id="useradd创建用户"><a href="#useradd创建用户" class="headerlink" title="useradd创建用户"></a>useradd创建用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">常用选项：</span><br><span class="line">-u 指定用户UID</span><br><span class="line">-d 指定用户家目录</span><br><span class="line">-c --comment用户描述信息</span><br><span class="line">-g 指定用户gid</span><br><span class="line">-G 指定用户附加组（次要组）</span><br><span class="line">-s --shell指定用户的解释器程序   </span><br><span class="line">⽆权访问系统上的交互式shell：/sbin/noloogin   /bin/false</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建用户指定用户UID、描述信息、附加组</span></span><br><span class="line">[root@localhost ~]# useradd -u 1600 -c yunwei -G <span class="built_in">test</span> xiaozhang</span><br><span class="line">[root@localhost ~]# <span class="built_in">id</span> xiaozhang</span><br><span class="line">uid=1600(xiaozhang) gid=1600(xiaozhang) 组=1600(xiaozhang),1401(<span class="built_in">test</span>)</span><br></pre></td></tr></table></figure><h3 id="groupadd创建组"><a href="#groupadd创建组" class="headerlink" title="groupadd创建组"></a>groupadd创建组</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建组</span></span><br><span class="line"> groupadd -g GID   <span class="comment">#指定组的GID</span></span><br><span class="line">[root@localhost ~]# groupadd -g 1555 student</span><br></pre></td></tr></table></figure><h3 id="chgrp改变文件或目录所属组"><a href="#chgrp改变文件或目录所属组" class="headerlink" title="chgrp改变文件或目录所属组"></a>chgrp改变文件或目录所属组</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看文件或目录所属组</span></span><br><span class="line"><span class="built_in">ls</span> -l</span><br><span class="line"></span><br><span class="line"><span class="built_in">chgrp</span> [选项] [所属组] 文件/目录</span><br><span class="line">--reference=RFILE  使用参考文件的所属组</span><br><span class="line">-R  递归的更改目录下的所有目录以及文件</span><br><span class="line"></span><br><span class="line"><span class="built_in">chgrp</span> group1 /etc/niki</span><br><span class="line"></span><br><span class="line">sgid：给目录设置了sgid权限，在该目录下创建的文件或者目录的**属组**都与该目录一致</span><br><span class="line"></span><br><span class="line">授权格式：</span><br><span class="line"><span class="built_in">chmod</span> g+s 文件名称</span><br><span class="line">撤销格式：</span><br><span class="line"><span class="built_in">chmod</span> g-s 文件名称</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="chown归属关系管理"><a href="#chown归属关系管理" class="headerlink" title="chown归属关系管理"></a>chown归属关系管理</h3><p>chown（英文全拼：change owner）用于设置文件的所有者和所属组关系</p><ul><li>命令格式：<ul><li>chown [-选项] 所有者:所属组 文档</li><li>chown [-选项] 所有者 文档</li><li>chown [-选项] :所属组 文档</li></ul></li><li>常用选项:<ul><li><code>R</code> 递归地改变指定目录及其子目录和文件的所有者</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改文件所有者与所属组为lisi</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">chown</span> lisi:lisi /hello.txt </span><br></pre></td></tr></table></figure><h3 id="id查看信息"><a href="#id查看信息" class="headerlink" title="id查看信息"></a>id查看信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# <span class="built_in">id</span> user1</span><br><span class="line">uid=1001(user1) gid=1001(user1) 组=1001(user1)</span><br></pre></td></tr></table></figure><h3 id="passwd修改密码"><a href="#passwd修改密码" class="headerlink" title="passwd修改密码"></a>passwd修改密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置用户密码</span></span><br><span class="line">[root@localhost ~]# passwd user1</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 密码 |passwd --stdin user1</span><br></pre></td></tr></table></figure><h3 id="etc-passwd用户信息文件"><a href="#etc-passwd用户信息文件" class="headerlink" title="&#x2F;etc&#x2F;passwd用户信息文件"></a>&#x2F;etc&#x2F;passwd用户信息文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">**[root@localhost ~]# vim /etc/passwd</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line"><span class="comment">#每个字段含义解释：用户名:密码占位符:UID:基本组GID:用户描述信息:家目录:解释器程序</span></span><br><span class="line">UID：0 超级用户</span><br><span class="line">UID：1-999 系统伪用户，不能登录系统</span><br><span class="line">UID：1000-65535 普通用户，管理员创建的用户**</span><br></pre></td></tr></table></figure><h3 id="wheel用户组"><a href="#wheel用户组" class="headerlink" title="wheel用户组"></a>wheel用户组</h3><p><a href="https://www.cnblogs.com/linuxshare/p/18609179">linux中的wheel用户 - 爱折腾的大臭臭 - 博客园</a></p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker</title>
      <link href="/2023/10/20/docker/"/>
      <url>/2023/10/20/docker/</url>
      
        <content type="html"><![CDATA[<h1 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h1><p><img src="/(/images/U1.png" alt="Untitled"></p><h2 id="一：Docker基础、"><a href="#一：Docker基础、" class="headerlink" title="一：Docker基础、"></a>一：Docker基础、</h2><h3 id="什么是Docker？"><a href="#什么是Docker？" class="headerlink" title="什么是Docker？"></a>什么是Docker？</h3><h3 id="Docker是什么？"><a href="#Docker是什么？" class="headerlink" title="Docker是什么？"></a><strong>Docker是什么？</strong></h3><p><strong>开源的容器化平台，用于构建、打包和运行应用程序和服务</strong></p><h3 id="架构：client-server"><a href="#架构：client-server" class="headerlink" title="架构：client-server"></a>架构：<strong>client-server</strong></h3><p><img src="/(/images/U2.png" alt="Untitled"></p><h3 id="Docker的优势和用途"><a href="#Docker的优势和用途" class="headerlink" title="Docker的优势和用途"></a>Docker的优势和用途</h3><ol><li><p><strong>轻量级容器：</strong> Docker容器相对于传统虚拟机更轻量，因为它们共享操作系统内核，而不是运行完整的操作系统。这使得容器更快速启动、更节省资源，并提高了可扩展性。</p></li><li><p><strong>一致性和可移植性：</strong> Docker容器封装了应用程序及其依赖，确保在不同环境中运行一致。这意味着你可以在开发、测试和生产环境之间轻松迁移应用程序。</p></li><li><p><strong>快速部署：</strong> Docker容器可以迅速启动和停止，因此可以更快速地部署和更新应用程序，有助于实现持续集成和持续交付（CI&#x2F;CD）。</p></li><li><p><strong>隔离性：</strong> Docker提供了强大的容器隔离，确保容器内的应用程序不会相互干扰，并提供了一定程度的安全性。</p></li><li><p><strong>生态系统和社区支持：</strong> Docker拥有广泛的生态系统和强大的社区支持，有大量的官方和第三方容器镜像，以及丰富的工具和插件，使得它更容易集成到不同的应用和基础架构中。</p></li></ol><p>📌 用途</p><ol start="6"><li><p><strong>微服务架构：</strong> Docker容器可用于构建和管理微服务，使每个微服务都运行在独立的容器中，有助于系统的模块化和可伸缩性。</p></li><li><p><strong>持续集成和持续交付（CI&#x2F;CD）：</strong> Docker容器在CI&#x2F;CD流程中扮演重要角色，帮助自动化构建、测试和部署过程，提高交付速度和可靠性。</p></li><li><p><strong>多云环境部署：</strong> Docker容器的可移植性使得在不同云服务提供商之间迁移应用程序变得更加容易，同时也有助于混合云和多云战略的实施。</p></li><li><p><strong>资源隔离和多租户环境：</strong> Docker容器可用于隔离不同租户或应用程序，确保资源分配和安全性。</p></li></ol><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>📌 Linux基础</p><p>📌 CentOS 7</p><p>基于开源 Linux 发行版 Red Hat Enterprise Linux (RHEL) 的免费、企业级操作系统。它采用了稳定性和可靠性为主要目标，适用于服务器环境和企业级应用程序。</p><p>📌 Xshell连接远程服务器进行操作</p><ol start="10"><li>环境查看：</li></ol><p>#系统内核<br> [root@iZ2vcet9lnxw7ajh08wb59Z ~]# uname -r<br> 4.18.0-305.3.1.el8.x86_64</p><p>#系统版本  </p><p> [root@iZ2vcet9lnxw7ajh08wb59Z ~]# cat &#x2F;etc&#x2F;os-release<br> NAME&#x3D;”CentOS Linux”<br> VERSION&#x3D;”8”<br> ID&#x3D;”centos”<br> ID_LIKE&#x3D;”rhel fedora”<br> VERSION_ID&#x3D;”8”<br> PLATFORM_ID&#x3D;”platform:el8”<br> PRETTY_NAME&#x3D;”CentOS Linux 8”<br> ANSI_COLOR&#x3D;”0;31”<br> CPE_NAME&#x3D;”cpe:&#x2F;o:centos:centos:8”<br> HOME_URL&#x3D;”<a href="https://centos.org/">https://centos.org/</a>“<br> BUG_REPORT_URL&#x3D;”<a href="https://bugs.centos.org/">https://bugs.centos.org/</a>“<br> CENTOS_MANTISBT_PROJECT&#x3D;”CentOS-8”<br> CENTOS_MANTISBT_PROJECT_VERSION&#x3D;”8”  </p><ol start="11"><li>安装</li></ol><p> # 1、卸载旧的版本<br> sudo yum remove docker \<br>                   docker-client \<br>                   docker-client-latest \<br>                   docker-common \<br>                   docker-latest \<br>                   docker-latest-logrotate \<br>                   docker-logrotate \<br>                   docker-engine<br>​<br> # 2、需要的安装包<br> sudo yum install -y yum-utils  </p><p> # 3、设置镜像的仓库<br> yum-config-manager –add-repo <a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a>  </p><p> # 更新yum软件包索引<br> yum makecache fast  </p><p> # 4、安装docker相关的源 docker-ce 社区 ee 企业版<br> yum install docker-ce docker-ce-cli containerd.io  </p><p> # 5、启动docker<br> systemctl start docker  </p><p> # 6、使用docker version 查看是否安装成功  </p><p> # 7、docker run hello-world  </p><p> # 8、查看下载的这个 hello-world 镜像  </p><h3 id="Docker基本概念"><a href="#Docker基本概念" class="headerlink" title="Docker基本概念"></a>Docker基本概念</h3><p>🪞 image-镜像</p><p>Docker 镜像是容器的模板</p><p>它包含了运行容器所需的文件系统、库和配置等。</p><p>tomat镜像—–&gt;run—–&gt;Tomcat01 容器（提供服务器）</p><p>🧂 container-容器</p><p>Docker 容器是基于 Docker 镜像创建的运行<strong>实例</strong></p><ul><li>容器可以看做简易的Linux系统</li></ul><p>🈁 repository-仓库</p><p>存放镜像的地方</p><p>分为公有仓库和私有仓库</p><h3 id="镜像（Images）和容器（Containers）的区别"><a href="#镜像（Images）和容器（Containers）的区别" class="headerlink" title="镜像（Images）和容器（Containers）的区别"></a>镜像（Images）和容器（Containers）的区别</h3><p>镜像（Images）和容器（Containers）是Docker中两个关键的概念，它们在Docker生态系统中有不同的角色和用途。以下是镜像和容器之间的主要区别：</p><p><strong>1. 定义和用途：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像是一个只读的文件，其中包含了应用程序、运行时环境、系统工具和库等的静态快照。镜像可以看作是应用程序的构建模块，它包含了所有启动容器所需的文件系统和配置信息。镜像通常用于创建容器。</p></li><li><p><strong>容器（Containers）：</strong> 容器是基于镜像运行的实例。它是镜像的一个运行时环境，包括正在运行的应用程序和其依赖的进程。容器是可读写的，并且可以与主机系统和其他容器进行交互。容器是实际运行和执行应用程序的实体。</p></li></ul><p><strong>2. 可变性：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像是不可变的，一旦创建，其内容不会改变。如果需要对应用程序进行更新或修改，通常需要创建一个新的镜像。</p></li><li><p><strong>容器（Containers）：</strong> 容器是可变的，可以在容器内部运行应用程序，进行文件操作、修改配置等。容器的状态可以随着应用程序的运行而改变。</p></li></ul><p><strong>3. 生命周期：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像的生命周期是静态的，它存在于Docker主机上，可以被多个容器实例引用。镜像通常是持久的，直到手动删除。</p></li><li><p><strong>容器（Containers）：</strong> 容器的生命周期是动态的，它可以被创建、启动、停止和删除。容器是短暂的，存在于需要运行应用程序的时候，然后可以被销毁。</p></li></ul><p><strong>4.资源消耗：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像通常占用较大的磁盘空间，因为它包含了应用程序的完整静态快照。</p></li><li><p><strong>容器（Containers）：</strong> 容器通常比镜像占用更少的磁盘空间，因为容器只包含运行应用程序所需的可写层，并且可以共享底层镜像的内容。</p></li></ul><p>总之，镜像是Docker中的静态构建块，用于创建容器的基础，而容器是运行时实体，代表一个应用程序的运行实例。理解镜像和容器之间的区别对于有效使用Docker和容器化应用程序非常重要。容器化技术使得应用程序更容易管理、部署和扩展。</p><p>DockerFile : 构建文件，定义了一切的步骤，源代码</p><p>DockerImages ： 通过DokerFile构建生成的镜像，是最终发布和运行的产品</p><p>Docker容器：容器就是镜像运行起来提供服务器</p><p><img src="/(/images/U3.png" alt="Untitled"></p><h1 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h1><h3 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a><strong>镜像命令</strong></h3><ul><li><p>查看所有本地主机上的镜像：<code>docker images</code></p><blockquote><p>REPOSITORY：镜像的仓库源TAG：镜像的标签IMAGE ID：镜像的IDCREATED：镜像的创建时间</p></blockquote></li><li><p>搜索镜像：<code>docker search 镜像名</code></p><blockquote><p>–filter, -f：根据提供的条件筛选输出</p></blockquote></li><li><p>下载镜像：<code>docker pull 镜像名[:tag]</code></p><blockquote><p>docker pull mysql:5.7</p></blockquote></li><li><p>删除镜像：<code>docker rmi</code></p><ul><li><p>删除指定的容器：<code>docker rmi -f 容器id</code></p></li><li><p>删除多个容器：<code>docker rmi -f 容器id1 容器id2 ...</code></p></li><li><p>删除全部容器：<code>docker rmi -f $(docker images -aq)</code></p></li></ul></li></ul><h3 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a><strong>容器命令</strong></h3><ul><li><p><strong>新建容器并启动：</strong><code>docker run 镜像名</code></p><table><thead><tr><th>可选参数</th><th>说明</th></tr></thead><tbody><tr><td>-p</td><td>设置端口映射，宿主机端口:容器端口</td></tr><tr><td>-P</td><td>随机分配端口</td></tr><tr><td>-i</td><td>前台交互式启动，通常与 -t 配合使用</td></tr><tr><td>-t</td><td>启动容器内的伪终端，通常与 -i 配合使用</td></tr><tr><td>-d</td><td>后台守护式启动</td></tr><tr><td>–name</td><td>为容器命名</td></tr></tbody></table><blockquote><p>-可选参数：</p><ul><li><p>name&#x3D;”Name”：容器名字，用于区分容器</p></li><li><p>d：后台方式运行</p></li><li><p>it：使用交互方式运行</p></li><li><p>p：指定容器的端口映射&lt;主机端口&gt;:&lt;容器内部端口&gt;</p></li><li><p>v：挂载数据卷</p></li></ul></blockquote><hr><p>  注意 -d后台方式运行<br>  docker run -d centos<br>  ​<br>  #但docker ps后发现 centos 停止了<br>  ​  </p><h1 id="docker容器使用后台运行，就必须要有一个前台进程，"><a href="#docker容器使用后台运行，就必须要有一个前台进程，" class="headerlink" title="docker容器使用后台运行，就必须要有一个前台进程，"></a>docker容器使用后台运行，就必须要有一个前台进程，</h1><p>  docker发现没有应用，就会自动停止<br>  nginx,容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序了</p><hr></li><li><p><strong>列出所有运行中的容器：<code>docker ps</code></strong></p><blockquote><p>可选项：</p><ul><li><p>a：列出所有容器（包括历史运行过的）</p></li><li><p>n&#x3D;?：显示最近创建的容器</p></li><li><p>q：只显示容器的编号</p></li></ul></blockquote><ul><li><p>进入一个正在运行的Docker容器:<code>docker exec</code></p></li><li><p><strong>docker exec -it &lt;容器名称或容器ID&gt; &lt;shell命令&gt;</strong></p><blockquote><p>-it：这是两个选项的组合，</p><p><code>-i</code>表示交互式</p><p><code>-t</code>表示分配一个终端（TTY）。这允许您与容器进行交互，就像您在本地计算机上使用终端一样。</p><p><code>&lt;shell命令&gt;</code>：这是您要在容器内执行的shell命令。通常，您可以使用<code>/bin/bash</code>或<code>/bin/sh</code>来启动一个shell会话。</p></blockquote></li></ul></li><li><p><strong>退出容器：exit</strong></p><blockquote><p>直接容器停止并退出：exit</p><p>容器不停止退出：<code>Ctrl + P + Q</code></p></blockquote></li><li><p>**删除容器：**docker rm 容器id</p><blockquote><p>删除指定容器：docker rm 容器id</p><p>删除所有容器：<code>docker rm -f $(docker ps -aq)</code> 或 <code>docker ps -aq | xargs docker rm</code></p></blockquote></li><li><p><strong>启动、重启和停止容器：</strong></p><blockquote><p>启动容器：docker start 容器id</p><p>重启容器：<code>docker restart 容器id</code></p><p>停止容器：<code>docker stop 容器id</code></p><p>强制停止容器：<code>docker kill 容器id</code></p></blockquote></li></ul><h3 id="其他常用命令"><a href="#其他常用命令" class="headerlink" title="其他常用命令"></a><strong>其他常用命令</strong></h3><ul><li><p>后台启动容器：<code>docker run -d 镜像名</code></p></li><li><p>查看容器日志：<code>docker logs -f -t --tail 容器id</code></p></li><li><p>查看容器中的进程信息：<code>docker top 容器id</code></p></li><li><p>查看容器源数据：<code>docker inspect 容器id</code></p></li><li><p>进入当前正在运行的容器：<code>docker exec -it 容器id 命令</code></p></li><li><p><code>docker run</code>：运行容器</p></li><li><p><code>docker pull</code>：拉取镜像</p></li><li><p><code>docker ps</code>：查看运行中的容器</p></li><li><p><code>docker images</code>：查看镜像列表</p></li><li><p><code>docker stop</code> 和 <code>docker rm</code>：停止和删除容器</p></li></ul><h3 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a><strong>帮助命令</strong></h3><ul><li><p>显示Docker版本信息：<code>docker version</code></p></li><li><p>显示Docker系统信息，包括镜像和容器的数量：<code>docker info</code></p></li><li><p>获取Docker命令的帮助：<code>docker 命令 --help</code></p></li><li><p>帮助文档地址：<a href="https://docs.docker.com/reference/">Docker官方文档</a></p></li><li><p>重启docker服务<code>systemctl restart docker</code></p></li></ul><h1 id="dickerfile-创建自定义镜像"><a href="#dickerfile-创建自定义镜像" class="headerlink" title="dickerfile-创建自定义镜像"></a>dickerfile-创建自定义镜像</h1><p><strong>Docker image由只读层组成，每个层代表一条 Dockerfile 指令。这些层是堆叠在一起的，每一层都是与前一层的变化的增量</strong></p><p><strong>dockerfile—&gt;文本文件</strong>，用于定义Docker镜像的构建过程。它包含一系列的指令和参数，这些指令告诉Docker引擎如何从一个基础镜像构建一个新的镜像，包括如何添加应用程序代码、依赖项、配置文件等。</p><ul><li><input disabled type="checkbox"> <strong>注意事项</strong><ul><li><input disabled type="checkbox"> 保留关键字都必须大写！</li><li><input disabled type="checkbox"> 执行顺序：从上到下</li><li><input disabled type="checkbox"> 每个指令都创建提交一个新的镜像层</li><li><input disabled type="checkbox"> dockerfile是面向开发的</li></ul></li></ul><h3 id="dockerfile的指令"><a href="#dockerfile的指令" class="headerlink" title="dockerfile的指令"></a>dockerfile的指令</h3><p><strong>FROM</strong>         #指定基础镜像<br><strong>MAINTAINER</strong>   #指定维护者信息：姓名+邮箱<br><strong>RUN         #每执行一条RUN命令,镜像添加新的一层.  <br>ADD</strong>          #将文件或目录复制到容器中，自动解压<br><strong>WORKDIR</strong>      #工作目录，类似于 cd 命令，即切换目录<br>通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、 COPY等命令都会在该目录下执行。  </p><p><strong>VOLUNME</strong>      #创建一个挂载点，<br><strong>EXPOSE</strong>       #指定容器监听的端口<br>ENV # 构建的时候设置环境变量！<br>VOLUME [“volume01”,”volume02”]   # 定义一个挂载点,用于持久化数据</p><p><strong>CMD :设置容器启动后默认执行的命令和参数ENTRYPOINT :设置容器启动时运行的命令</strong></p><p>ADD带有自动解压功能 COPY没有自动解压功能</p><p>构建镜像</p><h1 id="命令-docker-build-f-文件路径-t-镜像名-tag"><a href="#命令-docker-build-f-文件路径-t-镜像名-tag" class="headerlink" title="命令 docker build -f 文件路径 -t 镜像名:[tag]"></a>命令 docker build -f 文件路径 -t 镜像名:[tag]</h1><p><code>docker buildx build -t nikicentos:1.0 -f mydockerfile</code> <em>#用于构建一个名为 nikicentos，标签为 1.0 的 Docker 镜像 #使用名为 mydockerfile 的 Dockerfile，并且<strong>构建上下文路径是当前目录（.）</strong>。</em></p><h3 id="docker-history"><a href="#docker-history" class="headerlink" title="docker history &lt;镜像ID或名称&gt;-"></a><code>docker history &lt;镜像ID或名称&gt;</code>-</h3><p><strong>查看 Docker 镜像的构建历史</strong></p><p><code>CMD</code><em>指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代。</em></p><p><code>ENTRYPOINT</code> <em>指定这个容器启动的时候要运行的命令，可以追加命令</em></p><ul><li><p>如果你只关心容器的默认命令，使用 <strong><code>CMD</code></strong> 即可。</p></li><li><p>如果你希望容器的默认命令可以接受参数，使用 <strong><code>ENTRYPOINT</code></strong>。</p></li></ul><p><a href="https://www.notion.so/test-centOS-e15001a2ff8944258855e5d810b7cd16?pvs=21">test-构建自己的centOS</a></p><p><a href="https://www.notion.so/test2-Tomcat-dfabe04415fa4501934d91f827a00469?pvs=21">test2-Tomcat镜像</a></p><h3 id="1-容器数据卷（Container-Volumes）："><a href="#1-容器数据卷（Container-Volumes）：" class="headerlink" title="1. 容器数据卷（Container Volumes）："></a><strong>1. 容器数据卷（Container Volumes）：</strong></h3><h3 id="容器之间共享和持久化数据的机制"><a href="#容器之间共享和持久化数据的机制" class="headerlink" title="容器之间共享和持久化数据的机制"></a>容器之间共享和持久化数据的机制</h3><ul><li><p>容器数据卷是Docker容器内部的目录或文件，它们映射到宿主机的文件系统目录，或者可以共享给其他容器使用。</p></li><li><p>容器数据卷可以包含应用程序数据、配置文件、日志文件等。这些数据卷可以在容器之间传递信息，以及在容器的生命周期内保持数据的一致性。</p></li><li><p>创建容器数据卷的方法包括在容器启动命令中使用<code>v</code>或<code>-volume</code>选项，或在Docker Compose文件中定义<code>volumes</code>部分。</p></li><li><p>示例：创建一个容器并将它的<code>/data</code>目录映射到宿主机的<code>/var/data</code>目录，以实现数据持久化和共享。</p><p>  docker run -v &#x2F;var&#x2F;data:&#x2F;data my-container<br>  ​</p></li></ul><h3 id="具名挂载-匿名挂载"><a href="#具名挂载-匿名挂载" class="headerlink" title="具名挂载 &amp; 匿名挂载"></a>具名挂载 &amp; 匿名挂载</h3><p>在Docker中，有两种主要的数据卷挂载方式：具名挂载（named volumes）和匿名挂载（anonymous volumes）。这些挂载方式允许容器与主机之间共享数据，但它们在用法和管理上有一些区别。</p><p><strong>1. 具名挂载（Named Volumes）：</strong></p><ul><li><p>具名挂载是通过为数据卷指定名称来创建的。</p></li><li><p>这些数据卷的名称对用户可见，可以随时引用和管理。</p></li><li><p>具名挂载通常用于保存应用程序的数据，例如数据库数据、配置文件等。</p></li><li><p>创建具名挂载可以使用<code>docker volume create</code>命令，或者在容器运行时通过<code>v</code>标志来指定。</p></li><li><p>例子：<code>docker run -v mydata:/app/data myapp</code>，其中<code>mydata</code>是具名挂载的名称。</p></li></ul><p><strong>2. 匿名挂载（Anonymous Volumes）：</strong></p><ul><li><p>匿名挂载是未命名的，不需要为其指定名称。</p></li><li><p>这些数据卷的名称由Docker自动生成，用户通常不需要直接操作它们。</p></li><li><p>匿名挂载通常用于容器内部的临时数据，例如日志文件或运行时状态。</p></li><li><p>匿名挂载通常在容器运行时通过<code>v</code>标志来创建，但不指定具体的卷名称。</p></li><li><p>例子：<code>docker run -v /app/data myapp</code>，其中<code>/app/data</code>是匿名挂载。</p></li></ul><p>无论使用具名挂载还是匿名挂载，数据卷都允许容器之间或容器与主机之间共享数据，并且在容器之间启动、停止和删除时，数据都会得到保留。这使得容器可以更灵活地管理和存储数据，而不受容器生命周期的限制。</p><p> # 匿名挂载<br> -v 容器内路径!<br> docker run -d -P –name nginx01 -v &#x2F;etc&#x2F;nginx nginx  </p><p> # 查看所有的volume的情况<br> ➜  ~ docker volume ls<br> DRIVER              VOLUME NAME<br> local               33ae588fae6d34f511a769948f0d3d123c9d45c442ac7728cb85599c2657e50d<br> local<br> # 这里发现，这种就是匿名挂载，我们在 -v只写了容器内的路径，没有写容器外的路劲！  </p><p> # 具名挂载<br> ➜  ~ docker run -d -P –name nginx02 -v juming-nginx:&#x2F;etc&#x2F;nginx nginx<br> ➜  ~ docker volume ls<br> DRIVER              VOLUME NAME<br> local               juming-nginx  </p><p> # 通过 -v 卷名：容器内路径<br> # 查看一下这个卷  </p><h3 id="2-数据卷容器（Data-Volume-Containers）："><a href="#2-数据卷容器（Data-Volume-Containers）：" class="headerlink" title="2. 数据卷容器（Data Volume Containers）："></a><strong>2. 数据卷容器（Data Volume Containers）：</strong></h3><h3 id="管理和存储数据卷的特殊容器"><a href="#管理和存储数据卷的特殊容器" class="headerlink" title="管理和存储数据卷的特殊容器"></a>管理和存储数据卷的特殊容器</h3><ul><li><p>数据卷容器是一种特殊类型的<strong>Docker容器</strong>，其主要目的是提供数据卷的存储和管理。它不运行应用程序，而只包含数据卷。</p></li><li><p>你可以创建一个数据卷容器，然后在其他容器中使用<code>-volumes-from</code>选项来共享这个数据卷容器的数据卷。</p></li><li><p>数据卷容器可以用于集中管理多个容器之间共享的数据，使得备份、恢复和数据共享更加方便。</p></li><li><p>示例：创建一个数据卷容器，然后在另一个容器中使用它的数据卷。</p><p>  docker create -v &#x2F;data –name my-data-container my-data-image<br>  docker run –volumes-from my-data-container my-app-container<br>  ​</p></li></ul><h3 id="docker-网络"><a href="#docker-网络" class="headerlink" title="docker 网络"></a>docker 网络</h3><h3 id="Docker网络是Docker容器之间通信的一种方式。"><a href="#Docker网络是Docker容器之间通信的一种方式。" class="headerlink" title="Docker网络是Docker容器之间通信的一种方式。"></a>Docker网络是Docker容器之间通信的一种方式。</h3><p><img src="/(/images/U4.png" alt="Untitled"></p><ol start="12"><li><p><strong>lo (回环接口)</strong>:</p><ul><li>IP地址：<code>127.0.0.1/8</code> -</li></ul></li><li><p><strong>eth0(阿里云内网地址）</strong></p><ul><li>IP地址：<code>172.23.91.165/20</code></li></ul></li><li><p><strong>docker0</strong>:</p><ul><li><p>用于在同一主机上的Docker容器之间进行通信。</p></li><li><p>IP地址：<code>172.17.0.1/16</code></p></li></ul><h3 id="veth-pair"><a href="#veth-pair" class="headerlink" title="veth-pair"></a>veth-pair</h3><p><code>veth</code> 是 Linux 中的虚拟以太网设备。它通常以对成对出现，每对之间存在一个虚拟的连接。这种连接一端被连接到宿主机的网络命名空间中，另一端被连接到一个容器的网络命名空间中。</p><p>具体来说：</p><ul><li><p>一端的 <code>veth</code> 设备（通常以 <code>vethXXXXXX</code> 的形式命名）会被放置在宿主机的网络命名空间中。</p></li><li><p>另一端会被分配给容器，并以另一个名称（通常是 <code>ethX</code>）存在于容器的网络命名空间中。</p></li></ul><p>这两端的 <code>veth</code> 设备相互连接，形成一个虚拟的以太网链路。这样，宿主机和容器就可以通过这个虚拟链路进行通信。</p></li></ol><p>Docker提供了多种网络模式，可以根据需要选择适合的网络配置。以下是一些常用的Docker网络概念和操作：</p><ol start="15"><li><p><strong>默认网络（bridge）</strong>:</p><ul><li><p>这是Docker的默认网络模式。在这种模式下，Docker容器可以相互通信，但通常不能直接从主机外部访问。默认情况下，容器会通过NAT方式连接到宿主机的网络。</p></li><li><p>创建一个容器并且默认会连接到这个网络：</p></li></ul><p>docker run -d –name my_container nginx<br>​</p><ul><li>默认网络的子网和网关可以通过以下命令查看：</li></ul><p>docker network inspect bridge<br>​</p></li><li><p><strong>主机网络（host）</strong>:</p><ul><li><p>使用主机网络模式，容器将直接共享主机的网络命名空间，这意味着容器将可以使用宿主机的网络接口，并且不会进行端口映射。</p></li><li><p>使用主机网络模式启动容器：</p></li></ul><p>docker run -d –network host nginx<br>​</p></li><li><p><strong>用户定义网络</strong>:</p><ul><li><p>用户可以创建自己的自定义网络，可以在这个网络上创建容器，并且容器可以相互通信。</p></li><li><p>创建一个自定义网络：</p></li></ul><p>docker network create my_network<br>​</p><ul><li>在自定义网络上运行容器：</li></ul><p>docker run -d –network my_network –name container1 nginx<br>docker run -d –network my_network –name container2 nginx<br>​</p></li><li><p><strong>覆盖网络（overlay）</strong>:</p><ul><li><p>覆盖网络允许在不同主机上的Docker守护程序之间创建跨主机的容器通信。这在Docker集群中很有用。</p></li><li><p>创建覆盖网络：</p></li></ul><p>docker network create –driver overlay my_overlay_network<br>​</p><ul><li>在覆盖网络上启动容器：</li></ul><p>docker service create –network my_overlay_network –name my_service nginx<br>​</p></li><li><p><strong>Macvlan网络</strong>:</p><ul><li><p>Macvlan网络允许将容器直接连接到物理网络，每个容器都有自己的MAC地址。</p></li><li><p>创建Macvlan网络：</p></li></ul><p>docker network create -d macvlan –subnet&#x3D;192.168.1.0&#x2F;24 –gateway&#x3D;192.168.1.1 -o parent&#x3D;eth0 my_macvlan_network<br>​</p><ul><li>在Macvlan网络上运行容器：</li></ul><p>docker run -d –network my_macvlan_network –name container1 nginx<br>​</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-SAA-C03题解思路</title>
      <link href="/2023/09/01/AWS-SAA-C03%E9%A2%98%E8%A7%A3%E6%80%9D%E8%B7%AF/"/>
      <url>/2023/09/01/AWS-SAA-C03%E9%A2%98%E8%A7%A3%E6%80%9D%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<h2 id="422-D"><a href="#422-D" class="headerlink" title="422-D"></a>422-D</h2><p>  一家公司正在 AWS 上开发新的机器学习 (ML) 模型解决方案。这些模型被开发为独立的微服务，在启动时从 Amazon S3 获取大约 1 GB 的模型数据并将数据加载到内存中。</p><p>  用户通过<strong>异步</strong> API 访问模型。用户可以发送一个请求或一批请求，并指定结果应发送到何处。该公司为数百名用户提供模型。模型的使用模式是不规则的。某些型号可能会闲置数天或数周。其他模型可以一次接收数千个批次的请求。<br>  解决方案架构师应该推荐哪种设计来满足这些要求？</p><p>  <strong>A</strong>. 将来自 API 的请求定向到NLB</p><p>  将模型部署为 NLB 调用的 AWS Lambda 函数。</p><p>  <strong>B</strong>. 将请求从 API 定向到ALB。将模型部署为从SQS 队列读取的  ECS 服务</p><pre><code> 使用 AWS App Mesh 根据 SQS 队列大小扩展 ECS 集群的实例。</code></pre><p>  <strong>C</strong>. 将来自 API 的请求定向到 SQS队列。将模型部署为由 SQS 事件调用的 AWS Lambda 函数</p><p>  使用 AWS Auto Scaling <strong>根据 SQS 队列大小</strong>增加 Lambda 函数的 vCPU 数量。</p><p>  <strong>D</strong>. 将来自 API 的请求定向到 SQS队列。将模型部署为从队列中读取的  ECS 服务。</p><p>  根据<strong>队列大小</strong>为集群和服务副本在 Amazon ECS 上启用 AWS Auto Scaling。</p><p>  <img src="/images/aws1.png" alt="在这里插入图片描述"></p><p>  ➡️ SQS队列是一种适用于<strong>异步</strong>消息传递的服务，可以帮助解耦和分离不同部分的系统，从而提高可靠性和弹性。</p><p>  ➡️ ALB非常适用于<strong>微服务</strong>和基于<strong>容器</strong>的应用程序,，但ALB和NLB更适合处理<strong>实时性请求</strong>，而不是异步处理。它们适用于传统的请求-响应式Web应用程序，其中客户端发出请求，然后期望快速获得响应。</p><p>  ➡️ ALB和NLB具有一些高级的负载均衡和路由功能，可以确保请求被迅速传递到后端实例并返回响应。</p><p>  Lambda函数通常用于处理短暂的、事件驱动的任务，在这个问题中，由于模型数据较大，需要在启动时从S3中加载，而且需要长时间运行，使用Lambda可能会受到限制，因为Lambda的运行时间有限制，而且加载1 GB的模型数据可能会造成延迟。</p><h2 id="330-A"><a href="#330-A" class="headerlink" title="330-A"></a>330-A</h2><p>  公司计划在Amazon RDS数据库实例上存储数据。公司必须对<strong>静态数据</strong>进行加密。解决方案架构师应采取什么措施来满足这个要求？</p><p>  A. 在AWS Key Management Service（<strong>AWS KMS</strong>）中创建一个密钥。启用数据库实例的加密。</p><p>  B. 创建一个加密密钥。将密钥存储在AWS Secrets Manager中。使用该密钥加密数据库实例。</p><p>  C. 在AWS Certificate Manager（ACM）中生成证书。使用该证书在数据库实例上启用SSL&#x2F;TLS。</p><p>  D. 在AWS Identity and Access Management（IAM）中生成证书。使用该证书在数据库实例上启用SSL&#x2F;TLS。</p><p>  当需要在Amazon RDS数据库实例上存储数据时，要求对这些数据进行加密，以保护数据的安全。在这种情况下，最适合的方法是：</p><p>  A. 在AWS Key Management Service（AWS KMS）中创建一个密钥，并启用数据库实例的加密。</p><p>  解释：</p><ul><li>AWS Key Management Service（KMS）是用于管理加密密钥的服务。</li><li>通过在AWS KMS中创建一个密钥并在数据库实例上启用加密，数据库实例中存储的数据将使用AWS KMS密钥进行自动加密，以确保数据在存储时得到加密保护。</li><li>这是<strong>在Amazon RDS实例上加密静态数据的标准和推荐方法</strong>。</li></ul><p>  AWS Secrets Manager用于管理敏感信息，但不推荐将其用于在Amazon RDS实例上对数据进行静态加密。</p><p>   AWS Certificate Manager（ACM）用于管理用于保护网络通信的SSL&#x2F;TLS证书，但与在Amazon RDS实例上对数据进行静态加密无直接关系。</p><p>  AWS Identity and Access Management（<strong>IAM</strong>）用于管理对AWS资源的访问，但在IAM中生成证书并不是对Amazon RDS实例上的数据进行静态加密的方法。</p><h2 id="338-D"><a href="#338-D" class="headerlink" title="338-D"></a>338-D</h2><p>  解决方案架构师必须为<strong>大容量</strong>软件即服务 (SaaS) 平台创建灾难恢复 (DR) 计划。该平台的<br>  所有数据都存储在 Amazon Aurora MySQL 数据库集群中。DR 计划必须将数据复制到辅助 AWS 区域。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <strong>A.</strong> 使用 MySQL 二进制日志复制到辅助区域中的 Aurora 集群。为辅助区域中的 Aurora<br>  集群配置一个数据库实例。</p><p>  <code>需要手动配置和管理二进制日志复制，可能需要更多的操作和维护。另外，如果主区域出现问题，需要手动干预来切换到辅助区域。</code></p><p>  <strong>B</strong>. 为数据库集群设置 Aurora global数据库。设置完成后，从辅助区域中删除数据库实例。</p><p>  <code>涉及更高的成本，因为需要在两个区域都配置 Aurora 数据库实例。</code></p><p>  <strong>C.</strong> 使用 AWS Database Migration Service (AWS DMS) 将数据持续复制到次要区域中的Aurora 集群。从次要区域中删除数据库实例。</p><p>  <code>与选项 A 类似，需要管理复制过程和可能的切换过程。</code></p><p>   <strong>D.</strong> 为数据库集群设置 Aurora global数据库。在次要区域中指定至少一个数据库实例</p><ul><li><p>343-C</p><p>解决方案架构师正在设计公司的灾难恢复 (DR) 架构。该公司拥有一个 MySQL 数据库，该数据库在私有子网中的 Amazon EC2 实例上运行，并具有计划备份。灾难恢复设计需要包括<strong>多个 AWS 区域multiple AWS Regions.</strong>。<br>哪种解决方案能够以最少的运营开销满足这些要求？</p><p><strong>A.</strong> 将 MySQL 数据库迁移到多个 EC2 实例。在 DR 区域配置备用 EC2 实例。打开复<br>制。</p><p><code>Multiple EC2 instances to be configured and updated manually手动地 in case of DR.</code></p><p><code>需要手动配置</code></p><p><strong>B.</strong> 将 MySQL 数据库迁移到 Amazon RDS。使用多可用区部署。为不同可用区中的主数据<br>库实例启用读取复制。<code>multi-AZ,题目要求multi region</code></p><p><strong>C.</strong> 将 MySQL 数据库迁移到 Amazon Aurora global数据库。在主区域中托管主数据库集群。<br>在 DR 区域中托管辅助数据库集群。</p><p><strong>D.</strong> 将 MySQL 数据库的计划备份存储在为 S3 跨区域复制 (CRR) 配置的 Amazon S3 存<br>储桶中。使用数据备份恢复灾备区域的数据库。</p><p><code>需要手动配置</code></p></li></ul><h2 id="348-B"><a href="#348-B" class="headerlink" title="348-B"></a>348-B</h2><p>  一家公司从大量使用可穿戴设备的参与者那里收集数据。该公司将数据存储在 Amazon<br>  DynamoDB 表中，并使用应用程序分析数据。数据工作量是<em><strong>恒定且可预测</strong></em>的。该公司希望将DynamoDB 的预算保持在或低于其预测。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <strong>A.</strong> 使用provisioned mode和 DynamoDB Standard-<strong>Infrequent Access</strong> (DynamoDB Standard-IA)。为预测的工作负载预留容量。</p><p>  <code>题目“使用应用程序分析数据”表明可能需要经常访问数据，不频繁访问不适合</code></p><p>  <strong>B</strong>. 使用provisioned mode模式。指定读取容量单位 (RCU) 和写入容量单位 (WCU)。</p><p>  <strong>C.</strong> 使用on-demand mode。将读取容量单位 (RCU) 和写入容量单位 (WCU) 设置得足够高，以适<br>  应工作负载的变化。</p><p>  <strong>D.</strong> 使用on-demand mode。指定具有保留容量的读取容量单位 (RCU) 和写入容量单位 (WCU)。</p><p>  <code>provisioned mode允许您为读取和写入容量单元（RCUs 和 WCUs）预先配置容量，适用于数据工作负载是持续且可预测的情况。</code></p><p>  <code>按需容量模式适用于具有*不稳定和不可预测*流量的应用程序</code></p><ul><li><p>357-A</p><p>一家游戏公司正在将其公共记分牌从<strong>数据中心迁移到 AWS 云</strong>。该公司在ALB后面使用 Amazon EC2 <strong>Windows Server</strong> 实例来托管其动态应用程序。该公司需要为应用程序提供高度可用的存储解决方案。该应用程序由<strong>静态文件</strong>和<strong>动态服务器端代码</strong>组成。解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p><strong>A.</strong> 将静态文件存储在 Amazon S3 上。使用 Amazon CloudFront 在边缘缓存对象。</p><p> B. 将静态文件存储在 Amazon S3 上。使用 Amazon ElastiCache 在边缘缓存对象。</p><p><code>ElastiCache 主要用于存储缓存数据，不适合存储静态文件。</code></p><p> C. 将服务器端代码存储在 Amazon Elastic File System (Amazon EFS) 上。在每个 EC2 实例上挂载<br>EFS 卷以共享文件。</p><p><code>EFS不适用于 Windows 实例。</code></p><p><strong>D.</strong> 将服务器端代码存储在 Amazon FSx for Windows File Server 上。在每个 EC2 实例上挂<br>载 FSx for Windows File Server 卷以共享文件。</p><p>E. 将服务器端代码存储在通用 SSD (gp2) Amazon Elastic Block Store (Amazon EBS) 卷上。<br>在每个 EC2 实例上挂载 EBS 卷以共享文件</p><p><code>EBS，用于块存储，不适合共享文件系统</code></p></li><li><p>359-C</p><p>医院需要将患者记录存储在 Amazon S3 存储桶中。医院的合规团队必须确保所有受保护的<br>健康信息 (PHI) <strong>encrypted in transit and at rest</strong>。合作<em><strong>团队必须管理静态数据的加密密钥</strong></em>。<br>哪种解决方案可以满足这些要求？</p><p>A. 在 AWS Certificate Manager (ACM) 中创建公共 SSL&#x2F;TLS 证书。将证书与 Amazon S3<br>关联。配置每个 S3 存储桶的默认加密，以使用带有 AWS KMS 密钥(SSE-KMS）的服务器端加密。分配合规团队来管理 KMS 密钥。</p><p><code>在桶策略上使用“aws:SecureTransport”条件---无法使用非加密的连接来访问存储桶内的数据，从而确保数据在传输过程中是安全加密的。</code></p><p><code>强制只有通过加密的连接（如 HTTPS/TLS）才能访问存储桶中的数据。</code><br>B. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 的加密连接。配置每个 S3 存储桶的默认加密，以使用带有 S3 托管加密密钥 (SSE-S3) 的服务器端加密。分配合规团队来管理 SSE-S3 密钥。</p><p><code>(SSE-S3) 是AWS来管理密钥</code></p><p>C. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 的加密连接。配置每个 S3 存储桶的默认加密，以使用带有 AWS KMS 密钥的服务器端加密(SSE-KMS)。分配合规团队来管理 KMS 密钥。</p><p><code>SSE-KMS是KMS管理密钥</code></p><p>D. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 进行加密连接。使用 Amazon Macie 保护存储在 Amazon S3 中的敏感数据。分配合规团队来管理</p><p><code>Macie只保护不加密</code></p></li><li><p>372-B</p><p>一家公司想要将 Oracle 数据库迁移到 AWS。该数据库由一个表组成，其中包含数百万张高分辨率的地理信息系统 (GIS) 图像，并通过地理代码进行识别。当自然灾害发生时，<strong>每隔几分钟就会更新数万张图像。每个地理代码都有一个与之相关联的图像或行<code>暗示着数据的频繁更新和变化</code>。</strong>。该公司希望有一个在此类事件期间具有高可用性和可扩展性的解决方案。<br>哪种解决方案最经济高效地满足这些要求？</p><p>A. 将图像和地理代码存储在数据库表中。使用在 Amazon RDS 多可用区数据库实例上运行的 Oracle。</p><p>B. 将图像存储在 Amazon S3 存储桶中。使用 Amazon DynamoDB，将地理代码作为键，将图像 S3 URL 作为值。</p><p><code>您可以将图像存储在高度可扩展的 Amazon S3 中，同时使用 DynamoDB 来快速检索地理代码和图像的映射关系。这种方式可以处理数据的频繁更新，同时也确保数据的可用性和可靠性。</code></p><p>C. 将图像和地理代码存储在 Amazon DynamoDB 表中。在高负载期间配置 DynamoDB<br>Accelerator (DAX)。</p><p><code>DAX没必要</code></p><p>D. 将图像存储在 Amazon S3 存储桶中。将地理代码和图像 S3 URL 存储在数据库表中。使用在 Amazon RDS 多可用区数据库实例上运行的 Oracle</p><p><code>将地理代码和图像 S3 URL 存储在数据库表中可能会导致**数据库过于庞大**，**降低性能和可维护性。**</code></p></li><li><p>379-B</p><p>一家公司托管一个使用与 AWS Lambda 集成的 Amazon API Gateway API 后端的前端应用程序.当 API 收到请求时，<strong>the Lambda function loads many libraries-Lambda 函数会加载许多库</strong>。然后，Lambda 函数连接到Amazon RDS 数据库，处理数据，并将数据返回到前端应用程序。该公司希望确保所有用户的响应延迟尽可能低，同时对公司运营的更改最少。<br>哪种解决方案可以满足这些要求？</p><aside>➡️ 在 AWS Lambda 中，当一个函数实例首次启动时，它需要加载执行所需的运行时环境、代码和依赖项（例如库、模块等）。这个过程被称为 "冷启动"。</aside><p>A. 在前端应用程序和数据库之间建立连接，绕过 API 使查询速度更快。</p><p><code>建议使用 API Gateway 来处理前端应用程序和数据库之间的交互。直接连接前端应用程序和数据库可能导致安全性和性能问题。</code></p><p>B. 配置处理请求的 Lambda 函数的并发性。</p><p>Congure <strong>provisioned concurrency</strong> for the Lambda function that handles the requests</p><p>确保有足够数量的 Lambda 函数实例一直处于活动状态，从而减少冷启动延迟，提高响应时间并降低用户的等待时间。</p><p>C. 在 Amazon S3 中缓存查询结果，以便更快地检索类似数据集。</p><p><code>Lambda 函数在每次请求时需要从数据库获取数据，然后进行处理，这可能会导致缓存的效果有限。</code></p><p>D. 增加数据库的大小以增加 Lambda 一次可以建立的连接数。</p><p><code>增加连接数并不一定会直接解决延迟问题</code></p></li><li><p>385-C</p><p>解决方案架构师正在创建新的 VPC 设计。有两个用于负载均衡器的公有子网、两个用于Web 服务器的私有子网和两个用于 MySQL 的私有子网。 Web 服务器仅使用 HTTPS。解决方案架构师已经为负载均衡器创建了一个安全组，允许来自 0.0.0.0&#x2F;0 的端口 443。公司政策要求每个资源具有仍能够执行其任务所需的<em><strong>最少访问权限</strong></em>。<br>解决方案架构师应使用哪种附加配置策略来满足这些要求？</p><p>A. 为 Web 服务器创建<strong>security group</strong>并允许来自 0.0.0.0&#x2F;0 的端口 443。为 MySQL 服务器创建<strong>security group</strong>，并允许 Web 服务器安全组的端口 3306。 </p><p>B. 为 Web 服务器创建<strong>NACL</strong>，并允许来自 0.0.0.0&#x2F;0 的端口 443。为 MySQL 服务器创建<strong>NACL</strong>，并允许来自 Web 服务器安全组的端口 3306。 </p><p>C. 为 Web 服务器创建<strong>security group</strong>并允许来自负载均衡器的端口443。为 MySQL 服务器创建<strong>security group</strong>,并允许 Web 服务器安全组的端口 3306。</p><p>D. 为 Web 服务器创建<strong>NACL</strong>，并允许来自负载均衡器的端口 443。为 MySQL 服务器创建<strong>NACL</strong>，并允许来自 Web 服务器安全组的端口 3306。</p><p>**<code>最少访问权限**：根据公司政策，每个资源应具有执行其任务所需的最少访问权限。因此，应该限制不必要的公开访问。安全组是在instance level控制流量的一种有效方式。</code></p><p><code>私有子网中Web,mysql需要从负载均衡器接收 HTTPS 流量。因此，为 Web 服务器创建一个安全组，仅允许来自负载均衡器的端口 443 的流量。</code></p></li></ul><h2 id="210-D"><a href="#210-D" class="headerlink" title="210-D"></a>210-D</h2><p>  一家公司提供的食品配送服务发展迅速。由于业务增长，该公司的订单处理系统在高峰时<br>  段遇到了扩展问题。当前的架构包括以下内容：<br>  • 在 Amazon EC2 Auto Scaling 组中运行的一组 Amazon EC2 实例，用于从应用程序收集订单 </p><p>  • 在 Amazon EC2 Auto Scaling 组中运行的另一组 EC2 实例，用于完整订单</p><p>  订单收集过程发生得很快，<strong>但订单履行过程可能需要更长的时间</strong>。数据不得因缩放事件而丢失。<br>  解决方案架构师必须确保订单收集流程和订单履行流程都可以在高峰时段适当扩展。该解决方案必须优化公司 AWS 资源的利用率。<br>  哪种解决方案满足这些要求？</p><p>  A. 使用 Amazon CloudWatch 指标监控 Auto Scaling 组中每个实例的 CPU。根据峰值工作<br>  负载值配置每个 Auto Scaling 组的最小容量。</p><p>  B. 使用 Amazon CloudWatch 指标监控 Auto Scaling 组中每个实例的 CPU。配置CloudWatch 警报以调用 Amazon Simple Notication Service (Amazon SNS) 主题，该主题根据需要创建其他 Auto Scaling 组。</p><p>  C. 预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例以轮询其各自的队列。根据队列发送的通知扩展 Auto Scaling 组。</p><p>  D. 预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例以轮询其各自的队列。根据每个实例的积压计算创建一个指标<strong>Create a metric based on a backlog per instance calculation</strong>, 根据此指标扩展 Auto Scaling 组&#x2F;</p><p>  <code>在每个 Amazon EC2 实例上计算一个指标，该指标反映了待处理的消息数量（即积压）。然后，根据这个指标来动态地调整 Auto Scaling 组中的实例数量。</code></p><p>  <code>SQS 队列充当订单收集流程和订单处理流程之间的缓冲，使系统能够更有效地处理突发的订单流量。</code></p><h2 id="218-AE"><a href="#218-AE" class="headerlink" title="218-AE"></a>218-AE</h2><p>  一家公司拥有一个在具有弹性 IP 地址的公有子网中的 Amazon EC2 实例上运行的 Web服务器。默认安全组分配给 EC2 实例。默认网络 ACL 已修改为阻止所有 trac。</p><p>  解决方案架构师需要使 Web 服务器可以<strong>通过端口 443 从任何地方访问</strong>。<br>  哪种步骤组合可以完成此任务？ （选择两个。）</p><p>  A. 创建一个安全组，其中包含允许来自源 0.0.0.0&#x2F;0 的 TCP 端口 443 的规则。</p><p>  B. 创建一个安全组，其中包含允许 TCP 端口 443 到达目标 0.0.0.0&#x2F;0 的规则。</p><p>  C. 更新网络 ACL 以允许来自源 0.0.0.0&#x2F;0 的 TCP 端口 443。</p><p>  D. 更新网络 ACL 以允许从源 0.0.0.0&#x2F;0 到目标 0.0.0.0&#x2F;0 的入站&#x2F;出站 TCP 端口 443。</p><p>  E. 更新网络 ACL 以允许从源 0.0.0.0&#x2F;0 的入站 TCP 端口 443 和到目标 0.0.0.0&#x2F;0 的出站<br>  TCP 端口 32768-65535。</p><p>  NACL是stateless，<strong>必须</strong>同时配置入站和出站规则。例如，如果你允许某个端口的入站流量，但没有相应的出站规则，那么服务器可能会接收请求，但由于出站规则的限制，无法正常发送响应。</p><ul><li><p>224-CE</p><p>一家公司最近通过在单个 AWS 区域的 Amazon EC2 实例上重新托管应用程序，将其 Web应用程序迁移到 AWS。该公司希望重新设计其应用程序架构，以实现高可用性和容错能力。 Trac 必须随机到达所有正在运行的 EC2 实例。<br>公司应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>A. 创建 Amazon Route 53 故障转移路由策略。<br>B. 创建 Amazon Route 53 加权路由策略。<br>C. 创建 Amazon Route 53 多值应答路由策略。</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td><em><strong>故障转移路由策略（Failover）</strong></em></td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td><em><strong>权重路由策略（Weighted）</strong></em></td><td>- 按照权重分配到不同资源</td></tr><tr><td><em><strong>多值路由策略（Multivalue）</strong></em></td><td>- 用于将流量路由到多个资源</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr></tbody></table><p>D. 启动三个 EC2 实例：两个实例位于一个可用区，一个实例位于另一个可用区。</p><p><code>考虑以下情况：</code></p><ul><li><code>如果一个可用区中的实例出现问题（如硬件故障），那么该可用区中的所有实例都将受到影响。</code></li><li><code>当只有一个实例在一个可用区中时，如果该可用区出现故障，会导致流量不能被完全分配。</code></li></ul><p>E. 启动四个 EC2 实例：一个可用区中的两个实例和另一个可用区中的两个实例。</p><p><code>这样做的好处在于：</code></p><ul><li><code>如果一个可用区中的一个实例出现问题，该可用区的另一个实例仍然可以处理流量，确保服务的持续可用性。</code></li><li><code>即使一个可用区完全失效，另一个可用区中的两个实例仍然可以处理流量，保证了更高的容错性和可用性。</code></li><li><code>由于每个可用区都有两个实例，流量在可用区之间更均匀地分布，从而提供更好的负载均衡。</code></li></ul></li></ul><h2 id="226-AE"><a href="#226-AE" class="headerlink" title="226-AE"></a>226-AE</h2><p>  一家公司使用在 Amazon EC2 实例上运行的 <strong>RESTful Web 服务应用程序</strong>从数千个远程设备收集数据。 EC2 实例<strong>接收</strong>原始数据，<strong>转换</strong>原始数据，并将所有数据存储在 Amazon S3存储桶中。远程设备的数量很快将增加到数百万。该公司需要一个高度可扩展的解决方案，最大限度地减少运营开销。<br>  解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>  <strong>A.</strong> 使用 AWS Glue 处理 Amazon S3 中的原始数据。</p><p>  <code>可扩展、无服务器的托管式数据集成、转换和加载服务。</code><br>  <strong>B.</strong> 使用 Amazon Route 53 将 trac 路由到不同的 EC2 实例。<br>  <strong>C.</strong> 添加更多 EC2 实例以适应不断增加的传入数据量。</p><p>  <strong>D.</strong> 将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。<br>  <strong>E.</strong> 使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流。配置 Amazon Kinesis Data Firehose 以使用数据流作为源将数据传输到 Amazon S3</p><p>  <code>Amazon API Gateway 是 AWS 提供的一项托管服务，用于创建、部署和管理 API。它可以用于实现 **RESTful web services**，即基于 REST 原则的应用程序架构风格。</code></p><h2 id="273-B"><a href="#273-B" class="headerlink" title="273-B"></a>273-B</h2><p>  一家快速发展的电子商务公司正在单个 AWS 区域中运行其工作负载。解决方案架构师必须创建包含**不同 AWS 区域【看清楚！是区域region，不是AZ可用区】**的灾难恢复 (DR) 策略。该公司希望其数据库在灾难恢复区域保持最新状态，并尽可能减少延迟。灾难恢复地区的剩余基础设施需要以减少的容量运行，并且必须能够在必要时扩大规模。<br>  哪种解决方案能够以最低的恢复时间目标 (RTO) 满足这些要求？</p><p>  <strong>A.</strong> 使用 Amazon Aurora 全局数据库进行pilot light deployment.。<br>  <strong>B.</strong> 使用具有warm standby deployment的 Amazon Aurora 全局数据库。</p><p>  <strong>C</strong>. 将 Amazon RDS 多<em><strong>可用区</strong></em>数据库实例与pilot light deployment.结合使用。<br>  <strong>D</strong>. 将 Amazon RDS 多<em><strong>可用区</strong></em>数据库实例与warm standby deployment结合使用</p><p>  <code>multi-AZ而不是cross region</code></p><blockquote><p><strong>Pilot Light</strong></p><ul><li>仅创建必需的基础设施</li><li>在灾难发生时，扩展这些核心组件以支持完整环境的恢复。</li></ul></blockquote><blockquote><p><strong>Warm Standby 温备策略</strong>：</p><ul><li><em><strong>部署比Pilot Light更多的基础设施</strong></em>，以便可以更快地切换为活动状态。在DR区域中维护一个较大的读副本，以减少灾难恢复时的启动时间。</li><li>可以快速扩展并恢复到完整环境。</li></ul></blockquote><h2 id="247-CE"><a href="#247-CE" class="headerlink" title="247-CE"></a>247-CE</h2><p>  一家公司在 Amazon RDS for MySQL 中部署了数据库。由于事务增加，数据库支持团队报告数据库实例读取速度缓慢，并建议添加只读副本。<br>  在实施此更改之前，解决方案架构师应采取哪些操作组合？ （选择两个。）</p><p>  A. 在 RDS 主节点上启用 binlog 复制。</p><p>  <code>确保主数据库的更改在各个实例间进行同步。</code></p><p>  B. 为源数据库实例选择故障转移优先级。</p><p>  <strong>C. 允许长时间运行的事务在源数据库实例上完成。</strong></p><p>  <code>确保在添加只读副本之前，所有事务都已经完成</code></p><p>  D. 创建全局表并指定该表可用的 AWS 区域。</p><p>  <strong>E. 通过将备份保留期设置为 0 以外的值，在源实例上启用自动备份。</strong></p><p>  <code>启用自动备份并设置备份保留期可以确保有备份可供恢复，以防在添加只读副本期间出现问题。</code></p><ul><li><p>289-B</p><p>一家公司有一个 AWS Lambda 函数，需要对位于同一 AWS 账户中的 Amazon S3 存储桶进行读取访问。<br>哪种解决方案能够以最安全的方式满足这些要求？</p><p>A. 应用授予对 S3 存储桶的读取访问权限的 S3 存储桶策略。</p><p><strong>B. 将 IAM 角色应用于 Lambda 函数。将 IAM 策略应用于角色以授予对 S3 存储桶的<br>读取访问权限。</strong></p><p><code>选项 B 使用更精细的权限控制方法，仅允许特定 Lambda 函数访问资源，而选项 A 是在存储桶级别上设置权限，可能不如选项 B 提供的安全性高。</code></p><p>C. 在 Lambda 函数的代码中嵌入访问密钥和秘密密钥，以授予对 S3 存储桶进行读取访问<br>所需的 IAM 权限。</p><p><code>将访问密钥和秘密密钥嵌入代码中是不安全的做法，因为这会暴露凭证并增加泄露风险，从而可能导致安全漏洞。</code></p><p>D. 将 IAM 角色应用于 Lambda 函数。将 IAM 策略应用于角色以授予对账户中<strong>所有 S3</strong><br>存储桶的读取访问权限。</p><p><code>提供了对**所有 S3 存储桶**的读取权限</code></p></li></ul><h2 id="3-A"><a href="#3-A" class="headerlink" title="3-A"></a>3-A</h2><p>  一家公司使用 AWS Organizations 管理不同部门的多个 AWS 账户。管理账户有一个包含项目报告的 Amazon S3 存储桶。该公司希望仅限 AWS Organizations 中组织内账户的用户访问此 S3 存储桶。哪种解决方案能够以最少的<em><strong>运营开销</strong></em>满足这些要求？</p><p>  <strong>A. 将 aws PrimaryOrgID  global condition key以及对organization ID 的引用添加到 S3 存储桶策略。</strong></p><p>  <code>在Condition元素中指定组织ID，而不是列出作为组织成员的所有帐户</code></p><p>  B. 为每个部门<em><strong>创建</strong></em>一个组织单位 (OU)。将 aws:PrincipalOrgPaths  global condition key添加到 S3存储桶策略。</p><p>  <code>基于AWS Organizations的组织结构来控制访问权限。您可以定义哪些部门、组织单元【OU】或账户可以访问特定资源。</code></p><p>  C. 使用 AWS CloudTrail 监控CreateAccount、InviteAccountToOrganization、LeaveOrganization 和RemoveAccountFromOrganization 事件。相应地更新 S3 存储桶策略。</p><p>  D. 标记需要访问 S3 存储桶的每个用户。将 aws:PrincipalTag  global condition key添加到 S3 存储桶策略。</p><p>  <code>它允许您根据附加到身份的标签（Tag）来控制访问权限。这可以用于根据用户、角色或实体的标签来限制访问。</code></p><h3 id="条件键【condition-keys】"><a href="#条件键【condition-keys】" class="headerlink" title="条件键【condition keys】"></a>条件键【condition keys】</h3><p>   **IAM advanced：**条件（Conditions）是一种用于增强访问策略的机制。通过在策略中添加条件，你可以进一步限制对 AWS 资源的访问，使访问控制更加精细和灵活。</p><h2 id="5-C"><a href="#5-C" class="headerlink" title="5-C"></a>5-C</h2><p>  一家公司使用单个 Amazon EC2 实例在 AWS 上托管 Web 应用程序，该实例将用户上传的文档存储在 Amazon EBS 卷中。为了获得更好的可扩展性和可用性，该公司复制了架构，并在<strong>另一个可用区中</strong>创建了第二个 EC2 实例和 EBS 卷，将两者放置在应用程序负载均衡器后面。完成此更改后，用户报告说，每次刷新网站时，他们都可以看到文档的一个子集或另一个子集，但永远不会同时看到所有文档。解决方案架构师应该提出什么建议来确保用户立即看到他们的所有文档？</p><h3 id="EBS不支持跨AZ共享文件"><a href="#EBS不支持跨AZ共享文件" class="headerlink" title="EBS不支持跨AZ共享文件"></a><code>EBS不支持跨AZ共享文件</code></h3><h3 id="只支持multi-attach-多重附加：Attach-the-same-EBS-volume-to-multiple-EC2-instances-in-the-same-AZ"><a href="#只支持multi-attach-多重附加：Attach-the-same-EBS-volume-to-multiple-EC2-instances-in-the-same-AZ" class="headerlink" title="只支持multi attach -多重附加：Attach the same EBS volume to multiple EC2 instances in the same AZ"></a>只支持multi attach -多重附加：Attach the same EBS volume to multiple EC2 instances <strong>in the same AZ</strong></h3><p>  Attach the same EBS volume to multiple EC2 instances <strong>in the same AZ</strong></p><p>  A. 复制数据，使两个 EBS 卷都包含所有文档</p><p>  B. 配置应用程序负载均衡器以将用户定向到包含文档的服务器 </p><p>  C. 将数据从两个 EBS 卷复制到 Amazon EFS。修改应用程序以将新文档保存到 Amazon EFS</p><p>  D. 配置应用程序负载均衡器以将请求发送到两台服务器。从正确的服务器返回每个文档</p><ul><li><p>12-A</p><p>一家跨国公司将其 Web 应用程序托管在应用程序负载均衡器 (<strong>ALB</strong>) 后面的 Amazon EC2实例上。 Web 应用程序有静态数据和动态数据。该公司将其静态数据存储在 Amazon S3存储桶中。该公司希望提高静态数据和动态数据的性能并减少延迟。该公司正在使用自己在 Amazon Route 53上注册的域名。解决方案架构师应该如何做才能满足这些要求？</p><p><code>ALB→ HTTP</code></p><p><code>Global Accelerator → 非HTTP</code><br>A. 创建以 S3 存储桶和 ALB 作为源的 Amazon CloudFront 分配。配置 Route 53 将 trac<br>路由到 CloudFront 分配。</p><p>ALB适用于HTTP流量，而global accelerator更适用于<em><strong>非HTTP</strong></em>,或者<em><strong>静态IP的HTTP流量</strong></em></p><p><img src="/images/aws2.png" alt="在这里插入图片描述"></p><p>B. 创建以 ALB 作为源的 Amazon CloudFront 分配。创建一个 AWS <strong><del>Global Accelerator</del></strong> 标准加速器，将 S3 存储桶作为终端节点 配置 Route 53 以将 trac 路由到 CloudFront 分配。</p><p>C. 创建以 S3 存储桶作为源的 Amazon CloudFront 分配。创建一个以 ALB 和 CloudFront分配作为终端节点的 AWS <strong><del>Global Accelerator</del></strong> 标准加速器。创建指向加速器 DNS 名称的自定义域名。使用自定义域名作为 Web 应用程序的端点。</p><p>D. 创建以 ALB 作为源的 Amazon CloudFront 分配。创建一个以 S3 存储桶作为终端节点的 AWS <strong><del>Global Accelerator</del></strong> 标准加速器。创建两个域名。将一个域名指向动态内容的CloudFront DNS 名称。将另一个域名指向静态内容的加速器 DNS 名称。使用域名作为<br>Web 应用程序的端点</p></li></ul><h2 id="51-BD"><a href="#51-BD" class="headerlink" title="51-BD"></a>51-BD</h2><p>  一家公司正在开发一个应用程序，该应用程序提供订单运输统计信息以供 REST API 检索。该公司希望提取运输统计数据，将数据组织成易于阅读的 HTML 格式，并每天早上同时将报告发送到多个电子邮件地址。解决方案架构师应该采取哪些步骤组合来满足这些要求？（选择两个。）</p><p>  A. 配置应用程序以将数据发送到 Amazon Kinesis Data Firehose。</p><p>  <code>Firehose =&gt; 流式传输</code></p><p>  B. 使用 Amazon Simple Email Service (Amazon <strong>SES</strong>) 格式化数据并通过电子邮件发送报告。</p><p>  C. 创建一个 Amazon EventBridge (Amazon CloudWatch Events) 计划事件，该事件调用<br>  <strong>AWS Glue</strong> 作业来查询应用程序的 API 中的数据。</p><p>  <code>Glue = ETL 服务：数据抽取、转换和加载不能查询</code></p><p>  D. 创建一个 Amazon EventBridge (Amazon CloudWatch Events) 计划事件，该事件调用AWS <strong>Lambda 函数</strong>来查询应用程序的 API 中的数据。 </p><p>  <code>EventBridge = 定时事件，Lambda = 查询 API 获取数据的函数</code></p><p>  E. 将应用程序数据存储在 Amazon S3 中。创建 Amazon Simple Notation Service (Amazon <strong>SNS</strong>) 主题作为 S3 事件目标以通过电子邮件发送报告。</p><p>  <code>SNS只可以发送简单文本邮件，HTML email需要通过SES</code></p><h2 id="56-C"><a href="#56-C" class="headerlink" title="56-C"></a>56-C</h2><p>  一家公司已在 Amazon Route 53 中注册了其域名。该公司使用 ca-central-1 区域中的Amazon API Gateway 作为其后端微服务 API 的公共接口。第三方服务安全地使用 API。该公司希望使用该公司的域名和相应的证书来设计其 API 网关 URL，以便第三方服务可以使用 HTTPS。哪种解决方案可以满足这些要求？</p><blockquote><p>当我在一个电商公司工作时，我们有一个复杂的在线商城应用。这个应用包含了很多功能，比如用户注册、浏览商品、下订单、付款等等。为了让开发和维护变得更容易，我们采用了后端微服务 API 的架构。</p></blockquote><p>  <strong>Amazon API Gateway可以帮助管理和保护API，并将不同的后端服务整合到一个统一的接口中。</strong></p><blockquote><p>每个功能模块都被拆分成独立的微服务，比如有一个用户服务处理用户注册和登录，有一个订单服务处理订单的创建和查询，有一个支付服务处理付款操作等等。每个微服务都有自己的数据库和逻辑，它们可以独立开发和部署。</p></blockquote><blockquote><p>现在，为了使我们的电商应用更加安全和高效，我们决定要求<strong>所有的请求都通过 HTTPS 进行安全通信</strong>，并<strong>使用我们公司的域名来访问这些微服务</strong>。我们已经在 Amazon Route 53 注册了公司域名，比如 “<a href="http://example.com/">example.com</a>“。我们<strong>希望用户能够通过类似 “<a href="http://api.example.com/">api.example.com</a>“ 的 URL 访问我们的后端微服务。</strong></p></blockquote><hr><p>  为了实现这个目标，我们采用了选项 C 的解决方案：</p><ol><li>在 AWS 的 “ca-central-1” 区域创建了一个 API Gateway 终端节点，作为我们后端微服务的入口。</li><li>然后，我们将 “<a href="http://api.example.com/">api.example.com</a>“ 域名与这个 API Gateway 终端节点关联起来，这样用户就可以通过这个自定义的域名来访问我们的 API。</li><li>我们导入了<strong>与 “<a href="http://api.example.com/">api.example.com</a>“ 域名关联的公共 SSL&#x2F;TLS 证书</strong>到 AWS Certificate Manager（ACM）中。</li><li>我们将这个证书附加到了 API Gateway 终端节点，从而确保通过 HTTPS 实现了安全的通信。</li><li>最后，我们使用 Amazon Route 53 配置 DNS 记录，将流量从 “<a href="http://api.example.com/">api.example.com</a>“ 域名路由到我们的 API Gateway 终端节点，这样用户就可以使用这个域名来访问我们的微服务，并享受到 HTTPS 提供的安全通信。</li></ol><p>  A. 在 API Gateway 中创建 Name&#x3D;”Endpoint-URL” 和 Value&#x3D;”公司域名” 的阶段变量以覆盖默认 URL。将与公司域名关联的公共证书导入到 AWS Certicate Manager (ACM)。</p><p>  B. 使用公司域名创建 Route 53 DNS 记录。将别名记录指向区域 API 网关阶段端点。将与公司域名关联的公共证书导入到 <strong>us-east-1</strong> 区域中的 AWS Certicate Manager (ACM) 中。</p><p>  C. 创建区域 API 网关端点。将 API 网关端点与公司域名关联。将与公司域名关联的公共证书导入到<strong>同一区域中</strong>的 AWS Certicate Manager (ACM) 中。将证书附加到 API 网关端点。配置 Route 53 将 trac 路由到 API 网关终端节点。</p><p>  D. 创建区域 API 网关端点。将 API 网关端点与公司域名关联。将与公司域名关联的公共证书导入到 <strong>us-east-1</strong> 区域中的 AWS Certicate Manager (ACM) 中。将证书附加到 API 网关 API。使用公司的域名创建 Route 53 DNS 记录。将 A 记录指向公司的域名。</p><h2 id="74-AC"><a href="#74-AC" class="headerlink" title="74-AC"></a>74-AC</h2><p>  解决方案架构师正在设计一个两层 Web 应用程序。该应用程序由托管在公有子网中的Amazon EC2 上的<strong>面向公众的 Web 层</strong>组成。数据库层由在<strong>私有子网</strong>中的 Amazon EC2 上运行的 Microsoft SQL Server 组成。安全是公司的重中之重。在这种情况下应该如何配置安全组？ （选择两个。）<br>  <strong>A. 配置 Web 层的安全组以允许端口 443 上来自 0.0.0.0&#x2F;0 的入站跟踪。</strong></p><p>  Web Server Rules: Inbound traffic from 443 (HTTPS) Source 0.0.0.0&#x2F;0 - Allows inbound HTTPS access from any IPv4 address</p><p>  B. 配置 Web 层的安全组以允许端口 443 上来自 0.0.0.0&#x2F;0 的出站跟踪。</p><p>  <strong>C. 配置数据库层的安全组以允许端口 1433 上来自 Web 层的安全组的入站跟踪。</strong></p><p>  Database Rules : 1433 (MS SQL)The default port to access a Microsoft SQL Server database, for example, on an Amazon RDS instance</p><p>  D. 配置数据库层的安全组以允许端口 443 和 1433 上的出站跟踪到 Web 层的安全组。</p><p>  E. 配置数据库层的安全组以允许来自 Web 层安全组的端口 443 和 1433 上的入站跟踪。</p><h2 id="95-D"><a href="#95-D" class="headerlink" title="95-D"></a>95-D</h2><p>  应用程序允许公司总部的用户访问产品数据。产品数据存储在 Amazon RDS MySQL 数据库实例中。运营团队<strong>已隔离应用程序性能下降问题</strong>，并<strong>希望将读取跟踪与写入跟踪分开</strong>。解决方案架构师需要快速优化应用程序的性能。解决方案架构师应该推荐什么？</p><p>  A. 将现有数据库更改为多可用区部署。服务来自the primary Availability Zone.的读取请求。<br>  B. 将现有数据库更改为多可用区部署。服务来自the secondary Availability Zone的读取请求。</p><p>  <code>A+B out this is not Aurora</code></p><p>  <strong>Aurora全球数据库（推荐）：</strong></p><ul><li>1个primary <strong>region</strong>（读&#x2F;写）</li><li>最多5个secondary region (read-only），复制延迟(replication lag)小于1秒</li></ul><p>  C. 为数据库创建只读副本。将一半计算和存储资源的只读副本配置为源数据库。<br>  D. 为数据库创建只读副本。为只读副本配置与源数据库相同的计算和存储资源。</p><p>  <code>D seems ok   D. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.</code></p><h2 id="97-D"><a href="#97-D" class="headerlink" title="97-D"></a>97-D</h2><p>  一家公司有一个在本地运行的大型 Microsoft SharePoint 部署，需要 Microsoft Windows <strong>共享文件存储</strong>。该公司希望将此工作负载迁移到 AWS 云，并正在考虑各种存储选项。存储解决方案必须具有高可用性，并与 Active Directory 集成以进行访问控制。哪种解决方案可以满足这些要求？</p><p>  <del>A.</del> 配置 Amazon EFS 存储并设置用于身份验证的 Active Directory 域。</p><p>  <code>EFS is for Linux</code></p><p>  <code>没有专门针对 Windows 文件共享进行优化,而是多个instance之间共享</code></p><p>  B. 在两个可用区的 AWS Storage Gateway 文件网关上创建 SMB 文件共享。</p><p>  <code>适合需要较低要求的文件存储工作负载</code></p><p>  <del>C.</del> 创建Amazon S3 存储桶并配置 Microsoft Windows Server 以将其挂载为卷。</p><p>  <code>S3 存储桶虽然也可以用来存储文件，但它不是直接提供 Windows 文件共享功能的解决方案。</code></p><p>  <strong>D. 在 AWS 上创建 Amazon FSx for Windows File Server 文件系统并设置用于身份验证的<br>  Active Directory 域。</strong></p>  <aside>  📌 Active Directory 域是一种用于管理和组织网络资源的目录服务，它提供了对用户、计算机和其他资源的统一身份验证和访问控制。  </aside><h2 id="101-A"><a href="#101-A" class="headerlink" title="101-A"></a>101-A</h2><p>  解决方案架构师正在设计具有公有子网和私有子网的 VPC。 VPC 和子网使用 IPv4 CIDR块。三个可用区 (AZ) 中各有 1 个公有子网和 1 个私有子网，以实现高可用性。 Internet网关用于为公共子网提供 Internet 访问。私有子网需要访问互联网才能允许 Amazon EC2实例下载软件更新。解决方案架构师应该怎样做才能实现私有子网的 Internet 访问？</p><p>  非VPC（公共互联网）流量<br>  A. 创建三个 <strong>NAT 网关</strong>，每个可用区中的每个公有子网一个。为每个可用区创建私有路由<br>  表，将非 VPC trac 转发到其可用区中的 NAT 网关。</p><p>  B. 创建三个 <strong>NAT 实例</strong>，每个可用区中的每个私有子网一个。为每个可用区创建私有路由<br>  表，将非 VPC trac 转发到其可用区中的 NAT 实例。</p><p>  <code>NAT实例较旧，可扩展性较差</code></p><p>  C. 在其中一个私有子网上创建第二个 <strong>Internet 网关</strong>。更新将非 VPC 跟踪转发到私有<br>  Internet 网关的私有子网的路由表。</p><p>  <code>不安全，导致整个私有子网的流量直接流向互联网</code></p><p>  D. 在公共子网上之一创建egress-only internet gateway<strong>仅出口 Internet 网关</strong>。更新将非 VPC 跟踪转发到仅出口 Internet网关的私有子网的路由表</p><p>  <code>出站专用互联网网关是为IPv6-only VPC设计的，不适用于基于IPv4的资源实现出站互联网连接。</code></p><h2 id="108-A"><a href="#108-A" class="headerlink" title="108-A"></a>108-A</h2><p>  一家公司拥有一个汽车销售网站，该网站将其列表存储在 Amazon RDS 的数据库中。当汽车出售时，需要从网站上删除列表，并且数据必须发送到多个目标系统。解决方案架构师应该推荐哪种设计？</p><p>  <strong>A. 创建一个在 Amazon RDS 上的数据库更新时触发的 AWS Lambda 函数，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) 队列以供目标使用。</strong></p><p>  B. 创建一个 AWS Lambda 函数，该函数在 Amazon RDS 上的数据库更新时触发，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列以供目标使用。</p><p>  <code>不需要顺序处理</code></p><p>  C. 订阅 <strong>RDS 事件通知</strong>并将 Amazon Simple Queue Service (Amazon SQS) 队列发送到多个Amazon Simple Notication Service (Amazon SNS) 主题。使用 AWS Lambda 函数更新目标。</p><p>  <code>RDS 事件通知主要适用于数据库的操作事件（例如快照、参数组更改等），不适用于数据**修改**事件。</code></p><p>  D. 订阅 RDS 事件通知并将 Amazon Simple Notication Service (Amazon SNS) 主题发送到多个 Amazon Simple Queue Service (Amazon SQS) 队列。使用 AWS Lambda 函数更新目标。</p><p>  <code>Amazon RDS事件通知主要用于通知与数据库管理和运维相关的事件，如数据库实例的创建、启动、停止、备份完成等。</code></p><p>  <code>数据库 内容更改无法通知</code></p><h2 id="131-D"><a href="#131-D" class="headerlink" title="131-D"></a>131-D</h2><p>  一家公司正在开发一个文件共享应用程序，该应用程序将使用 Amazon S3 存储桶进行存储。该公司希望通过 Amazon CloudFront 发行版提供所有文件。该公司不希望通过直接导航到 S3 URL 来访问这些文件。解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 为每个 S3 存储桶编写单独的策略，以仅授予 CloudFront 访问的读取权限。<br>  B. 创建 IAM 用户。授予用户对 S3 存储桶中对象的读取权限。将用户分配到CloudFront。<br>  C. 编写一个 S3 存储桶策略，将 CloudFront 分配 ID 分配为主体，并将目标 S3 存储桶分配为 Amazon 资源名称 (ARN)。</p><p>  D. 创建源访问身份 (OAI)。将 OAI 分配给 CloudFront 分配。配置 S3 存储桶权限，仅OAI 具有读取权限。<br>  正确答案：D</p><h2 id="132-A"><a href="#132-A" class="headerlink" title="132-A"></a>132-A</h2><p>  一家公司的网站为用户提供可下载的<strong>历史</strong>绩效报告。该网站需要一个能够扩展的解决方案，以满足公司在全球范围内的网站需求。该解决方案应该具有成本效益，限制基础设施资源的配置，并提供尽可能最快的响应时间。解决方案架构师应该推荐哪种组合来满足这些要求？</p><p>  <code>historical reports ⇒ static content ⇒ S3</code></p><p>  A. Amazon CloudFront 和 Amazon S3<br>  B.AWS Lambda 和 Amazon DynamoDB<br>  C. 使用 Amazon EC2 Auto Scaling 的应用程序负载均衡器<br>  D. 具有内部应用程序负载均衡器的 Amazon Route 53</p><h2 id="133-C"><a href="#133-C" class="headerlink" title="133-C"></a>133-C</h2><p>  一家公司在本地运行 Oracle 数据库。作为公司迁移到 AWS 的一部分，该公司希望将数据库升级到最新的可用版本。该公司还希望为数据库设置灾难恢复（DR）。公司需要最大限度地减少正常运营和灾难恢复设置的运营开销。<em><strong>该公司还需要维护对数据库底层操作系统的访问</strong></em>。哪种解决方案可以满足这些要求？</p><p>  A. 将 Oracle 数据库迁移到 Amazon <del>EC2 实例</del>。设置数据库复制到不同的 AWS 区域。</p><p>  B. 将 Oracle 数据库迁移到 Amazon RDS for Oracle。激活跨区域自动备份以将快照复制到<br>  另一个 AWS 区域。</p><p>  C. 将 Oracle 数据库迁移到 Amazon RDS Custom for Oracle。为另一个 AWS <strong>区域</strong>中的数<br>  据库创建只读副本。</p><p>  **<code>*RDS Custom***可以访问底层操作系统，并且提供较少的操作开销。另一个 region的读副本也可以用于容灾活动</code></p><p>  <code>只读副本可以晋升为独立的数据库</code></p><p>  D. 将 Oracle 数据库迁移到 Amazon RDS for Oracle。在另一个可用区创建备用数据库。</p><h2 id="136-AC"><a href="#136-AC" class="headerlink" title="136-AC"></a>136-AC</h2><p>  一家公司正在将其本地 PostgreSQL 数据库迁移到 Amazon Aurora PostgreSQL。<strong>本地数据库必须在迁移期间保持在线且可访问</strong>。 Aurora 数据库必须与本地数据库<strong>保持同步</strong>。解决方案架构师必须采取哪些操作组合才能满足这些要求？ （选择两个。）</p><p>  A. 创建<strong>持续复制任务ongoing replication task</strong>。</p><p>  <code>设置一种机制来持续地将源数据库的变更（如新增、更新、删除等操作）复制到目标数据库中，以保持两个数据库之间的数据**同步**。</code><br>  B. 创建本地数据库的数据库备份。<br>  C. 创建 AWS Database Migration Service (AWS DMS) 复制服务器。</p><p>  <code>迁移过程始终可用</code><br>  D. 使用 AWS Schema Conversion Tool (AWS SCT) 转换数据库架构。<br>  E. 创建 Amazon EventBridge (Amazon CloudWatch Events) 规则来监控数据库同步。</p><h2 id="301-C"><a href="#301-C" class="headerlink" title="301-C"></a>301-C</h2><p>  某大学研究实验室需要将 30 TB 数据从本地 Windows 文件服务器迁移到 Amazon FSx for<br>  Windows File Server。该实验室拥有 1 Gbps 的网络链路，与大学的许多其他部门共享。该实验室希望实施一项数据迁移服务，以最大限度地提高数据传输的性能。然而，实验室需要能够控制服务使用的带宽量，以尽量减少对其他部门的影响。数据迁移必须在接下来的 5 天内进行。<br>  哪种 AWS 解决方案能够满足这些要求？</p><p>  <del>A.AWS Snowcone</del></p><p>  B.Amazon FSx 文件网关</p><p>  <strong>C.AWS 数据同步</strong></p><p>  D. AWS 传输系列</p><p>  <code>不支持Windows</code></p><h2 id="308-BD"><a href="#308-BD" class="headerlink" title="308-BD"></a>308-BD</h2><p>  一家公司拥有多个使用合并账单的 AWS 账户。该公司为 Oracle 按需数据库实例运行多<br>  个活动高性能 Amazon RDS 90 天。该公司的财务团队可以访问<strong>合并计费账户</strong>和所有其他<br>  AWS 账户中的 AWS Trusted Advisor。<br>  财务团队需要使用适当的 AWS 账户来访问 RDS 的 Trusted Advisor 检查建议。财务团队<br>  必须审查适当的 Trusted Advisor 检查以降低 RDS 成本。<br>  财务团队应采取哪些步骤组合来满足这些要求？ （选择两个。）<br>  A. 使用运行 RDS 实例的账户中的 Trusted Advisor 建议。<br>  B. 使用合并计费帐户中的 Trusted Advisor 建议同时查看所有 RDS 实例检查。<br>  C. 查看 Trusted Advisor 检查 Amazon RDS 预留实例优化。<br>  D. 查看 Trusted Advisor 检查 Amazon RDS 空闲数据库实例。 </p><p>  E. 查看 Trusted Advisor 检查 Amazon Redshift 预留节点优化。</p><h2 id="309-A"><a href="#309-A" class="headerlink" title="309-A"></a>309-A</h2><p>  解决方案架构师需要优化存储成本。解决方案架构师必须识别不再被访问或很少访问的任何 Amazon S3 存储桶。<br>  哪种解决方案能够以最少的运营开销实现这一目标？</p><p>  <strong>A. 使用 S3 Storage Lens 仪表板来分析存储桶访问模式以获取高级活动指标。</strong><br>  B. 使用 AWS 管理控制台中的 S3 仪表板分析存储桶访问模式。<br>  C. 打开存储桶的 Amazon CloudWatch BucketSizeBytes 指标。通过使用 Amazon Athena 的<br>  指标数据来分析存储桶访问模式。<br>  D. 打开 AWS CloudTrail 以进行 S3 对象监控。使用与 Amazon CloudWatch Logs 集成的<br>  CloudTrail 日志分析存储桶访问模</p><h2 id="310-B"><a href="#310-B" class="headerlink" title="310-B"></a>310-B</h2><p>  一家公司向从事人工智能和机器学习 (AI&#x2F;ML) 研究的客户出售数据集。数据集是大型格式化文件，存储在 us-east-1 区域的 Amazon S3 存储桶中。该公司托管一个 Web 应用程序，客户可以使用该应用程序购买给定数据集的访问权限。 Web 应用程序部署在应用程序负载均衡器后面的多个 Amazon EC2 实例上。购买后，客户会收到一个 S3 签名的 URL，允许访问这些文件。</p><p>  客户遍布北美和欧洲。该公司希望<strong>降低与数据传输相关的成本，并希望维持或提高性能</strong>。<br>  解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 在现有 S3 存储桶上配置 <del>S3 传输加速</del>。将客户请求定向到 S3 Transfer Acceleration 端点。继续使用 S3 签名 URL 进行访问控制。</p><p>  <strong>B. 使</strong>用现有 S3 存储桶作为源部署 Amazon CloudFront 分配。将客户请求定向到CloudFront URL。切换到 CloudFront 签名 URL 进行访问控制。</p><p>  C. 在 eu-central-1 区域中设置第二个 S3 存储桶，并在存储桶之间进行 S3 <strong>跨区域复制</strong>。将客户请求直接发送至最近的区域。继续使用 S3 签名 URL 进行访问控制。</p><p>  <code>跨区域复制（CRR）或同区域复制（SRR），只有在激活复制后**创建的新对象会被复制**到目标存储桶，而不会追溯复制旧对象。</code></p><p>  D. 修改 Web 应用程序以<del>将数据集流式传输给最终用户</del>。配置 Web 应用程序以从现有 S3<br>  存储桶读取数据。直接在应用程序中实施访问控制。</p><h2 id="314-B"><a href="#314-B" class="headerlink" title="314-B"></a>314-B</h2><p>  一家公司拥有一个本地 MySQL 数据库，供全球销售团队使用，且访问模式不频繁。销售团队要求数据库的停机时间最少。数据库管理员希望将此数据库迁移到 AWS，<strong>而不选择特定实例类型</strong>，以应对未来更多用户的需求。<br>  解决方案架构师应该推荐哪种服务？</p><p>  A. Amazon Aurora MySQL<br>  B. 适用于 MySQL 的 Amazon Aurora Serverless</p><p>  <strong><code>&quot;without selecting a particular instance type&quot; = serverless</code></strong><br>  C.Amazon Redshift Spectrum<br>  D. 适用于 MySQL 的 Amazon RDS</p><h2 id="319-A"><a href="#319-A" class="headerlink" title="319-A"></a>319-A</h2><p>  一家公司在 AWS 云中拥有数百个基于 Linux 的 Amazon EC2 实例。系统管理员使用共<br>  享 SSH 密钥来管理实例。经过最近的审计后，该公司的安全团队要求删除所有共享密钥。<br>  解决方案架构师必须设计一个能够提供对 EC2 实例的安全访问的解决方案。<br>  哪种解决方案能够以最少的管理开销满足此要求？</p><p>  A. 使用 AWS Systems Manager 会话管理器连接到 EC2 实例。<br>  B. 使用 AWS Security Token Service (AWS STS) 按需生成一次性 SSH 密钥。<br>  C. 允许对一组堡垒实例进行共享 SSH 访问。将所有其他实例配置为仅允许来自堡垒实例<br>  的 SSH 访问。<br>  D. 使用 Amazon Cognito 自定义授权方对用户进行身份验证。调用 AWS Lambda 函数来<br>  生成临时 SSH 密钥。</p><h2 id="325-A"><a href="#325-A" class="headerlink" title="325-A"></a>325-A</h2><p>  一家公司正在托管 Amazon S3 存储桶中的 Web 应用程序。该应用程序使用 Amazon Cognito 作为身份提供商来对用户进行身份验证并返回 JSON Web 令牌 (JWT)，该令牌提供对存储在另一个 S3 存储桶中的受保护资源的访问权限。<br>  部署应用程序后，用户报告错误并且无法访问受保护的内容。解决方案架构师必须通过提<br>  供适当的权限来解决此问题，以便用户可以访问受保护的内容。<br>  哪种解决方案满足这些要求？</p><p>  <strong>A.</strong> 更新 Amazon Cognito 身份池以承担适当的 IAM 角色来访问受保护的内容。</p><p>  <code>在 Amazon Cognito 身份池中配置一个 IAM 角色，该角色具有访问另一个 S3 存储桶中资源所需的权限。</code></p><p>  B. 更新 S3 ACL 以允许应用程序访问受保护的内容。</p><p>  C. 将应用程序重新部署到 Amazon S3，以防止 S3 存储桶中的最终一致性读取影响用户访问受保护内容的能力。</p><p>  D. 更新 Amazon Cognito 池以使用身份池中的自定义属性映射，并授予用户访问受保护内容的适当权限。</p><p>  <code>即使使用了自定义属性映射，也需要通过适当的 IAM 角色来管理访问权限，以确保一致的身份验证和授权过程。</code></p><h2 id="454-C"><a href="#454-C" class="headerlink" title="454-C"></a>454-C</h2><p>  一家公司拥有<strong>跨多个 AWS 区域和账户</strong>的资源。新雇用的解决方案架构师发现以前的员工没有提供有关资源库存的详细信息。解决方案架构师需要构建和映射所有帐户中各种工作负载的关系详细信息。<br>  哪种解决方案能够以最高效的方式满足这些要求？</p><p>  A. 使用 AWS Systems Manager Inventory 从详细视图报告生成地图视图。</p><p>  <code>用于收集关于操作系统和应用程序的信息，不适用于构建工作负载关系图。</code></p><p>   B. 使用 AWS Step Functions 收集工作负载详细信息。手动构建工作负载的架构图。</p><p>  <code>Step Functions 可用于编排和协调不同服务的工作流</code><br>  <strong>C. 使用 AWS 上的工作负载发现生成工作负载的架构图。</strong></p><p>  <code>在跨多个 AWS 区域和账户拥有资源的情况下，最高效的方法是使用 AWS 上的工作负载发现来生成工作负载的架构图。</code><br>  D. 使用 AWS X-Ray 查看工作负载详细信息。构建具有关系的架构图。<br>  <code>AWS X-Ray 是用于分析和调试分布式应用程序的服务</code></p><h2 id="455-ADF"><a href="#455-ADF" class="headerlink" title="455-ADF"></a>455-ADF</h2><p>  一家公司使用 AWS Organizations。该公司希望以不同的预算来运营其一些 AWS 账户。该公司希望在特定时间段内达到分配的预算阈值时接收警报并自动阻止在 AWS 账户上配置额外资源。<br>  哪种解决方案组合可以满足这些要求？ （选择三项。）</p><p>  A. 使用 AWS Budgets 创建预算。在所需 AWS 账户的成本和使用情况报告部分下设置预<br>  算金额。</p><p>  B. 使用 AWS Budgets 创建预算。在所需 AWS 账户的账单仪表板下设置预算金额。</p><p>  C. 为 AWS Budgets 创建 IAM **用户，**以使用所需权限运行预算操作。</p><p>  D. 为 AWS Budgets创建 IAM <strong>角色</strong>，以使用所需权限运行预算操作。 </p><p>  E. 添加警报，以便在每个帐户达到其预算阈值时通知公司。添加预算操作，选择使用适当的 cong 规则创建的 IAM 身份，以防止配置额外资源。</p><p>  F. 添加警报，以便在每个帐户达到其预算阈值时通知公司。添加预算操作，选择使用适当<br>  的服务控制策略 (SCP) 创建的 IAM 身份，以防止配置额外资源。<br>   <code>Organizations中SCP</code></p><h2 id="457-C"><a href="#457-C" class="headerlink" title="457-C"></a>457-C</h2><p>  一家使用 AWS 的公司正在构建一个应用程序来将数据传输给产品制造商。该公司拥有自<br>  己的身份提供商 (IdP)。该公司希望 IdP 在用户使用应用程序传输数据时对应用程序用户<br>  进行身份验证。公司必须使用适用性声明 2 <strong><code>(AS2)</code></strong> 协议。<br>  哪种解决方案可以满足这些要求？</p><p>  A. 使用 AWS DataSync 传输数据。创建用于 IdP 身份验证的 AWS Lambda 函数。<br>  B. 使用 Amazon AppFlow 流传输数据。创建用于 IdP 身份验证的 Amazon Elastic Container<br>  Service (Amazon ECS) 任务。<br>  C. 使用 AWS Transfer Family 传输数据。创建用于 IdP 身份验证的 AWS Lambda 函数。</p><p>   <strong><code>(AS2)</code></strong><br>  D. 使用 AWS Storage Gateway 传输数据。创建用于 IdP 身份验证的 Amazon Cognito 身份池。<br>  正确答案：C</p><h2 id="458-BC"><a href="#458-BC" class="headerlink" title="458-BC"></a>458-BC</h2><p>  解决方案架构师正在 Amazon API Gateway 中设计 RESTAPI 以实现现金回报服务。该应用程序需要 1 GB 内存和 2 GB 存储空间用于其计算资源。</p><p>  <strong>应用程序将要求数据采用关系格式The application will require that the data is in a relational format.</strong>。<br>  哪种额外的 AWS 服务组合能够以最少的管理工作满足这些要求？ （选择两个。）</p><p>  A、亚马逊 EC2</p><p>  B.AWS Lambda</p><p>  <code>serverless</code></p><p>  C.亚马逊 RDS</p><p>  D.亚马逊 DynamoDB</p><p>  <code>NoSQL database - 不是关系型数据库</code> </p><p>  E.Amazon Elastic Kubernetes 服务 (Amazon EKS)</p><h2 id="459-A"><a href="#459-A" class="headerlink" title="459-A"></a>459-A</h2><p>  一家公司使用 AWS Organizations 在多个 AWS 账户中运行工作负载。当公司创建标签时，标记策略会将部门标签添加到 AWS 资源。<br>  会计团队需要确定 Amazon EC2 消耗的支出。会计团队必须确定哪些部门负责成本，无论AWS 账户如何。会计团队可以访问组织内所有 AWS 账户的 AWS Cost Explorer，并且需要访问 Cost Explorer 中的所有报告。<br>  哪种解决方案以最高效的方式满足这些要求？</p><p>  <strong>A.</strong> From the Organizations <strong>management account</strong> billing console, activate a <strong>user-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  <code>管理账户具有***付款人账户***的责任，并负责支付成员账户产生的所有费用。您无法更改一个组织的管理账户。</code><br>  <strong>B.</strong> From the Organizations <strong>management account</strong> billing console, activate an <strong>AWS-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  <strong>C.</strong> From the Organizations <strong>member account</strong> billing console, activate a <strong>user-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, and lter by EC2.</p><p>  <strong>D.</strong> From the Organizations <strong>member account</strong> billing console, activate an <strong>AWS-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  A. 从组织管理帐户计费控制台中，激活名为“部门”的用户定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  B. 从组织管理账户计费控制台中，激活名为“部门”的 AWS 定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  C. 从组织成员帐户计费控制台，激活名为“部门”的用户定义成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 进行过滤。<br>  D. 从组织成员账户计费控制台中，激活名为“部门”的 AWS 定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  正确答案：A</p><h2 id="464-A"><a href="#464-A" class="headerlink" title="464-A"></a>464-A</h2><p>  一家公司托管一个在线购物应用程序，该应用程序将所有订单存储在 Amazon RDS for<br>  PostgreSQL 单可用区数据库实例中。管理层希望消除单点故障，并要求解决方案架构师推<br>  荐一种方法来最大限度地<strong>减少数据库停机时间，而无需对应用程序代码进行任何更改</strong>。<br>  哪种解决方案满足这些要求？</p><p>  <code>与涉及创建新实例、恢复快照或手动设置复制的其他解决方案相比，转换到Multi-AZ部署是一种更简单、更精简的方法，开销更低。总的来说，选项A提供了一种经济有效的方法来最小化数据库停机时间，而不需要进行重大更改或增加复杂性</code><br>  A. 通过修改数据库实例并指定多可用区选项，将现有数据库实例转换为多可用区部署。</p><p>  B. 创建新的 RDS 多可用区部署。拍摄当前 RDS 实例的快照并使用该快照恢复新的多可<br>  用区部署。</p><p>  C. 在另一个可用区中创建 PostgreSQL 数据库的只读副本。使用 Amazon Route 53 加权记<br>  录集在数据库之间分配请求。</p><p>  D. 将 RDS for PostgreSQL 数据库放入 Amazon EC2 Auto Scaling 组中，组大小至少为 2。使用 Amazon Route 53 加权记录集跨实例分配请求。</p><h2 id="478-B"><a href="#478-B" class="headerlink" title="478-B"></a>478-B</h2><p>  律师事务所需要与公众共享信息。该信息包括数百个必须公开可读的文件。<strong>禁止任何人在指定的未来日期之前修改或删除文件。</strong><br>  哪种解决方案能够以最安全的方式满足这些要求？</p><p>  启用版本控制会跟踪每个对象的多个版本，这意味着当您上传新的版本时，旧版本不会被删除。</p><p>  <del>A. 将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。向在指定日期之前访问S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。</del></p><p>  B. 创建启用 S3 <strong>版本控制</strong>的新 Amazon S3 存储桶。使用 S3 对象锁，并根据指定日期保留期限。配置静态网站托管的 S3 存储桶。设置 S3 存储桶策略以允许对对象进行只读访问。</p><p>  C. 创建启用 S3 版本控制的新 Amazon S3 存储桶。配置事件触发器以在对象修改或删除时运行AWS Lambda 函数。配置 Lambda 函数以将对象替换为私有 S3 存储桶中的原始</p><p>  D. 将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。选择包含文件的文件夹。使用S3 对象锁，并根据指定日期保留期限。<strong>向访问 S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。</strong></p><p>  <code>未启用versioning</code></p><h2 id="479-B"><a href="#479-B" class="headerlink" title="479-B"></a>479-B</h2><p>  一家公司正在通过手动配置必要的基础设施来为其新网站制作基础设施原型。该基础设施包括 Auto Scaling 组、Application Load Balancer 和 Amazon RDS 数据库。配置经过彻底验证后，该公司希望能够<strong>立即以自动化方式</strong>在两个可用区中部署基础设施以供开发和生产使用。<br>  解决方案架构师应该建议什么来满足这些要求？</p><p>  A. 使用 AWS Systems Manager 在两个可用区中复制和配置原型基础设施</p><p>  <code>它通常用于管理运行中的资源状态和配置，而不是用于部署基础设施。</code></p><p>  B. 使用原型基础设施作为指导，将基础设施定义为模板。使用 AWS CloudFormation 部署基础设施。<br>  C. 使用 AWS Cong 记录原型基础设施中使用的资源清单。使用 AWS Cong 将原型基础设施部署到两个可用区。<br>  D. 使用 AWS Elastic Beanstalk 并将其配置为使用对原型基础设施的自动引用来自动在两个可用区中部署新环境。</p><p>  <code>AWS Elastic Beanstalk 是一种托管服务，用于部署和管理应用程序。</code></p><p>  <code>需求是部署基础设施，而不仅仅是应用程序。</code></p><h2 id="481-B"><a href="#481-B" class="headerlink" title="481-B"></a>481-B</h2><p>  一家公司在 AWS 云中托管一个三层 Web 应用程序。多可用区 Amazon RDS for MySQL服务器构成数据库层 Amazon ElastiCache 构成缓存层。该公司需要一种缓存策略，当客户将项目添加到数据库时，该策略可以添加或更新缓存中的数据。缓存中的数据必须始终与数据库中的数据匹配。<br>  哪种解决方案可以满足这些要求？<br>  A. 实现延迟加载缓存策略</p><p>  <code>延迟加载通常是指在数据被请求时才将其加载到缓存中</code></p><p>  B. 实现直写式缓存策略</p><p>  <code>直写式缓存策略是指在更新数据库数据时，首先更新数据库，然后再更新缓存，以确保缓存中的数据始终与数据库中的数据匹配。这种方法可以保持数据的一致性，因为先更新数据库可以确保缓存中的数据不会过时或不准确。</code></p><p>  C. 实现添加 TTL 缓存策略</p><p>  <code>添加 TTL（生存时间）缓存策略可以在一段时间后从缓存中删除数据，以确保数据不会太旧。</code></p><p>  D. 实施 AWS AppCong 缓存策略</p><p>  <code>AWS AppCong 是用于自动化调整容量的服务，与缓存策略无关。</code></p><p>  正确答案：B</p><h2 id="482-B"><a href="#482-B" class="headerlink" title="482-B"></a>482-B</h2><p>  一家公司希望将 100 GB 的历史数据从本地位置迁移到 Amazon S3 存储桶。该公司拥有每秒 100 兆比特 (Mbps) 的内部互联网连接。该公司需要对传输到 S3 存储桶的数据进行加密。该公司将把新数据直接存储在 Amazon S3 中。<br>  哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 在 AWS CLI 中使用 s3sync 命令将数据直接移动到 S3 存储桶</p><p>  <code>不支持自动加密</code></p><p>  B. 使用 AWS DataSync 将数据从本地位置迁移到 S3 存储桶</p><p>  <code>本地到 AWS 以及 AWS 之间的数据传输</code></p><p>  <code>它会处理数据的加密，确保数据安全性。</code></p><p>  C. 使用 AWS Snowball 将数据移动到 S3 存储桶</p><p>  <strong><code>TB级别</code></strong></p><p>  D. 设置从本地位置到 AWS 的 IPsec VPN。使用 AWS CLI 中的 s3 cp 命令将数据直接移动到 S3 存储桶</p><p>  <code>复杂和昂贵</code></p><p>  正确答案：B</p><h2 id="483-B"><a href="#483-B" class="headerlink" title="483-B"></a>483-B</h2><p>  一家公司对在 Windows 容器下的 .NET 6 Framework 上运行的 Windows 作业进行了容器<br>  化。该公司希望在 AWS 云中运行此作业。该作业每 10 分钟运行一次。作业的运行时间<br>  在 1 分钟到 3 分钟之间变化。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <code>AWS Lambda 和 Amazon EventBridge 可能更适用于事件驱动型的任务，而选项 C 和 D 中的 ECS 和计划任务可能需要更多的配置和管理。</code><br>  A. 根据作业的容器映像创建 AWS Lambda 函数。配置 Amazon EventBridge 以每 10 分<br>  钟调用该函数。</p><p>  <code>更多手动配置</code><br>  <strong>B. 使用 AWS Batch 创建使用 AWS Fargate 资源的作业。将作业调度配置为每 10 分钟运<br>  行一次。</strong></p><p>  <code>AWS Batch 允许您以成本效益的方式在 AWS 上执行大量的计算工作负载，可以自动为您管理和调度容器化作业。</code><br>  C. 在 AWS Fargate 上使用 Amazon Elastic Container Service (Amazon ECS) 运行作业。根<br>  据作业的容器镜像创建计划任务，每 10 分钟运行一次。</p><p>  D. 在 AWS Fargate 上使用 Amazon Elastic Container Service (Amazon ECS) 运行作业。根<br>  据作业的容器镜像创建独立任务。使用 Windows 任务计划程序每 10 分钟运行一次作业。</p><h2 id="484-AE"><a href="#484-AE" class="headerlink" title="484-AE"></a>484-AE</h2><p>  一家公司希望从许多独立的 AWS 账户迁移到整合的多账户架构。该公司计划为不同的业务部门创建许多新的 AWS 账户。该公司需要使用集中式企业目录服务来验证对这些 AWS账户的访问权限。<br>  解决方案架构师应该推荐哪种操作组合来满足这些要求？ （选择两个。）<br>  A. 在 AWS Organizations 中创建一个新组织并启用所有功能。在组织中创建新的 AWS 账户。</p><p>  B. 设置 Amazon Cognito 身份池。配置 AWS IAM Identity Center (AWS Single Sign-On)以接受 Amazon Cognito 身份验证。</p><p>  C. 配置服务控制策略 (SCP) 来管理 AWS 账户。将 AWS IAM Identity Center（AWS Single  Sign-On）添加到 AWS Directory Service。</p><p>  D. 在 AWS Organizations 中创建一个新组织。配置组织的身份验证机制以直接使用 AWS Directory Service。</p><p>  E. 在组织中设置 AWS IAM Identity Center (AWS Single Sign-On)。配置IAM Identity Center，并将其与公司的企业目录服务集成。</p><p>  正确答案：AE</p><h2 id="486-A"><a href="#486-A" class="headerlink" title="486-A"></a>486-A</h2><p>  一家公司正在 AWS 上构建三层应用程序。表示层将服务于静态网站。逻辑层是容器化应用程序。该应用程序将数据存储在关系数据库中。该公司希望简化部署并降低运营成本。哪种解决方案可以满足这些要求？</p><p>  A. 使用 Amazon S3 托管静态内容。将ECS与AWS Fargate 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。 </p><ul><li>**<code>Amazon S3 托管静态内容**：Amazon S3 是一种高度可扩展的对象存储服务，适用于托管静态网站的静态内容。这将提供可靠的、低延迟的内容传送。</code></li><li>**<code>ECS 与 AWS Fargate**：无需管理底层基础设施</code></li></ul><p>  B. 使用 Amazon CloudFront 托管静态内容。将ECS与 Amazon EC2 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  <code>S3 更简单、成本效益更高。</code></p><p>  C. 使用 Amazon S3 托管静态内容。将  EKS与AWS Fargate 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  <code>EKS比ECS贵</code></p><p>  D. 使用 Amazon EC2 预留实例托管静态内容。将EKS与 Amazon EC2 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  正确答案：A</p><h2 id="496-BD"><a href="#496-BD" class="headerlink" title="496-BD"></a>496-BD</h2><p>  一家公司使用本地服务器来托管其应用程序。该公司的存储容量即将耗尽。这些应用程序同时使用<strong>块存储和 NFS 存储</strong>。该公司需要一个高性能的解决方案，支持本地缓存，而无需重新构建现有应用程序。<br>  解决方案架构师应该采取哪些操作组合来满足这些要求？ （选择两个。）</p><p>  A. 将 Amazon S3 作为文件系统安装到本地服务器。<br>  <strong>B. 部署 AWS Storage Gateway file网关来替换 NFS 存储</strong>。<br>  C. 部署 AWS Snowball Edge 以将 NFS 挂载配置到本地服务器。</p><p>  <code>AWS Snowball Edge 是一种用于数据迁移和边缘计算的设备</code><br>  <strong>D. 部署 AWS Storage Gateway volume网关来替换块存储。</strong> </p><p>  E. 部署 Amazon Elastic File System(Amazon EFS) 卷并将其挂载到本地服务器。</p><h2 id="498-A"><a href="#498-A" class="headerlink" title="498-A"></a>498-A</h2><p>  一家公司使用 Amazon S3 将高分辨率图片存储在 S3 存储桶中。为了最大限度地减少应用程序更改，该公司将图片存储为 S3 对象的最新版本。该公司只需保留图片的两个最新版本。<br>  该公司希望降低成本。该公司已将 S3 存储桶视为一项巨额开支。<br>  哪种解决方案能够以最少的运营开销降低 S3 成本？</p><p>  <strong>A. 使用 S3 Lifecycle 删除过期的对象版本并保留两个最新版本。</strong></p><p>  B. 使用 AWS Lambda函数检查旧版本并删除除两个最新版本之外的所有版本。</p><p>  C. 使用 S3 批量操作删除非当前对象版本并仅保留两个最新版本。</p><p>  D. 停用 S3 存储桶上的版本控制并保留两个最新版本。</p><h2 id="154-B"><a href="#154-B" class="headerlink" title="154-B"></a>154-B</h2><p>  公司需要将医学试验的结果保存到 Amazon S3 存储库。存储库必须允许少数科学家添加新文件，并且必须限制所有其他用户的只读访问权限。<strong>任何用户都无法修改或删除存储库中的任何文件</strong>。公司必须将每个文件在创建之日起至少保留 1 年。哪种解决方案可以满足这些要求？</p><p>  A. 在治理模式下使用 S3 对象锁，合法持有期为 1 年。</p><p>  B. 在合规模式下使用 S3 对象锁，保留期为 365 天。</p><p>  **<code>合规模式（Compliance Mode）**：</code></p><p>  <code>对象一旦被锁定，即使具有管理权限的用户（**包括 root** 用户）也无法删除或更改对象，直到锁定期结束。</code></p><p>  C. 使用 IAM 角色限制所有用户删除或更改 S3 存储桶中的对象。使用 S3 存储桶策略仅<br>  允许 IAM 角色。</p><p>  D. 配置 S3 存储桶以在每次添加对象时调用 AWS Lambda 函数。配置该函数来跟踪已保<br>  存对象的哈希值，以便可以相应地标记修改的对象。</p><p>  正确答案：B</p><h2 id="155-C"><a href="#155-C" class="headerlink" title="155-C"></a>155-C</h2><p>  一家大型媒体公司在 AWS 上托管 Web 应用程序。该公司希望开始<strong>缓存</strong>机密媒体文件，以便世界各地的用户能够可靠地访问这些文件。内容存储在 Amazon S3 存储桶中。公司必须快速交付内容，无论请求来自何处。哪种解决方案可以满足这些要求？</p><p>  A. 使用 AWS DataSync 将 S3 存储桶连接到 Web 应用程序。</p><p>  B. 部署 AWS Global Accelerator 以将 S3 存储桶连接到 Web 应用程序。</p><p>  <code>BC都使用**边缘位置（Edge Locations**</code><br>  C. 部署 Amazon CloudFront 以将 S3 存储桶连接到 CloudFront 边缘服务器。</p><p>  <code>C, Caching == Edge location == CloudFront</code></p><p>  D. 使用 Amazon Simple Queue Service (Amazon SQS) 将 S3 存储桶连接到 Web 应用程序。</p><h2 id="157-DE"><a href="#157-DE" class="headerlink" title="157-DE"></a>157-DE</h2><p>  一家公司将数据存储在 Amazon Aurora PostgreSQL 数据库集群中。公司必须将所有数据保<br>  存 5 年，并在 5 年后删除所有数据。公司还必须永久保存在数据库中执行的操作的审核日<br>  志。目前，该公司已为 Aurora 配置了自动备份。<br>  解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>  A. 拍摄数据库集群的手动快照。</p><p>  <code>手动快照需要手动管理，并且在 5 年后可能会变得非常繁琐且不可行。</code></p><p>  B. 为<strong>自动备份</strong>创建生命周期策略。</p><p>  C. 配置<strong>自动备份</strong>保留 5 年。</p><p>  <code>最长35天</code></p><p>  D. 为数据库集群配置 Amazon CloudWatch Logs 导出。</p><p>  E. 使用 AWS Backup 进行备份并将备份保留 5 年。</p><p>  <code>配置备份策略以保留备份至少 5 年，以满足长期数据保留的需求。</code></p><h2 id="158-A"><a href="#158-A" class="headerlink" title="158-A"></a>158-A</h2><p>  解决方案架构师正在为即将举行的音乐活动优化网站。表演视频将实时传输，然后按需提供。该活动预计将吸引全球在线观众。</p><p>  哪种服务可以提高实时流媒体和点播流媒体的性能？</p><p>  A. 亚马逊 CloudFront</p><p>  <code>use CloudFront to deliver video on demand (VOD) or live streaming video using any HTTP origin</code><br>  B.AWS 全球加速器</p><p>  更适合非HTTP<br>  C. 亚马逊 53 号公路<br>  D. Amazon S3 传输加速</p><h2 id="159"><a href="#159" class="headerlink" title="159"></a>159</h2><p>  一家公司正在运行一个使用 Amazon API Gateway 和 AWS Lambda 的可公开访问的无服务<br>  器应用程序。由于来自僵尸网络的欺诈请求，该应用程序的访问量最近激增。<br>  解决方案架构师应采取哪些步骤来阻止未经授权用户的请求？ （选择两个。）</p><p>  <strong>A. 使用仅与真实用户共享的 API 密钥创建使用计划。</strong></p><p>  B. 在 Lambda 函数中集成逻辑以忽略来自欺诈性 IP 地址的请求。</p><p>  <code>比较繁琐</code></p><p>  <strong>C. 实施 AWS WAF 规则来定位恶意请求并触发操作以将其过滤掉。</strong></p><p>  D. 将现有的公共 API 转换为私有 API。更新 DNS 记录以将用户重定向到新的 API 端点。</p><p>   E. 为每个尝试访问 API 的用户创建一个 IAM 角色。用户在进行 API 调用时将承担该角色。</p><p>  正确答案：A C</p><h2 id="160-C"><a href="#160-C" class="headerlink" title="160-C"></a>160-C</h2><p>  一家电子商务公司在 AWS 云中托管其分析应用程序。该应用程序每月生成约 300 MB 的数据。数据以 JSON 格式存储。该公司正在评估备份数据的<strong>灾难恢复解决方案</strong>。如果需要，数据必须可以在毫秒内访问，并且数据必须保留 30 天。<br>  哪种解决方案最经济高效地满足这些要求？</p><p>  A. Amazon OpenSearch 服务（Amazon Elasticsearch 服务）</p><p>  <code>适用于搜索和分析数据，但不是最经济的存储选择，而且可能超过需求。</code></p><p>  B. 亚马逊 S3 Glacier</p><p>  <code>适用于存档和长期保存数据，但数据恢复可能需要数分钟到数小时，不符合毫秒级访问要求</code></p><p>  C. Amazon S3 标准</p><p>  <code>JSON is object notation. S3 stores objects</code></p><p>  D. 适用于 PostgreSQL 的 Amazon RDS</p><p>  <code>关系型数据库服务，不太适合存储大量的 JSON 格式数据，</code></p><h2 id="161-B"><a href="#161-B" class="headerlink" title="161-B"></a>161-B</h2><p>  一家公司有一个小型 Python 应用程序，用于处理 <strong>JSON 文档</strong>并将结果输出到本地 SQL数据库。该应用程序每天运行数千次。该公司希望将应用程序迁移到 AWS 云。该公司需要一个高度可用的解决方案，最大限度地提高可扩展性并最大限度地减少运营开销。<br>  哪种解决方案可以满足这些要求？</p><p>  <code>JSON is object notation. S3 stores objects</code></p><p>  A. 将 JSON 文档放入 Amazon S3 存储桶中。在多个 Amazon EC2 实例上运行 Python 代码以处理文档。将结果存储在 Amazon Aurora 数据库集群中。</p><p>  <code>涉及到自己管理 EC2 实例，并需要设置自动扩展</code></p><p>  B. 将 JSON 文档放入 Amazon S3 存储桶中。创建一个 AWS Lambda 函数，该函数运行Python 代码以在文档到达 S3 存储桶时对其进行处理。将结果存储在 Amazon Aurora 数据库集群中。</p><p>  C. 将 JSON 文档放入 Amazon Elastic Block Store (Amazon EBS) 卷中。使用 EBS 多重附加功能将卷附加到多个 Amazon EC2 实例。在 EC2 实例上运行 Python 代码来处理文档。将结果存储在 Amazon RDS 数据库实例上。</p><p>  D. 将 JSON 文档作为消息放入 Amazon Simple Queue Service (Amazon SQS) 队列中。将Python 代码部署为配置了 Amazon EC2 启动类型的 Amazon Elastic Container Service(Amazon ECS) 集群上的容器。使用容器来处理 SQS 消息。将结果存储在 Amazon RDS 数<br>  据库实例上。</p><h2 id="165"><a href="#165" class="headerlink" title="165"></a>165</h2><p>  解决方案架构师必须设计一个使用 Amazon CloudFront 和 Amazon S3 源来存储静态网站<br>  的解决方案。该公司的安全策略要求所有网站跟踪均由 AWS WAF 检查。<br>  解决方案架构师应该如何满足这些要求？<br>  A. 配置 S3 存储桶策略以仅接受来自 AWS WAF Amazon 资源名称 (ARN) 的请求。<br>  B. 配置 Amazon CloudFront 以在从 S3 源请求内容之前将所有传入请求转发到 AWS<br>  WAF。<br>  C. 配置一个安全组，仅允许 Amazon CloudFront IP 地址访问 Amazon S3。将 AWS WAF<br>  关联到 CloudFront。<br>  D. 配置 Amazon CloudFront 和 Amazon S3 以使用源访问身份 (OAI) 来限制对 S3 存储<br>  桶的访问。在分配上启用 AWS WAF。<br>  正确答案：D</p><h2 id="167-D"><a href="#167-D" class="headerlink" title="167-D"></a>167-D</h2><p>  一家公司在一组 Amazon EC2 实例上运行生产应用程序。该应用程序从 Amazon SQS 队<br>  列读取数据并<em><strong>并行</strong></em>处理消息。消息量是不可预测的，并且经常有间歇性的踪迹。</p><p>  <strong>该应用程序需要持续处理消息而不会造成任何停机。</strong></p><p>  <strong>This application should continuallyprocess messages without any downtime.</strong></p><p>  哪种解决方案最经济高效地满足这些要求？<br>  A. 仅使用 Spot 实例来处理所需的最大容量。<br>  B. 仅使用预留实例来处理所需的最大容量。</p><p>  C. 使用预留实例作为基准容量，并使用 Spot 实例来处理额外容量。</p><p>  <code>SPOT适用于可以容忍实例终止的工作负载</code><br>  D. 使用预留实例作为基准容量，并使用按需实例来处理额外容量。</p><h2 id="170-C"><a href="#170-C" class="headerlink" title="170-C"></a>170-C</h2><p>  一家公司的 Web 应用程序在应用程序负载均衡器后面的 Amazon EC2 实例上运行。该公司最近改变了政策，现在要求只能从一个特定的国家&#x2F;地区访问该应用程序。<br>  哪种配置可以满足这个要求？</p><p>  A. 配置 EC2 实例的安全组。<br>  B. 在应用程序负载均衡器上配置安全组。</p><p>  <code>AB仅限于控制流量进出实例或负载均衡器，而无法实现特定国家/地区的访问控制。</code><br>  C. 在 VPC 中的 Application Load Balancer 上配置 AWS WAF。</p><p>  <code>AWS WAF可以用于实现Web应用程序的访问控制和保护，包括基于IP地址的访问限制。</code><br>  D. 配置包含 EC2 实例的子网的网络 ACL。</p><p>  <code>子网级别的流量控制</code><br>  正确答案：C</p><h2 id="172-C"><a href="#172-C" class="headerlink" title="172-C"></a>172-C</h2><p>  解决方案架构师正在为应用程序创建新的 Amazon CloudFront 发行版。用户提交的一些信息属于敏感信息。该应用程序使用 HTTPS，但需要另一层安全性。敏感信息应在整个应用程序堆栈中受到保护，并且对信息的访问应仅限于某些应用程序。<br>  解决方案架构师应该采取哪些行动？</p><p>  A. 配置 CloudFront 签名 URL。<br>  B. 配置 CloudFront 签名 cookie。</p><p>  <code>选项A和选项B中的CloudFront签名URL和签名Cookie用于验证请求的来源和完整性，但并不涉及字段级加密或敏感信息的保护。</code><br>  C. 配置 CloudFront 字段级加密配置文件。<br>  D. 配置 CloudFront 并将查看器协议策略的源协议策略设置为仅 HTTPS。</p><p>  <code>为了强制CloudFront仅接受HTTPS连接，但并不涉及字段级加密或敏感信息的保护。</code><br>  正确答案：C</p><h2 id="176-A"><a href="#176-A" class="headerlink" title="176-A"></a>176-A</h2><p>  应用程序在私有子网中的 Amazon EC2 实例上运行。应用程序需要访问 Amazon<br>  DynamoDB 表。在确保 <strong>trac 不会离开 AWS 网络</strong>的同时访问表的最安全方法是什么？</p><p>  A. 使用 DynamoDB 的 VPC 终端节点。</p><p>  <code>VPC终端节点是一种允许您的VPC中的资源与支持的AWS服务（例如DynamoDB）进行私有连接的方式。</code><br>  B. 在公共子网中使用 NAT 网关。</p><p>  <code>NAT gateway使私有实例访问互联网</code></p><p>  <code>NAT实例和NAT网关都应该放置在公共子网</code><br>  C. 在私有子网中使用 NAT 实例。<br>  D. 使用连接到 VPC 的<del>互联网网关</del>。</p><h2 id="180-BC"><a href="#180-BC" class="headerlink" title="180-BC"></a>180-BC</h2><p>  一家公司正在设计一个由 API 驱动的云通信平台。该应用程序托管在网络负载均衡器(NLB) 后面的 Amazon EC2 实例上。该公司使用 Amazon API Gateway 为外部用户提供通过 API 访问应用程序的权限。该公司希望保护平台免受 <strong>SQL 注入</strong>等 Web 攻击，<strong>还希望检测和缓解大型、复杂的DDoS 攻击。</strong></p><p>  哪种解决方案组合可提供最强的保护？ （选择两个。）</p><p>  <strong>AWS WAF来路由和保护服务中任务中的 HTTP (S) 第 7 层流量。</strong></p><p>  <strong>Shield - Load Balancer, CF, Route53<br>  AWF - CF, ALB, API Gateway</strong></p><p>  A. 使用 AWS WAF 保护 NLB。</p><p>  <code>NLB是TCP,UDP</code></p><p>  B. 将 AWS Shield Advanced 与 NLB 结合使用。</p><p>  C. 使用 AWS WAF 保护 Amazon API Gateway。</p><p>  D. 将 Amazon GuardDuty 与 AWS Shield Standard 结合使用 </p><p>  E. 将 AWS Shield Standard与 Amazon API Gateway 结合使用。</p><h2 id="183-A"><a href="#183-A" class="headerlink" title="183-A"></a>183-A</h2><p>  一家公司正在构建一个新的动态订购网站。该公司希望最大限度地减少服务器维护和修补。网站必须具有高可用性，并且必须<strong>尽快扩展读写容量</strong>，以满足用户需求的变化。哪种解决方案可以满足这些要求？<br>  A. 在 Amazon S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动<br>  态内容。使用具有<strong>按需</strong>数据库容量的 <strong>Amazon DynamoDB</strong>。配置 Amazon CloudFront 以交<br>  付网站内容。</p><p>  B. 在 Amazon S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动<br>  态内容。将 Amazon Aurora 与 Aurora Auto Scaling 结合使用作为数据库。配置 Amazon<br>  CloudFront 以交付网站内容。</p><p>  <code>Aurora auto scaling scales only read replicas</code></p><p>  <del>C. 在 Amazon EC2 实例上托管所有网站内容。创建 Auto Scaling 组以扩展 EC2 实例。使<br>  用应用程序负载均衡器来分发 trac。使用具有为数据库预置的写入容量的 Amazon<br>  DynamoDB。<br>  D. 在 Amazon EC2 实例上托管所有网站内容。创建 Auto Scaling 组以扩展 EC2 实例。<br>  使用应用程序负载均衡器来分发 trac。将 Amazon Aurora 与 Aurora Auto Scaling 结合使用<br>  作为数据库。</del></p><h2 id="184-A"><a href="#184-A" class="headerlink" title="184-A"></a>184-A</h2><p>  一家公司拥有一个用于软件工程的 AWS 账户。 AWS 账户可以通过一对 AWS Direct<br>  Connect 连接访问公司的本地数据中心。所有非 VPC trac 都会路由到虚拟专用网关。<br>  一个开发团队最近通过控制台创建了一个 AWS Lambda 函数。开发团队需要允许该函数访<br>  问在公司数据中心的私有子网中运行的数据库。<br>  哪种解决方案可以满足这些要求？<br>  <strong>A. 将 Lambda 函数配置为在具有适当安全组的 VPC 中运行。</strong><br>  B. 设置从 AWS 到数据中心的 VPN 连接。通过 VPN 从 Lambda 函数路由 trac。<br>  C. 更新 VPC 中的路由表，以允许 Lambda 函数通过 Direct Connect 访问本地数据中心。<br>  D. 创建弹性 IP 地址。配置 Lambda 函数以通过弹性 IP 地址发送 trac，无需弹性网络接</p><h2 id="185-B"><a href="#185-B" class="headerlink" title="185-B"></a>185-B</h2><p>  一家公司使用 Amazon ECS 运行应用程序。该应用程序创建原始图像的调整大小版本，然后进行 Amazon S3 API 调用以将调整大小的图像存储在 Amazon S3 中。<br>  解决方案架构师如何确保应用程序有权访问 Amazon S3？</p><p>  A. 更新 AWS IAM 中的 S3 角色以允许从 Amazon ECS 进行读&#x2F;写访问，然后重新启动容器。<br>  B. 创建具有 S3 权限的 IAM 角色，然后将该角色指定为任务定义中的 taskRoleArn。</p><p>  <code>通过创建具有适当的 Amazon S3 权限的 IAM 角色，并将该角色的 ARN（Amazon Resource Name）指定为任务定义的 taskRoleArn，容器就可以使用这个角色的权限来访问 Amazon S3。</code><br>  C. 创建一个允许从 Amazon ECS 访问 Amazon S3 的安全组，并更新 ECS 集群使用的启动配置。</p><p>  <code>安全组通常用于控制网络流量进出 EC2 实例，而不是用来控制应用程序对 AWS 服务的访问权限。</code><br>  D. 创建具有 S3 权限的 IAM 用户，然后在以此账户登录时重新启动 ECS 集群的 Amazon EC2 实例。</p><h2 id="193-B"><a href="#193-B" class="headerlink" title="193-B"></a>193-B</h2><p>  一家公司正在 Amazon EC2 实例上运行批处理应用程序。该应用程序由具有多个 Amazon<br>  RDS 数据库的后端组成。该应用程序导致对数据库的大量读取。解决方案架构师<strong>必须减少<br>  数据库读取次数</strong>，同时确保<strong>高可用性</strong>。<br>  解决方案架构师应该做什么来满足这个要求？</p><p>  A. 添加 Amazon RDS 只读副本。</p><p>  B. 使用 Amazon ElastiCache for Redis</p><p>  <code>redis 高可用</code></p><p>  <strong>Redis vs Memcached:<br>  The question states high availability which Memcached does not support.<br>  Redis supports Multi-AZ and therefore - ensures high availability.</strong></p><p>  C. 使用 Amazon Route 53 DNS 缓存</p><p>  D. 使用 Amazon ElastiCache for Memcached。</p><h2 id="64-D"><a href="#64-D" class="headerlink" title="64-D"></a>64-D</h2><p>  一家公司在本地运行的 Windows 文件服务器上拥有超过 5 TB 的文件数据。用户和应用程序每天都与数据进行交互。该公司正在将其 Windows 工作负载迁移到 AWS。随着公司继续这一流程，公司需要以最小的延迟<strong>访问 AWS 和本地文件存储</strong>。该公司需要一种能够最大限度地减少运营开销且无需对现有文件访问模式进行重大更改的解决方案。</p><p>  该公司使用AWS 站点到站点 VPN 连接来连接到 AWS。解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 在 AWS 上部署并配置 Amazon FSx for Windows File Server。将本地文件数据移动到FSx for Windows File Server。重新配置工作负载以使用 FSx for Windows File Server on AWS。</p><p>  B. 在本地部署并配置 Amazon S3 文件网关。将本地文件数据移动到 S3 文件网关。重新配置本地工作负载和云工作负载以使用 S3 文件网关</p><p>  C. 在本地部署并配置 Amazon S3 文件网关。将本地文件数据移动到 Amazon S3。重新配置工作负载以直接使用 Amazon S3 或 S3 文件网关。取决于每个工作负载的位置。</p><p>  D. 在 AWS 上部署并配置 Amazon FSx for Windows File Server。在本地部署和配置Amazon FSx 文件网关。将本地文件数据移动到 FSx 文件网关。配置云工作负载以使用FSx for Windows File Server on AWS。配置本地工作负载以使用 FSx 文件网关</p><h2 id="66-C"><a href="#66-C" class="headerlink" title="66-C"></a>66-C</h2><p>  问题 #66<br>  一家公司的应用程序会生成大量文件，每个文件大小约为 5 MB。这些文件存储在 Amazon<br>  S3 中。公司政策要求这些文件必须保存 4 年才能删除。<strong>始终需要立即可访问</strong>，因为文件<br>  包含不易复制的<strong>关键业务数据</strong>。这些文件在对象创建的前 30 天内经常被访问，但在前 30<br>  天之后很少被访问。哪种存储解决方案最具成本效益？</p><p>  A. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到S3 Glacier。对象创建 4 年后删除文件。</p><p>  <code>如果他们没有明确提到他们正在使用Glacier Instant Retrieval，我们应该假设冰川-&gt;需要更多的时间来检索，可能不符合要求</code></p><p>  B. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到<br>  S3 One Zone-Infrequent Access (S3 One Zone-IA)。对象创建 4 年后删除文件。</p><p>  <code>one zone-IA不适合关键性数据</code></p><p>  C. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到<br>  S3 Standard-Infrequent Access (S3 Standard-IA)。对象创建 4 年后删除文件。</p><p>  D. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到S3 Standard-Infrequent Access (S3 Standard-IA)。在对象<del>创建 4 年后将文件移至 S3 Glacier。</del><br>  正确答案：C</p><h2 id="71-B"><a href="#71-B" class="headerlink" title="71-B"></a>71-B</h2><p>  一家公司运行一个使用 Amazon DynamoDB 存储客户信息的购物应用程序。在数据损坏的<br>  情况下，解决方案架构师需要设计一个满足恢复点目标（RPO）为 15 分钟和恢复时间目标<br>  （RTO）为 1 小时的解决方案。为了满足这些需求，解决方案架构师应该推荐什么？</p><p>  A.聚集 DynamoDB 全局表。对于 RPO 恢复，请将应用程序指向不同的 AWS 区域。</p><p>  <code>将应用程序指向不同的 AWS 区域可能会导致数据丢失，因为数据同步可能需要一些时间。</code></p><p>  <strong>B.拥塞动态数据库point-in-time recover。对于 RPO 恢复，请还原到所需的时间点。</strong></p><p>  C.出口每天将 DynamoDB 数据传输到 Amazon S3 Glacier。对于 RPO 恢复，请将数据从S3 Glacier 导入到 DynamoDB。</p><p>  <code>但在 RPO 恢复时，需要将数据从 S3 Glacier 恢复并导入 DynamoDB，可能会花费较长时间。</code></p><p>  D.计划每 15 分钟为 DynamoDB 表创建一次 Amazon EBS 快照。对于 RPO 恢复，可以使用EBS 快照恢复 DynamoDB 表。<br>  <code>DynamoDB是无服务器的…DynamoDB 并不支持 EBS 快照</code></p><h2 id="73-CD"><a href="#73-CD" class="headerlink" title="73-CD"></a>73-CD</h2><p>  一家公司最近在私有子网中的 Amazon EC2 上启动了基于 Linux 的应用程序实例，并在<br>  VPC 的公有子网中的 Amazon EC2 实例上启动了基于 Linux 的堡垒主机。解决方案架构<br>  师需要通过公司的 Internet 连接从本地网络连接到堡垒主机和应用程序服务器。解决方案<br>  架构师必须确保所有 EC2 实例的安全组都允许该访问。解决方案架构师应该采取哪些步骤<br>  组合来满足这些要求？ （选择两个。）</p><p>  A. 将堡垒主机的当前安全组替换为仅允许来自应用程序实例的入站访问的安全组。<br>  B. 将堡垒主机当前的安全组替换为仅允许来自公司内部 IP 范围的入站访问的安全组。<br>  C. 将堡垒主机当前的安全组替换为仅允许来自公司<strong>外部 IP 范围</strong>的入站访问的安全组。</p><p>  <code>从本地网络到堡垒通过互联网(使用本地资源的公共IP)</code><br>  D. 将应用程序实例的当前安全组替换为仅允许来自堡垒主机的私有 IP 地址的入站 SSH访问的安全组。 </p><p>  <code>堡垒和ec2在同一个VPC中，这意味着堡垒可以通过它的私有IP地址与ec2通信</code></p><p>  E. 将应用程序实例的当前安全组替换为仅允许从堡垒主机的公共 IP 地址进行入站 SSH 访问的安全组。</p><h2 id="87"><a href="#87" class="headerlink" title="87"></a>87</h2><p>  一家公司在由 Amazon API Gateway API 调用的 AWS Lambda 函数上托管应用程序。Lambda 函数将客户数据保存到 Amazon Aurora MySQL 数据库。<em><em>每当公司升级数据库时，Lambda 函数都无法建立数据库连接，直到升级完成。<strong>结果是某些事件的客户数据没有被记录。解决方案架构师需要设计一个解决方案来</strong></em>存储数据库升级期间创建的客户数据</em>**。哪种解决方案可以满足这些要求？</p><p>  A. 配置 Amazon RDS 代理以位于 Lambda 函数和数据库之间。配置 Lambda 函数以连接到 RDS 代理。</p><p>  **<code>可以处理与数据库的连接和请求**，从而减轻数据库的负担。</code></p><p>  <code>可以解决数据库升级期间的连接问题，但不直接解决存储升级期间创建的客户数据的需求。</code><br>  B. 将 Lambda 函数的运行时间增加到最大值。在将客户数据存储在数据库中的代码中创建重试机制。<br>  选项 C: 将客户数据持久化到 Lambda 本地存储。配置新的 Lambda 函数扫描本地存储以将客户数据保存到数据库。</p><p>  <code>Lambda 函数的本地存储是临时的，</code></p><p>  D. 将客户数据存储在 Amazon Simple Queue Service (Amazon SQS) FIFO 队列中。创建一个新的 Lambda 函数来轮询队列并将客户数据存储在数据库中。</p><h2 id="93-B"><a href="#93-B" class="headerlink" title="93-B"></a>93-B</h2><p>  一家公司运行由 MySQL 数据库提供支持的本地应用程序。该公司正在将应用程序迁移到<br>  AWS，以提高应用程序的弹性和可用性。当前的体系结构在正常操作期间显示数据库上的<br>  大量读取活动。每 4 小时，公司的开发团队就会完整导出生产数据库，以填充临时环境中<br>  的数据库。在此期间，用户会遇到不可接受的应用程序延迟。在该过程完成之前，开发团<br>  队无法使用暂存环境。解决方案架构师必须推荐可缓解应用程序延迟问题的替代架构。替<br>  换架构还必须使开发团队能够立即继续使用登台环境。哪种解决方案满足这些要求？、</p><p>  A. 将 Amazon Aurora MySQL 与多可用区 Aurora 副本结合使用进行生产。通过实施使用<br>  <em><strong>mysqldump</strong></em> 实用程序的备份和恢复过程来填充临时数据库。</p><p>  <code>涉及mysqldump实用程序来备份和恢复数据，这可能会在数据库很大的情况下导致较长的恢复时间。</code></p><p>  B. 使用 Amazon Aurora MySQL 和多可用区 Aurora 副本进行生产。使用<strong>数据库克隆</strong>按需<br>  创建临时数据库。</p><p>  <code>使用了数据库克隆，可以在需要时快速创建临时数据库，而不需要长时间的恢复过程</code>。</p><p>  C. 使用 Amazon RDS for MySQL 进行多可用区部署和生产只读副本。使用备用实例作为<br>  临时数据库。</p><p>  D. 使用 Amazon RDS for MySQL 进行多可用区部署和生产只读副本。通过实施使用<br>  mysqldump 实用程序的备份和恢复过程来填充临时数据库。</p><p>  <code>涉及mysqldump实用程序来备份和恢复数据，这可能会在数据库很大的情况下导致较长的恢复时间。</code><br>  正确答案：B</p><h2 id="94-C"><a href="#94-C" class="headerlink" title="94-C"></a>94-C</h2><p>  一家公司正在设计一个应用程序，用户可以将<strong>小文件</strong>上传到 Amazon S3。用户上传文件后，<br>  需要对文件进行一次性简单处理，将数据进行转换，并将数据保存为 JSON 格式以供后续<br>  分析。每个文件上传后必须尽快进行处理。需求会有所不同。有时，用户会上传大量文件。<br>  在其他日子里，用户会上传一些文件或不上传文件。哪种解决方案能够以最少的运营开销<br>  满足这些要求？</p><p>  <strong>JSON 文件适合存储在一些现代的NoSQL数据库, S3【key-value】</strong></p><p>  A. 配置 Amazon EMR 以从 Amazon S3 读取文本文件。运行处理脚本来转换数据。将生<br>  成的 JSON 文件存储在 Amazon Aurora 数据库集群中。</p><p>  <code>EMR来处理数据，但可能过于复杂和昂贵，尤其是针对简单的数据转换任务。</code></p><p>  B. 配置 Amazon S3 以将事件通知发送到 Amazon Simple Queue Service (Amazon SQS) 队<br>  列。使用 Amazon <strong>EC2 实例</strong>从队列中读取并处理数据。将生成的 JSON 文件存储在<br>  Amazon DynamoDB 中。</p><p>  <code>EC2实例需要管理</code></p><p>  C. 配置 Amazon S3 以将事件通知发送到 Amazon Simple Queue Service (Amazon SQS) 队<br>  列。使用 AWS Lambda 函数从队列中读取并处理数据。将生成的 JSON 文件存储在<br>  Amazon DynamoDB 中。</p><p>  D. 配置 Amazon EventBridge (Amazon CloudWatch Events) 以在上传新文件时将事件发送到<br>  Amazon Kinesis Data Streams。使用 AWS Lambda 函数使用流中的事件并处理数据。将生<br>  成的 JSON 文件存储在 Amazon Aurora 数据库集群中。</p><p>  <code>不必要的复杂，存储在Aurora中不适合</code><br>  正确答案：C</p><h2 id="107-B"><a href="#107-B" class="headerlink" title="107-B"></a>107-B</h2><p>  一家自行车共享公司正在开发一种多层架构，以在高峰运营时间跟踪其自行车的位置。该<br>  公司希望<strong>在其现有的分析平台中使用这些数据点</strong>。解决方案架构师必须确定最可行的多层<br>  选项来支持该架构。数据点必须可从 REST API 访问。哪种操作满足存储和检索位置数据<br>  的这些要求？</p><p>  A. 将 Amazon Athena 与 Amazon S3 结合使用。</p><p>  <strong>B.</strong> 将 Amazon API Gateway 与 AWS Lambda 结合使用</p><ul><li>**<code>Amazon API Gateway：** 它作为 REST API 请求的入口点，允许您创建和管理可以与各种后端服务集成的 API。它为客户端提供与之交互的 RESTful 接口。</code></li><li>**<code>AWS Lambda：** 可以用来实现存储和检索位置数据的后端逻辑。当从 API Gateway 收到请求时，可以调用 Lambda 来处理请求，处理数据，并与数据存储（如数据库或Amazon S3）交互。</code></li></ul><p>  C. 将 Amazon QuickSight 与 Amazon Redshift 结合使用。</p><p>  <strong>D.</strong> 将 Amazon API Gateway 与 Amazon Kinesis Data Analytics 结合使用。</p><h2 id="109-D"><a href="#109-D" class="headerlink" title="109-D"></a>109-D</h2><p>  公司需要将数据存储在 Amazon S3 中，并且必须防止数据被更改。该公司希望上传到<br>  Amazon S3 的新对象在一段非特定时间内保持不变，直到公司决定修改这些对象。只有公<br>  司 AWS 账户中的特定用户才可以删除对象。 10 解决方案架构师应该怎样做才能满足这<br>  些要求？</p><p>  <del>A. 创建 S3 Glacier 文件库</del>。对对象应用一次写入多次读取 (WORM) 保管库锁定策略。</p><p>  B. 创建启用了 S3 对象锁定的 S3 存储桶。启用版本控制。<del>设置保留期限为 100 年</del>。使用<strong>治理模式</strong>作为 S3 存储桶新对象的默认保留模式。 </p><p>  C. 创建 S3 存储桶。使用 AWSCloudTrail 跟踪修改对象的任何 S3 API 事件。收到通知后，从公司拥有的任何备份版本中恢复修改的对象。 </p><p>  D. 创建启用了 S3 对象锁定的 S3 存储桶。启用版本控制。为对象添加合法保留。将s3:PutObjectLegalHold 权限添加到需要删除对象的用户的 IAM 策略中。<br>  使用对象锁，您还可以在对象版本上放置<strong>legal hold合法的保留</strong>。与保留期一样，合法保留可以防止对象版本被覆盖或删除。然而，合法持有并没有相应的保留期限，在解除之前一直有效</p><h2 id="116-AD"><a href="#116-AD" class="headerlink" title="116-AD"></a>116-AD</h2><p>  一家公司为其公司网站使用流行的内容管理系统 (CMS)。然而，**所需的修补和维护是繁重<br>  的。**该公司正在重新设计其网站并需要新的解决方案。该网站每年更新四次，<strong>不需要提供<br>  任何动态内容</strong>。该解决方案必须提供高可扩展性和增强的安全性。哪种变更组合能够以最<br>  少的运营开销满足这些要求？ （选择两个。）</p><p>  A. 在网站前面配置 Amazon CloudFront 以使用 HTTPS 功能。</p><p>  B. 在网站前面部署 AWS <del>WAF Web ACL</del> 以提供 HTTPS 功能。</p><p>  C. 创建并部署 AWS Lambda 函数来<strong>管理</strong>和提供网站内容。</p><p>  D. 创建新网站和 Amazon S3 存储桶。在启用静态网站托管的 S3 存储桶上部署网站。</p><p>  E.创建新网站。使用 Application Load Balancer 后面的 <del>Amazon EC2 实例</del> Auto Scaling 组部<br>  署网站。</p><h2 id="119-B"><a href="#119-B" class="headerlink" title="119-B"></a>119-B</h2><p>  一家跨国公司正在使用 Amazon API Gateway 为其位于 us-east-1 区域和 ap-southeast-2 区<br>  域的忠诚俱乐部用户设计 REST API。解决方案架构师必须设计一个解决方案来保护这些<br>  <strong>跨多个帐户</strong>的 API Gateway 管理的 REST API 免受 SQL 注入和跨站点脚本攻击。哪种解<br>  决方案能够以最少的管理工作满足这些要求？<br>  A. 在两个区域中设置 AWS WAF。将区域 Web ACL 与 API 阶段关联。<br>  B. 在两个区域中设置 AWS Firewall Manager。集中配置 AWS WAF 规则。<br>  C. 在 Bath 区域设置 AWS Shield。将区域 Web ACL 与 API 阶段关联。<br>  D. 在其中一个区域设置 AWS Shield。将区域 Web ACL 与 API 阶段关联。</p><h2 id="121-A"><a href="#121-A" class="headerlink" title="121-A"></a>121-A</h2><p>  一家公司正在 AWS 上运行在线事务处理 (OLTP) 工作负载。此工作负载在多可用区部署<br>  中使用未加密的 Amazon RDS 数据库实例。每日数据库快照均从此实例中获取。解决方案<br>  架构师应该做什么来确保数据库和快照始终加密？</p><p>  A. 加密最新数据库快照的副本。通过恢复加密快照来替换现有数据库实例。</p><p>  <em>Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.</em><br>  B. 创建一个新的加密 Amazon Elastic Block Store (Amazon EBS) 卷并将快照复制到其中。<br>  在数据库实例上启用加密。</p><p>  C. 复制快照并使用 AWS Key Management Service (AWS KMS) 启用加密 将加密快照恢复<br>  到现有数据库实例。</p><p>  <em>Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS) Restore encrypted snapshot to an existing DB instance</em></p><p>  D. 将快照复制到使用 AWS Key Management Service (AWS KMS) 托管密钥 (SSE-KMS) 的<br>  服务器端加密进行加密的 Amazon S3 存储桶。<br>  正确答案：A</p><h2 id="123-D"><a href="#123-D" class="headerlink" title="123-D"></a>123-D</h2><p>  一家公司有一个动态 Web 应用程序托管在两个 Amazon EC2 实例上。该公司拥有自己的<br>  SSL 证书，该证书在每个实例上执行 SSL 终止。最近，trac 有所增加，运营团队确定 SSL<br>  加密和解密导致 Web 服务器的计算能力达到最大限制。解决方案架构师应该怎样做才能<br>  提高应用程序的性能？<br>  A. 使用 AWS Certicate Manager (ACM) 创建新的 SSL 证书。在每个实例上安装 ACM<br>  证书。<br>  B. 创建 Amazon S3 存储桶 将 SSL 证书迁移到 S3 存储桶。配置 EC2 实例以引用用于<br>  SSL 终止的存储桶。<br>  C. 创建另一个 EC2 实例作为代理服务器。将 SSL 证书迁移到新实例并将其配置为直接连<br>  接到现有 EC2 实例。<br>  D. 将 SSL 证书导入 AWS Certificate Manager (ACM)。创建具有 HTTPS 侦听器的应用程<br>  序负载均衡器，该侦听器使用来自 ACM 的 SSL 证书。</p><h2 id="125-AD"><a href="#125-AD" class="headerlink" title="125-AD"></a>125-AD</h2><p>  一家公司在 AWS 上运行其两层电子商务网站。 Web 层由一个负载均衡器组成，该负载<br>  均衡器将 trac 发送到 Amazon EC2 实例。数据库层使用 Amazon RDS 数据库实例。 EC2<br>  实例和 RDS 数据库实例不应暴露于公共互联网。 EC2 实例需要互联网访问才能通过第三<br>  方 Web 服务完成订单的支付处理。该应用程序必须具有高可用性。哪种配置选项组合可<br>  以满足这些要求？ （选择两个。）<br>  A. 使用 Auto Scaling 组启动私有子网中的 EC2 实例。在私有子网中部署 RDS 多可用区数据库实例。<br>  B. 在两个可用区中配置具有两个私有子网和两个 NAT 网关的 VPC。在私有子网中部署应用程序负载均衡器。<br>  C. 使用 Auto Scaling 组在两个可用区的公有子网中启动 EC2 实例。在私有子网中部署RDS 多可用区数据库实例。<br>  D. 跨两个可用区配置具有 1 个公有子网、1 个私有子网和 2 个 NAT 网关的 VPC。在公有子网中部署应用程序负载均衡器。<br>  E. 在两个可用区中配置具有两个公有子网、两个私有子网和两个 NAT 网关的 VPC。在公有子网中部署应用程序负载均衡器。</p><h2 id="127-D"><a href="#127-D" class="headerlink" title="127-D"></a>127-D</h2><p>  一家媒体公司正在评估将其系统迁移到 AWS 云的可能性。该公司需要至少 10 TB 的存储<br>  空间（具有最大可能的 I&#x2F;O 性能）用于视频处理，300 TB 的非常耐用的存储空间用于存储<br>  媒体内容，以及 900 TB 的存储空间以满足不再使用的存档媒体的要求。解决方案架构师<br>  应该推荐哪组服务来满足这些要求？<br>  A. Amazon EBS 用于实现最佳性能，Amazon S3 用于持久数据存储，Amazon S3 Glacier 用<br>  于归档存储<br>  B. Amazon EBS 用于实现最佳性能，Amazon EFS 用于持久数据存储，Amazon S3 Glacier<br>  用于归档存储<br>  C. Amazon EC2 实例存储可实现最佳性能，Amazon EFS 可实现持久数据存储，Amazon S3<br>  可实现归档存储<br>  D. Amazon EC2 实例存储可实现最佳性能，Amazon S3 可实现持久数据存储，Amazon S3<br>  Glacier 可实现归档存储</p><p>  <code>EC2 has newer feature to support video</code></p><h2 id="134-C"><a href="#134-C" class="headerlink" title="134-C"></a>134-C</h2><p>  一家公司希望将其应用程序迁移到无服务器解决方案。无服务器解决方案需要使用 SL 来<br>  分析<strong>现有数据和新数据</strong>。该公司将数据存储在 Amazon S3 存储桶中。数据需要加密并且必<br>  须复制到不同的 AWS 区域。哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制(CRR) 将加密对象复制到另一个区域中的 S3 存储桶。将服务器端加密与 AWS KMS 多区域密钥 (SSE-KMS) 结合使用。使用 Amazon Athena 查询数据。<br>  B. 创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制(CRR) 将加密对象复制到另一个区域中的 S3 存储桶。将服务器端加密与 AWS KMS 多区域密钥 (SSE-KMS) 结合使用。使用 Amazon RDS 查询数据。</p><p>  <strong>C. 将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域中的 S3 存储桶。使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。使用 Amazon Athena 查询数据。</strong> </p><p>  <code>SSE-S3会为每个对象使用唯一的加密密钥，并且由S3管理加密密钥的生命周期，从而减轻了密钥管理的负担。</code></p><p>  D. 将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域中的 S3 存储桶。使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。使用 Amazon RDS 查询数据。</p><h2 id="137-B"><a href="#137-B" class="headerlink" title="137-B"></a>137-B</h2><p>  一家公司使用 AWS Organizations 为每个业务部门创建专用 AWS 账户，以便根据请求独<br>  立管理每个业务部门的账户。根电子邮件收件人错过了发送到一个帐户的根用户电子邮件<br>  地址的通知。该公司希望确保不会错过所有未来的通知。未来的通知必须仅限于帐户管理<br>  员。哪种解决方案可以满足这些要求？</p><p>  A. 配置公司的电子邮件服务器，将发送到 AWS 账户根用户电子邮件地址的通知电子邮件转发给组织中的所有用户。</p><p>  <strong>B. 将所有 AWS 账户根用户电子邮件地址配置为分发列表，发送给少数可以响应警报的管<br>  理员。在 AWS Organizations 控制台中或以编程方式配置 AWS 账户备用联系人。</strong></p><p>  C. 将所有 AWS 账户根用户电子邮件配置为发送给一名管理员，该管理员负责监控警报并将这些警报转发到适当的组。</p><p>  D. 将所有现有 AWS 账户和所有新创建的账户配置为使用相同的根用户电子邮件地址。在<br>  AWS Organizations 控制台中或以编程方式配置 AWS 账户备用联系人。</p><h2 id="139-D"><a href="#139-D" class="headerlink" title="139-D"></a>139-D</h2><p>  报告团队每天都会在 Amazon S3 存储桶中收到文件。报告团队每天同时手动检查此初始S3 存储桶中的文件并将其复制到分析 S3 存储桶，以与 Amazon QuickSight 一起使用。更多团队开始将更多更大尺寸的文件发送到初始 S3 存储桶。报告团队希望在文件进入初始S3 存储桶时自动分析 S3 存储桶。报告团队还希望使用 AWS Lambda 函数对复制的数据运行模式匹配代码。此外，报告团队希望将数据文件发送到 Amazon SageMaker Pipelines中的管道。解决方案架构师应该如何做才能以最少的运营开销满足这些要求？</p><p>  <code>排除了A和B，因为它需要一个额外的Lambda作业来完成复制，而S3复制将以很少甚至没有开销来处理它。C是不正确的，因为S3通知不支持Sagemake管道</code></p><p>  &#96;&#96;A. 创建 Lambda 函数以将文件复制到分析 S3 存储桶。为分析 S3 存储桶创建 S3 事件通知。将Lambda 和 SageMaker Pipelines 配置为事件通知的目的地。配置s3:ObjectCreated:Put 作为事件类型。</p><p>  B. 创建 Lambda 函数以将文件复制到分析 S3 存储桶。配置分析 S3 存储桶以将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatchEvents) 中配置 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为规则的目标。</p><p>  C. 配置 S3 存储桶之间的 S3 复制。为分析 S3 存储桶创建 S3 事件通知。将 Lambda 和SageMaker Pipelines 配置为事件通知的目的地。配置 s3:ObjectCreated:Put 作为事件类型</p><p>  D. 配置 S3 存储桶之间的 S3 复制。配置分析 S3 存储桶以将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatch Events) 中配置ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为规则的目标。</p><h2 id="140-AC"><a href="#140-AC" class="headerlink" title="140-AC"></a>140-AC</h2><p>  解决方案架构师需要帮助公司优化在 AWS 上运行应用程序的成本。该应用程序将使用Amazon EC2 实例、AWS Fargate 和 AWS Lambda 在架构内进行计算。 EC2 实例将运行应用程序的数据摄取层。 **EC2 的使用将是零星且不可预测的。**在 EC2 实例上运行的工作负载可以随时中断。应用程序前端将在 Fargate 上运行，Lambda 将服务于 API 层。**明年的前端利用率和 API 层利用率将是可预测的。**哪种购买选项组合将为托管此应用程序提供最具成本效益的解决方案？ （选择两个。）<br>  A. 使用 Spot 实例作为数据摄取层<br>  B. 对数据摄取层使用按需实例<br>  C. 为前端和 API 层购买 1 年compute节省计划。<br>  D. 为数据摄取层购买 1 年期的预付费用预留实例。 </p><table><thead><tr><th>特征</th><th>EC2 Savings Plans</th><th>AWS Compute Savings Plans</th></tr></thead><tbody><tr><td>适用范围</td><td>EC2 实例</td><td><strong>EC2 实例和 Fargate 任务</strong></td></tr><tr><td>适用性灵活性</td><td>更大的实例选择</td><td>限于 EC2 实例</td></tr><tr><td>跨区域使用</td><td>可以在多个 AWS 区域使用</td><td>限于一个 AWS 区域</td></tr></tbody></table><h2 id="141-A"><a href="#141-A" class="headerlink" title="141-A"></a>141-A</h2><p>  一家公司运营一个基于网络的门户网站，为用户提供全球突发新闻、本地警报和天气更新。<br>  该门户通过混合使用静态和动态内容为每个用户提供个性化视图。内容通过在应用程序负<br>  载均衡器 (ALB) 后面的 Amazon EC2 实例上运行的 API 服务器通过 HTTPS 提供。该公<br>  司希望该门户尽快向世界各地的用户提供此内容。解决方案架构师应如何设计应用程序以<br>  确保所有用户的延迟最少？</p><p>  <strong>A. 在单个 AWS 区域中部署应用程序堆栈。通过指定 ALB 作为源，使用 Amazon CloudFront 提供所有静态和动态内容。</strong></p><p>  B. 在两个 AWS 区域中部署应用程序堆栈。使用 Amazon Route 53 延迟路由策略提供来自最近区域中 ALB 的所有内容。</p><p>  C. 在单个 AWS 区域中部署应用程序堆栈。使用 Amazon CloudFront 提供静态内容。直接从 ALB 提供动态内容。</p><p>  D. 在两个 AWS 区域中部署应用程序堆栈。使用 Amazon Route 53 地理位置路由策略在最近的区域中提供来自 ALB 的所有内容。</p><h2 id="145-D、"><a href="#145-D、" class="headerlink" title="145-D、"></a>145-D、</h2><p>  一家公司在单个 Amazon EC2 按需实例上托管网站分析应用程序。该分析软件是用 PHP<br>  编写的，并使用 MySQL 数据库。分析软件、提供 PHP 的 Web 服务器以及数据库服务<br>  器都托管在 EC2 实例上。该应用程序在繁忙时间显示出性能下降的迹象，并出现 5xx 错<br>  误。公司需要使应用程序无缝扩展。哪种解决方案能够最具成本效益地满足这些要求？<br>  A. 将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。<br>  使用 AMI 启动第二个 EC2 按需实例。使用应用程序负载均衡器将负载分配到每个 EC2<br>  实例。<br>  B. 将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。使用 AMI 启动第二个 EC2 按需实例。使用 Amazon Route 53 加权路由在两个 EC2 实例之间分配负载。</p><p>  C. 将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建 AWS Lambda 函数来停止<br>  EC2 实例并更改实例类型。创建 Amazon CloudWatch 警报以在 CPU 利用率超过 75% 时<br>  调用 Lambda 函数。</p><p>  D. 将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建 Web 应用程序的 AMI。将<br>  AMI 应用到启动模板。使用启动模板创建 Auto Scaling 组 配置启动模板以使用 Spot 队<br>  列。将应用程序负载均衡器附加到 Auto Scaling 组。<br>  正确答案：D</p><h2 id="7-D"><a href="#7-D" class="headerlink" title="7-D"></a>7-D</h2><p>  一家公司有一个接收传入消息的应用程序。然后，数十个其他应用程序和微服务快速消耗<br>  这些消息。消息数量变化很大，有时突然增加到每秒 100,000 条。该公司希望解耦解决方<br>  案并提高可扩展性。哪种解决方案满足这些要求？<br>  A. 将消息保留到 Amazon Kinesis Data Analytics。配置消费者应用程序以读取和处理消息。</p><p>  B. 在 Auto Scaling 组中的 Amazon EC2 实例上部署提取应用程序，以根据 CPU 指标扩<br>  展 EC2 实例的数量。</p><p>  C. 使用单个分片将消息写入 Amazon Kinesis Data Streams。使用 AWS Lambda 函数预处<br>  理消息并将其存储在 Amazon DynamoDB 中。配置消费者应用程序以从 DynamoDB 读取<br>  数据来处理消息。</p><p>  D. 将消息发布到具有多个 Amazon Simple Queue Service (Amazon SOS) 订阅的 Amazon<br>  Simple Notication Service (Amazon SNS) 主题。配置使用者应用程序以处理来自队列的消息。</p><p>  <code>fan out</code></p><h2 id="16-B"><a href="#16-B" class="headerlink" title="16-B"></a>16-B</h2><p>  一家公司在 AWS 上托管数据湖。数据湖由 Amazon S3 和 Amazon RDS for PostgreSQL中的数据组成。该公司需要一个提供数据可视化并包含数据湖中所有数据源的报告解决方案。只有公司的管理团队才能完全访问所有可视化。公司的其他成员应该只有有限的访问权限。</p><p>  哪种解决方案可以满足这些要求？</p><p>  A. 在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以<br>  可视化数据。与适当的 <strong>IAM 角色</strong>共享仪表板。</p><p>  B. 在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以<br>  可视化数据。与适当的<strong>用户和组</strong>共享仪表板。</p><p>  <code>发布仪表板后，您可以将其与QuickSight账户中的其他**用户或群组**共享。</code><br>  C. 为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。创建 AWS Glue 提取、转换<br>  和加载 (ETL) 作业以生成报告。将报告发布到 Amazon S3。使用 <strong>S3 存储桶策略</strong>来限制对<br>  报告的访问。<br>  D. 为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。使用 Amazon Athena 联合查<br>  询访问 Amazon RDS for PostgreSQL 中的数据。使用 Amazon Athena 生成报告。将报告发<br>  布到 Amazon S3。使用 <strong>S3 存储桶策略</strong>来限制对报告的访问。</p><h2 id="21-D"><a href="#21-D" class="headerlink" title="21-D"></a>21-D</h2><p>  一家电子商务公司希望在 AWS 上推出每日一交易网站。每天 24 小时内都会有一款产品<br>  在促销。该公司希望能够在高峰时段以<strong>毫秒</strong>级延迟处理每小时数百万个请求。哪种解决方<br>  案能够以最少的运营开销满足这些要求</p><p>  A. 使用 Amazon S3 在不同的 S3 存储桶中托管完整网站。添加 Amazon CloudFront 发行<br>  版。将 S3 存储桶设置为分发的来源。将订单数据存储在 Amazon S3 中。</p><p>  not provide the required performance and scale for millions of requests each hour with millisecond latency.</p><p>  B. 在跨多个可用区的 Auto Scaling 组中运行的 <strong><del>Amazon EC2 实例</del></strong>上部署完整网站。添加<br>  应用程序负载均衡器 (ALB) 以分发网站 trac。为后端 API 添加另一个 ALB。将数据存储<br>  在 Amazon RDS for MySQL 中。</p><p>  C. <del>迁移完整应用程序以在容器中运行</del>。在 Amazon Elastic Kubernetes Service (Amazon EKS)<br>  上托管容器。使用 Kubernetes Cluster Autoscaler 增加和减少 trac 中处理突发的 pod 数量。<br>  将数据存储在 Amazon RDS for MySQL 中。</p><p>  D. 使用 Amazon S3 存储桶托管网站的静态内容。部署 Amazon CloudFront 发行版。将 S3<br>  存储桶设置为原点。使用 Amazon API Gateway 和 AWS Lambda 函数作为后端 API。将<br>  数据存储在 Amazon DynamoDB 中。</p><h2 id="24-B"><a href="#24-B" class="headerlink" title="24-B"></a>24-B</h2><pre><code>  问题＃24一家公司在最近的账单中发现 Amazon EC2 成本有所增加。计费团队注意到几个 EC2 实例的实例类型出现不必要的垂直扩展。解决方案架构师需要创建一个图表来比较过去 2 个月的 EC2 成本，并进行深入分析以确定垂直扩展的根本原因。解决方案架构师应如何以最少的运营开销生成信息？A. 使用 AWS Budgets 创建预算报告并根据实例类型比较 EC2 成本。`无法深入分析`**B. 使用 Cost Explorer 的粒度过滤功能根据实例类型对 EC2 成本进行深入分析。**C. 使用 AWS Billing and Cost Management 仪表板中的图表来比较过去 2 个月基于实例类型的 EC2 成本。`需要更多手动操作和配置`D. 使用 AWS 成本和使用情况报告创建报告并将其发送到 Amazon S3 存储桶。使用Amazon QuickSight 和 Amazon S3 作为源，根据实例类型生成交互式图表。`是一个可行的方法，但可能涉及更多的配置和复杂性。`</code></pre><h2 id="36-B"><a href="#36-B" class="headerlink" title="36-B"></a>36-B</h2><p>  一家公司正在 AWS 云中构建应用程序。该应用程序将数据存储在两个 AWS 区域的Amazon S3 存储桶中。公司必须使用 AWS Key Management Service (AWS KMS) <strong>客户托管密钥</strong>来加密存储在 S3 存储桶中的所有数据。**两个 S3 存储桶中的数据必须使用相同的KMS 密钥进行加密和解密。**数据和密钥必须存储在两个区域中的每一个中。</p><p>  哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 在每个区域创建一个 S3 存储桶。配置 S3 存储桶以使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。</p><p>  <strong>B. 创建客户管理的多区域 KMS 密钥。在每个区域创建一个 S3 存储桶。配置 S3 存储桶之间的复制。配置应用程序以使用带有客户端加密的 KMS 密钥。</strong></p><p>  C. 在每个区域中创建客户管理的 KMS 密钥和 S3 存储桶。配置 S3 存储桶以使用带有Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。</p><p>  D. 在每个区域中创建客户管理的 KMS 密钥和 S3 存储桶。配置 S3 存储桶以使用带有AWS KMS 密钥的服务器端加密 (SSE-KMS)。配置 S3 存储桶之间的复制。</p><h2 id="501-C"><a href="#501-C" class="headerlink" title="501-C"></a>501-C</h2><p>  一家公司希望将客户支付数据提取到公司的 Amazon S3 数据湖中。该公司平均每分钟都会<br>  收到付款数据。该公司希望实时分析支付数据。然后该公司希望将数据提取到数据湖中。<br>  哪种解决方案能够以最高的运营效率满足这些要求？<br>  A. 使用 Amazon Kinesis Data Streams 提取数据。使用 AWS Lambda 实时分析数据。<br>  B. 使用 AWS Glue 提取数据。使用 Amazon Kinesis Data Analytics 实时分析数据。</p><p>  C. 使用 Amazon Kinesis Data Firehose 提取数据。使用 Amazon Kinesis Data Analytics 实时<br>  分析数据。</p><p>  <code>Kinesis Data Firehose 可以从多个数据源（如日志、传感器数据、应用程序事件等）中收集实时数据流，将其传输到各种目标。</code><br>  D. 使用 Amazon API Gateway 提取数据。使用 AWS Lambda 实时分析数据。<br>  正确答案：C</p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-16【 网络】Route 53-域名系统</title>
      <link href="/2023/08/17/AWS-16%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91Route%2053-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F/"/>
      <url>/2023/08/17/AWS-16%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91Route%2053-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="Amazon-Route-53"><a href="#Amazon-Route-53" class="headerlink" title="Amazon Route 53"></a><strong>Amazon Route 53</strong></h1><p><img src="/images/Untitled%20165.png" alt="Untitled"></p><ul><li>“Route 53”是指传统DNS使用的端口号（53）</li></ul><ol><li><strong>域名解析</strong>：Route 53 允许您将域名映射到各种 AWS 资源，如 **Amazon S3 存储桶、Amazon EC2 实例、Elastic Load Balancer（ELB）**等。您可以配置 DNS 记录，将用户输入的域名转换为 IP 地址，从而使用户能够通过域名访问您的资源。</li><li><strong>高可用和可靠性</strong>：Route 53 提供全球分布的 DNS 服务，具有高可用性和可靠性。它将自动将 DNS 记录分发到多个全球边缘位置，以确保用户能够就近访问资源，提高响应速度和可用性。</li><li><strong>负载均衡</strong>：Route 53 可与 Amazon Elastic Load Balancing 集成，实现负载均衡。您可以配置 DNS 记录，将流量分发到不同的负载均衡器，以实现高可用性和性能优化。</li></ol><ul><li>能够检查您的资源的健康状态</li><li><strong>100% SLA保证</strong>：Route 53是唯一一个AWS服务提供100%可用性的服务级别协议（SLA）。</li></ul><h3 id="“Route-53-Active-Passive”"><a href="#“Route-53-Active-Passive”" class="headerlink" title="“Route 53 Active-Passive”"></a>“Route 53 Active-Passive”</h3><p>是一种架构配置，主要用于实现高可用性和故障恢复。</p><p>在 Active-Passive 配置中，我们通常考虑系统中的两种状态：活动状态（Active）和待命状态（Passive）。</p><ul><li><strong>活动状态（Active）：</strong> 这是系统中当前正在提供服务的状态。在一个 “Route 53 Active-Passive” 配置中，活动状态通常指向一个实际提供服务的资源，比如一个服务器、虚拟机实例或应用程序。</li><li><strong>待命状态（Passive）：</strong> 这是系统中备用的、处于待命状态的资源。它不提供实际的服务，而是等待在活动状态不可用时接管服务。待命状态的资源会与活动状态资源保持同步，以确保数据的一致性。</li></ul><h3 id="Route-53故障转移的关键点如下："><a href="#Route-53故障转移的关键点如下：" class="headerlink" title="Route 53故障转移的关键点如下："></a><strong>Route 53故障转移</strong>的关键点如下：</h3><ol start="4"><li><strong>Failover Routing Policy</strong>：Route 53的Failover路由策略允许您配置主&#x2F;备份资源，以便在主资源不可用时自动将流量切换到备份资源。例如，您可以将流量引导到主要AWS区域中的资源，但如果该区域发生故障，Route 53可以将流量切换到另一个备份区域中的资源。</li><li><strong>Health Checks</strong>：您可以设置Route 53的健康检查来监控各个资源的可用性。当主资源不可用时，健康检查可以自动触发Route 53的Failover策略，将流量切换到备份资源。</li><li><strong>Global Accelerator Integration</strong>：Route 53可以与AWS Global Accelerator结合使用，以提供全球级别的流量管理和故障转移。Global Accelerator可以优化全球范围内的流量分发，确保将用户流量快速引导到最近的健康资源。</li><li><strong>Latency-Based Routing</strong>：虽然不直接是故障转移，但根据延迟的路由策略可以确保将用户流量引导到距离最近且延迟最低的资源，从而提高用户体验并减少延迟。</li></ol><h3 id="Routing-Policies-路由策略"><a href="#Routing-Policies-路由策略" class="headerlink" title="Routing Policies-路由策略"></a>Routing Policies-<strong>路由策略</strong></h3><ul><li><p>Defines how Route53 responds to DNS queries</p><p>  定义了如何将 DNS 查询路由到资源</p><p>  以下是展示 Amazon Route 53 不同路由策略及其特点和适用场景的表格：</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>权重路由策略（Weighted）</td><td>- 按照权重分配到不同资源</td></tr><tr><td>故障转移路由策略（Failover）</td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr><tr><td>多值路由策略（Multivalue）</td><td>- 用于将流量路由到多个资源</td></tr></tbody></table><p>  这个表格展示了 Amazon Route 53 不同的路由策略，以及每个策略的特点和适用场景。希望这能够帮助您更清楚地了解每种路由策略的用途和优势。</p></li></ul><h3 id="Simple-Routing（简单路由）"><a href="#Simple-Routing（简单路由）" class="headerlink" title="Simple Routing（简单路由）:"></a><strong>Simple Routing</strong>（简单路由）:</h3><ul><li>返回单个资源的所有记录</li><li>如果返回了多个相同记录的值，则客户端将随机选择一个</li><li>不能与健康检查相关联</li></ul><h3 id="Weighted-Routing（加权路由）"><a href="#Weighted-Routing（加权路由）" class="headerlink" title="Weighted Routing（加权路由）:"></a><strong>Weighted Routing</strong>（加权路由）:</h3><ul><li>control traffic by weight</li><li>can be associated with Health Checks</li><li>Assign a weight of 0 to a record to stop sending traffic to a resource • If all records have we</li><li><strong>按照权重分配到不同资源</strong></li><li>按权重控制流量</li><li>可以与健康检查相关联</li><li>将记录的权重分配为0，以停止向资源发送流量</li><li>如果所有记录的权重都为0，则不会向该资源发送流量</li></ul><h3 id="Failover-Routing（故障转移路由）"><a href="#Failover-Routing（故障转移路由）" class="headerlink" title="Failover Routing（故障转移路由）:"></a><strong>Failover Routing</strong>（故障转移路由）:</h3><ul><li>When an active instance failed the health check, the standby instance will failover and become active</li></ul><p>当<strong>活动实例未通过健康检查时，备用实例将接管并成为活动实例。</strong></p><h3 id="Latency-based-Routing（基于延迟的路由）"><a href="#Latency-based-Routing（基于延迟的路由）" class="headerlink" title="Latency-based Routing（基于延迟的路由）:"></a><strong>Latency-based Routing</strong>（基于延迟的路由）:</h3><ul><li>Redirect to the resource that has the least latency close to user</li><li>Latency is based on traffic between users and AWS Regions</li><li>Can be associated with Health Checks</li><li>重定向到距离用户最近的资源</li><li>延迟基于用户和AWS区域之间的流量</li><li>可以与健康检查相关联</li></ul><h3 id="Geolocation-Routing（地理位置路由）"><a href="#Geolocation-Routing（地理位置路由）" class="headerlink" title="Geolocation Routing（地理位置路由）:"></a><strong>Geolocation Routing</strong>（地理位置路由）:</h3><ul><li>This routing is based on user location</li><li>Can be associated with Health Checks</li></ul><h3 id="Multi-Value-Answer-Routing（多值回答路由）"><a href="#Multi-Value-Answer-Routing（多值回答路由）" class="headerlink" title="Multi-Value Answer Routing（多值回答路由）:"></a><strong>Multi-Value Answer Routing</strong>（多值回答路由）:</h3><ul><li>Use when routing traffic to multiple resources</li><li>Each resource receives a separate DNS response, and Route 53 responds to DNS queries with multiple IP addresses.</li><li>Can be associated with Health Checks (return only values for healthy resources)</li><li>用于将流量路由到多个资源</li><li>每个资源都会收到单独的 DNS 响应，并且 Route 53 会用多个 IP 地址响应 DNS 查询。</li><li>可以与健康检查相关联（仅返回健康资源的值）</li><li>有助于实现<strong>负载均衡</strong>和<strong>高可用性</strong>。</li></ul><h3 id="Geoproximity-Routing（地理接近路由）"><a href="#Geoproximity-Routing（地理接近路由）" class="headerlink" title="Geoproximity Routing（地理接近路由）:"></a><strong>Geoproximity Routing</strong>（地理接近路由）:</h3><ul><li>Route traffic to your resources based on the geographic location of users and resources</li><li>Ability to shift more traffic to resources based on the defined bias</li></ul><h3 id="Route-53-–-Records记录集"><a href="#Route-53-–-Records记录集" class="headerlink" title="Route 53 – Records记录集"></a><strong>Route 53 – Records</strong>记录集</h3><p>用于将域名映射到特定资源（例如IP地址、其他域名或负载均衡器）的信息</p><ul><li><strong>Domain&#x2F;subdomain Name</strong> – e.g., example.com</li><li><strong>Record Type</strong> – e.g., A or AAAA</li><li><strong>Value</strong> – e.g., 12.34.56.78</li><li><strong>Routing Policy</strong> – how Route 53 responds to queries</li><li><strong>TTL（time to live）</strong> – amount of time the record cached at DNS Resolvers</li></ul><h3 id="Record-Types-记录类型"><a href="#Record-Types-记录类型" class="headerlink" title="Record Types-记录类型"></a><strong>Record Types-记录类型</strong></h3><ul><li><strong>A</strong> – maps a hostname to IPv4</li><li><strong>AAAA</strong> – maps a hostname to IPv6</li><li><strong>CNAME</strong> – maps a hostname to another hostname<ul><li>The target is a domain name which must have an A or AAAA record</li><li>Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)</li><li>Example: you can’t create for example.com, but you can create for <a href="http://www.example.com/">www.example.com</a></li></ul></li><li><strong>NS</strong> – Name Servers for the Hosted Zone<ul><li>Control how traffic is routed for a domain</li></ul></li></ul><h3 id="hosted-zone-托管区域"><a href="#hosted-zone-托管区域" class="headerlink" title="hosted zone-托管区域"></a>hosted zone-托管区域</h3><p>Hosted Zone（托管区域）是一个与特定域名（例如 <a href="http://example.com/">example.com</a>）关联的 DNS 区域。它包含了该域名下所有 DNS 记录的信息，用于解析域名到相应的 IP 地址或其他资源。</p><p><strong>一个包含定义如何路由流量到域名及其子域名的记录的容器</strong></p><ul><li><strong>公有托管区域</strong><ul><li>包含指定如何在互联网上路由流量的记录</li></ul></li><li><strong>私有托管区域</strong><ul><li>包含指定如何在一个或多个VPC中路由流量的记录</li></ul></li><li>每个托管区域每月收取0.5美元的费用</li></ul><h3 id="Alias-Records-别名记录"><a href="#Alias-Records-别名记录" class="headerlink" title="Alias Records-别名记录"></a>Alias Records-<strong>别名记录</strong></h3><ul><li>将主机名映射到AWS资源</li><li>别名记录始终为AWS资源的类型A&#x2F;AAAA（IPv4&#x2F;IPv6）</li><li>您无法设置TTL, route53自动设置</li><li>您无法为EC2 DNS名称设置别名记录</li><li>You cannot set an ALIAS record for an EC2 DNS name</li></ul><h3 id="Health-Checks-健康检查"><a href="#Health-Checks-健康检查" class="headerlink" title="Health Checks-健康检查"></a>Health Checks-健康检查</h3><ul><li>HTTP Health Checks are only for public resources</li><li>Health Check &#x3D;&gt; Automated DNS Failover</li><li>健康检查与CloudWatch指标集成</li><li>配置路由器&#x2F;防火墙以允许来自Route 53 Health Checkers的传入请求</li></ul><h3 id="Health-checks-that-monitor-an-endpoint"><a href="#Health-checks-that-monitor-an-endpoint" class="headerlink" title="Health checks that monitor an endpoint"></a><strong>Health checks that monitor an endpoint</strong></h3><p>您可以配置运行状况检查来监控通过 IP 地址或域名指定的端点。Route 53 按照您指定的固定间隔，通过互联网向您的应用程序、服务器或其它资源自动提交请求，以验证其是否可到达、是否可用及功能是否正常。您也可以通过配置运行状况检查来发出与用户发出的请求类似的请求，如从特定 URL 请求网页。</p><h3 id="calculated-health-checks"><a href="#calculated-health-checks" class="headerlink" title="calculated health checks"></a><strong>calculated health checks</strong></h3><ul><li>Combine the results of multiple Health Checks into a single Health Check</li><li>You can use OR, AND, or NOT</li><li>Can monitor up to 256 Child Health Checks</li><li>Specify how many of the health checks need to pass to make the parent pass</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-13【 网络】VPC</title>
      <link href="/2023/08/16/AWS-14%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91VPC/"/>
      <url>/2023/08/16/AWS-14%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91VPC/</url>
      
        <content type="html"><![CDATA[<h1 id="VPC"><a href="#VPC" class="headerlink" title="VPC"></a><strong>VPC</strong></h1><h3 id="Virtual-Private-Cloud"><a href="#Virtual-Private-Cloud" class="headerlink" title="Virtual Private Cloud"></a>Virtual Private Cloud</h3><p><img src="/images/Untitled%20133.png" alt="Untitled"></p><h2 id="1-VPC-概述"><a href="#1-VPC-概述" class="headerlink" title="1. VPC 概述"></a>1. VPC 概述</h2><ul><li>VPC 是一个逻辑隔离的 AWS 云网络，允许您在自己定义的虚拟网络中运行 AWS 资源。</li><li>VPC 具有 IP 地址范围（CIDR 块）。</li><li>类似传统网络中的<strong>VLAN</strong></li><li>multiple VPCs  in a region(最多5个）</li><li>VPC的最大CIDR范围可以是&#x2F;16（65,536个IP地址）到&#x2F;28（16个IP地址）</li></ul><p><img src="/images/Untitled%20134.png" alt="Untitled"></p><h2 id="2-Subnets-子网"><a href="#2-Subnets-子网" class="headerlink" title="2. Subnets-子网"></a>2. Subnets-子网</h2><ul><li>Subnet 是 VPC IP 地址范围的一部分，用于在 VPC 内部划分不同的网络区域。</li></ul><p><img src="/images/Untitled%20135.png" alt="Untitled"></p><ul><li>子网必须位于单个可用区中</li><li>子网可以分配给不同的AZ，确保高可用性。<ul><li>保留5个IP地址，前四个和最后一个</li></ul></li><li><strong>公有子网（Public Subnet</strong>：与 Internet Gateway（IGW）关联，可以直接访问 Internet。</li><li><strong>私有子网（Private Subnet）</strong>：无法直接访问 Internet，通常用于安全敏感的工作负载。通过NAT网关或NAT实例来实现对Internet的有限访问</li></ul><h2 id="3-Route-Table-路由表"><a href="#3-Route-Table-路由表" class="headerlink" title="3.Route Table-路由表"></a>3.<strong>Route Table-路由表</strong></h2><p>路由表定义了网络流量如何在子网之间和VPC内部进行路由。每个子网都会关联一个路由表，该表指定了流量的目标以及如何将流量转发到目标。</p><h2 id="4-安全组-Security-Group-和NACL"><a href="#4-安全组-Security-Group-和NACL" class="headerlink" title="4. 安全组 (Security Group) 和NACL"></a>4. 安全组 (Security Group) 和NACL</h2><ul><li><p><strong>安全组（Security Group）</strong></p><ul><li><strong>层次： instance-level</strong>每个实例可以关联一个或多个安全组。它是第一层防御，应用在每个实例上。</li><li><strong>规则：</strong> 基于”allow”的原则。如果规则没有明确允许，那么它就会被隐式地拒绝。</li><li><strong>状态：stateful</strong></li><li><strong>应用：</strong> 用于实现实例级别的访问控制，通常用于控制实例之间的通信。</li></ul></li><li><p><strong>网络访问控制列表（NACL）-Network Access Control List</strong></p><p>  <strong>默认情况下，它允许所有入站和出站 IPv4 流量以及 IPv6 流量</strong></p><ul><li><p><strong>层次：</strong> NACL是在子网级别操作的，每个子网都有一个关联的NACL。它是第二层防御，应用在子网内。</p></li><li><p><strong>规则：</strong> 基于”allow”和”deny”。</p></li><li><p><strong>状态：</strong> <strong>stateless，如果您允许出站流量，入站回复流量不会自动被允许。<code>这意味着你需要同时考虑入站和出站规则，因为出站规则也会影响入站流量的回复。</code></strong></p><ul><li><strong><code>需要确保相关的出站规则允许响应的HTTPS流量返回</code></strong></li></ul></li><li><p><strong>应用：</strong> 用于实现子网级别的访问控制，通常用于控制子网之间的通信。</p></li><li><p>Default NACL</p><ul><li>Accepts everything inbound&#x2F;outbound with the subnets it’s associated with</li><li>Do NOT modify the Default NACL, instead create custom NACLs</li></ul><p>  <img src="/images/Untitled%20136.png" alt="Untitled"></p></li></ul></li></ul><table><thead><tr><th>特点 &#x2F; 注意事项</th><th>安全组 (SG)</th><th>网络访问控制列表 (NACL)</th></tr></thead><tbody><tr><td>类型</td><td>实例级别防火墙</td><td>子网级别防火墙</td></tr><tr><td>方向</td><td>可以配置入站和出站规则</td><td><strong>必须</strong>同时配置入站和出站规则</td></tr><tr><td>默认规则</td><td>拒绝所有流量</td><td>允许所有流量</td></tr><tr><td>有状态性</td><td>有状态，自动允许相关回复流量</td><td>无状态，入站和出站流量的状态是分开维护</td></tr><tr><td>数量限制</td><td>一个实例可以关联多个安全组</td><td>一个子网只能关联一个网络访问控制列表</td></tr><tr><td>功能</td><td>简单，易于使用</td><td>较为复杂，可用于更细粒度的控制</td></tr></tbody></table><p><strong>注意事项：</strong></p><p><strong>安全组 (SG)：</strong></p><ul><li>安全组适用于实例级别的访问控制，配置更简单，但只能定义基于协议、端口和IP范围的规则。</li><li>可以在安全组之间进行联动，一个实例可以关联多个安全组，规则叠加。</li><li>入站规则优先于出站规则，相关回复流量自动允许。</li></ul><p><strong>网络访问控制列表 (NACL)：</strong></p><ul><li>NACL 适用于子网级别的访问控制，可以更细粒度地定义入站和出站规则。</li><li>需要同时配置入站和出站规则，注意规则的顺序和编号。</li><li>无状态性意味着入站和出站流量的状态是分开维护的，需要确保出站规则允许相关回复流量。</li><li>更适合处理较复杂的网络策略，但需要更多的配置工作。</li></ul><p>请根据你的需求和网络架构，选择合适的访问控制方式。一般情况下，安全组用于基本的实例级别防火墙，而 NACL 则用于更细粒度的子网级别控制。</p><p><img src="/images/Untitled%20137.png" alt="Untitled"></p><p><strong>选择安全组还是NACL：</strong></p><ul><li>如果您需要更精细的控制，并且关注于实例级别的访问控制，使用安全组。</li><li>如果您需要更高层次的网络防御，以及控制子网之间的通信，使用NACL。</li><li>在复杂的网络环境中，通常会同时使用安全组和NACL来提供多层次的安全性。</li></ul><h2 id="5-VPC-Peering-对等连接"><a href="#5-VPC-Peering-对等连接" class="headerlink" title="5. VPC Peering-对等连接"></a>5. VPC Peering-<strong>对等连接</strong></h2><p>VPC Peering 允许在不同的 VPC 之间创建私有连接。</p><ul><li><strong>连接不同VPC：</strong> VPC Peering允许您将两个不同的VPC连接在一起，使它们之间可以进行安全的通信。</li><li><strong>不具备传递性</strong></li><li><strong>跨帐户&#x2F;区域：</strong> 您可以在不同的AWS帐户或不同的AWS区域之间创建VPC Peering连接，从而实现多个帐户或区域之间的私有通信。<ul><li>可以在不同 AWS 账户之间或同一账户下的不同 VPC 之间建立 VPC Peering。</li></ul></li><li><strong>引用安全组：</strong> 在同一区域的不同帐户之间，您可以通过VPC Peering引用另一个VPC中的安全组，以实现资源间的访问控制。</li><li><strong>路由表更新：</strong> 在建立VPC Peering后，您需要更新每个VPC子网的路由表，以确保VPC内的EC2实例可以通过Peering连接进行通信。</li></ul><h2 id="6-VPC-端点-Endpoints"><a href="#6-VPC-端点-Endpoints" class="headerlink" title="6. VPC 端点 (Endpoints)"></a>6. VPC 端点 (Endpoints)</h2><p>用于在 <strong>VPC 内部与 AWS 服务</strong>进行安全通信。</p><ul><li>VPC 端点允许 <strong>VPC 中的实例与 AWS 服务</strong>通信，而无需通过 Internet。</li><li>分为网关端点（Gateway Endpoint）和接口端点（Interface Endpoint）。</li><li>They’re redundant and scale horizontally冗余性并且水平扩展</li></ul><p><img src="/images/Untitled%20138.png" alt="Untitled"></p><ul><li><p><strong>类型：</strong> 有两种类型的VPC终端节点：</p><ul><li><strong>接口终端节点（Interface Endpoints）：</strong> 使用AWS PrivateLink提供支持，它为您的VPC分配一个Elastic Network Interface（<strong>ENI</strong>），作为访问AWS服务的入口点。支持大多数AWS服务，<strong>需要按小时计费并按数据处理量付费。</strong></li></ul><p>  <img src="/images/Untitled%20139.png" alt="Untitled"></p><ul><li><strong>网关终端节点（Gateway Endpoints）：</strong> 适用于S3和DynamoDB，可以将终端节点作为目标添加到VPC的路由表中。网关终端节点<strong>免费且不使用安全组。</strong></li></ul><p>  <img src="/images/Untitled%20140.png" alt="Untitled">  </p></li><li><p><strong>适用场景：</strong></p><ul><li>对于需要安全地连接到AWS服务的情况，如数据库、存储和计算资源，VPC终端节点是一个理想的选择。</li><li>接口终端节点适用于需要连接多种AWS服务的场景，而网关终端节点适用于S3和DynamoDB的访问</li></ul></li><li><p>Gateway or Interface Endpoint for <strong>S3</strong>?</p><ul><li>Gateway is most likely going to be preferred all the time at the exam</li><li>Unless, access is required from on premises (Site to Site VPN or Direct Connect), a different VPC or a different region</li><li>选择S3的网关终端节点还是接口终端节点？<br>  在考试中，gateway很可能会始终被优先选择<br>  除非需要从本地环境（站点到站点VPN或直接连接）、不同的VPC或不同的区域访问。</li></ul></li></ul><h2 id="7-VPC-流日志-Flow-Logs"><a href="#7-VPC-流日志-Flow-Logs" class="headerlink" title="7. VPC 流日志 (Flow Logs)"></a>7. VPC 流日志 (Flow Logs)</h2><ul><li>VPC 流日志可捕获 VPC 内部网络流量的详细信息，用于安全审计和网络监控。</li><li>流日志可以将数据发送到 Amazon S3、CloudWatch Logs 或 Amazon ES。</li></ul><h2 id="VPC-Flow-Logs"><a href="#VPC-Flow-Logs" class="headerlink" title="VPC Flow Logs"></a>VPC Flow Logs</h2><ul><li>Capture information about IP traffic going into your interfaces</li><li>Helps to monitor &amp; troubleshoot connectivity issues</li><li>Flow logs data can go to S3 &#x2F; CloudWatch Logs</li><li>Query VPC flow logs using Athena on S3 or CloudWatch Logs Insights</li><li>捕获进入接口的IP流量信息</li><li>有助于监视和解决连接问题</li><li>流日志数据可发送到S3 &#x2F; CloudWatch日志</li><li>使用Athena在S3上查询VPC流日志或CloudWatch日志洞察</li></ul><p><img src="/images/Untitled%20141.png" alt="Untitled"></p><h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><img src="/images/Untitled%20142.png" alt="Untitled"></p><p><img src="/images/Untitled%20143.png" alt="Untitled"></p><p><img src="/images/Untitled%20144.png" alt="Untitled"></p><p><img src="/images/Untitled%20145.png" alt="Untitled"></p><p><img src="/images/Untitled%20146.png" alt="Untitled"></p><p><img src="/images/Untitled%20147.png" alt="Untitled"></p><p><img src="/images/Untitled%20148.png" alt="Untitled"></p><p><img src="/images/Untitled%20149.png" alt="Untitled"></p><p><img src="/images/Untitled%20150.png" alt="Untitled"></p><p><img src="/images/Untitled%20151.png" alt="Untitled"></p><h1 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h1><h2 id="1-Internet-Gateway-IGW"><a href="#1-Internet-Gateway-IGW" class="headerlink" title="1. Internet Gateway (IGW)"></a>1. Internet Gateway (IGW)</h2><ul><li><strong>IGW（Internet gateway）是AWS提供的，用来实现VPC和Internet之间相互通信的高可用组件。</strong></li><li>IGW 是连接 VPC 内部<strong>私有子网</strong>和<strong>公共 Internet</strong> 的组件。</li><li>在公有子网中，IGW 允许实例与 Internet 通信，且可以使用公有 IP。</li><li>一个VPC只能连接到一个IGW，反之亦然</li></ul><h2 id="2-NAT"><a href="#2-NAT" class="headerlink" title="2. NAT"></a>2. NAT</h2><h3 id="NAT-Network-Address-Translation"><a href="#NAT-Network-Address-Translation" class="headerlink" title="NAT &#x3D; Network Address Translation"></a>NAT &#x3D; Network Address Translation</h3><p>NAT 网关主要用于<strong>私有子网中的实例</strong>访问互联网</p><p><strong><code>出站连接</code></strong></p><h3 id="NAT-instance"><a href="#NAT-instance" class="headerlink" title="NAT instance"></a><strong>NAT instance</strong></h3><p>需要手动配置，适用于小规模流量。Old, must be setup in a public subnet, disable Source &#x2F; Destination check flag</p><p><img src="/images/Untitled%20152.png" alt="Untitled"></p><h3 id="NAT-gateway"><a href="#NAT-gateway" class="headerlink" title="NAT gateway"></a>NAT gateway</h3><p>AWS 托管，适用于大规模流量和高可用性需求。</p><p>NAT Gateway由AWS管理，提供可扩展的IPv4私有EC2实例Internet访问。</p><p>性能和可用性较高，所以通常优于NAT Instance。</p><p><img src="/images/Untitled%20153.png" alt="Untitled"></p><h2 id="3-AWS-Direct-Connect-DX-直连"><a href="#3-AWS-Direct-Connect-DX-直连" class="headerlink" title="3. AWS Direct Connect (DX)-直连"></a>3. AWS Direct Connect (DX)-直连</h2><p><img src="/images/Untitled%20154.png" alt="Untitled"></p><ul><li><strong>专用的物理连接</strong></li><li>AWS Direct Connect 在您的本地部署网络和 AWS 之间建立专用网络连接。</li><li>可以实现更稳定、低延迟的连接，用于大数据传输和混合云架构。</li></ul><h2 id="Direct-Connect-DX"><a href="#Direct-Connect-DX" class="headerlink" title="Direct Connect (DX)"></a>Direct Connect (DX)</h2><ul><li>提供从远程网络到您的VPC的dedicated private专用私有连接。</li><li>Data Center and <em><strong>AWS Direct Connect locations</strong></em>之间设置专用连接。</li></ul><aside>💡 DX Location是AWS Direct Connect服务的实际物理位置，通过连接到这些位置，您可以建立专用的物理连接</aside><ul><li><p>可以在同一连接上访问公共资源（如S3）和私有资源（如EC2）。</p></li><li><p>支持IPv4和IPv6。</p><p>  <img src="/images/Untitled%20155.png" alt="Untitled"></p></li></ul><blockquote><p><strong>连接流程：</strong></p></blockquote><ol><li>您在AWS控制台中选择一个DX Location，这是您将要建立连接的物理位置。</li><li>在您的本地网络中，您配置一个CGW，以确保它能够连接到DX Location。</li><li>您在AWS中创建一个VGW，并分配一个公共IP地址。</li><li>您在CGW和VGW之间建立IPSec隧道，通过配置加密和认证参数，以建立安全的通信通道。</li><li>一旦隧道建立，数据可以通过VPN连接在CGW和VGW之间进行加密传输。</li></ol><h2 id="Direct-Connect-Gateway"><a href="#Direct-Connect-Gateway" class="headerlink" title="Direct Connect Gateway"></a>Direct Connect Gateway</h2><ul><li>如果您想要在许多不同的区域（同一账户）中设置与一个或多个VPC的Direct Connect连接，您必须使用Direct Connect网关。If you want to set up a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway</li><li>建立新连接需要一个月以上的时间。</li><li>在传输中的数据未加密，但是保持私密性。<ul><li>AWS Direct Connect + VPN提供了一个IPsec加密的私有连接。</li></ul></li><li>如果Direct Connect发生故障，您可以设置备份Direct Connect连接（费用较高），或者设置站点到站点VPN连接。In case Direct Connect fails, you can set up a backup Direct Connect connection (expensive), or a Site-to-Site VPN connection</li><li></li></ul><p><img src="/images/Untitled%20156.png" alt="Untitled"></p><p><img src="/images/Untitled%20157.png" alt="Untitled"></p><h2 id="4-Bastion-Hosts"><a href="#4-Bastion-Hosts" class="headerlink" title="4. Bastion Hosts"></a>4. Bastion Hosts</h2><ul><li>一个作为跳板的 EC2 instance</li><li>Bastion Host 是放置在公有子网中的实例，用于安全远程访问私有子网中的实例。</li><li>通常用于管理和维护私有子网中的实例，提供临时访问。</li></ul><p>访问跳板：在受保护的内部网络和外部网络之间进行访问的中间节点。</p><p>位于公共网络中</p><p>使用bastion hosts  to SSH into 私有EC2实例</p><p><img src="/images/Untitled%20158.png" alt="Untitled"></p><h2 id="5-Ephemeral-Ports"><a href="#5-Ephemeral-Ports" class="headerlink" title="5. Ephemeral Ports"></a>5. Ephemeral Ports</h2><p><code>临时端口，短暂端口或动态端口</code></p><ul><li>随机分配的临时端口</li><li>Ephemeral Ports（短暂端口）是客户端与服务器之间临时建立的端口，用于数据传输。</li><li>通常在连接时随机分配，并在连接终止后释放。</li><li>Clients connect to a defined port, and expect a response on this port</li></ul><h2 id="6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN"><a href="#6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN" class="headerlink" title="6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN"></a>6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN</h2><h2 id="Site-to-Site-VPN"><a href="#Site-to-Site-VPN" class="headerlink" title="Site-to-Site VPN"></a>Site-to-Site VPN</h2><p>将本地数据中心与 VPC 直接连接的方法，作为备份连接方式。</p><p><strong>建立本地到VPC的连接：</strong> VPC站点到站点VPN允许您在VPC和本地数据中心之间建立一个加密的连接，使您的本地资源可以与VPC中的资源进行通信。</p><aside>💡 **VPN Gateway：** 在云服务中和本地网络中分别创建VPN Gateway：<aside>💡 VGW表示VPC侧的VPN设备</aside><aside>💡 LWG表示本地数据中心侧的VPN设备。</aside></aside><h3 id="VGW（Virtual-Private-Gateway）："><a href="#VGW（Virtual-Private-Gateway）：" class="headerlink" title="VGW（Virtual Private Gateway）："></a><strong>VGW（Virtual Private Gateway）：</strong></h3><ul><li>VGW是云服务提供商（如AWS）中的虚拟设备，用于建立VPN连接并处理数据的传入和传出。</li><li>VGW is created and attached to the VPC from which you want to create the Site-to-Site VPN connection</li></ul><h3 id="CGW（Customer-Gateway）："><a href="#CGW（Customer-Gateway）：" class="headerlink" title="CGW（Customer Gateway）："></a><strong>CGW（Customer Gateway）：</strong></h3><ul><li>本地网络中的物理设备或虚拟设备</li><li>与VGW之间建立IPSec隧道来实现安全通信。</li></ul><p><img src="/images/Untitled%20159.png" alt="Untitled"></p><h2 id="Site-to-Site-VPN-connection-as-a-backup"><a href="#Site-to-Site-VPN-connection-as-a-backup" class="headerlink" title="Site-to-Site VPN connection as a backup"></a>Site-to-Site VPN connection as a backup</h2><p><img src="/images/Untitled%20160.png" alt="Untitled"></p><h2 id="AWS-VPN-CloudHub"><a href="#AWS-VPN-CloudHub" class="headerlink" title="AWS VPN CloudHub"></a>AWS VPN CloudHub</h2><p>AWS VPN CloudHub 允许多个站点通过 VPN 连接到 AWS。</p><p>集中式的解决方案</p><ul><li>Provide secure communication between multiple sites, if you have multiple VPN connections</li><li>Low-cost hub-and-spoke model for primary or secondary network connectivity between different locations (VPN only)</li><li>It’s a VPN connection so it goes over the public Internet</li><li>如果有多个 VPN 连接，可以在多个站点之间提供安全通信</li><li>低成本的枢纽-辐射模型，用于不同位置之间的主要或次要网络连接 (仅限 VPN)</li><li>这是一种 VPN 连接，因此它经过公共互联网传输</li></ul><ol start="6"><li><strong>多站点连接：</strong> AWS VPN CloudHub支持同时连接多个远程站点。这些站点可以是不同地理位置的办公室、数据中心等。</li><li><strong>中心式架构：</strong> CloudHub采用中心式架构，其中AWS云中的一个VPC被用作中心（hub），连接到多个远程站点（spokes）。</li><li><strong>单一VPN连接：</strong> 在CloudHub配置中，每个远程站点与AWS云中的中心VPC之间只需要一个VPN连接。</li></ol><h2 id="7-Transit-Gateway-中转网关"><a href="#7-Transit-Gateway-中转网关" class="headerlink" title="7. Transit Gateway-中转网关"></a>7. Transit Gateway-<strong>中转网关</strong></h2><ul><li>Transit Gateway 是中心化的路由交换设备，用于连接多个 VPC、VPN 和 Direct Connect。</li><li>它简化了大规模 VPC 网络的管理和扩展。</li></ul><h2 id="Transit-Gateway（中转网关）"><a href="#Transit-Gateway（中转网关）" class="headerlink" title="Transit Gateway（中转网关）"></a><em><strong>Transit Gateway（中转网关）</strong></em></h2><p><strong>support  IP Multicast</strong></p><p>Transit Gateway是一种网络服务，用于在成千上万个VPC和本地网络之间建立具有<strong>传递性</strong>的中心式（星型）连接。以下是Transit Gateway的关键概念：</p><ul><li><strong>传递性对等连接：</strong> Transit Gateway允许在多个VPC和本地网络之间建立传递性的对等连接，形成一个中心枢纽连接。</li><li>Regional resource**：** Transit Gateway是region级别的资源，可以cross-region工作，实现不同AWS区域的连接。</li><li>Share cross-account contents using Resource Access Manager (RAM)</li><li>**使用RAM（Resource Access Manager）**Share cross-account contents</li></ul><p><img src="/images/Untitled%20161.png" alt="Untitled"></p><h3 id="Site-to-Site-VPN-ECMP"><a href="#Site-to-Site-VPN-ECMP" class="headerlink" title="Site-to-Site VPN ECMP"></a>Site-to-Site VPN ECMP</h3><ul><li>ECMP &#x3D; Equal-cost multi-path routing</li><li>Routing strategy to allow to forward a packet over multiple best path</li><li>Use case: create multiple Site-To-Site VPN connections to increase the bandwidth of your connection to AWS</li><li>站点对站点 VPN ECMP<ul><li>ECMP &#x3D; 等价多路径路由</li><li>转发数据包的路由策略，允许通过多个最佳路径</li><li>使用场景：创建多个站点对站点 VPN 连接，以增加到 AWS 的带宽</li></ul></li></ul><p><img src="/images/Untitled%20162.png" alt="Untitled"></p><p><img src="/images/Untitled%20163.png" alt="Untitled"></p><p><img src="/images/Untitled%20164.png" alt="Untitled"></p><h2 id="8-Traffic-Mirroring"><a href="#8-Traffic-Mirroring" class="headerlink" title="8. Traffic Mirroring"></a>8. Traffic Mirroring</h2><ul><li><strong>流量镜像：</strong> 通过使用流量镜像，您可以将来自<strong>生产 VPC</strong> 的流量镜像到特定的目标（例如 EC2 实例或另一个 VPC），然后在目标上执行流量<strong>检查和过滤</strong>。</li><li><strong>将流量路由到安全设备：</strong> 以进行内容检查、威胁监控、故障排除等操作。</li><li><strong>源和目标位置：</strong> 流量镜像的源和目标可以在同一VPC内或不同VPC之间（通过VPC Peering）。</li><li><strong>应用场景：</strong> 使用Transit Gateway的流量镜像功能可以用于内容检查、威胁监控、故障排除等场景。</li></ul><h1 id="Route-53-域名系统"><a href="#Route-53-域名系统" class="headerlink" title="Route 53-域名系统"></a>Route 53-域名系统</h1><h3 id="Amazon-Route-53"><a href="#Amazon-Route-53" class="headerlink" title="Amazon Route 53"></a><strong>Amazon Route 53</strong></h3><p><img src="/images/Untitled%20165.png" alt="Untitled"></p><ul><li>“Route 53”是指传统DNS使用的端口号（53）</li></ul><ol start="9"><li><strong>域名解析</strong>：Route 53 允许您将域名映射到各种 AWS 资源，如 **Amazon S3 存储桶、Amazon EC2 实例、Elastic Load Balancer（ELB）**等。您可以配置 DNS 记录，将用户输入的域名转换为 IP 地址，从而使用户能够通过域名访问您的资源。</li><li><strong>高可用和可靠性</strong>：Route 53 提供全球分布的 DNS 服务，具有高可用性和可靠性。它将自动将 DNS 记录分发到多个全球边缘位置，以确保用户能够就近访问资源，提高响应速度和可用性。</li><li><strong>负载均衡</strong>：Route 53 可与 Amazon Elastic Load Balancing 集成，实现负载均衡。您可以配置 DNS 记录，将流量分发到不同的负载均衡器，以实现高可用性和性能优化。</li></ol><ul><li>能够检查您的资源的健康状态</li><li><strong>100% SLA保证</strong>：Route 53是唯一一个AWS服务提供100%可用性的服务级别协议（SLA）。</li></ul><h3 id="“Route-53-Active-Passive”"><a href="#“Route-53-Active-Passive”" class="headerlink" title="“Route 53 Active-Passive”"></a>“Route 53 Active-Passive”</h3><p>是一种架构配置，主要用于实现高可用性和故障恢复。</p><p>在 Active-Passive 配置中，我们通常考虑系统中的两种状态：活动状态（Active）和待命状态（Passive）。</p><ul><li><strong>活动状态（Active）：</strong> 这是系统中当前正在提供服务的状态。在一个 “Route 53 Active-Passive” 配置中，活动状态通常指向一个实际提供服务的资源，比如一个服务器、虚拟机实例或应用程序。</li><li><strong>待命状态（Passive）：</strong> 这是系统中备用的、处于待命状态的资源。它不提供实际的服务，而是等待在活动状态不可用时接管服务。待命状态的资源会与活动状态资源保持同步，以确保数据的一致性。</li></ul><h3 id="Route-53故障转移的关键点如下："><a href="#Route-53故障转移的关键点如下：" class="headerlink" title="Route 53故障转移的关键点如下："></a><strong>Route 53故障转移</strong>的关键点如下：</h3><ol start="12"><li><strong>Failover Routing Policy</strong>：Route 53的Failover路由策略允许您配置主&#x2F;备份资源，以便在主资源不可用时自动将流量切换到备份资源。例如，您可以将流量引导到主要AWS区域中的资源，但如果该区域发生故障，Route 53可以将流量切换到另一个备份区域中的资源。</li><li><strong>Health Checks</strong>：您可以设置Route 53的健康检查来监控各个资源的可用性。当主资源不可用时，健康检查可以自动触发Route 53的Failover策略，将流量切换到备份资源。</li><li><strong>Global Accelerator Integration</strong>：Route 53可以与AWS Global Accelerator结合使用，以提供全球级别的流量管理和故障转移。Global Accelerator可以优化全球范围内的流量分发，确保将用户流量快速引导到最近的健康资源。</li><li><strong>Latency-Based Routing</strong>：虽然不直接是故障转移，但根据延迟的路由策略可以确保将用户流量引导到距离最近且延迟最低的资源，从而提高用户体验并减少延迟。</li></ol><h3 id="Routing-Policies-路由策略"><a href="#Routing-Policies-路由策略" class="headerlink" title="Routing Policies-路由策略"></a>Routing Policies-<strong>路由策略</strong></h3><ul><li><p>Defines how Route53 responds to DNS queries</p><p>  定义了如何将 DNS 查询路由到资源</p><p>  以下是展示 Amazon Route 53 不同路由策略及其特点和适用场景的表格：</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>权重路由策略（Weighted）</td><td>- 按照权重分配到不同资源</td></tr><tr><td>故障转移路由策略（Failover）</td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr><tr><td>多值路由策略（Multivalue）</td><td>- 用于将流量路由到多个资源</td></tr></tbody></table><p>  这个表格展示了 Amazon Route 53 不同的路由策略，以及每个策略的特点和适用场景。希望这能够帮助您更清楚地了解每种路由策略的用途和优势。</p></li></ul><h3 id="Simple-Routing（简单路由）"><a href="#Simple-Routing（简单路由）" class="headerlink" title="Simple Routing（简单路由）:"></a><strong>Simple Routing</strong>（简单路由）:</h3><ul><li>返回单个资源的所有记录</li><li>如果返回了多个相同记录的值，则客户端将随机选择一个</li><li>不能与健康检查相关联</li></ul><h3 id="Weighted-Routing（加权路由）"><a href="#Weighted-Routing（加权路由）" class="headerlink" title="Weighted Routing（加权路由）:"></a><strong>Weighted Routing</strong>（加权路由）:</h3><ul><li>control traffic by weight</li><li>can be associated with Health Checks</li><li>Assign a weight of 0 to a record to stop sending traffic to a resource • If all records have we</li><li><strong>按照权重分配到不同资源</strong></li><li>按权重控制流量</li><li>可以与健康检查相关联</li><li>将记录的权重分配为0，以停止向资源发送流量</li><li>如果所有记录的权重都为0，则不会向该资源发送流量</li></ul><h3 id="Failover-Routing（故障转移路由）"><a href="#Failover-Routing（故障转移路由）" class="headerlink" title="Failover Routing（故障转移路由）:"></a><strong>Failover Routing</strong>（故障转移路由）:</h3><ul><li>When an active instance failed the health check, the standby instance will failover and become active</li></ul><p>当<strong>活动实例未通过健康检查时，备用实例将接管并成为活动实例。</strong></p><h3 id="Latency-based-Routing（基于延迟的路由）"><a href="#Latency-based-Routing（基于延迟的路由）" class="headerlink" title="Latency-based Routing（基于延迟的路由）:"></a><strong>Latency-based Routing</strong>（基于延迟的路由）:</h3><ul><li>Redirect to the resource that has the least latency close to user</li><li>Latency is based on traffic between users and AWS Regions</li><li>Can be associated with Health Checks</li><li>重定向到距离用户最近的资源</li><li>延迟基于用户和AWS区域之间的流量</li><li>可以与健康检查相关联</li></ul><h3 id="Geolocation-Routing（地理位置路由）"><a href="#Geolocation-Routing（地理位置路由）" class="headerlink" title="Geolocation Routing（地理位置路由）:"></a><strong>Geolocation Routing</strong>（地理位置路由）:</h3><ul><li>This routing is based on user location</li><li>Can be associated with Health Checks</li></ul><h3 id="Multi-Value-Answer-Routing（多值回答路由）"><a href="#Multi-Value-Answer-Routing（多值回答路由）" class="headerlink" title="Multi-Value Answer Routing（多值回答路由）:"></a><strong>Multi-Value Answer Routing</strong>（多值回答路由）:</h3><ul><li>Use when routing traffic to multiple resources</li><li>Each resource receives a separate DNS response, and Route 53 responds to DNS queries with multiple IP addresses.</li><li>Can be associated with Health Checks (return only values for healthy resources)</li><li>用于将流量路由到多个资源</li><li>每个资源都会收到单独的 DNS 响应，并且 Route 53 会用多个 IP 地址响应 DNS 查询。</li><li>可以与健康检查相关联（仅返回健康资源的值）</li><li>有助于实现<strong>负载均衡</strong>和<strong>高可用性</strong>。</li></ul><h3 id="Geoproximity-Routing（地理接近路由）"><a href="#Geoproximity-Routing（地理接近路由）" class="headerlink" title="Geoproximity Routing（地理接近路由）:"></a><strong>Geoproximity Routing</strong>（地理接近路由）:</h3><ul><li>Route traffic to your resources based on the geographic location of users and resources</li><li>Ability to shift more traffic to resources based on the defined bias</li></ul><h3 id="Route-53-–-Records记录集"><a href="#Route-53-–-Records记录集" class="headerlink" title="Route 53 – Records记录集"></a><strong>Route 53 – Records</strong>记录集</h3><p>用于将域名映射到特定资源（例如IP地址、其他域名或负载均衡器）的信息</p><ul><li><strong>Domain&#x2F;subdomain Name</strong> – e.g., example.com</li><li><strong>Record Type</strong> – e.g., A or AAAA</li><li><strong>Value</strong> – e.g., 12.34.56.78</li><li><strong>Routing Policy</strong> – how Route 53 responds to queries</li><li><strong>TTL（time to live）</strong> – amount of time the record cached at DNS Resolvers</li></ul><h3 id="Record-Types-记录类型"><a href="#Record-Types-记录类型" class="headerlink" title="Record Types-记录类型"></a><strong>Record Types-记录类型</strong></h3><ul><li><strong>A</strong> – maps a hostname to IPv4</li><li><strong>AAAA</strong> – maps a hostname to IPv6</li><li><strong>CNAME</strong> – maps a hostname to another hostname<ul><li>The target is a domain name which must have an A or AAAA record</li><li>Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)</li><li>Example: you can’t create for example.com, but you can create for <a href="http://www.example.com/">www.example.com</a></li></ul></li><li><strong>NS</strong> – Name Servers for the Hosted Zone<ul><li>Control how traffic is routed for a domain</li></ul></li></ul><h3 id="hosted-zone-托管区域"><a href="#hosted-zone-托管区域" class="headerlink" title="hosted zone-托管区域"></a>hosted zone-托管区域</h3><p>Hosted Zone（托管区域）是一个与特定域名（例如 <a href="http://example.com/">example.com</a>）关联的 DNS 区域。它包含了该域名下所有 DNS 记录的信息，用于解析域名到相应的 IP 地址或其他资源。</p><p><strong>一个包含定义如何路由流量到域名及其子域名的记录的容器</strong></p><ul><li><strong>公有托管区域</strong><ul><li>包含指定如何在互联网上路由流量的记录</li></ul></li><li><strong>私有托管区域</strong><ul><li>包含指定如何在一个或多个VPC中路由流量的记录</li></ul></li><li>每个托管区域每月收取0.5美元的费用</li></ul><h3 id="Alias-Records-别名记录"><a href="#Alias-Records-别名记录" class="headerlink" title="Alias Records-别名记录"></a>Alias Records-<strong>别名记录</strong></h3><ul><li>将主机名映射到AWS资源</li><li>别名记录始终为AWS资源的类型A&#x2F;AAAA（IPv4&#x2F;IPv6）</li><li>您无法设置TTL, route53自动设置</li><li>您无法为EC2 DNS名称设置别名记录</li><li>You cannot set an ALIAS record for an EC2 DNS name</li></ul><h3 id="Health-Checks-健康检查"><a href="#Health-Checks-健康检查" class="headerlink" title="Health Checks-健康检查"></a>Health Checks-健康检查</h3><ul><li>HTTP Health Checks are only for public resources</li><li>Health Check &#x3D;&gt; Automated DNS Failover</li><li>健康检查与CloudWatch指标集成</li><li>配置路由器&#x2F;防火墙以允许来自Route 53 Health Checkers的传入请求</li></ul><h3 id="Health-checks-that-monitor-an-endpoint"><a href="#Health-checks-that-monitor-an-endpoint" class="headerlink" title="Health checks that monitor an endpoint"></a><strong>Health checks that monitor an endpoint</strong></h3><p>您可以配置运行状况检查来监控通过 IP 地址或域名指定的端点。Route 53 按照您指定的固定间隔，通过互联网向您的应用程序、服务器或其它资源自动提交请求，以验证其是否可到达、是否可用及功能是否正常。您也可以通过配置运行状况检查来发出与用户发出的请求类似的请求，如从特定 URL 请求网页。</p><h3 id="calculated-health-checks"><a href="#calculated-health-checks" class="headerlink" title="calculated health checks"></a><strong>calculated health checks</strong></h3><ul><li>Combine the results of multiple Health Checks into a single Health Check</li><li>You can use OR, AND, or NOT</li><li>Can monitor up to 256 Child Health Checks</li><li>Specify how many of the health checks need to pass to make the parent pass</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-12【 architecture】选择合适database</title>
      <link href="/2023/08/16/AWS-12%E3%80%90%20architecture%E3%80%91%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82database/"/>
      <url>/2023/08/16/AWS-12%E3%80%90%20architecture%E3%80%91%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82database/</url>
      
        <content type="html"><![CDATA[<h1 id="选择合适database"><a href="#选择合适database" class="headerlink" title="选择合适database"></a>选择合适database</h1><p><img src="/images/Untitled%2050.png" alt="Untitled"></p><p><strong>Online Transaction Processing”（在线事务处理）</strong></p><p>它是一种数据库处理方式，用于处理实时交易和事务。OLTP系统旨在支持并发的数据库操作，通常用于处理大量短期和频繁的交易请求，例如在线购买、银行交易、航班预订等。</p><p>OLTP系统通常具有以下特点：</p><ul><li>快速的读写操作：用于处理实时交易，需要快速响应和处理数据库记录的插入、更新和查询操作。</li><li>事务支持：OLTP系统必须支持ACID属性（原子性、一致性、隔离性和持久性），确保数据库的完整性和一致性。</li><li>高并发性：OLTP系统通常面对许多用户同时进行交易，需要能够处理高并发的请求。</li><li>精细的数据模型：OLTP系统的数据模型通常是规范化的，以减少数据冗余并提高查询性能。</li><li>实时数据访问：OLTP系统提供实时数据访问，允许用户即时获取最新的交易信息。</li></ul><h3 id="适用于OLTP的AWS服务："><a href="#适用于OLTP的AWS服务：" class="headerlink" title="适用于OLTP的AWS服务："></a>适用于OLTP的AWS服务：</h3><ol><li><strong>Amazon RDS</strong>（Relational Database Service）：支持多种关系型数据库引擎，适用于在线交易处理和实时事务。</li><li><strong>Amazon Aurora</strong>：是RDS的一个变种，专为OLTP工作负载而设计，具有高性能和高可用性。</li><li><strong>Amazon DynamoDB</strong>：全托管的NoSQL数据库，适用于高度可扩展的实时交易处理和高并发操作。</li><li><strong>Amazon ElastiCache</strong>：提供托管的内存缓存服务，加速读取操作，适用于缓存频繁读取的交易数据。</li></ol><h3 id="RDBMS"><a href="#RDBMS" class="headerlink" title="RDBMS"></a>RDBMS</h3><p>代表关系数据库管理系统（Relational Database Management System），是一种基于关系型数据库模型的软件系统。它是用于管理和操作关系型数据库的专用软件。</p><p>在RDBMS中，数据以表格的形式组织，每个表格由行和列组成。每行代表一个记录，每列代表记录的属性或字段。RDBMS使用结构化查询语言（SQL）来操作和查询数据库中的数据。</p><p>RDBMS具有以下特点：</p><ol><li><strong>表格结构</strong>：数据以表格形式存储，每个表格有唯一的名称，并定义了数据的结构和约束。</li><li><strong>关系</strong>：不同表格之间可以建立关系，通过使用主键和外键来连接数据。</li><li><strong>数据完整性</strong>：RDBMS支持定义数据完整性规则，确保数据的一致性和准确性。</li><li><strong>事务支持</strong>：RDBMS支持事务处理，保证数据的原子性、一致性、隔离性和持久性（ACID属性）。</li><li><strong>并发控制</strong>：RDBMS能够处理多用户同时对数据库进行读写的情况，并确保数据的一致性和可靠性。</li><li><strong>查询语言</strong>：通过使用SQL，用户可以方便地查询和操作数据库中的数据。</li></ol><p>常见的RDBMS包括MySQL、Oracle Database、Microsoft SQL Server、PostgreSQL和IBM DB2等。RDBMS被广泛用于企业和组织中，用于管理和存储大量结构化数据，如业务数据、客户信息、交易记录等。</p><h2 id="Amazon-RDS"><a href="#Amazon-RDS" class="headerlink" title="Amazon RDS"></a>Amazon RDS</h2><ul><li>Managed PostgreSQL&#x2F; MySOL &#x2F; Oracle&#x2F; SOL Server&#x2F; MariaDB &#x2F; Custom<ul><li><p>Provisioned RDS Instance Size and EBS Volume Type &amp; Size</p></li><li><p>Auto-scaling capability for Storage</p></li><li><p>Support for Read Replicas and Multi AZ</p></li><li><p>Security through lAM, Security Groups, KMS, SSL in transit</p></li><li><p>Automated Backup with Point in time restore feature (up to 35 days)</p></li><li><p>Manual DB Snapshot for longer-term recovery</p></li><li><p>Managed and Scheduled maintenance (with downtime)</p></li><li><p>Support for IAM Authentication, integration with Secrets Manager</p></li><li><p>RDS Custom for access to and customize the underlying instance (Oracle &amp; SQL Server)</p></li><li><p>Use case: Store relational datasets (RDBMS &#x2F; OLTP), perform SQL queries, transactions</p></li></ul></li><li>为 RDS 实例大小和 EBS 卷类型和大小提供支持</li><li>存储Auto-scaling capability</li><li>支持 Read Replicas and Multi AZ</li><li>通过IAM、安全组、KMS,SSL实现安全性传输</li><li><strong>自动备份，具备点时间还原功能（长达35天）</strong></li><li>用于长期恢复的手动DB Snapshot</li><li>管理和定期维护（with downtime）</li><li>支持IAM认证，与Secrets Manager 集成</li><li>RDS Custom 用于访问和自定义底层实例（Oracle 和 SQL Server）</li></ul><aside>🍋 use case：存储关系数据集（RDBMS/ OLTP），执行SQL查询，事务</aside><h2 id="Amazon-Aurora"><a href="#Amazon-Aurora" class="headerlink" title="Amazon Aurora"></a>Amazon Aurora</h2><ul><li><p>Compatible API for PostgreSQL &#x2F; MySQL, separation of storage and compute</p><ul><li>Storage: data is stored in 6 replicas, across 3 AZ -highly available, self-healing, auto-scaling</li><li>Compute: Cluster of DB Instance across multiple AZ, auto-scaling of Read Replicas</li><li>Cluster: Custom endpoints for writer and reader DB instances</li><li>Same security &#x2F; monitoring&#x2F; maintenance features as RDS</li><li>Know the backup &amp; restore options for Aurora</li><li><strong>Aurora Serverless</strong> - for unpredictable &#x2F; intermittent workloads, no capacity planning</li><li><strong>Aurora Multi-Master</strong> - for continuous writes failover (high write availability)</li><li><strong>Aurora Global</strong>: up to 16 DB Read instances in each region, &lt; I second storage replication</li><li><strong>Aurora Machine Learning:</strong> perform ML using SageMaker &amp; Comprehend on Aurora</li><li><strong>Aurora Database Cloning</strong>: new cluster from existing one, faster than restoring a snapshot</li><li>Use case: same as RDS,but with less maintenance &#x2F; more flexibility &#x2F; more performance &#x2F; more features</li></ul><p>  <img src="/images/Untitled%2051.png" alt="Untitled">  </p></li><li><p>兼容的 PostgreSQL &#x2F; MySQL API，存储和计算分离</p></li><li><p>存储：数据存储在6个副本中，跨越3个可用区, 高可用、自我修复、自动扩展</p></li><li><p>计算：Cluster of DB Instance across multiple AZ,， auto-scaling of Read Replicas</p></li><li><p>集群:编写器和阅读器DB实例的自定义终端节点</p></li><li><p>与RDS相同的安全&#x2F;监控&#x2F;维护功能</p></li><li><p>了解Aurora的备份和恢复选项</p></li><li><p><strong>Aurora Serverless</strong> - 适用于不可预测&#x2F;<strong>间歇性</strong>工作负载，<strong>无需容量规划</strong></p></li><li><p><strong>Aurora Multi-Master</strong> - for continuous writes failover 用于连续写入故障转移（高写入可用性）</p></li><li><p><strong>Aurora Global</strong>：在每个区域中最多有16个DB读取实例，storage replication存储复制小于1秒</p></li><li><p><strong>Aurora Machine Learning</strong>：使用SageMaker和Comprehend在Aurora上执行ML</p></li><li><p><strong>Aurora Database Cloning</strong>：从现有集群创建新集群，比恢复快</p>  <aside>  🍋 use case：与RDS相同，但维护较少/更灵活/性能更好/具有更多功能AZ    </aside></li></ul><h2 id="Amazon-ElastiCache"><a href="#Amazon-ElastiCache" class="headerlink" title="Amazon ElastiCache"></a>Amazon ElastiCache</h2><ul><li><p>Managed Redis&#x2F; Memcached (similar offering as RDS, but for caches)</p><ul><li>In-memory data store, sub-millisecond latency</li><li>Must provision an EC2 instance type</li><li>Support for Clustering (Redis) and Multi AZ, Read Replicas (sharding)</li><li>Security through IAM, Security Groups, KMS, Redis Auth</li><li>Backup &#x2F; Snapshot &#x2F; Point in time restore feature</li><li>Managed and Scheduled maintenance</li><li><strong>Requires some application code changes to be leveraged</strong></li></ul>  <aside>  🍋 Use Case: Key/Value store, Frequent reads, less writes, cache results for DB queries, store session data for websites, cannot use SQL    </aside>  <p>  <img src="/images/Untitled%2052.png" alt="Untitled">  </p></li><li><p>内存数据存储，<strong>亚毫秒延迟sub-millisecond latency</strong></p></li><li><p>compatible with Redis or Memcached.</p></li><li><p>必须预配EC2实例类型</p></li><li><p>支持集群（Redis）和多AZ，读取副本（分片）Read Replicas (sharding)</p></li><li><p>通过IAM，Security Groups，KMS，Redis Auth实现安全性</p></li><li><p>备份&#x2F;快照&#x2F;时间点恢复功能</p></li><li><p>托管和计划维护</p></li><li><p><strong>需要更改应用程序代码才能利用</strong></p></li></ul><aside>🍋 用例：键/值存储，频繁读取，较少写入，缓存DB查询结果，存储网站会话数据，无法使用SQL</aside><h2 id="Amazon-DynamoDB"><a href="#Amazon-DynamoDB" class="headerlink" title="Amazon DynamoDB"></a>Amazon DynamoDB</h2><ul><li><p>AWS proprietary technology,managed serverless NoSOL database, milisecond latency</p><ul><li>Capacity modes: provisioned capacity with optional auto-scaling or on-demand capacity</li><li>Can replace ElastiCache as a key&#x2F;value store (storing session data for example, using TL feature)</li><li>Highly Available, Multi AZ by default, Read and Writes are decoupled, transaction capability</li><li>DAX cluster for read cache, microsecond read latency</li><li>Security authentication and authorization is done through IAM</li><li>Event Processing: DynamoDB Streams to integrate with AWS Lambda, or Kinesis Data Streams</li><li>Global Table feature; active -active setup</li><li>Autorated backups up to 35 days with PITR (restore to new table), or on demand backups Export to S3 without using RCU within the PITR, window, import from S3 without using WCU• Great to rapidly evolve schemas</li></ul>  <aside>  🍋 Use Case: Serverless applications development (small documents 100s KB), distributed serverless       cache, doesn't have SOL query language available    </aside>  <p>  <img src="/images/Untitled%2053.png" alt="Untitled"></p></li></ul><p><img src="/images/Untitled%2054.png" alt="Untitled"></p><ul><li>Amazon DynamoDB is a key-value, document, NoSQL database.</li><li>AWS专有技术，托管无服务器NoSQL数据库，毫秒级延迟 milisecond latency</li><li>容量模式：预置容量和可选自动扩展或按需容量</li><li>可以替换ElastiCache作为键&#x2F;值存储（例如存储会话数据，使用TL功能）</li><li>默认高可用性，多AZ，读写解耦，具有事务功能</li><li><strong>DAX集群用于读取缓存，微秒级读取延迟</strong></li><li>安全认证和授权通过IAM完成</li><li>事件处理：DynamoDB Streams与AWS Lambda或Kinesis Data Streams集成</li><li>全局表功能；<strong>主动-主动设置</strong></li><li>自动化备份长达35天，具有PITR（还原到新表）或按需备份，可在PITR窗口内无需使用RCU导出到S3，从S3导入无需使用WCU</li><li><strong>适用于快速演变的架构</strong></li></ul><aside>🍋 用例：无服务器应用程序开发（小型文档100 KB），分布式无服务器缓存，**doesn't have SOL query language available**</aside><h2 id="Amazon-S3"><a href="#Amazon-S3" class="headerlink" title="Amazon S3"></a>Amazon S3</h2><ul><li><p>S3 is a… key&#x2F; value store for objects</p><ul><li>Great for bigger objects, not so great for many small objects</li><li>Serverless, scales infinitely, max object size is 5 TB, versioning capability</li><li>Tiers: S3 Standard, S3 Infrequent Access, S3 Intelligent, S3 Glacier + lifecycle policy</li><li>Features: Versioning, Encryption, Replication, MFA-Delete, Access Logs…</li><li>Security. I&#x2F;AM, Bucket Palicies, ACL, Access Points, Object Lambda, CORS. Object&#x2F;aut Lock</li><li>Encryption: SSE-S3, SSE-KMS, SSE-C, client-side, TLS in transit, default encryption</li><li>Batch operations on objects using S3 Batch, listing files using S3 Inventory</li><li>Performance: Multi-part upload, S3 Transfer Acceleration, S3 Select</li><li>Automation: S3 Event Notifications (SNS, SOS, Lambda, EventBridge)</li><li>Use Cases; static files, key value store for big files, website hosting</li></ul><p>  <img src="/images/Untitled%2055.png" alt="Untitled">  </p></li><li><p>S3是一个用于object的<strong>键&#x2F;值存储系统</strong></p></li><li><p>非常适合存储大型对象，但对于<strong>大量</strong>小对象则不太适用</p></li><li><p><strong>无服务器</strong>架构，可无限扩展，单个对象最大大小为5TB，支持versioning</p></li><li><p>存储类型：S3 Standard, S3 Infrequent Access, S3 Intelligent, S3 Glacier + lifecycle policy</p></li><li><p>功能：版本控制、加密、复制、MFA-删除、访问日志等等</p></li><li><p>安全性：IAM、存储桶策略、ACL、访问点、对象Lambda、CORS、对象&#x2F;自动锁定</p></li><li><p>加密：SSE-S3、SSE-KMS、SSE-C、客户端加密、TLS in transit、默认加密</p></li><li><p>使用S3 Batch进行对象批量操作，使用S3 Inventory列出文件</p></li><li><p>性能：Multi-part upload, S3 Transfer Acceleration, S3 Select</p></li><li><p>自动化：S3事件通知（SNS、SOS、Lambda、EventBridge）</p></li></ul><aside>🍋 使用场景：静态文件存储static files、大文件的键值存储 key value store for big files、网站托管 website hosting</aside><h2 id="DocumentDB"><a href="#DocumentDB" class="headerlink" title="DocumentDB"></a>DocumentDB</h2><ul><li><p>documentDB</p><p>  <img src="/images/Untitled%2056.png" alt="Untitled"></p></li><li><p>Aurora是对PostgreSQL &#x2F; MySQL的AWS实现…</p></li><li><p><strong>DocumentDB是MongoDB的AWS实现（MongoDB是一种NoSQL数据库）</strong></p></li><li><p>MongoDB用于存储、查询和索引JSON数据</p></li><li><p>与Aurora类似的部署概念</p></li><li><p>完全托管，高可用性，跨3个可用区进行复制</p></li><li><p>Aurora存储会自动增长，每次增加10GB，最多可达64TB。</p></li><li><p>automatically scales to workloads with millions of request per seconds</p></li></ul><p>自动缩放以处理每秒数百万个请求的工作负载</p><h2 id="Neptune"><a href="#Neptune" class="headerlink" title="Neptune"></a>Neptune</h2><ul><li><p>neptune</p><p>  <img src="/images/Untitled%2057.png" alt="Untitled"></p></li></ul><p>Amazon Neptune is a <strong>fast, reliable, fully-managed graph database service</strong> that makes it easy to build and run applications that work with highly connected datasets</p><ul><li>Neptune是一个托管的图形数据库服务，用于构建图形数据应用程序。</li><li>支持图形数据库模型和图形查询语言，处理复杂的关系型数据。</li><li>完全托管的图形数据库</li><li>一个流行的图形数据集可以是一个社交网络<ul><li>用户拥有朋友</li><li>帖子有评论</li><li>评论有用户的喜欢</li><li>用户分享和喜欢帖子……</li></ul></li><li>在3个可用区内高可用性，最多支持15个读取副本</li><li>构建和运行与高度连接的数据集合一起工作的应用程序 - 为这些复杂和繁重的查询进行了优化</li><li>可以存储上百亿个关系并以毫秒级的延迟查询图</li><li>通过多个可用区进行复制来实现高可用性</li></ul><aside>🍋 适用于知识图谱（如维基百科）、欺诈检测、推荐引擎、社交网络等应用</aside><h2 id="Keyspaces："><a href="#Keyspaces：" class="headerlink" title="Keyspaces："></a>Keyspaces：</h2><ul><li><p>keyspaces</p><p>  <img src="/images/Untitled%2058.png" alt="Untitled"></p></li><li><p>用于Apache Cassandra）：</p></li><li><p>Apache Cassandra是一种开源的分布式NoSQL数据库。</p></li><li><p>这是一种托管的与Apache Cassandra兼容的数据库服务。</p></li><li><p>无服务器架构，可扩展，高可用性，由AWS全面托管。</p></li><li><p>根据应用程序的流量自动调整表格的规模。</p></li><li><p>表格在多个可用区内复制3次。</p></li><li><p>使用Cassandra查询语言（CQL）。</p></li><li><p>即使在大规模情况下，单位数毫秒的延迟，每秒数千个请求。</p></li><li><p>容量：按需模式或配额模式与自动扩展。</p></li><li><p>支持加密、备份和35天的按时间点恢复（PITR）</p></li></ul><aside>🍋 使用场景：存储物联网设备信息、时间序列数据等。</aside><ul><li>具有高度可扩展性和高性能，适用于处理海量的分布式数据。</li><li></li></ul><h2 id="QLDB（Quantum-Ledger-Database）："><a href="#QLDB（Quantum-Ledger-Database）：" class="headerlink" title="QLDB（Quantum Ledger Database）："></a>QLDB（Quantum Ledger Database）：</h2><ul><li><p>QLDB</p><p>  <img src="/images/Untitled%2059.png" alt="Untitled"></p></li><li><p>QLDB是一个全托管、不可变、透明的账本数据库。</p></li><li><p>Quantum Ledger Database-量子账本数据库</p></li><li><p>用于记录交易历史和变更，并保证数据的安全性和完整性。</p></li><li><p>账本是记录财务交易的记录册</p></li><li><p>完全托管、无服务器、高可用性，在3个可用区进行复制</p></li><li><p>用于查看应用程序数据的所有更改历史</p></li><li><p>不可变系统；任何条目都无法删除或修改，具有加密验证</p></li><li><p>使用SQL轻松操作数据，性能比常见的账本区块链框架提高2-3倍</p></li><li><p>与Amazon Managed Blockchain集成，提供强大的区块链功能</p></li></ul><h2 id="Timestream："><a href="#Timestream：" class="headerlink" title="Timestream："></a>Timestream：</h2><ul><li><p>timestream</p><p>  <img src="/images/Untitled%2060.png" alt="Untitled"></p></li><li><p>Timestream是一个全托管的时间序列数据库服务，用于存储和分析时间序列数据，如IoT传感器数据、应用程序日志等。</p></li><li><p>完全托管、快速、可扩展、无服务器的时间序列数据库</p></li><li><p>自动按需调整容量，实现自动扩缩容</p></li><li><p>可存储和分析每天数万亿个事件</p></li><li><p>比关系型数据库快1000倍，成本仅为其十分之一</p></li><li><p>支持定期查询、多指标记录、SQL兼容性</p></li><li><p>数据存储层次：近期数据保存在内存中，历史数据保存在成本优化的存储中</p></li><li><p>内置时间序列分析功能（帮助您在近实时中识别数据中的模式）</p></li><li><p>在传输和静态状态下进行加密</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-14【 网络】网络连接</title>
      <link href="/2023/08/16/AWS-15%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"/>
      <url>/2023/08/16/AWS-15%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Internet-Gateway-IGW"><a href="#1-Internet-Gateway-IGW" class="headerlink" title="1. Internet Gateway (IGW)"></a>1. Internet Gateway (IGW)</h2><ul><li><strong>IGW（Internet gateway）是AWS提供的，用来实现VPC和Internet之间相互通信的高可用组件。</strong></li><li>IGW 是连接 VPC 内部<strong>私有子网</strong>和<strong>公共 Internet</strong> 的组件。</li><li>在公有子网中，IGW 允许实例与 Internet 通信，且可以使用公有 IP。</li><li>一个VPC只能连接到一个IGW，反之亦然</li></ul><h2 id="2-NAT"><a href="#2-NAT" class="headerlink" title="2. NAT"></a>2. NAT</h2><h3 id="NAT-Network-Address-Translation"><a href="#NAT-Network-Address-Translation" class="headerlink" title="NAT &#x3D; Network Address Translation"></a>NAT &#x3D; Network Address Translation</h3><p>NAT 网关主要用于<strong>私有子网中的实例</strong>访问互联网</p><p><strong><code>出站连接</code></strong></p><h3 id="NAT-instance"><a href="#NAT-instance" class="headerlink" title="NAT instance"></a><strong>NAT instance</strong></h3><p>需要手动配置，适用于小规模流量。Old, must be setup in a public subnet, disable Source &#x2F; Destination check flag</p><p><img src="/images/Untitled%20152.png" alt="Untitled"></p><h3 id="NAT-gateway"><a href="#NAT-gateway" class="headerlink" title="NAT gateway"></a>NAT gateway</h3><p>AWS 托管，适用于大规模流量和高可用性需求。</p><p>NAT Gateway由AWS管理，提供可扩展的IPv4私有EC2实例Internet访问。</p><p>性能和可用性较高，所以通常优于NAT Instance。</p><p><img src="/images/Untitled%20153.png" alt="Untitled"></p><h2 id="3-AWS-Direct-Connect-DX-直连"><a href="#3-AWS-Direct-Connect-DX-直连" class="headerlink" title="3. AWS Direct Connect (DX)-直连"></a>3. AWS Direct Connect (DX)-直连</h2><p><img src="/images/Untitled%20154.png" alt="Untitled"></p><ul><li><strong>专用的物理连接</strong></li><li>AWS Direct Connect 在您的本地部署网络和 AWS 之间建立专用网络连接。</li><li>可以实现更稳定、低延迟的连接，用于大数据传输和混合云架构。</li></ul><h2 id="Direct-Connect-DX"><a href="#Direct-Connect-DX" class="headerlink" title="Direct Connect (DX)"></a>Direct Connect (DX)</h2><ul><li>提供从远程网络到您的VPC的dedicated private专用私有连接。</li><li>Data Center and <em><strong>AWS Direct Connect locations</strong></em>之间设置专用连接。</li></ul><aside>💡 DX Location是AWS Direct Connect服务的实际物理位置，通过连接到这些位置，您可以建立专用的物理连接</aside><ul><li><p>可以在同一连接上访问公共资源（如S3）和私有资源（如EC2）。</p></li><li><p>支持IPv4和IPv6。</p><p>  <img src="/images/Untitled%20155.png" alt="Untitled"></p></li></ul><blockquote><p><strong>连接流程：</strong></p></blockquote><ol><li>您在AWS控制台中选择一个DX Location，这是您将要建立连接的物理位置。</li><li>在您的本地网络中，您配置一个CGW，以确保它能够连接到DX Location。</li><li>您在AWS中创建一个VGW，并分配一个公共IP地址。</li><li>您在CGW和VGW之间建立IPSec隧道，通过配置加密和认证参数，以建立安全的通信通道。</li><li>一旦隧道建立，数据可以通过VPN连接在CGW和VGW之间进行加密传输。</li></ol><h2 id="Direct-Connect-Gateway"><a href="#Direct-Connect-Gateway" class="headerlink" title="Direct Connect Gateway"></a>Direct Connect Gateway</h2><ul><li>如果您想要在许多不同的区域（同一账户）中设置与一个或多个VPC的Direct Connect连接，您必须使用Direct Connect网关。If you want to set up a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway</li><li>建立新连接需要一个月以上的时间。</li><li>在传输中的数据未加密，但是保持私密性。<ul><li>AWS Direct Connect + VPN提供了一个IPsec加密的私有连接。</li></ul></li><li>如果Direct Connect发生故障，您可以设置备份Direct Connect连接（费用较高），或者设置站点到站点VPN连接。In case Direct Connect fails, you can set up a backup Direct Connect connection (expensive), or a Site-to-Site VPN connection</li><li></li></ul><p><img src="/images/Untitled%20156.png" alt="Untitled"></p><p><img src="/images/Untitled%20157.png" alt="Untitled"></p><h2 id="4-Bastion-Hosts"><a href="#4-Bastion-Hosts" class="headerlink" title="4. Bastion Hosts"></a>4. Bastion Hosts</h2><ul><li>一个作为跳板的 EC2 instance</li><li>Bastion Host 是放置在公有子网中的实例，用于安全远程访问私有子网中的实例。</li><li>通常用于管理和维护私有子网中的实例，提供临时访问。</li></ul><p>访问跳板：在受保护的内部网络和外部网络之间进行访问的中间节点。</p><p>位于公共网络中</p><p>使用bastion hosts  to SSH into 私有EC2实例</p><p><img src="/images/Untitled%20158.png" alt="Untitled"></p><h2 id="5-Ephemeral-Ports"><a href="#5-Ephemeral-Ports" class="headerlink" title="5. Ephemeral Ports"></a>5. Ephemeral Ports</h2><p><code>临时端口，短暂端口或动态端口</code></p><ul><li>随机分配的临时端口</li><li>Ephemeral Ports（短暂端口）是客户端与服务器之间临时建立的端口，用于数据传输。</li><li>通常在连接时随机分配，并在连接终止后释放。</li><li>Clients connect to a defined port, and expect a response on this port</li></ul><h2 id="6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN"><a href="#6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN" class="headerlink" title="6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN"></a>6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN</h2><h2 id="Site-to-Site-VPN"><a href="#Site-to-Site-VPN" class="headerlink" title="Site-to-Site VPN"></a>Site-to-Site VPN</h2><p>将本地数据中心与 VPC 直接连接的方法，作为备份连接方式。</p><p><strong>建立本地到VPC的连接：</strong> VPC站点到站点VPN允许您在VPC和本地数据中心之间建立一个加密的连接，使您的本地资源可以与VPC中的资源进行通信。</p><aside>💡 **VPN Gateway：** 在云服务中和本地网络中分别创建VPN Gateway：<aside>💡 VGW表示VPC侧的VPN设备</aside><aside>💡 LWG表示本地数据中心侧的VPN设备。</aside></aside><h3 id="VGW（Virtual-Private-Gateway）："><a href="#VGW（Virtual-Private-Gateway）：" class="headerlink" title="VGW（Virtual Private Gateway）："></a><strong>VGW（Virtual Private Gateway）：</strong></h3><ul><li>VGW是云服务提供商（如AWS）中的虚拟设备，用于建立VPN连接并处理数据的传入和传出。</li><li>VGW is created and attached to the VPC from which you want to create the Site-to-Site VPN connection</li></ul><h3 id="CGW（Customer-Gateway）："><a href="#CGW（Customer-Gateway）：" class="headerlink" title="CGW（Customer Gateway）："></a><strong>CGW（Customer Gateway）：</strong></h3><ul><li>本地网络中的物理设备或虚拟设备</li><li>与VGW之间建立IPSec隧道来实现安全通信。</li></ul><p><img src="/images/Untitled%20159.png" alt="Untitled"></p><h2 id="Site-to-Site-VPN-connection-as-a-backup"><a href="#Site-to-Site-VPN-connection-as-a-backup" class="headerlink" title="Site-to-Site VPN connection as a backup"></a>Site-to-Site VPN connection as a backup</h2><p><img src="/images/Untitled%20160.png" alt="Untitled"></p><h2 id="AWS-VPN-CloudHub"><a href="#AWS-VPN-CloudHub" class="headerlink" title="AWS VPN CloudHub"></a>AWS VPN CloudHub</h2><p>AWS VPN CloudHub 允许多个站点通过 VPN 连接到 AWS。</p><p>集中式的解决方案</p><ul><li>Provide secure communication between multiple sites, if you have multiple VPN connections</li><li>Low-cost hub-and-spoke model for primary or secondary network connectivity between different locations (VPN only)</li><li>It’s a VPN connection so it goes over the public Internet</li><li>如果有多个 VPN 连接，可以在多个站点之间提供安全通信</li><li>低成本的枢纽-辐射模型，用于不同位置之间的主要或次要网络连接 (仅限 VPN)</li><li>这是一种 VPN 连接，因此它经过公共互联网传输</li></ul><ol start="6"><li><strong>多站点连接：</strong> AWS VPN CloudHub支持同时连接多个远程站点。这些站点可以是不同地理位置的办公室、数据中心等。</li><li><strong>中心式架构：</strong> CloudHub采用中心式架构，其中AWS云中的一个VPC被用作中心（hub），连接到多个远程站点（spokes）。</li><li><strong>单一VPN连接：</strong> 在CloudHub配置中，每个远程站点与AWS云中的中心VPC之间只需要一个VPN连接。</li></ol><h2 id="7-Transit-Gateway-中转网关"><a href="#7-Transit-Gateway-中转网关" class="headerlink" title="7. Transit Gateway-中转网关"></a>7. Transit Gateway-<strong>中转网关</strong></h2><ul><li>Transit Gateway 是中心化的路由交换设备，用于连接多个 VPC、VPN 和 Direct Connect。</li><li>它简化了大规模 VPC 网络的管理和扩展。</li></ul><h2 id="Transit-Gateway（中转网关）"><a href="#Transit-Gateway（中转网关）" class="headerlink" title="Transit Gateway（中转网关）"></a><em><strong>Transit Gateway（中转网关）</strong></em></h2><p><strong>support  IP Multicast</strong></p><p>Transit Gateway是一种网络服务，用于在成千上万个VPC和本地网络之间建立具有<strong>传递性</strong>的中心式（星型）连接。以下是Transit Gateway的关键概念：</p><ul><li><strong>传递性对等连接：</strong> Transit Gateway允许在多个VPC和本地网络之间建立传递性的对等连接，形成一个中心枢纽连接。</li><li>Regional resource**：** Transit Gateway是region级别的资源，可以cross-region工作，实现不同AWS区域的连接。</li><li>Share cross-account contents using Resource Access Manager (RAM)</li><li>**使用RAM（Resource Access Manager）**Share cross-account contents</li></ul><p><img src="/images/Untitled%20161.png" alt="Untitled"></p><h3 id="Site-to-Site-VPN-ECMP"><a href="#Site-to-Site-VPN-ECMP" class="headerlink" title="Site-to-Site VPN ECMP"></a>Site-to-Site VPN ECMP</h3><ul><li>ECMP &#x3D; Equal-cost multi-path routing</li><li>Routing strategy to allow to forward a packet over multiple best path</li><li>Use case: create multiple Site-To-Site VPN connections to increase the bandwidth of your connection to AWS</li><li>站点对站点 VPN ECMP<ul><li>ECMP &#x3D; 等价多路径路由</li><li>转发数据包的路由策略，允许通过多个最佳路径</li><li>使用场景：创建多个站点对站点 VPN 连接，以增加到 AWS 的带宽</li></ul></li></ul><p><img src="/images/Untitled%20162.png" alt="Untitled"></p><p><img src="/images/Untitled%20163.png" alt="Untitled"></p><p><img src="/images/Untitled%20164.png" alt="Untitled"></p><h2 id="8-Traffic-Mirroring"><a href="#8-Traffic-Mirroring" class="headerlink" title="8. Traffic Mirroring"></a>8. Traffic Mirroring</h2><ul><li><strong>流量镜像：</strong> 通过使用流量镜像，您可以将来自<strong>生产 VPC</strong> 的流量镜像到特定的目标（例如 EC2 实例或另一个 VPC），然后在目标上执行流量<strong>检查和过滤</strong>。</li><li><strong>将流量路由到安全设备：</strong> 以进行内容检查、威胁监控、故障排除等操作。</li><li><strong>源和目标位置：</strong> 流量镜像的源和目标可以在同一VPC内或不同VPC之间（通过VPC Peering）。</li><li><strong>应用场景：</strong> 使用Transit Gateway的流量镜像功能可以用于内容检查、威胁监控、故障排除等场景。</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-11【Storage Gateway】</title>
      <link href="/2023/08/15/AWS-13%E3%80%90Storage%20Gateway%E3%80%91/"/>
      <url>/2023/08/15/AWS-13%E3%80%90Storage%20Gateway%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="Storage-Gateway-混合存储"><a href="#Storage-Gateway-混合存储" class="headerlink" title="Storage Gateway-混合存储"></a><strong>Storage Gateway-混合存储</strong></h1><p><strong>Storage Gateway-混合存储</strong><br><img src="/images/Untitled%2038.png" alt="Untitled"></p><p><strong>在本地环境和AWS云存储之间建立连接</strong></p><p>AWS Storage Gateway充当本地应用和AWS云存储之间的桥梁，使您能够轻松<strong>扩展本地存储容量</strong>，将本地数据备份到AWS云中，并在本地应用和AWS云存储之间实现<strong>无缝的数据迁移</strong>。</p><p><img src="/images/Untitled%2039.png" alt="Untitled"></p><ul><li>文件网关接口：NFS 和 SMB。</li></ul><p>NFS和SMB都是用于文件共享的协议：</p><ol><li>NFS（Network File System）：NFS是一种用于在计算机网络中共享文件的协议，最初由Sun Microsystems开发。它允许不同操作系统的计算机之间通过网络访问和共享文件和目录。NFS主要在Unix和Linux系统中使用。</li><li>SMB（Server Message Block）：SMB是一种用于共享文件、打印机和其他资源的网络协议，最初由微软开发，后来被称为CIFS（Common Internet File System）。SMB&#x2F;CIFS协议通常用于Windows操作系统中的文件和打印机共享。</li></ol><p>在S3文件网关的情境中，NFS和SMB是用于创建本地网络共享，使得应用程序可以通过这些共享访问存储在Amazon S3中的数据。</p><h2 id="use-cases"><a href="#use-cases" class="headerlink" title="use cases"></a>use cases</h2><ol><li><strong>Backup &amp; recovery</strong></li><li><strong>Disaster Recovery</strong></li><li><strong>Local Storage Extension</strong></li><li><strong>tiered storage</strong></li><li><strong>Data Archiving and Long-Term Storage数据归档和长期存储</strong></li><li><strong>Cloud Backup and Data Migration云中备份和数据迁移</strong></li><li><strong>Hybrid Cloud Environments混合云环境</strong></li></ol><h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p><img src="/images/Untitled%2040.png" alt="Untitled"></p><h3 id="S3-File-Gateway："><a href="#S3-File-Gateway：" class="headerlink" title="S3 File Gateway："></a><strong>S3 File Gateway</strong>：</h3><p><strong>S3文件网关特点：</strong></p><ul><li>将S3文件网关部署在本地，作为本地文件系统和Amazon S3                                                                      之间的桥梁。</li><li>支持四种存储网关类型：文件、卷、缓存和虚拟带。</li><li>可以<strong>使用文件共享协议（NFS、SMB）访问存储在Amazon S3中的数据</strong>。</li><li>文件网关提供本地缓存，可以缓存频繁访问的数据，提供更快的访问速度。</li><li>支持数据在本地缓存和Amazon S3之间的自动传输。</li></ul><p><strong>适合使用场景：</strong></p><ul><li>需要在本地应用程序和Amazon S3之间建立文件共享的场景。</li><li>需要快速访问本地缓存数据和远程S3数据的应用程序，提高数据访问速度。</li><li>需要自动化数据传输，将本地数据定期或按需上传到Amazon S3中。</li><li>适用于文件备份、归档、协作等需要本地和云存储的场景。</li></ul><p><img src="/images/Untitled%2041.png" alt="Untitled"></p><h3 id="FSx-File-Gateway"><a href="#FSx-File-Gateway" class="headerlink" title="FSx  File Gateway"></a>FSx  <strong>File Gateway</strong></h3><p><img src="/images/Untitled%2042.png" alt="Untitled"></p><h3 id="Volume-Gateway-卷网关"><a href="#Volume-Gateway-卷网关" class="headerlink" title="Volume Gateway-卷网关"></a><strong>Volume Gateway-卷网关</strong></h3><ul><li><strong>缓存卷（Cached Volumes）</strong>：在<strong>本地缓存中保留常用数据</strong>，将数据异步上传到云中。适用于需要低延迟访问的应用程序。<ul><li>缓存卷的大小范围可以是 1 GiB 到 32 TiB</li></ul></li><li><strong>存储卷（Stored Volumes）</strong>：将<strong>数据完全保存在本地</strong>，并异步备份到云中。适用于需要在本地保留副本的应用程序。<ul><li>存储卷的大小范围从1gib到16tib</li></ul></li></ul><p><img src="/images/Untitled%2043.png" alt="Untitled"></p><p>卷网关允许您在本地创建iSCSI（Internet Small Computer System Interface）卷，将卷视为本地存储设备。然后，您可以通过卷网关将这些iSCSI卷的快照备份到AWS S3或AWS EBS（Elastic Block Store）卷中。</p><p>适用于将本地存储扩展到云中或进行数据备份和灾难恢复的场景。</p><ul><li>特点：提供iSCSI协议的块级别访问，允许在本地服务器上挂载虚拟卷。分为缓存卷和存储卷两种模式，数据可以部分或完全存储在云中。</li></ul><h3 id="Tape-Gateway-虚拟磁带库存储网关"><a href="#Tape-Gateway-虚拟磁带库存储网关" class="headerlink" title="**Tape Gateway-**虚拟磁带库存储网关"></a>**Tape Gateway-**虚拟磁带库存储网关</h3><p><img src="/images/Untitled%2044.png" alt="Untitled"></p><p>虚拟磁带库允许您在本地创建虚拟磁带库，将虚拟磁带视为磁带存储设备。您可以通过虚拟磁带库将磁带数据备份到AWS S3 Glacier或AWS S3 Glacier Deep Archive中，以实现长期数据归档和存储。</p><ul><li>特点：模拟磁带库，允许将备份和归档数据保存为虚拟磁带，并将其存储在Amazon S3中。<strong>适用于长期数据保留和归档</strong>。</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-10【DynamoDB】</title>
      <link href="/2023/08/12/AWS-10%E3%80%90DynamoDB%E3%80%91/"/>
      <url>/2023/08/12/AWS-10%E3%80%90DynamoDB%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h1><p><img src="/images/Untitled%2031.png" alt="Untitled"></p><p>Amazon DynamoDB 是一种全托管式 NoSQL 数据库服务，可提供快速且可预测的性能，能够实现无缝扩展。</p><ul><li>完全托管，高可用性，在多个可用区进行复制</li><li>NoSQL database - 不是关系型数据库</li><li><ul><li>with transaction support</li></ul></li><li>可扩展到大规模工作负载，<strong>分布式数据库distributed database</strong></li><li>每秒数百万次请求，数万亿行数据，数百TB的存储</li><li>高性能且稳定（单位数<strong>毫秒级</strong>）</li><li>与IAM集成以提供安全性、授权和管理</li><li>低成本和自动扩展能力</li><li>无需维护或打补丁，始终可用No maintenance or patching, always available</li><li>标准和低频访问（IA）表格类型</li></ul><aside>🍁 DynamoDB 在许多应用场景中得到广泛应用，包括 Web 应用程序、移动应用程序、游戏、物联网（IoT）设备、实时分析等。它的高可用性、弹性扩展性和低延迟性能使其成为处理大规模非结构化数据的优秀选择。</aside><h2 id="capacity-modes-数据流容量模式"><a href="#capacity-modes-数据流容量模式" class="headerlink" title="capacity modes-数据流容量模式"></a>capacity modes-数据流<em>容量模式</em></h2><p>在 DynamoDB 中，读取和写入容量模式是一种用于配置表格吞吐量的选项:</p><ol><li><p><strong>Provisioned Capacity Mode（预配置容量模式）default：</strong></p><p> default<br> 在预配置容量模式下，您需要在创建表格时显式指定预期的读取容量单位（Read Capacity Units，RCUs）和写入容量单位（Write Capacity Units，WCUs）。每个 RCU 和 WCU 表示每秒钟读取或写入项目的数量。根据您的配置，DynamoDB 将分配所需的硬件资源来支持指定的吞吐量。</p></li></ol><p>预配置容量模式适用于具有<strong>可预测和稳定流量</strong>的应用程序。您可以根据业务需求预先分配容量，并根据需要随时进行调整。这种模式允许您更精确地控制和优化数据库的性能和成本。</p><ol start="2"><li><p><strong>On-Demand Capacity Mode（点播&#x2F;按需容量模式）：</strong><br>在按需容量模式下，DynamoDB 会根据您的实际读取和写入请求的数量动态地自动缩放表格的吞吐量。您无需预先配置 RCUs 和 WCUs，只需根据实际使用情况支付实际使用的读写吞吐量。</p><p> 按需容量模式适用于具有<em>不稳定和不可预测</em>流量的应用程序</p></li></ol><p>。它提供了更大的灵活性和简便性，无需手动管理吞吐量配置。按需模式适用于突发性负载或流量波动较大的场景，因为它可以自动缩放以满足您的应用需求，同时避免了预配置容量可能带来的浪费。</p><p><img src="/images/Untitled%2032.png" alt="Untitled"></p><h3 id="DynamoDB-Global-Tables"><a href="#DynamoDB-Global-Tables" class="headerlink" title="DynamoDB Global Tables"></a><strong>DynamoDB Global Tables</strong></h3><p>DynamoDB Global Tables是一种全球性的多主区域数据库解决方案。它允许您在不同AWS区域中创建多个DynamoDB副本，并确保这些副本之间的数据同步。这样可以实现数据的全球性复制和低延迟的读写操作。</p><ul><li><strong>多主区域数据库</strong>：每个区域中的DynamoDB表格都可以作为主表（Master Table），允许在该区域内执行读写操作。这样，当数据写入到一个区域时，会自动复制到其他区域中的主表。</li><li><strong>自动复制和同步</strong></li><li><strong>低延迟访问</strong></li></ul><p><img src="/images/Untitled%2033.png" alt="Untitled"></p><h3 id="DynamoDB-Backup-备份"><a href="#DynamoDB-Backup-备份" class="headerlink" title="DynamoDB Backup-备份"></a><strong>DynamoDB Backup-备份</strong></h3><p>DynamoDB Backup是一种全托管的备份服务，可用于定期备份DynamoDB表格的数据。备份可以保留在AWS中，以防止意外数据丢失或系统故障。</p><ul><li><strong>全托管备份</strong>：DynamoDB Backup由AWS完全管理，您无需关心备份的维护和管理。您可以使用AWS控制台或AWS SDK创建和管理备份。</li><li><strong>点-in-time恢复</strong>：备份不仅可以用于恢复整个表格，还支持<strong>点-in-time</strong>恢复。这允许您将表格恢复到特定时间点之前的状态。</li><li><strong>自动保留</strong>：您可以设置备份的保留期，AWS将自动保留备份，并在保留期过后自动删除旧备份。</li></ul><h3 id="DynamoDB与S3的集成"><a href="#DynamoDB与S3的集成" class="headerlink" title="DynamoDB与S3的集成:"></a><strong>DynamoDB与S3的集成</strong>:</h3><p>DynamoDB与Amazon S3之间有多种集成方式，这可以帮助您更好地处理和存储数据。</p><ul><li><p><strong>DynamoDB Streams与Lambda集成</strong>：DynamoDB Streams是一种记录表格中数据更改的数据流服务。您可以使用AWS Lambda来订阅DynamoDB Streams，然后根据数据更改触发特定的逻辑和处理。这样，您可以在表格中的数据发生变化时，自动触发Lambda函数，处理和分析数据。</p></li><li><p><strong>DynamoDB导出到S3</strong>：您可以使用DynamoDB的数据导出功能将表格中的数据导出到Amazon S3中。导出后的数据可以用于数据备份、数据分析和长期存储等用途。</p></li><li><p><strong>DynamoDB与S3之间的数据交互</strong>：您可以编写AWS Lambda函数，实现DynamoDB表格与S3之间的数据同步和交互。这可以帮助您将数据从DynamoDB表格导出到S3，或者将S3中的数据导入到DynamoDB表格中。</p><p>  <img src="/images/Untitled%2034.png" alt="Untitled"></p></li></ul><h3 id="Stream-Processing-数据流处理"><a href="#Stream-Processing-数据流处理" class="headerlink" title="Stream Processing (数据流处理):"></a><strong>Stream Processing (数据流处理)</strong>:</h3><p>DynamoDB Streams和AWS Lambda结合使用，使得实时数据流处理变得非常方便。数据流处理允许您实时地对DynamoDB表格中的数据更改进行处理和分析。</p><ul><li><strong>数据流订阅</strong>：使用AWS Lambda函数订阅DynamoDB Streams，以便在数据更改时自动触发Lambda函数。</li><li><strong>实时处理</strong>：当表格中的数据更改时，DynamoDB Streams会捕获这些变化，并将记录发送给Lambda函数。Lambda函数可以实时处理这些数据，执行特定的业务逻辑或将数据发送到其他服务。</li><li><strong>数据流处理的用途</strong>：数据流处理可以用于实时数据分析、数据同步、业务逻辑处理、监控和告警等场景。</li></ul><aside>🍁 use case典型使用场景：</aside><ol start="3"><li>react to changes in real-time (welcome email to new users)</li><li>real-time analytics-<strong>实时数据分析</strong>：通过订阅DynamoDB Streams并使用AWS Lambda函数来实时处理表格中的数据变更，可以进行实时数据分析和计算。</li><li><strong>数据同步</strong>：在多个DynamoDB表格之间进行数据同步是常见的应用场景。通过DynamoDB Streams，您可以捕获一个表格的数据变更，并将这些变更实时地复制到其他表格中，从而保持数据的一致性。</li><li><strong>触发事件</strong>：DynamoDB Streams可以作为触发器，当表格中的数据发生变更时，自动触发相应的事件。这可以用于实现业务流程、发送通知、执行后续操作等。</li><li><strong>实时通知</strong>：通过订阅DynamoDB Streams并与其他服务集成，可以实现实时通知。例如，当有新数据插入到DynamoDB表格中时，可以触发Lambda函数发送实时通知到移动设备或者Web应用程序。</li><li><strong>实时监控</strong>：利用DynamoDB Streams和Lambda函数，可以实现对表格的实时监控。您可以设置特定的数据变更规则，当满足条件时，触发监控和告警操作。</li><li><strong>版本控制</strong>：通过DynamoDB Streams，可以记录数据变更的历史，并实现数据的版本控制。这有助于跟踪和回溯数据的变更历史。</li><li><strong>数据审计</strong>：DynamoDB Streams可以用于数据审计目的，记录表格中的数据变更和操作，确保数据的安全性和合规性。</li></ol><p>总体而言，DynamoDB Stream Processing为DynamoDB表格的实时处理提供了强大的功能和灵活性。它可以与其他AWS服务集成，帮助您构建强大的实时数据处理和响应机制，从而更好地满足业务需求和用户期望。</p><p><img src="/images/Untitled%2035.png" alt="Untitled"></p><h3 id="dynamoDB-scream-VS-kinesis-data-scream"><a href="#dynamoDB-scream-VS-kinesis-data-scream" class="headerlink" title="dynamoDB scream VS kinesis data scream"></a>dynamoDB scream <strong>VS</strong> kinesis data scream</h3><table><thead><tr><th>特性</th><th>DynamoDB Streams</th><th>Kinesis Data Streams</th></tr></thead><tbody><tr><td><strong>Retention（数据保留期限）</strong></td><td>24小时</td><td>按需配置，默认值 24 小时。最长365天</td></tr><tr><td><strong>消费者数量</strong></td><td>limit</td><td>high</td></tr><tr><td>数据源和目的地的集成</td><td>主要用于DynamoDB，与Lambda函数</td><td>适用于多种数据源和目的地</td></tr><tr><td>数据目的</td><td>实时处理和分析</td><td>实时处理和分析</td></tr><tr><td>数据传递方式</td><td>服务器推送</td><td>客户端拉取</td></tr><tr><td>可订阅的事件</td><td>插入、更新、删除</td><td>数据记录</td></tr><tr><td>数据延迟</td><td>通常为毫秒级</td><td>可以自行配置</td></tr></tbody></table><ol start="11"><li><strong>Retention（数据保留期限）</strong>：<ul><li>DynamoDB Streams：默认的数据保留期限是24小时，即数据变更记录在DynamoDB Streams中保留24小时，过期后会自动删除。</li><li>Kinesis Data Streams：数据保留期限可以根据需求进行配置，最长可达7天，可以设置数据在Stream中保留的时间。</li></ul></li><li><strong>Of Consumers（消费者）</strong>：<ul><li>DynamoDB Streams：DynamoDB Streams主要用于实时处理DynamoDB表格中的数据变更。消费者通常是AWS Lambda函数，可以使用Lambda函数订阅DynamoDB Streams，并在数据变更时触发Lambda函数执行特定逻辑。</li><li>Kinesis Data Streams：Kinesis Data Streams适用于多种数据源，并可以根据业务需求实现实时处理和分析。消费者可以是Lambda函数，也可以是自行实现的Kinesis Client Library。</li></ul></li><li><strong>Processing Using（数据处理方式）</strong>：<ul><li>DynamoDB Streams：主要用于实时处理DynamoDB表格中的数据变更，通常与Lambda函数结合使用。Lambda函数可以对数据变更进行实时处理，比如计算、聚合、触发事件等。</li><li>Kinesis Data Streams：适用于多种数据源和场景，数据消费者可以根据需求自行实现数据处理逻辑。Kinesis Data Streams通常用于实时数据流处理，如设备数据采集、日志数据处理、实时监控等。</li></ul></li></ol><h3 id="DynamoDB-Accelerator-DAX"><a href="#DynamoDB-Accelerator-DAX" class="headerlink" title="DynamoDB Accelerator-DAX"></a>DynamoDB Accelerator-DAX</h3><ul><li><strong>DAX集群用于读取缓存，微秒级读取延迟</strong></li></ul><p>AWS 提供的全托管的缓存服务，专门为<strong>加速 Amazon DynamoDB 数据库的读取操作</strong>而设计。</p><p>它允许您将缓存层置于 DynamoDB 之前，从而显著提高读取操作的性能，降低对 DynamoDB 的负载压力，并降低应用程序的延迟。</p><p>DAX 具有以下关键特点和优势：</p><ol start="14"><li><strong>高性能缓存：</strong> DAX 使用一个分布式内存缓存，可以存储 DynamoDB 表中经常访问的数据。这使得读取操作可以在缓存中完成，从而大大加快响应时间和降低 DynamoDB 的负载。</li><li><strong>无缝集成：</strong> DAX 可以无缝集成到现有的 DynamoDB 应用程序中，无需更改应用程序代码。通过使用 DAX，您的应用程序可以保持对 DynamoDB 表的相同访问模式，但获得更快的响应时间。</li><li><strong>自动缓存管理：</strong> DAX 提供自动缓存管理，会根据数据的使用频率和模式来自动填充和更新缓存。这样，您无需手动管理缓存，可以专注于应用程序的开发。</li><li><strong>高可用性：</strong> DAX 提供多个可用区的多活功能，以实现高可用性和容错性。它在多个可用区内复制缓存数据，以保证缓存的可用性。</li><li><strong>安全性：</strong> DAX 与 DynamoDB 一样，提供了多层级的安全性措施，包括 VPC 网络隔离、IAM 访问控制和加密。</li><li><strong>降低成本：</strong> 通过使用 DAX，您可以显著降低 DynamoDB 的读取操作费用，因为 DAX 缓存数据后，大部分读取操作都可以在缓存中完成，无需访问 DynamoDB 表。</li></ol><p>DAX 适用于需要高度响应性和低延迟的读取操作的应用程序，特别是对于具有高流量的读取工作负载的应用程序。它可以显著提高应用程序的性能，并为用户提供更好的体验，同时还可以降低与 DynamoDB 读取操作相关的费用。</p><h2 id="DAX（DynamoDB-Accelerator）和-Elasticache"><a href="#DAX（DynamoDB-Accelerator）和-Elasticache" class="headerlink" title="DAX（DynamoDB Accelerator）和 Elasticache"></a>DAX（DynamoDB Accelerator）和 Elasticache</h2><ol start="20"><li><strong>适用的数据库：</strong><ul><li>DAX 是专门为加速 Amazon DynamoDB 的读取操作而设计的缓存服务。它与 DynamoDB 密切集成，通过将缓存层置于 DynamoDB 之前，加快读取操作的性能。</li><li>Elasticache 是 AWS 提供的通用缓存服务，支持多种缓存引擎，如 Redis 和 Memcached。它可以用于缓存各种数据库的查询结果、计算结果或应用程序的状态，不限于特定数据库。</li></ul></li><li><strong>目标数据库类型：</strong><ul><li>DAX 主要用于加速 DynamoDB 的读取操作，对于写入操作（写入数据到 DynamoDB 表）仍然需要直接访问 DynamoDB。</li><li>Elasticache 可以用于任何需要缓存的应用场景，无论是读取还是写入操作。</li></ul></li><li><strong>缓存引擎：</strong><ul><li>DAX 使用一个专门针对 DynamoDB 设计的缓存引擎，支持高性能和自动缓存管理。</li><li>Elasticache 支持多种缓存引擎，包括 Redis 和 Memcached。您可以根据应用程序的需求选择合适的缓存引擎。</li></ul></li><li><strong>特定应用场景：</strong><ul><li>DAX 适用于对 DynamoDB 读取操作延迟要求较高的应用场景。当应用程序需要频繁读取 DynamoDB 表的数据，并且要求低延迟和高吞吐量时，DAX 可以显著提高性能。</li><li>Elasticache 适用于各种应用程序，特别是需要缓存读取结果、频繁访问外部数据源、降低数据库负载压力或提供临时计算结果的场景。</li></ul></li><li><strong>集群规模：</strong><ul><li>DAX 可以配置成多个节点的集群，但其规模通常不会像 Elasticache 那样大，因为 DAX 主要用于加速 DynamoDB 读取操作，而 DynamoDB 本身已经具有高度的水平扩展性。</li><li>Elasticache 可以根据需求配置成更大规模的缓存集群，以支持大量的缓存数据和高并发访问。</li></ul></li></ol><p>总的来说，DAX 是专为加速 DynamoDB 读取操作而设计的缓存服务，针对 DynamoDB 表的读取优化。而 Elasticache 则是通用的缓存服务，可以用于任何需要缓存的应用场景，支持多种缓存引擎，并适用于各种不同类型的数据库和应用程序。</p><p><img src="/images/Untitled%2036.png" alt="Untitled"></p><p>DynamoDB Accelerator (DAX) 为访问最终一致性数据提供快速响应时间。</p><p><img src="/images/Untitled%2037.png" alt="Untitled"></p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-09【ElastiCache】</title>
      <link href="/2023/08/11/AWS-11%E3%80%90ElastiCache%E3%80%91/"/>
      <url>/2023/08/11/AWS-11%E3%80%90ElastiCache%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="Amazon-ElastiCache"><a href="#Amazon-ElastiCache" class="headerlink" title="Amazon ElastiCache"></a><strong>Amazon ElastiCache</strong></h1><p><img src="/images/Untitled%2030.png" alt="Untitled"></p><p><code>缓存是一种用于提高数据访问性能的技术，通过将数据存储在高速存储介质（如内存）中，避免了频繁从慢速的数据存储（如数据库）中读取数据。</code></p><p>doesn’t cache at <em><strong>edge locations</strong></em></p><p>Amazon ElastiCache允许您在云中轻松创建和管理cache。</p><p>缓存是一种快速存储数据的方法，可以加快应用程序的速度。</p><p>它提供了高性能、低延迟的内存数据库，用于缓存数据。</p><ul><li>ElastiCache支持两种流行的缓存引擎：Redis和Memcached。</li><li><strong>内存数据库（Caches）的高性能和低延迟：</strong> ElastiCache提供了高性能和低延迟的内存数据库，允许您在内存中存储和检索数据，从而加快数据访问速度。</li><li><strong>减轻数据库负载：</strong> 使用ElastiCache可以将读取密集型工作负载的负载转移到缓存数据库中，从而减轻主数据库的负载，提高数据库的性能和响应能力。</li><li><strong>用户会话存储：</strong> ElastiCache还可以用作应用程序的用户会话存储，帮助使应用程序无状态化。通过将用户会话存储在缓存中，可以实现应用程序的无状态设计，从而更好地处理负载均衡和可扩展性。</li><li><strong>AWS管理和维护：</strong> Amazon ElastiCache负责托管Redis或Memcached的操作系统维护、补丁管理、性能优化、设置、配置、监控、故障恢复和备份。这样，您无需担心底层基础设施和管理任务。</li><li><strong>应用程序代码更改：</strong> 使用ElastiCache通常需要对应用程序代码进行适度的更改，以支持缓存功能。例如，您需要调整应用程序的读取逻辑，以先查找缓存，如果缓存中没有，则再查找主数据库。</li></ul><p><strong>Redis与Memcached对比：</strong></p><table><thead><tr><th>特征</th><th>Redis</th><th>Memcached</th></tr></thead><tbody><tr><td>数据结构支持</td><td>支持更丰富的数据结构，如字符串、哈希、列表、集合、有序集等</td><td>仅支持简单的键值对存储</td></tr><tr><td>persistent data持久化数据</td><td>✅</td><td>❌</td></tr><tr><td>replication</td><td>✅</td><td>❌</td></tr><tr><td>backup and restore</td><td>✅</td><td>❌</td></tr><tr><td>多节点分区</td><td>✅</td><td>✅</td></tr><tr><td>多线程支持</td><td>单线程</td><td>多线程</td></tr><tr><td>适用场景</td><td>复杂数据结构、持久化需求、<strong>高可用性</strong></td><td>简单键值对缓存、高性能需求</td></tr></tbody></table><h2 id="Cache-Security"><a href="#Cache-Security" class="headerlink" title="Cache Security"></a><strong>Cache Security</strong></h2><ul><li>All caches in ElastiCache:<ul><li>不支持IAM身份验证</li><li>ElastiCache上的IAM策略仅用于AWS API级别的安全性</li></ul></li><li>Redis认证（AUTH）：<ul><li>令牌：You can set a “password&#x2F;token” when you create a Redis cluster</li><li>This is an extra level of security for your cache (<strong>on top of security groups</strong>)</li><li>Support SSL in flight encryption</li></ul></li><li>Memcached<ul><li>支持基于SASL的身份验证（高级功能）</li></ul></li></ul><h2 id="patterns-for-ElasticCache"><a href="#patterns-for-ElasticCache" class="headerlink" title="patterns for ElasticCache"></a>patterns for ElasticCache</h2><p><strong>Lazy Loading (延迟加载)：</strong><br>这个方法很lazy，读取数据首先检查cache里面有没有，有的话直接读取，没有再到持久性数据储存中读取。但这样导致cache里的数据可能会过时，必须额外设置更新数据</p><p><strong>Write-through (写入透穿)：</strong><br>在写入数据库时同时将数据添加或更新到缓存中</p><p><strong>Session Store (会话存储)：</strong><br>将临时会话数据存储在缓存中（使用TTL功能）。</p><h2 id="ElastiCache-–-Redis-Use-Case"><a href="#ElastiCache-–-Redis-Use-Case" class="headerlink" title="ElastiCache – Redis Use Case"></a><strong>ElastiCache – Redis Use Case</strong></h2><ul><li>游戏排行榜的复杂计算</li><li>Redis排序集保证了唯一性和元素顺序</li><li>每次添加新元素时，都会对其进行实时排名，然后添加到正确的顺序</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-09【Amazon Aurora】</title>
      <link href="/2023/08/10/AWS-09%E3%80%90Amazon%20Aurora%E3%80%91/"/>
      <url>/2023/08/10/AWS-09%E3%80%90Amazon%20Aurora%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="Amazon-Aurora"><a href="#Amazon-Aurora" class="headerlink" title="Amazon Aurora"></a><strong>Amazon Aurora</strong></h2><p><img src="/images/Untitled%2026.png" alt="Untitled"></p><p>Amazon Aurora 是一款完全托管式关系数据库引擎，专为云端打造，与 MySQL 和 PostgreSQL 兼容。Amazon Aurora 是 Amazon RDS 的一部分。</p><p><strong>separation of storage and compute</strong></p><ul><li>Aurora is a proprietary technology from AWS (not open sourced)</li><li>Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database)</li><li>Aurora被称为“AWS云优化”，声称相比RDS上的MySQL，性能提高了5倍，比RDS上的PostgreSQL性能提高了3倍。</li><li>Aurora存储会自动以10GB为增量增长，最高可达128TB。</li><li>Aurora最多可以有**15个raplica，而MySQL只能有5个，**并且复制过程更快（副本延迟低于10毫秒）。</li><li>Aurora的故障切换是即时的。它具有本地高可用性（High Availability）。</li><li>Aurora的成本比RDS更高（高出20%），但更高效。</li></ul><h3 id="Aurora-High-Availability-and-Read-Scaling"><a href="#Aurora-High-Availability-and-Read-Scaling" class="headerlink" title="Aurora High Availability and Read Scaling"></a><strong>Aurora High Availability and Read Scaling</strong></h3><ul><li>数据在3个AZ中有6个copies：<ul><li>对于写入，需要6个副本中的4个。</li><li>对于读取，需要6个副本中的3个。</li><li>使用点对点复制实现自动修复。</li><li>存储跨数百个卷进行条带化（striped）。</li></ul></li><li>一个Aurora实例用于写入（master）。</li><li>automated failover for instance for master in less then 30s</li><li>主实例和最多15 Aurora Read Replicas serve用于读取服务。</li><li><strong>支持跨区域复制（Cross Region Replication）</strong>。</li></ul><h3 id="Aurora-DB-Cluster"><a href="#Aurora-DB-Cluster" class="headerlink" title="Aurora DB Cluster"></a>Aurora DB Cluster</h3><p><img src="/images/Untitled%2027.png" alt="Untitled"></p><h3 id="Aurora-replicas-auto-scaling"><a href="#Aurora-replicas-auto-scaling" class="headerlink" title="Aurora replicas -auto scaling"></a>Aurora replicas -auto scaling</h3><p><img src="/images/Untitled%2028.png" alt="Untitled"></p><h3 id="Aurora-–-Custom-Endpoints"><a href="#Aurora-–-Custom-Endpoints" class="headerlink" title="Aurora – Custom Endpoints"></a><strong>Aurora – Custom Endpoints</strong></h3><ul><li>将一组Aurora实例定义为自定义终端节点。</li><li>示例：在特定副本上运行分析查询。</li><li>在定义自定义终端节点后，通常不再使用读取终端节点（Reader Endpoint）。</li></ul><p><img src="https://img2022.cnblogs.com/blog/2122768/202204/2122768-20220417155832116-1925105483.png" alt="https:&#x2F;&#x2F;img2022.cnblogs.com&#x2F;blog&#x2F;2122768&#x2F;202204&#x2F;2122768-20220417155832116-1925105483.png"></p><h3 id="Aurora-serverless"><a href="#Aurora-serverless" class="headerlink" title="Aurora serverless"></a>Aurora serverless</h3><p>可以根据实际负载需求自动调整数据库的计算容量，从而实现按需自动缩放。</p><ol><li><strong>自动扩展和缩减</strong>：Aurora Serverless可以根据负载自动增加或减少计算容量，确保数据库能够高效地处理变化的工作负载，同时最大程度地降低成本。</li><li><strong>无需管理实例大小</strong>：用户无需手动配置数据库实例的大小，Aurora Serverless会自动处理资源调整。</li><li><strong>暂停和恢复功能</strong>：当数据库不活动时，Aurora Serverless可以自动暂停实例，从而节省资源并降低成本。一旦有查询请求或数据库活动，它会快速恢复并处理请求。</li><li><strong>基于秒级的计费</strong>：Aurora Serverless按照数据库使用的秒数进行计费，这意味着您只需支付实际使用的资源量。</li></ol><aside>🐳 适合infrequent不频繁, intermittent间歇性 or unpredictable 不可预测的workloads</aside><aside>🐳 对数据库负载有波动性的场景，如开发和测试环境、不规则的工作负载和季节性业务。</aside><h3 id="Aurora-Multi-master"><a href="#Aurora-Multi-master" class="headerlink" title="Aurora Multi-master"></a>Aurora Multi-master</h3><p>传统的数据库系统通常只有一个主节点，所有写入操作都要经过该主节点处理，这可能会成为瓶颈并限制数据库的写入吞吐量。而Aurora Multi-Master则允许多个主实例并行处理写入请求，从而显著提高了数据库的写入性能和容量。</p><p>主要特点如下：</p><ol><li><strong>多主节点</strong>：Aurora Multi-Master允许在Aurora集群中配置多个主节点，每个主节点都可以处理写入请求。</li><li><strong>并行写入</strong>：由于有多个主节点，写入操作可以并行处理，这样大大提高了数据库的写入吞吐量。</li><li><strong>高可用性</strong>：每个主节点都具有独立的网络和存储，因此即使某个主节点发生故障，其他主节点仍然可以继续处理写入请求，确保数据库的高可用性。</li><li><strong>读取负载均衡</strong>：Aurora Multi-Master还支持读取负载均衡，多个主节点可以处理读取请求，从而进一步提高数据库的读取性能。</li></ol><p>Aurora Multi-Master适用于高写入负载的场景，例如大规模的写入操作、高并发的写入请求或需要实时同步多个数据源的应用程序。通过允许多个主节点处理写入请求，Aurora Multi-Master提供了更高的可伸缩性和性能，使得数据库可以更好地适应大规模的写入操作。</p><h3 id="Global-Aurora"><a href="#Global-Aurora" class="headerlink" title="Global Aurora"></a><strong>Global Aurora</strong></h3><p><strong>Aurora multi-AZ replicas：用于disaster recovery</strong></p><p>这种设置适用于非常关键的应用程序，因为它提供了最小的故障恢复时间，但它并不提供在另一个区域中实时写入的能力。</p><p>-<br>    - 每个辅助区域最多16个 read replica<br>    - 有助于降低延迟<br>    - 将另一个区域提升为主要区域（用于灾难恢复）的恢复时间目标（RTO）小于1分钟<br>    - replicate data across-region takes less than 1s</p><h3 id="Aurora-Database-Cloning"><a href="#Aurora-Database-Cloning" class="headerlink" title="Aurora Database Cloning"></a>Aurora Database Cloning</h3><p>create a new aurora DB cluster from an existing one</p><p>faster than snapshot &amp; restore</p><ol><li><strong>快速创建准确副本</strong>：Aurora数据库克隆使用现有数据库的快照创建副本，因此它是原始数据库的准确复制。这个过程是非常快速的，不需要从头开始复制和创建数据库。</li><li><strong>节省时间和资源</strong>：通过克隆，您无需手动配置新的数据库实例，从头开始加载数据，或者执行其他复杂的操作。这节省了时间和资源，使得数据库克隆非常便捷。</li><li><strong>测试和开发</strong>：Aurora数据库克隆非常适合用于测试和开发环境。您可以创建数据库的克隆副本，并在测试或开发环境中使用它，而不影响生产环境的数据库。</li><li><strong>数据分析和报告</strong>：您可以使用克隆数据库来进行数据分析、生成报告以及运行复杂查询，而无需在生产数据库上执行这些操作，从而减少生产数据库的负担。</li><li><strong>数据库快照</strong>：数据库克隆是基于现有数据库的快照创建的。因此，在克隆数据库上执行的任何更改不会影响原始数据库</li></ol><p><img src="/images/Untitled%2029.png" alt="Untitled"></p><h3 id="RDS-Aurora-Security"><a href="#RDS-Aurora-Security" class="headerlink" title="RDS &amp; Aurora Security"></a><strong>RDS &amp; Aurora Security</strong></h3><h4 id="1-静态加密（At-rest-encryption）"><a href="#1-静态加密（At-rest-encryption）" class="headerlink" title="1 **-**静态加密（At rest encryption）"></a>1 **-**静态加密（At rest encryption）</h4><ul><li>可以使用AWS KMS（Key Management Service）的AES-256加密，对主数据库和只读副本进行加密。</li><li>加密必须在启动时定义。</li><li>如果主数据库未加密，则无法对只读副本进行加密。</li><li>对已存在的未加密数据库进行加密，可以通过创建数据库快照，并在恢复时选择使用加密方式进行恢复，以实现加密功能</li></ul><h4 id="2-动态加密（In-flight-encryption）"><a href="#2-动态加密（In-flight-encryption）" class="headerlink" title="2-动态加密（In-flight encryption）"></a>2-动态加密（In-flight encryption）</h4><ul><li>默认支持TLS，客户端使用AWS TLS根证书</li></ul><h4 id="3-安全组（Security-Groups）："><a href="#3-安全组（Security-Groups）：" class="headerlink" title="3.安全组（Security Groups）："></a>3.安全组（Security Groups）：</h4><p>控制对RDS &#x2F; Aurora数据库的网络访问</p><h4 id="4-IAM-Authentication（身份验证）"><a href="#4-IAM-Authentication（身份验证）" class="headerlink" title="4-IAM Authentication（身份验证）"></a>4-<strong>IAM Authentication（身份验证）</strong></h4><p>使用IAM角色连接数据库（而非用户名&#x2F;密码）</p><h4 id="5-审计日志可以启用，并发送到CloudWatch-Logs以便更长时间保留。"><a href="#5-审计日志可以启用，并发送到CloudWatch-Logs以便更长时间保留。" class="headerlink" title="5-审计日志可以启用，并发送到CloudWatch Logs以便更长时间保留。"></a>5-审计日志可以启用，并发送到CloudWatch Logs以便更长时间保留。</h4><h4 id="6-除RDS-Custom外，不支持SSH"><a href="#6-除RDS-Custom外，不支持SSH" class="headerlink" title="6-除RDS Custom外，不支持SSH"></a>6-除RDS Custom外，不支持SSH</h4>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-08【RDS】</title>
      <link href="/2023/08/09/AWS-08%E3%80%90RDS%E3%80%91/"/>
      <url>/2023/08/09/AWS-08%E3%80%90RDS%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="RDS"><a href="#RDS" class="headerlink" title="RDS"></a>RDS</h2><p> <strong>Relational Database Service 关系数据库服务</strong></p><p><img src="/images/Untitled%2023.png" alt="Untitled"></p><p> <strong>we can’t SSH into our RDS inst</strong></p><p>多种数据库引擎支持：包括MySQL、PostgreSQL、Oracle、Microsoft SQL Server和Amazon Aurora。这使得用户可以根据应用程序的需求选择合适的数据库引擎。</p><h3 id="RDS-Backups-备份"><a href="#RDS-Backups-备份" class="headerlink" title="RDS Backups 备份"></a><strong>RDS Backups 备份</strong></h3><ul><li>RDS中自动启用备份功能。</li><li>自动备份：<ul><li>每天在维护窗口期间对数据库进行完整备份。</li><li>RDS每隔5分钟备份一次事务日志。</li><li>可以还原到任意时间点（从最早的备份到5分钟前的时间点）。</li><li>保留备份数据的时间为7天（可以增加至<strong>35天</strong>）。</li></ul></li><li>数据库快照（DB Snapshots）：<ul><li>用户可以手动触发备份操作。</li><li>可以根据需要保留备份数据的时间，没有时间限制。</li></ul></li></ul><p>自动备份适用于对数据可靠性和恢复性有较高要求的场景</p><p>数据库快照更适用于具有特定备份需求或需要长期保留备份的场景。(花费更小）</p><h3 id="storage-auto-scaling存储自动扩展"><a href="#storage-auto-scaling存储自动扩展" class="headerlink" title="storage auto scaling存储自动扩展"></a>storage auto scaling存储自动扩展</h3><p>根据需要自动调整RDS数据库实例的存储空间</p><ul><li>您需要设置最大存储阈值（数据库存储的最大限制）</li><li>满足以下条件：<br>剩余存储空间少于已分配存储空间的10%<br>低存储状态持续至少5分钟<br>距离上次调整已经过去6小时</li><li>适用于具有<strong>不可预测的工作负载</strong>的应用程序。</li><li>支持所有RDS数据库引擎（MariaDB，MySQL，PostgreSQL，SQL Server，Oracle）。</li></ul><h3 id="RDS-Proxy-代理"><a href="#RDS-Proxy-代理" class="headerlink" title="RDS Proxy 代理"></a>RDS Proxy 代理</h3><p>RDS Proxy allows for managing thousands of concurrent database<br>connections, which can help reduce connection errors</p><p><strong>serverless, autoscaling, multi-AZ (high available)</strong></p><p><strong>RDS Proxy提高数据库的性能、可扩展性和安全性</strong></p><p>RDS Proxy是RDS（Amazon Relational Database Service）的全管理数据库代理，它为应用程序提供了一个连接池，并允许应用程序共享与数据库建立的连接。它的主要目标是<strong>通过减少数据库资源（如CPU、RAM）的负载和最小化开启的连接数</strong>（以及超时）来提高数据库的效率。</p><p><strong>解释：</strong></p><ul><li>RDS Proxy充当应用程序和数据库之间的中间代理，它<strong>可以处理与数据库的连接和请求</strong>，从而减轻数据库的负担。应用程序可以通过连接池共享已建立的数据库连接，而不是每次请求都创建一个新的连接，这样可以降低数据库上的开销，提高响应效率。</li><li>减少数据库资源（如CPU和RAM）的使用，</li><li>RDS Proxy可以显著减少RDS和Aurora数据库的failover time，据称可高达66%。</li><li>RDS Proxy通过IAM身份验证强制执行数据库连接的安全性，并使用AWS Secrets Manager安全地存储数据库凭据。这意味着连接到数据库的应用程序必须经过身份验证，并且凭据被安全地存储，以确保数据库的安全性。</li><li>RDS Proxy永远不会公开访问（不可公开访问），只能从VPC（Virtual Private Cloud）内部访问。这增加了数据库的安全性</li></ul><h3 id="RDS-read-replica-for-read-scalability读取可扩展性的只读副本"><a href="#RDS-read-replica-for-read-scalability读取可扩展性的只读副本" class="headerlink" title="RDS read replica for read scalability读取可扩展性的只读副本"></a>RDS read replica for read scalability读取可扩展性的只读副本</h3><p><strong>分担主数据库的读取负载，提高读取性能。</strong></p><p><strong>主数据库负责写入操作，而读取副本负责处理查询操作，从而减轻主数据库的负担。</strong></p><ul><li><p>最多可创建5个读取副本</p></li><li><p>支持<strong>Within AZ, Cross AZ or Cross Region</strong></p></li><li><p>复制是<strong>ASYNC</strong>，因此读取最终一致性</p><ul><li>主数据库对数据的更改会立即应用到主数据库本身，但不会立即传输到所有读取副本。这意味着读取副本的数据可能在某些时候是稍有延迟的，但最终会达到一致性。</li></ul></li><li><p>副本可以晋升为独立的数据库</p></li><li><p>应用程序必须更新连接字符串以使用读取副本</p><p>  <img src="/images/Untitled%2024.png" alt="Untitled"></p><h1 id="Network-Cost"><a href="#Network-Cost" class="headerlink" title="Network Cost"></a><strong>Network Cost</strong></h1><ul><li>In AWS there’s a network cost when data goes from one AZ to another</li><li><strong>For RDS Read Replicas within the same region, you don’t pay that fee</strong></li></ul><h1 id="网络成本"><a href="#网络成本" class="headerlink" title="网络成本"></a><strong>网络成本</strong></h1><ul><li>在AWS中，当数据从一个AZ传输到另一个AZ时，会产生网络成本。</li><li><strong>对于同一区域中的RDS只读副本，您不需要支付该费用</strong>。</li></ul></li></ul><h3 id="Multi-AZ-used-for-disaster-recovery-用于灾难恢复的多个可用区"><a href="#Multi-AZ-used-for-disaster-recovery-用于灾难恢复的多个可用区" class="headerlink" title="Multi AZ used for disaster recovery-用于灾难恢复的多个可用区"></a>Multi AZ used for disaster recovery-用于灾难恢复的多个可用区</h3><ul><li><strong>SYNC</strong> replication, Increase <strong>availability</strong></li><li><strong>同步</strong>复制，提高<strong>可用性</strong></li><li>RDS 主实例和辅助实例（读取副本）位于不同的可用区</li></ul><h3 id="RDS-–-From-Single-AZ-to-Multi-AZ"><a href="#RDS-–-From-Single-AZ-to-Multi-AZ" class="headerlink" title="RDS – From Single-AZ to Multi-AZ"></a><strong>RDS – From Single-AZ to Multi-AZ</strong></h3><ul><li>Zero downtime operation (no need to stop the DB)</li><li>Just click on “modify” for the database</li><li>The following happens internally:<ul><li>A snapshot is taken</li><li>A new DB is restored from the snapshot in a new AZ</li><li>Synchronization is established between the two databases</li></ul></li></ul><h3 id="RDS-–-从单可用区迁移到多可用区"><a href="#RDS-–-从单可用区迁移到多可用区" class="headerlink" title="RDS – 从单可用区迁移到多可用区"></a><strong>RDS – 从单可用区迁移到多可用区</strong></h3><ul><li>零停机操作（无需停止数据库）</li><li>只需单击数据库的“modify”按钮</li><li>下列操作在内部进行：<ul><li>拍摄一个快照</li><li>在新的 AZ 中从快照中还原一个新的数据库</li><li>在两个数据库之间建立同步</li></ul></li></ul><p><img src="/images/Untitled%2025.png" alt="Untitled"></p><h3 id="Important-ports"><a href="#Important-ports" class="headerlink" title="Important ports:"></a><strong>Important ports:</strong></h3><ul><li>FTP: 21</li><li>SSH: 22</li><li>SFTP: 22 (same as SSH)</li><li>HTTP: 80</li><li>HTTPS: 443</li></ul><h4 id="vs-RDS-Databases-ports"><a href="#vs-RDS-Databases-ports" class="headerlink" title="vs RDS Databases ports:"></a><strong>vs RDS Databases ports:</strong></h4><ul><li>PostgreSQL: 5432</li><li>MySQL: 3306</li><li>Oracle RDS: 1521</li><li>MSSQL Server: 1433</li><li>MariaDB: 3306 (same as MySQL)</li><li>Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-07【FSx】</title>
      <link href="/2023/08/07/AWS-07%E3%80%90FSx%E3%80%91/"/>
      <url>/2023/08/07/AWS-07%E3%80%90FSx%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="FSx"><a href="#FSx" class="headerlink" title="FSx"></a><strong>FSx</strong></h2><p> File System for Windows and Lustre</p><p><img src="/images/Untitled%2022.png" alt="Untitled"></p><ul><li>Amazon FSx for Windows File Server 是一种托管的Windows文件共享服务，支持标准的SMB协议，适用于文件共享和备份。</li><li>提供了完全托管的第三方文件系统。</li><li>启动、运行和扩缩功能丰富的高性能文件系统</li></ul><h3 id="FSx-for-Windows-File-Server："><a href="#FSx-for-Windows-File-Server：" class="headerlink" title="FSx for Windows File Server："></a><strong>FSx for Windows File Server：</strong></h3><ul><li><strong>Windows 兼容性</strong>：FSx for Windows File Server 支持标准的 Server Message Block（SMB）协议，这是 Windows 环境中常用的文件共享协议。您可以使用现有的 Windows 工具和应用程序，无缝地连接和访问 FSx 文件系统。</li><li><strong>可伸缩性</strong>：FSx 可以根据您的需求自动扩展存储和性能，确保您始终能够满足不断增长的文件存储需求。</li><li><strong>备份和数据复制</strong>：FSx 自动处理数据的备份和复制，确保数据的高度可靠性和持久性。</li><li><strong>集成 AWS 功能</strong>：FSx 与其他 AWS 服务紧密集成，例如 Amazon S3、AWS Identity and Access Management（IAM）等，帮助您构建全面的存储和数据管理解决方案。</li></ul><h3 id="FSx-for-Lustre："><a href="#FSx-for-Lustre：" class="headerlink" title="FSx for Lustre："></a><strong>FSx for Lustre：</strong></h3><p>**high performance computing(HPC)**高性能计算</p><p>可扩展的、低延迟的</p><p>适用于 HPC、机器学习、媒体处理等场景</p><h4 id="存储类型"><a href="#存储类型" class="headerlink" title="存储类型"></a><strong>存储类型</strong></h4><ul><li>固态硬盘 (SSD):<ul><li>对于低延迟、IOPS 密集型工作负载，这些工作负载通常具有小型随机文件操作，请选择其中一个 SSD 存储选项。</li></ul></li><li>硬盘驱动器 (HDD)<ul><li>对于吞吐量密集型工作负载，这些工作负载通常具有大型顺序文件操作，请选择其中一个 HDD 存储选项。</li></ul></li></ul><h3 id="seamless-integration-with-S3"><a href="#seamless-integration-with-S3" class="headerlink" title="seamless integration with S3"></a><strong>seamless integration with S3</strong></h3><p><strong>与S3无缝集成:</strong> 允许您在 Lustre 文件系统中无缝访问和处理 Amazon S3 存储的对象数据</p><ol><li><strong>直接访问 S3 数据</strong>：FSx for Lustre 可以直接访问存储在 Amazon S3 上的对象数据</li><li><strong>数据一致性</strong>：当您将数据从 Amazon S3 写入 Lustre 文件系统或从 Lustre 文件系统写回到 S3 时，FSx for Lustre 会确保数据的一致性。</li><li><strong>高性能</strong>：Lustre 文件系统和 Amazon S3 存储都是高性能的服务。通过 Seamless Integration with S3，您可以在 Lustre 文件系统中利用 Lustre 的低延迟和高吞吐量特性来快速读取和处理 S3 存储的数据，从而提高数据处理效率。</li><li><strong>数据持久性</strong>：由于 Lustre 文件系统直接访问 S3 存储的数据，数据的持久性和可靠性与 Amazon S3 保持一致。</li></ol><h3 id="FSx-file-system-deployment-options-文件部署选项"><a href="#FSx-file-system-deployment-options-文件部署选项" class="headerlink" title="FSx file system deployment options-文件部署选项"></a><strong>FSx file system deployment options-文件部署选项</strong></h3><ul><li><strong>Persistent File System (持久文件系统)</strong><ul><li>temporary storage</li><li>data is not replicated (doesn’t persist when file server fails).意味着如果文件服务器发生故障，数据可能会丢失。</li><li>high bust</li><li>usage :short-term processing, optimize costs</li></ul></li><li><strong>Scratch File System (短期文件系统)</strong><ul><li>long-term storage</li><li>data is replicated witnin same AZ</li><li>raplace failed files within minutes确保数据的可靠性和完整性。</li><li>usage: long-term processing , sensitive data</li></ul></li></ul><h4 id="FSx-for-NetApp-ONTAP："><a href="#FSx-for-NetApp-ONTAP：" class="headerlink" title="FSx for NetApp ONTAP："></a><strong>FSx for NetApp ONTAP：</strong></h4><p>一项完全托管的服务，提供基于流行的 ONTAP 文件系统构建的高可靠、可扩展、高性能和功能丰富的文件存储。</p><ul><li>企业级性能和功能：FSx for NetApp ONTAP 基于 NetApp 公司的存储操作系统，提供了企业级的性能、可靠性和功能。</li><li><strong>多协议支持：支持 Network File System (NFS) 和 Server Message Block (SMB) 等多种协议，与不同应用程序和环境无缝集成。</strong></li><li>高可用性：FSx for NetApp ONTAP 部署在多个 AWS 可用区，提供数据冗余和高可用性。</li><li>数据备份和恢复：FSx for NetApp ONTAP 支持数据备份、快照和灾难恢复，确保数据的安全性。</li></ul><h4 id="FSx-for-OpenZFS："><a href="#FSx-for-OpenZFS：" class="headerlink" title="FSx for OpenZFS："></a><strong>FSx for OpenZFS：</strong></h4><ul><li>Amazon FSx for Lustre 是一种高性能的托管文件系统服务，适用于高性能计算、机器学习、媒体处理等场景。可选择SSD或HDD存储类型，并可以与Amazon S3无缝集成。<ul><li><strong>Windows 兼容性</strong>：FSx for Windows File Server 支持标准的 Server Message Block（SMB）协议，这是 Windows 环境中常用的文件共享协议。您可以使用现有的 Windows 工具和应用程序，无缝地连接和访问 FSx 文件系统。</li><li><strong>可伸缩性</strong>：FSx 可以根据您的需求自动扩展存储和性能，确保您始终能够满足不断增长的文件存储需求。</li><li><strong>备份和数据复制</strong>：FSx 自动处理数据的备份和复制，确保数据的高度可靠性和持久性。</li><li><strong>集成 AWS 功能</strong>：FSx 与其他 AWS 服务紧密集成，例如 Amazon S3、AWS Identity and Access Management（IAM）等，帮助您构建全面的存储和数据管理解决方案。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-06【EFS】</title>
      <link href="/2023/08/06/AWS-06%E3%80%90EFS%E3%80%91/"/>
      <url>/2023/08/06/AWS-06%E3%80%90EFS%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="EFS"><a href="#EFS" class="headerlink" title="EFS"></a>EFS</h2><p> <strong>Elastic File System</strong></p><p><img src="/images/Untitled%2021.png" alt="Untitled"></p><h3 id="serverless"><a href="#serverless" class="headerlink" title="serverless"></a>serverless</h3><p><strong>可以挂在到一个instance上</strong></p><p><strong>可以挂载到multi-AZ的不同instance上</strong></p><p><strong>EFS 文件系统不能直接跨越多个 AWS  region进行挂载。</strong></p><p>扩展到 PB 级数，在添加和删除文件时自动增加和缩减</p><p>EFS 基于NFS协议的文件存储服务，是一个分布式的文件系统，允许多个 Amazon EC2 实例同时访问和共享文件。</p><p><strong>POSIX 兼容性</strong>：Amazon EFS 设计为与 POSIX 文件系统接口兼容，因此你可以将现有的应用程序和工作负载迁移到 EFS 上，而无需进行大量修改。</p><aside>➡️ POSIX（Portable Operating System Interface，可移植操作系统接口）是一组操作系统标准，旨在提供一种标准化的编程接口，使不同操作系统上的应用程序能够在不进行太多修改的情况下移植和运行。</aside><ul><li>Highly available, scalable, expensive (3x gp2), pay per use</li><li>Use cases: content management, web serving, data sharing,Wordpress</li><li>Uses NFSv4.1 protocol</li><li>Uses security group to control access to EFS</li><li><strong>Compatible with Linux based AMI (not Windows)：兼容Linux AMI（不支持Windows）</strong></li><li>不支持在基于微软 Windows 的Amazon EC2 实例上使用 Amazon EFS。</li><li>Encryption at rest using KMS</li></ul><h3 id="存储类别选项："><a href="#存储类别选项：" class="headerlink" title="存储类别选项："></a>存储类别选项：</h3><ul><li><strong>标准存储类别</strong><ul><li>EFS Standard: 经常访问的数据需要最高的耐久性和可用性。</li><li>EFS Standard–IA: 寿命长、不经常访问的数据，需要最高的耐久性和可用性。</li></ul></li><li><strong>单区存储类别</strong><ul><li><p>EFS One Zone:经常访问的数据，不需要最高水平的耐久性和可用性。</p></li><li><p>EFS One Zone-IA:寿命长、不经常访问的数据，不需要最高水平的耐久性和可用性。</p><blockquote><p>由于 EFS One Zone 存储类将数据存储在单个AWS可用区中，因此在发生影响可用区内所有数据副本的灾难或其他故障时，或者可用区被破坏时，存储在这些存储类中的数据可能会丢失。</p></blockquote></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-05【EBS】</title>
      <link href="/2023/08/05/AWS-05%E3%80%90EBS%E3%80%91/"/>
      <url>/2023/08/05/AWS-05%E3%80%90EBS%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="EBS-Elastic-block-system"><a href="#EBS-Elastic-block-system" class="headerlink" title="EBS-Elastic block system"></a>EBS-Elastic block system</h2><p><img src="/images/Untitled%2016.png" alt="Untitled"></p><p>一种持久性、高性能的存储解决方案，专为在AWS云环境中运行的EC2实例设计。</p><h3 id="EBS-Volume"><a href="#EBS-Volume" class="headerlink" title="EBS Volume:"></a><strong>EBS Volume:</strong></h3><p>EBS卷是AWS提供的一种块存储服务，用于为EC2实例提供持久性存储。它提供了可供EC2实例使用的虚拟硬盘。EBS卷可以附加到EC2实例，并用于存储应用程序数据和其他持久性数据。</p><p>以下是一些关键特点和用途：</p><ol><li><strong>持久性和可靠性</strong>：EBS卷的数据是持久存储的，即使EC2实例关机或遇到故障，数据也会得到保留。EBS数据具有高可靠性，并提供数据冗余和自动备份功能。</li><li><strong>可扩展性和高性能</strong>：EBS卷的容量和性能可以根据需要进行调整。你可以根据应用程序的需求增加或减少卷的大小，并调整卷的吞吐量和IOPS（每秒输入&#x2F;输出操作数）。</li><li><strong>快照备份</strong>：EBS提供了快照功能，可以创建卷的点-in-time备份。快照是卷数据的完整拷贝，可以用于数据备份、灾难恢复和创建新的EBS卷。</li><li><strong>多种卷类型</strong>：EBS提供多种卷类型，包括SSD（固态硬盘）和HDD（机械硬盘）等。每种类型都具有不同的性能和成本特性，可以根据应用程序的需求选择适合的卷类型。</li><li><strong>可用性和地理位置</strong>：EBS卷可以在不同的可用区之间进行复制和备份，以提高数据的可用性和可靠性。此外，EBS卷还可以进行跨区域复制，以实现地理位置的灾难恢复。</li></ol><h4 id="volume-types-卷类型"><a href="#volume-types-卷类型" class="headerlink" title="volume types-卷类型"></a>volume types-卷类型</h4><p>EBS volume types：</p><blockquote><p>• <strong>Only gp2&#x2F;gp3 and io1&#x2F;io2 can be used as boot volumes</strong></p></blockquote><ul><li><p><strong>gp2&#x2F;gp3（SSD）</strong>：General purpose SSD volume，提供平衡的价格和性能，适用于各种工作负载。</p><ul><li>gp3可以独立设置IOPS和throughput，gp2的IOPS和 throughput是linked</li><li>价格：</li></ul><p>  <img src="/images/Untitled%2017.png" alt="Untitled">  </p></li><li><h2 id="io1-io2（SSD）：Highest-performance-SSD-volume-for-mission-critical-low-latency-or-high-throughput-workloads-more-than-16000-IOPS-great-for-databases-workloads-increase-PIOPS-independently-from-storage-size"><a href="#io1-io2（SSD）：Highest-performance-SSD-volume-for-mission-critical-low-latency-or-high-throughput-workloads-more-than-16000-IOPS-great-for-databases-workloads-increase-PIOPS-independently-from-storage-size" class="headerlink" title="io1&#x2F;io2（SSD）：Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads  - more than 16000 IOPS  - great for databases workloads  - increase PIOPS independently from storage size"></a><strong>io1&#x2F;io2（SSD）</strong>：Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads<br>  - more than 16000 IOPS<br>  - great for databases workloads<br>  - increase PIOPS independently from storage size</h2><p>  <img src="/images/Untitled%2018.png" alt="Untitled"></p></li><li><p><strong>st1（HDD）</strong>：Low cost HDD volume，专为频繁访问、吞吐量密集型的工作负载而设计。</p></li><li><p><strong>sc1（HDD）</strong>：Low cost HDD volume，专为不频繁访问的工作负载而设计。</p><p>  <img src="/images/Untitled%2019.png" alt="Untitled"></p></li></ul><h3 id="delete-on-termination-attribute"><a href="#delete-on-termination-attribute" class="headerlink" title="delete on termination attribute"></a>delete on termination attribute</h3><p>EBS volume的属性</p><p>用于定义当关联的 EC2 实例终止时是否自动删除该 EBS 卷。具体而言，如果 “delete on termination” 属性被设置为启用（默认情况下是启用的），则当关联的 EC2 实例终止时，该 EBS 卷将自动被删除，其上的数据也将被清除。</p><p>By default, the Root volume type will be deleted as its “Delete On Termination” attribute checked by default. Any other EBS volume types will not be deleted as its “Delete On Termination” attribute disabled by default.</p><p>默认情况下，根卷类型将被删除，因为其“删除终止”属性已默认选中。任何其他EBS卷类型将不被删除，因为其“删除终止”属性默认禁用。</p><h3 id="root-volume-EBS-volume-instance-store"><a href="#root-volume-EBS-volume-instance-store" class="headerlink" title="root volume * EBS volume * instance store"></a>root volume * EBS volume * instance store</h3><p><img src="/images/Untitled%2020.png" alt="Untitled"></p><p>root volume是EC2实例的主要存储卷，通常用于操作系统和系统文件。它是<strong>EC2实例的一部分</strong>，与实例的生命周期绑定。</p><p>EBS volume是一种可附加attach到EC2实例的虚拟硬盘</p><p> <strong>root volume是instance的一部分，可以是instance store或EBS volume。</strong></p><ul><li>如果根卷是实例存储，直接连接到实例主机。它提供了高性能和低延迟的存储，但是它是<strong>临时性</strong>的，</li><li>如果根卷是EBS卷，它是一种持久性存储，数据会被保留，即使实例停止或终止</li></ul><h3 id="snapshot-快照"><a href="#snapshot-快照" class="headerlink" title="snapshot 快照"></a>snapshot 快照</h3><p>a backup of EBS volume at any point time</p><p>can copy snapshots across AZ or Region</p><p><strong>增量备份：</strong> 快照采用增量备份的方式，只备份卷上的更改数据，从而减少存储空间和传输成本。</p><h3 id="multi-attach-多重附加"><a href="#multi-attach-多重附加" class="headerlink" title="multi attach -多重附加"></a>multi attach -多重附加</h3><p>Attach the same EBS volume to multiple EC2 instances <strong>in the same AZ</strong></p><p><strong>io1&#x2F;io2 family</strong></p><ul><li>Attach the same EBS volume to multiple EC2 instances in the same AZ</li><li>Each instance has full read &amp; write permissions to the volume</li><li>Use case:<ul><li>Achieve <strong>higher application availability</strong> in clustered Linux applications (ex: Teradata)</li><li>Applications must manage concurrent write operations</li></ul></li><li>Must use a file system that’s cluster-aware (not XFS, EX4, etc…)</li></ul><h3 id="Encryption-加密"><a href="#Encryption-加密" class="headerlink" title="Encryption-加密"></a><strong>Encryption-加密</strong></h3><p>当您创建一个加密的EBS卷时：</p><ul><li><strong>数据静态存储时会在卷内部进行加密，保护数据的安全性。</strong></li><li><strong>实例和卷之间传输的所有数据都会进行加密，确保数据在传输过程中的机密性。</strong></li><li>所有的快照都会被加密，包括从未加密的卷创建的快照。</li><li><strong>从快照创建的所有卷都会继承快照的加密属性，成为加密卷。</strong></li><li>EBS加密使用来自AWS KMS的AES-256密钥进行加密和解密。</li></ul><p>要对未加密的EBS卷进行加密，您可以按照以下步骤操作：</p><ol start="6"><li>创建卷的快照。</li><li>使用复制操作对快照进行加密。</li><li>使用加密的快照创建新的EBS卷，这个卷也会是加密的。</li><li>将加密的卷附加到原始实例上。</li></ol><h3 id="Instance-store"><a href="#Instance-store" class="headerlink" title="Instance store"></a>Instance store</h3><p>EC2 Instance Store是<strong>基于物理硬盘</strong>的本地存储，它直接连接到运行实例的物理硬件。这意味着实例存储是实际的物理硬盘驱动器，提供了低延迟和高吞吐量的性能。</p><p>EBS 卷是基于<strong>网络连接</strong>的虚拟存储设备，它是通过网络连接到实例，并提供持久性数据存储。</p><p>EBS volume are network drives with good but limited performance</p><p>if you need a high-performance hardware disk, use EC2 instance store</p><ul><li>better I&#x2F;O performance</li><li>**ephemeral—**EC2 instance store lose their storage if they’re stopped</li><li>good for buffer&#x2F; cache &#x2F; scratch data &#x2F; temporary content</li><li>not for long term storage</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
            <tag> 存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-04【S3】</title>
      <link href="/2023/08/04/AWS-04%E3%80%90S3%E3%80%91/"/>
      <url>/2023/08/04/AWS-04%E3%80%90S3%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a><strong>S3</strong></h2><p><strong>Simple Storage Service</strong></p><p><img src="/images/203.png" alt="图片1"></p><ul><li>S3是AWS提供的对象存储服务，适用于存储和检索任意类型的数据，如文件、图像、视频等。</li><li>S3是高度可扩展、耐用、安全的存储解决方案。</li></ul><h3 id="S3-存储桶（Bucket）："><a href="#S3-存储桶（Bucket）：" class="headerlink" title="S3 存储桶（Bucket）："></a><strong>S3 存储桶（Bucket）：</strong></h3><ul><li>存储桶的名称在整个AWS中必须是全局唯一的。</li><li>Amazon S3 允许用户将object（文件）存储在“bucket”（目录）中。</li><li>存储桶必须有一个<strong>全局唯一的名称</strong>。</li><li>Buckets are defined at the region level存储桶在区域级别上定义。</li></ul><aside>🐳 命名约定<ul><li>不使用<strong>大写字母</strong></li><li>不使用下划线</li><li>长度为3-63个字符</li><li>不是IP地址</li><li>必须以小写字母或数字开头。</li></ul></aside><h3 id="S3-对象（Object）："><a href="#S3-对象（Object）：" class="headerlink" title="S3 对象（Object）："></a><strong>S3 对象（Object）：</strong></h3><p>可以是任意类型的数据，例如文本文件、图像、视频、数据库备份等。</p><p>在S3中，对象由以下三个主要组成部分构成：</p><ol><li><strong>键（Key）</strong>：<ul><li>键是对象的唯一标识符，用于在S3存储桶中唯一标识对象。</li><li>Key并不是完整路径，而是相对于存储桶的路径或文件名。</li></ul></li><li><strong>值（Value）</strong>：<ul><li>对象值是主体内容</li><li>值是实际的数据内容，也就是存储在对象中的实际数据。</li><li>值可以是任何字节流，允许存储各种类型的文件和数据。</li></ul></li><li><strong>元数据（Metadata）</strong>：<ul><li>元数据是关于对象的一组键值对信息，用于描述对象的属性和其他相关信息。</li><li>元数据可以包含诸如对象的创建日期、文件类型、大小、所有者等信息。</li></ul></li></ol><h3 id="storage-class-存储类别"><a href="#storage-class-存储类别" class="headerlink" title="storage class 存储类别"></a><strong>storage class 存储类别</strong></h3><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>S3 Standard（default）</td><td>标准存储</td><td>适用于频繁访问的数据大数据分析，移动应用，游戏</td></tr><tr><td>S3 Intelligent-Tiering</td><td>智能分层—数据根据<strong>访问模式</strong>分层存储</td><td>自动优化存储费用和性能；不确定访问频率的数据, 成本敏感型应用</td></tr><tr><td>S3 Standard-IA</td><td>infrequent access</td><td>**访问频率较低，但即时访问的数据。**灾难恢复，备份</td></tr><tr><td>S3 One Zone-IA</td><td>S3-One zone not suitable for business critical data<strong>不适合关键性数据</strong></td><td>可重新创建的、不经常访问的数据(每月一次)，存储在单个可用区中，访问时间为毫秒……………与 S3 Standard-IA相比具有<em><strong>更低的存储成本</strong></em></td></tr><tr><td>Glacier Instant Retrieval</td><td>Glacier <strong>即时</strong>检索，数据不可更新</td><td>适用于需要即时访问的归档数据；</td></tr><tr><td>Glacier Flexible Retrieval</td><td>Glacier 灵活检索，数据不可更新</td><td>适用于很少访问且不<strong>需要即时访问</strong>的长期数据；</td></tr><tr><td>S3 Glacier Deep Archive</td><td>Glacier 深度存档，</td><td>long-term:适用于以<strong>最低的云存储成本</strong>进行长期归档和数字保存。</td></tr></tbody></table><p>Amazon S3 还提供了在整个数据生命周期内管理数据的功能。设置 S3 生命周期策略之后，无需更改您的应用程序，您的数据将自动传输到其他存储类。</p><aside>🚫 您无法从以下内容进行转换：<ol><li>任何存储类别到S3 Standard。</li><li>任何存储类别到冗余存储（RRS）类别。</li><li>S3 Intelligent-Tiering存储类别到S3 Standard-IA。<br>S3 One Zone-IA存储类别到S3 Intelligent-Tiering，S3 Standard-IA或S3 Glacier即时检索存储类别。</li></ol></aside><h4 id="moving-between-storage-classes"><a href="#moving-between-storage-classes" class="headerlink" title="moving between storage classes"></a>moving between storage classes</h4><p>moving objects can be automated using a <strong>lifecycle configuration</strong></p><h3 id="Storage-Class-Analysis"><a href="#Storage-Class-Analysis" class="headerlink" title="Storage Class Analysis"></a><strong>Storage Class Analysis</strong></h3><ul><li>您可以设置S3分析以帮助确定何时将对象从标准转换为Standard_IA。</li><li>不适用于ONEZONE_IA或GLACIER。</li><li>报告每天更新。</li><li>首次启动需要约24小时至48小时。</li><li>组合生命周期规则（或改进生命周期规则）的好第一步！</li></ul><h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a><strong>数据管理</strong></h3><p>：对象版本控制、生命周期配置、跨区域复制、数据传输加速等功能。</p><h4 id="S3Versioning版本控制"><a href="#S3Versioning版本控制" class="headerlink" title="** S3Versioning版本控制**"></a>** S3Versioning版本控制**</h4><p>启用版本控制后，S3将为每个存储在存储桶中的对象创建不同的版本，而不是覆盖之前的版本。</p><ul><li>可在bucket级别启用</li><li>可恢复特定版本以及轻松回滚</li><li>默认版本 ID 为“null”</li><li>suspending versionsing does not delete the previous versions</li></ul><h4 id="S3-Lifecycle-Rules生命周期"><a href="#S3-Lifecycle-Rules生命周期" class="headerlink" title="S3 Lifecycle Rules生命周期"></a><strong>S3 Lifecycle Rules生命周期</strong></h4><ul><li><strong>Transition actions</strong>:：它定义了对象何时转换为另一个存储类别。<ul><li>创建后60天将对象移动到标准IA类别。</li><li>6个月后将对象移动到Glacier进行归档。</li></ul></li><li><strong>Expiration actions</strong>：<strong>配置对象在一定时间后过期（删除）</strong><ul><li>访问日志文件可以设置为在365天后删除。</li><li><strong>可用于删除旧文件版本（如果启用了版本控制）</strong></li><li>可<strong>用于删除未完成的多部分上传。</strong></li></ul></li><li>可以为某个前缀prefix创建规则（例如 - s3:&#x2F;&#x2F;mybucket&#x2F;mp3&#x2F;*）</li><li>可以为某些objects tags创建规则（例如 - Department: Finance）</li></ul><h4 id="对象锁定-保护对象免受删除和更改"><a href="#对象锁定-保护对象免受删除和更改" class="headerlink" title="对象锁定-保护对象免受删除和更改"></a>对象锁定-保护对象免受删除和更改</h4><ol><li><strong>合规模式（Compliance Mode）</strong>：<ul><li>合规模式是 Amazon S3 中的一种对象锁定模式，用于确保对象在指定的锁定期间内不被删除或更改。</li><li>在合规模式下，对象一旦被锁定，即使具有管理权限的用户（<strong>包括 root</strong> 用户）也无法删除或更改对象，直到锁定期结束。</li><li>合规模式适用于需要满足法规和合规性要求，确保数据不被篡改或删除的场景。</li></ul></li><li><strong>治理模式（Governance Mode）</strong>：<ul><li>治理模式也是 Amazon S3 中的一种对象锁定模式，用于在指定的锁定期间内保护对象免受删除和更改。</li><li>在治理模式下，具有管理权限的用户（如 root 用户）可以申请对对象进行更改或删除，但需要提前指定锁定结束的日期和时间。</li><li>治理模式适用于需要保护数据免受误删除或更改的场景，但允许有一定管理权限的用户提前申请解锁。</li></ul></li></ol><h4 id="S3-Replication-CRR-SRR-复制"><a href="#S3-Replication-CRR-SRR-复制" class="headerlink" title="S3 Replication (CRR &amp; SRR)复制"></a><strong>S3 Replication (CRR &amp; SRR)复制</strong></h4><ul><li><p><strong>Must enable versioning</strong> in source and destination</p></li><li><p><strong>跨区域复制Cross Region Replication (CRR)</strong></p></li><li><p><strong>同一区域复制Same Region Replication (SRR)</strong></p></li><li><p>复制是asynchronous异步的</p></li><li><p>存储桶可以位于不同的账户中</p></li><li><p>必须为S3授予适当的IAM权限</p></li><li><p>CRR - 使用场景：合规性，更低的延迟访问，跨账户复制</p></li><li><p>SRR - 使用场景：log aggregation日志聚合，live replication between production and test accounts生产和测试账户之间的实时复制</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><em><strong>注意事项</strong></em></h3></li><li><p>激活后，只有新对象会被复制（不会追溯复制旧对象）</p></li><li><p>对于删除操作：</p><ul><li>可以从源复制到目标删除maker（可选设置）</li><li>具有版本 ID 的删除不会被复制（以避免恶意删除）</li></ul></li><li><p>复制不传递</p><ul><li>如果 bucket 1 复制到 bucket 2，bucket 2 复制到 bucket 3, 那么在 bucket 1 中创建的对象不会被复制到 bucket 3</li></ul></li></ul><h4 id="S3-Transfer-Acceleration-数据传输加速"><a href="#S3-Transfer-Acceleration-数据传输加速" class="headerlink" title="S3 Transfer Acceleration 数据传输加速"></a><strong>S3 Transfer Acceleration</strong> 数据传输加速</h4><ul><li>通过将文件传输到AWS边缘位置，增加传输速度，该位置将数据转发到目标区域的S3存储桶</li><li>兼容多部分上传Compatible with multi-part upload</li></ul><h4 id="S3-–-Baseline-Performance基准性能"><a href="#S3-–-Baseline-Performance基准性能" class="headerlink" title="S3 – Baseline Performance基准性能"></a><strong>S3 – Baseline Performance基准性能</strong></h4><ul><li>Amazon S3可以自动扩展到高请求率，延迟为100-200毫秒。</li><li>您的应用程序每个存储桶前缀每秒可以实现至少3,500个PUT&#x2F;COPY&#x2F;POST&#x2F;DELETE和5,500个GET&#x2F;HEAD请求。</li></ul><h4 id="S3-Performance"><a href="#S3-Performance" class="headerlink" title="S3 Performance"></a><strong>S3 Performance</strong></h4><ul><li><p><strong>Multi-Part upload:</strong></p><ul><li><p>推荐用于大于100MB的文件，对于大于5GB的文件必须使用</p></li><li><p>可以并行上传（加快传输速度）</p></li></ul></li><li><p><strong>S3 Transfer Acceleration</strong></p><ul><li>通过将文件传输到AWS边缘位置，增加传输速度，该位置将数据转发到目标区域的S3存储桶</li><li>兼容多部分上传Compatible with multi-part upload</li></ul></li></ul><h4 id="S3-Select-Glacier-Select"><a href="#S3-Select-Glacier-Select" class="headerlink" title="S3 Select &amp; Glacier Select"></a><strong>S3 Select &amp; Glacier Select</strong></h4><ul><li>使用简单的<strong>SQL</strong>进行服务器端过滤，以检索<strong>较少的数据</strong></li><li><strong>可以按行和列进行过滤</strong></li><li>较少的网络传输和客户端的CPU成本</li><li><strong>Use Case</strong>:<ul><li>适用于需要从大型对象中仅提取特定数据的情况，例如从CSV或JSON文件中提取特定字段的值，而不需要下载整个对象。</li><li>Glacier Select则用于从S3 Glacier存储中检索特定数据，这样可以避免将整个归档文件恢复到S3中，从而节省时间和费用。</li></ul></li></ul><h4 id="S3-Batch-Operations批量操作"><a href="#S3-Batch-Operations批量操作" class="headerlink" title="S3 Batch Operations批量操作"></a><strong>S3 Batch Operations批量操作</strong></h4><ul><li>通过单个请求对现有S3对象执行批量操作<ul><li>一个作业包括一个对象列表，要执行的操作和可选参数</li><li>S3批量操作管理重试，跟踪进度，发送完成通知并生成报告</li><li>步骤：<ul><li>使用S3清单获取对象列表</li><li>使用S3 Select过滤对象</li><li>使用S3批量操作处理对象</li></ul></li></ul></li></ul><h4 id="S3-Byte-range-Fetches字节范围获取"><a href="#S3-Byte-range-Fetches字节范围获取" class="headerlink" title="S3 Byte-range Fetches字节范围获取"></a><strong>S3 Byte-range Fetches字节范围获取</strong></h4><ul><li>通过请求特定的字节范围并行化GET操作</li><li>使用场景：加快下载速度或只需要部分数据（例如文件头）</li><li><strong>Use Case</strong>: S3 Byte-range Fetches适用于需要仅获取对象的一部分内容的情况，例如音频或视频文件的部分播放、分块下载大文件或断点续传等。通过指定字节范围，客户端可以仅下载所需的部分数据，而不需要下载整个对象，从而提高效率和性能。</li></ul><h3 id="安全性security"><a href="#安全性security" class="headerlink" title="安全性security"></a><strong>安全性security</strong></h3><h4 id="Encryption-for-Objects-加密（服务器端加密、客户端加密）"><a href="#Encryption-for-Objects-加密（服务器端加密、客户端加密）" class="headerlink" title="Encryption for Objects-加密（服务器端加密、客户端加密）"></a><strong>Encryption for Objects-加密（服务器端加密、客户端加密）</strong></h4><ul><li><p><strong>服务器端加密（Server-Side Encryption，SSE）：</strong></p><p>S3 管理加密密钥（SSE-S3 或 SSE-KMS）</p><blockquote><p>SSE-S3</p></blockquote><ul><li>Object is encrypted server side</li><li>AES-256 encryption type</li><li>Must set header: <strong>“x-amz-server-side-encryption”: “AES256”</strong></li></ul><blockquote><p>SSE-KMS</p></blockquote><p>加密密钥由 AWS Key Management Service (KMS) 管理。</p><ul><li>KMS Advantages: user control + audit trail</li><li>Object is encrypted server side</li><li>Must set header: <strong>“x-amz-server-side-encryption”: “aws:kms”</strong></li></ul></li><li><p><strong>客户管理加密密钥（SSE-C）：</strong></p><ul><li>SSE-C（Server-Side Encryption with Customer-Provided Keys）</li><li><strong>Amazon S3 不会存储您提供的加密密钥</strong></li><li><strong>HTTPS must be used</strong></li><li>Encryption key must provided in HTTP headers, for every HTTP request made</li><li>允许客户使用自己管理的加密密钥对数据进行加密。客户在上传对象时必须提供加密密钥，并在后续下载时提供正确的密钥来解密数据。</li></ul></li><li><p><strong>客户端加密Client Side Encryption：</strong></p><ul><li>客户端必须在发送到S3之前自行加密数据</li><li>客户端必须在从S3检索数据时自行解密数据</li><li>客户完全管理密钥和加密周期</li></ul></li><li><p><strong>encryption in transit(SSL&#x2F;TSL)：</strong></p><ul><li>使用 SSL&#x2F;TLS 加密协议保护数据在传输过程中的安全性。</li><li>数据在从客户端上传到 S3 或从 S3 下载到客户端的过程中会被加密，防止中间人攻击或窃听。</li></ul></li></ul><h4 id="访问控制（IAM、桶策略、ACLs）"><a href="#访问控制（IAM、桶策略、ACLs）" class="headerlink" title="访问控制（IAM、桶策略、ACLs）"></a><strong>访问控制（IAM、桶策略、ACLs）</strong></h4><ul><li><p><strong>Bucket Policy-S3存储桶策略</strong></p><p>基于JSON的策略</p><ul><li>资源：buckets and objects</li><li>效果：Allow &#x2F; Deny</li><li>操作：允许或拒绝的API集合</li><li>主体：要应用策略的帐户或用户</li><li>应用场景<ul><li>授予公共访问桶</li><li>强制上传的对象进行加密</li><li>授予另一个帐户访问权限（跨帐户访问必须使用存储桶策略）</li></ul></li></ul></li><li><p><strong>使用IAM策略进行访问控制</strong></p><ul><li>基于用户<ul><li>IAM策略，控制特定用户从IAM可以允许哪些API调用</li></ul></li></ul></li><li><p><strong>使用预签名URL（Pre-Signed URL）授予临时访问权限</strong></p><ul><li>Can generate pre-signed URLs using SDK or CLI<ul><li>For downloads (easy, can use the CLI)</li><li>For uploads (harder, must use the SDK)</li></ul></li><li>Valid for a default of 3600 seconds, can change timeout with –expires-in [TIME_BY_SECONDS] argument</li><li>Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET &#x2F; PUT</li><li>可以使用SDK或CLI生成预签名URL<ul><li>对于下载（容易，可以使用CLI）</li><li>对于上传（更难，必须使用SDK）</li></ul></li><li>默认有效期为3600秒，可以使用–expires-in [TIME_BY_SECONDS]参数更改超时时间</li><li>获得预签名URL的用户继承生成URL的人的GET &#x2F; PUT权限</li></ul></li><li><p><strong>bucket setting for block public access</strong></p><p>在AWS S3（Simple Storage Service）中，”Block Public Access”（阻止公共访问）是一组设置，用于确保您的S3存储桶及其内容不会被未经授权的公众访问。这些设置旨在增加您数据的安全性，防止因配置错误或意外而导致敏感信息泄露。</p><p>Block Public Access有以下四个设置选项：</p><ol><li>Block all public access:</li><li>Block public access to buckets and objects granted through new access control lists (ACLs):</li><li>Block public access to buckets and objects granted through any public bucket or access point policies:</li><li>Block public access to buckets and objects granted through new public bucket or access point policies:</li></ol></li></ul><h4 id="S3-MFA-Delete"><a href="#S3-MFA-Delete" class="headerlink" title="S3 MFA-Delete"></a><strong>S3 MFA-Delete</strong></h4><ul><li>MFA（多因素认证）会强制用户在进行S3上的重要操作之前，在设备上（通常是手机或硬件）生成一个代码。</li><li><strong>要使用MFA-Delete，请在S3存储桶上启用Versioning。</strong></li><li>您需要MFA来<ul><li>permanently delete an object version</li><li>suspend versioning on the bucket</li><li>永久删除对象版本</li><li>暂停存储桶的版本控制</li></ul></li><li>您不需要MFA来<ul><li>启用版本控制</li><li>列出已删除的版本</li></ul></li><li><strong>只有桶所有者（root account）可以启用&#x2F;禁用MFA-Delete</strong></li><li>MFA-Delete目前只能使用CLI启用</li><li><strong>注意：默认加密之前会评估Bucket策略</strong></li></ul><h3 id="跨域资源共享（CORS）"><a href="#跨域资源共享（CORS）" class="headerlink" title="跨域资源共享（CORS）"></a><strong>跨域资源共享（CORS）</strong></h3><blockquote><p>（Cross-Origin Resource Sharing）</p></blockquote><p>用于处理跨域资源共享。</p><p>在Web开发中，当您的网页或Web应用程序在一个域名下加载资源（例如图片、字体、脚本等），然后尝试从另一个域名进行访问时，就会发生跨域请求。默认情况下，浏览器执行跨域请求时会阻止访问，并产生CORS错误。</p><p>为了允许其他域名下的网页或应用程序访问S3存储桶中的资源，您可以配置S3 CORS规则。CORS规则告诉S3允许哪些域名下的请求来访问S3资源，并在响应中附加适当的CORS头部信息，以允许浏览器处理跨域请求。</p><p>CORS规则通常包含以下信息：</p><ol><li>允许访问的来源（Origin）：指定允许访问S3资源的域名或URL，可以是单个域名、多个域名，或者使用通配符进行匹配。</li><li>允许的HTTP方法：指定允许的HTTP方法（例如GET、PUT、POST等），用于执行跨域请求。</li><li>允许的自定义头部：指定允许浏览器在跨域请求中包含的自定义头部信息。</li><li>允许的暴露头部：指定在响应中暴露给浏览器的自定义头部信息。</li></ol><p>配置S3 CORS规则可以确保其他域名下的网页或应用程序能够正常访问和加载S3存储桶中的资源，从而实现跨域资源共享。</p><h3 id="事件通知和监控"><a href="#事件通知和监控" class="headerlink" title="事件通知和监控"></a><strong>事件通知和监控</strong></h3><h4 id="S3-event-notification事件通知"><a href="#S3-event-notification事件通知" class="headerlink" title="S3 event notification事件通知"></a><strong>S3 event notification事件通知</strong></h4><p>S3的Event Notification功能允许您对存储桶中的对象操作事件进行监视，并在事件发生时自动触发相应的通知动作。这些事件可以包括对象的创建、删除、还原等。</p><ul><li>S3event notification<ul><li>当事件发生时，发送通知到<strong>SQS、SNS、Lambda或Amazon EventBridge</strong></li><li>Amazon EventBridge提供了<ul><li>使用JSON规则（元数据、对象大小、名称）的高级过滤选项</li><li>多个目的地-例如Step Functions，Kinesis Streams&#x2F;Firehose</li><li>EventBridge功能-归档、重放事件和可靠的传递</li></ul></li><li>可以进行对象名称过滤（例如*.jpg）</li><li>创建尽可能多的”S3事件”</li><li>通常只需要几秒钟，但可能需要1分钟或更长时间</li></ul></li></ul><ol><li><strong>目标（Destination）</strong>：事件发生时，您可以选择将通知发送到一个或多个目标，包括：<ul><li>S3存储桶</li><li>SNS主题（Simple Notification Service）</li><li>SQS队列（Simple Queue Service）</li><li>Lambda函数</li><li>其他支持的AWS服务</li></ul></li></ol><h3 id="S3-Glacier"><a href="#S3-Glacier" class="headerlink" title="S3 Glacier"></a>S3 <strong>Glacier</strong></h3><p><strong>Amazon  S3 Glacier（S3）是一项安全持久的服务，适用于低成本的数据存档和长期备份。</strong></p><ol><li><strong>Glacier: 数据不可变，创建存档后便无法对其进行更新</strong></li></ol><aside>🧊 **S3 Glacier Instant Retrieval**<p>– 用于归档很少访问的、需要毫秒检索的数据。</p></aside><aside>🧊 **S3 Glacier Flexible Retrieval**<p>-用于可能需要在几分钟内检索其部分数据的归档。使用加速检索只需 1-5 分钟即可访问 数据。您还可以在最多 5-12 小时内申请免费批量检索。</p></aside><aside>🧊 **S3 Glacier Deep Archive**<p>– 用于归档很少需要访问的数据。存储的数据的默认检索时间为 12 小时。</p></aside>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
            <tag> 存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-03【ELB】</title>
      <link href="/2023/08/03/AWS-03%E3%80%90ELB%E3%80%91/"/>
      <url>/2023/08/03/AWS-03%E3%80%90ELB%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="ELB-Elastic-Load-Balancing"><a href="#ELB-Elastic-Load-Balancing" class="headerlink" title="ELB- Elastic Load Balancing"></a>ELB- <strong>Elastic Load Balancing</strong></h2><p><img src="/images/Untitled%2010.png" alt="Untitled"></p><h3 id="ELB类型"><a href="#ELB类型" class="headerlink" title="ELB类型"></a>ELB类型</h3><h4 id="CLB-Classic-Load-Balancer"><a href="#CLB-Classic-Load-Balancer" class="headerlink" title="CLB-Classic Load Balancer"></a><strong>CLB-Classic Load Balancer</strong></h4><p>优势：价格便宜，容易上手劣势：效果没有NLB&#x2F;ALB好</p><p><img src="https://img2022.cnblogs.com/blog/2122768/202204/2122768-20220417095016651-1564828897.png" alt="https:&#x2F;&#x2F;img2022.cnblogs.com&#x2F;blog&#x2F;2122768&#x2F;202204&#x2F;2122768-20220417095016651-1564828897.png"></p><h4 id="ALB-Application-Load-Balancer"><a href="#ALB-Application-Load-Balancer" class="headerlink" title="ALB-Application Load Balancer"></a><strong>ALB-Application Load Balancer</strong></h4><ul><li><p>ALB非常适用于微服务和基于容器的应用程序（例如：Docker和Amazon ECS）</p></li><li><p>具有端口映射功能，可重定向到ECS中的动态端口</p></li><li><p>优势：支持基于Host和Path的转发；支持粘性会话；性能比CLB好；支持按比例的流量转发；可编辑安全组</p></li><li><p>负载均衡算法：默认算法为轮询算法,还可以使用<strong>最少未完成请求算法</strong></p><p>  最少未完成请求”算法，也称为“Least Outstanding Requests”算法。</p><p>  当一个新请求到达负载均衡器时，它会将新请求分发给当前负载最轻的服务器，以最大程度地平衡负载，从而避免某些服务器过载，而其他服务器却处于空闲状态。</p></li></ul><h5 id="good-to-know"><a href="#good-to-know" class="headerlink" title="good to know:"></a>good to know:</h5><ul><li>固定Fixed hostname (xxx.region.elb.amazonaws.com)</li><li>The application servers don’t see the IP of the client directly</li><li>The true IP of the client is inserted in the header <strong>X-Forwarded-For</strong> 请求标头可自动添加并帮助您识别客户端的 IP 地址</li><li>We can also get Port<ul><li>X-Forwarded-Port 请求标头可帮助您识别客户端与您的负载均衡器连接时所用的目标端口)</li><li>(X-Forwarded-Proto 请求标头可帮助您识别客户端与您的负载均衡器连接时所用的协议 (HTTP 或 HTTPS))</li></ul></li></ul><p><img src="https://img2022.cnblogs.com/blog/2122768/202204/2122768-20220417095141938-1484209070.png" alt="https:&#x2F;&#x2F;img2022.cnblogs.com&#x2F;blog&#x2F;2122768&#x2F;202204&#x2F;2122768-20220417095141938-1484209070.png"></p><h4 id="NLB-Network-Load-Balancer"><a href="#NLB-Network-Load-Balancer" class="headerlink" title="NLB-Network Load Balancer"></a><strong>NLB-Network Load Balancer</strong></h4><ul><li>优势：性能最好，每秒支持百万次请求，不需要预热（ALB和CLB流量大的话需要预热扩充负债均衡服务节点）；</li><li><strong>NLB的ip地址不会改变</strong>（CLB和ALB会随着时间改变，另外<strong>NLB可以分配固定弹性ip，ALB不能</strong>）</li><li><strong>无状态</strong>：NLB是无状态的，不会将请求粘滞在特定的后端实例上，适用于无状态应用。</li><li><strong>NLB has one static IP per AZ, and supports assigning Elastic IP</strong> (helpful for whitelisting specific IP)</li><li>NLB are used for extreme performance, TCP or UDP traffic</li><li><strong>Target Groups:</strong><ul><li>EC2 instances</li><li>IP Addresses – must be private IPs</li><li>Application Load Balancer</li></ul></li></ul><p><img src="https://img2022.cnblogs.com/blog/2122768/202204/2122768-20220417100514118-903354844.png" alt="https:&#x2F;&#x2F;img2022.cnblogs.com&#x2F;blog&#x2F;2122768&#x2F;202204&#x2F;2122768-20220417100514118-903354844.png"></p><h4 id="GWLB-Gateway-Load-Balancer"><a href="#GWLB-Gateway-Load-Balancer" class="headerlink" title="GWLB-Gateway Load Balancer"></a><strong>GWLB-Gateway Load Balancer</strong></h4><p>用于路由流量到多个目标（例如，虚拟机、容器、EC2 实例）以提高可用性和扩展性。GWLB 主要用于处理流量，例如 VPN、NAT（网络地址转换）、防火墙、代理和其他网络服务。以下是 Gateway Load</p><p>GWLB 是专为处理网络层流量而设计的，而不是应用层协议。它主要用于处理传输层的流量，例如 TCP 和 UDP。</p><p>典型的用途包括在 AWS 中设置网络架构，以便处理传输层的网络流量，如 VPN 连接、NAT 网关、防火墙、代理等。 GWLB 可以帮助实现高可用性和可扩展性，以满足网络流量的需求。</p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a><strong>对比</strong></h4><table><thead><tr><th><strong>特性</strong></th><th><strong>CLB</strong></th><th><strong>ALB</strong></th><th><strong>NLB</strong></th><th><strong>GWLB</strong></th></tr></thead><tbody><tr><td>负载均衡类型</td><td>传输层（TCP）和应用层（HTTP&#x2F;HTTPS）</td><td>应用层（HTTP&#x2F;HTTPS）</td><td>传输层（TCP&#x2F;UDP）</td><td>传输层（TCP&#x2F;UDP）</td></tr><tr><td>支持WebSocket和HTTP&#x2F;2</td><td>不支持</td><td>支持</td><td>不支持</td><td>支持</td></tr><tr><td><strong>layer7-redirect</strong></td><td>√</td><td>√</td><td>×</td><td>×</td></tr><tr><td>状态类型</td><td>stateful</td><td>stateful</td><td>stateless</td><td></td></tr><tr><td>支持容器化服务</td><td>不支持</td><td>支持</td><td>不支持</td><td>不支持</td></tr><tr><td>请求路由</td><td>基于传统标签或路径</td><td>基于多个标签、路径和主机</td><td>基于端口和规则</td><td>基于多个标签、路径和主机</td></tr><tr><td>健康检查</td><td>TCP&#x2F;HTTP&#x2F;HTTPS</td><td>HTTP&#x2F;HTTPS</td><td>TCP&#x2F;UDP&#x2F;HTTP&#x2F;HTTPS</td><td>TCP&#x2F;UDP&#x2F;HTTP&#x2F;HTTPS</td></tr><tr><td>多个Target Group支持</td><td>不支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>支持IPv6</td><td>不支持</td><td>部分支持</td><td>支持</td><td>支持</td></tr><tr><td>用途</td><td>传统应用和服务的负载均衡</td><td>现代应用，<strong>microservice微服务</strong>的负载均衡</td><td>处理高流量和低延迟应用的负载均衡</td><td>使用NAT实例转发流量到私有子网和VPN设备的负载均衡</td></tr></tbody></table><h5 id="注："><a href="#注：" class="headerlink" title="注："></a><strong>注：</strong></h5><ol><li>WebSocket是一种支持双向通信的网络协议，它允许在单个TCP连接上进行全双工通信。WebSocket通常用于实现实时的双向通信，如在线聊天应用、实时游戏等。</li><li>HTTP&#x2F;2是HTTP协议的新版本，它在HTTP&#x2F;1.1的基础上进行了改进，提供了更高的性能和效率。可以加速网页加载并减少网络延迟。</li><li>ALB和NLB选择和区别当客户的业务基于HTTP&#x2F;HTTPS&#x2F;Websocket时候，优先考虑使用ALB。<strong>NLB可以处理7层的流量，但NLB不解析7层的协议</strong>，不会对协议进行处理。如果选择了ALB，则处理不了4层的流量，主要取决于选择的负载均衡器类型。</li></ol><h3 id="Sticky-Sessions-Session-Affinity-粘性会话、会话保持"><a href="#Sticky-Sessions-Session-Affinity-粘性会话、会话保持" class="headerlink" title="Sticky Sessions (Session Affinity)-粘性会话、会话保持"></a><strong>Sticky Sessions (Session Affinity)-粘性会话、会话保持</strong></h3><p>确保在会话期间将来自用户的所有请求发送到相同的实例中。这通常通过在用户的浏览器中设置一个特定的 Cookie 来实现。</p><ul><li>可以通过实现粘性会话，确保同一客户端始终被重定向到负载均衡器后面的同一实例。</li><li>这适用于经典负载均衡器和应用程序负载均衡器。</li><li>用于粘性会话的”cookie”具有您可控制的过期日期。</li><li>使用案例：确保用户不会丢失其会话数据。</li><li>启用粘性会话可能会导致后端 EC2 实例之间的负载不均衡。</li></ul><h3 id="Cookie-类型"><a href="#Cookie-类型" class="headerlink" title="Cookie 类型"></a><strong>Cookie 类型</strong></h3><ul><li>1.<strong>Application-based Cookies</strong><ul><li>自定义 Cookie<ul><li>由目标生成</li><li>这些 Cookie 是由负载均衡器的目标（即后端服务器实例）生成的。</li><li>每个目标组（Target Group）可以定义一个自定义的 Cookie 名称，以便满足应用程序的需求。</li><li>不要使用 <strong>AWSALB</strong>、<strong>AWSALBAPP</strong> 或 <strong>AWSALBTG</strong>（这些由 ELB 保留使用）</li></ul></li><li>应用程序 Cookie<ul><li>由负载均衡器生成</li><li>Cookie 名称为 <strong>AWSALBAPP</strong></li></ul></li></ul></li><li>2.<strong>持续时间Duration-based Cookies</strong></li></ul><h3 id="Cross-Zone-Balancing"><a href="#Cross-Zone-Balancing" class="headerlink" title="Cross-Zone Balancing"></a><strong>Cross-Zone Balancing</strong></h3><p>Cross-Zone Balancing允许ASG在跨越多个AZ时，尽量均匀地分布实例，以确保各个可用区的负载相对平衡。</p><ul><li><strong>Application Load Balancer</strong><ul><li><strong>Always on</strong> (can’t be disabled)</li><li>No charges for inter AZ data</li></ul></li><li><strong>Network Load Balancer</strong><ul><li>Disabled by default</li><li>You pay charges ($) for inter AZ data if enabled</li></ul></li><li><strong>Classic Load Balancer</strong><ul><li>Disabled by default</li><li>No charges for inter AZ data if enabled</li></ul></li></ul><h3 id="SSL-–-client到LB的加密"><a href="#SSL-–-client到LB的加密" class="headerlink" title="SSL – client到LB的加密"></a><strong>SSL – client到LB的加密</strong></h3><p>a SSL certificate allows traffic between your <strong>clients</strong> and your <strong>load balancer</strong> to be encrypted in <em><strong>transit</strong></em></p><h3 id="SNI-Server-Name-Indication"><a href="#SNI-Server-Name-Indication" class="headerlink" title="SNI- Server Name Indication"></a><strong>SNI</strong>- <strong>Server Name Indication</strong></h3><p>SNI解决了将<strong>多个SSL证书加载到一个Web服务器</strong>的问题（用于提供多个网站）。</p><ul><li>它是一个“较新”的协议，要求客户端在初始SSL握手中<strong>指示</strong>目标服务器的主机名。</li><li>然后服务器将查找正确的证书或返回默认证书。</li><li>SNI仅适用于ALB和NLB（新一代负载均衡器），以及CloudFront。</li><li>不适用于CLB（旧一代负载均衡器）</li></ul><h3 id="connection-draining-deregistration-delay"><a href="#connection-draining-deregistration-delay" class="headerlink" title="connection draining &amp; deregistration delay"></a><strong>connection draining &amp; deregistration delay</strong></h3><p>用于确保在服务节点从负载均衡器中移除时，已有的连接能够平滑地处理完毕而不会立即中断。</p><ol start="4"><li>CLB———Connection Draining（连接逐出）：当需要从负载均衡器上移除一个服务节点时，connection draining 是一种机制，用于逐渐关闭正在进行的连接。负载均衡器不再将新的连接分发给该节点，而是允许已有的连接完成其请求，然后逐渐关闭连接。这样可以避免中断正在进行的操作或导致数据丢失。</li><li>ALB &amp; NLB———Deregistration Delay（注销延迟）：deregistration delay 是指在将一个服务节点从负载均衡器中注销（或移除）之前，等待一段时间的延迟。在此期间，负载均衡器仍然将一部分流量转发到该节点，以确保现有的连接有足够的时间完成，并且新的连接不会立即被拒绝。这个延迟时间允许连接逐渐被关闭，确保服务平稳过渡。</li></ol><h3 id="VCPU（虚拟-CPU）"><a href="#VCPU（虚拟-CPU）" class="headerlink" title="VCPU（虚拟 CPU）"></a>VCPU（虚拟 CPU）</h3><p>虚拟机实例中使用的概念，用于模拟物理计算机的处理能力。在AWS中，当您创建虚拟机实例（instance）时，可以选择分配给该实例的VCPU数量，以满足您的计算需求。虚拟机实例是在AWS云中运行的虚拟计算资源，可以运行操作系统和应用程序。</p><p>在虚拟化环境中，<em>物理服务器上的CPU被划分为多个虚拟CPU（vCPU）以支持并发运行</em>的虚拟机实例。</p><p><strong>一个可用区包含多个实例，每个实例有一个或多个卷附加，实例的计算能力由分配给它的VCPU决定。</strong></p>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-02【EC2】</title>
      <link href="/2023/08/02/AWS-02%E3%80%90EC2%E3%80%91/"/>
      <url>/2023/08/02/AWS-02%E3%80%90EC2%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a>EC2</h2><h3 id="elastic-compute-cloud，弹性计算云"><a href="#elastic-compute-cloud，弹性计算云" class="headerlink" title="elastic compute cloud，弹性计算云"></a>elastic compute cloud，弹性计算云</h3><p><img src="/images/3.png" alt="EC2"></p><p>EC2的本质是运行在云中虚拟机上的web服务。EC2 instance的本质是云上的虚拟机</p><p>Amazon EC2 提供以下功能：</p><ul><li>instance-虚拟计算环境</li><li>AMI-实例的预配置模板,也称为 *Amazon 系统映像</li><li><em>实例类型</em>:实例 CPU、内存、存储和网络容量的多种配置</li><li>使用<em>密钥对</em>的实例的安全登录信息（AWS 存储公有密钥，您在安全位置存储私有密钥）</li><li><em>实例存储卷</em>临时</li><li><em>Amazon EBS 卷</em></li><li>region AZ</li><li>防火墙，让您可以指定协议、端口，以及能够使用<em>安全组</em>到达您的实例的源 IP 范围</li><li>用于动态云计算的静态 IPv4 地址，称为<em>弹性 IP 地址</em></li><li>元数据，也称为<em>标签</em>，您可以创建元数据并分配给您的 Amazon EC2 资源</li><li>您可以创建的虚拟网络，这些网络与其余 AWS 云在逻辑上隔离，并且您可以选择连接到您自己的网络，也称为 <em>Virtual Private Cloud</em> (VPC)。</li></ul><h3 id="EC2购买选项"><a href="#EC2购买选项" class="headerlink" title="EC2购买选项"></a>EC2购买选项</h3><ol><li><p><strong>按需实例 (On-Demand Instances):</strong></p><ul><li><strong>特点：</strong> 按需实例没有长期合同，灵活性高，您只需支付您实际使用的计算能力，没有预付费或最低使用期要求。</li><li><strong>适用场景：</strong> 适用于临时工作负载、<strong>不可预测</strong>的工作负载、<strong>短期</strong>任务、初创企业或项目，以及需要快速扩展和缩减的情况。</li></ul></li><li><p><strong>预留实例 (Reserved Instances):</strong></p><ul><li><strong>特点：</strong> 预留实例需要事先支付部分费用，以换取更高的折扣，并在长期合同期间使用这些实例。分为标准、可转换、分摊和区域性预留实例。</li><li><strong>适用场景：</strong> 长期运行的<strong>稳定</strong>工作负载，具有可预测的使用需求，希望获得更大折扣的用户。</li></ul><blockquote><p>分类</p><ol><li><strong>标准预留实例（Standard Reserved Instances）：</strong><ul><li><em>指定的region 、instance family和大小</em>,不允许灵活更改实例类型</li><li>这些预留实例适用于长期稳定的工作负载。</li></ul></li><li><strong>可转换预留实例（Convertible Reserved Instances）：</strong><ul><li>可转换预留实例允许您在合同期内<strong>更改实例家族</strong>、大小和操作系统。这提供了更大的灵活性，适用于需要更改工作负载特性的情况。</li><li>虽然价格折扣通常较低，但您可以在长期合同内更改实例属性。</li></ul></li><li><strong>分摊预留实例（Scheduled Reserved Instances）：</strong><ul><li>在特定的时间窗口内使用实例</li></ul></li><li><strong>区域预留实例（Regional Reserved Instances）：</strong><ul><li>可在指定region内的多个AZ中使用</li><li>不允许更改实例家族（Instance Family）。</li></ul></li></ol></blockquote></li><li><p><strong>Spot 实例:</strong></p><ul><li><strong>特点：</strong> Spot 实例基于市场供求定价，价格通常低于按需实例，但实例可能会在供求波动时被终止。</li><li><strong>适用场景：</strong> 适用于可以容忍实例终止的工作负载，<strong>shot-time短期</strong>计算、批处理、大规模数据处理、测试和开发等。</li></ul></li><li><p><strong>Dedicated Hosts:</strong></p><ul><li><strong>特点：</strong> Dedicated Hosts 提供物理服务器，可以在上面运行 EC2 实例。适用于需要控制硬件分配和软件许可方面的情况。</li><li><strong>适用场景：</strong> 需要满足软件许可要求、安全性、合规性等需要的应用程序，以及需要在物理硬件上运行的特定工作负载。</li></ul></li></ol><h4 id="1-On-Demand-按需"><a href="#1-On-Demand-按需" class="headerlink" title="1. On Demand 按需"></a>1. On Demand 按需</h4><pre><code>recommended for **short-term** and **un-interrupted workloads**按照小时计费，根据使用时间的多少进行付费。 缺点：贵</code></pre><h4 id="2-Reserved-Instance-预留"><a href="#2-Reserved-Instance-预留" class="headerlink" title="2. Reserved Instance 预留"></a>2. Reserved Instance 预留</h4><pre><code>recommended for **steady-state usage applications**</code></pre><blockquote><p>使用类型:</p><p>可转换预留实例（Convertible Reserved Instance）</p><ul><li>实例类型转换</li><li>成本调整</li></ul><p>计划性预留实例（Scheduled Reserved Instance )</p><ul><li>预定灵活性：您可以指定特定的时间段，预订实例以满足您的计划性工作负载需求。例如，您可以预订每周的某个时间段或每天的特定时间段内的实例。</li><li>成本控制：通过计划性预留实例，您可以在计划性工作负载发生时，以更低的成本运行实例。</li></ul></blockquote><h4 id="3-Spot-Instance-竞价"><a href="#3-Spot-Instance-竞价" class="headerlink" title="3. Spot Instance 竞价"></a>3. Spot Instance 竞价</h4><p>请求未使用的 EC2 实例，这可能会显著降低您的 Amazon EC2 成本。</p><p>useful for workloads that are resilient to failure对于能够容忍故障的工作负载非常有用。</p><ul><li>batch jobs</li><li>data analysis</li><li>any distributed workloads</li></ul><p><strong>NOT suitable for critical job or database</strong></p><pre><code>竞价实例，当出价不够会被回收。 缺点：不稳定，但适合大规模集群计算</code></pre><h4 id="4-Dedicated-Hosts-专用主机"><a href="#4-Dedicated-Hosts-专用主机" class="headerlink" title="4. Dedicated Hosts 专用主机"></a>4. Dedicated Hosts 专用主机</h4><ul><li><p><strong>physical server</strong> with EC2 instance capacity</p><p>  物理服务器：EC2 Dedicated Hosts提供了一个完全专用的物理服务器，该服务器是由AWS托管的，专门为您的EC2实例提供。这意味着您的实例将独占整个物理服务器的计算资源，与其他用户的实例完全隔离。</p></li><li><p>help you address your <strong>compliance requirements</strong></p><p>  符合合规性要求：EC2 Dedicated Hosts可以帮助您满足合规性要求，例如在特定行业或法规中对计算资源的隔离性和可见性的要求。通过使用专用主机，您可以获得更高的隔离性和控制，以确保您的工作负载满足安全和合规性标准。</p></li><li><p>reduce cost by allowing you to <strong>use your existing server-bound software licenses</strong></p><p>  使用现有服务器绑定软件许可证：专用主机允许您使用您已拥有的、与特定物理服务器绑定的软件许可证。这意味着您可以将受限制的许可证软件（如特定操作系统、数据库或应用程序）部署到专用主机上，以充分利用您已经购买的软件许可证</p></li></ul><h4 id="5-Dedicate-instance"><a href="#5-Dedicate-instance" class="headerlink" title="5. Dedicate instance"></a>5. Dedicate instance</h4><h3 id="实例存储选项"><a href="#实例存储选项" class="headerlink" title="实例存储选项"></a>实例存储选项</h3><p>EBS 和 Instance Store</p><p> <strong>root volume &amp; EBS volume  &amp; instance store</strong></p><p>root volume是EC2实例的主要存储卷，通常用于操作系统和系统文件。</p><p>它是<strong>EC2实例的一部分</strong>，与实例的生命周期绑定。</p><p>EBS volume是一种可附加attach到EC2实例的虚拟硬盘</p><p><strong>root volume是instance的一部分，可以是instance store或EBS volume。</strong></p><ul><li>如果根卷是实例存储，直接连接到实例主机。它提供了高性能和低延迟的存储，但是它是<strong>临时性</strong>的，</li><li>如果根卷是EBS卷，它是一种持久性存储，数据会被保留，即使实例停止或终止</li></ul><h3 id="AWS-Savings-Plans"><a href="#AWS-Savings-Plans" class="headerlink" title="AWS Savings Plans"></a>AWS Savings Plans</h3><p><img src="/images/Untitled%204.png" alt="Untitled"></p><p>一种用于降低计算资源成本的计划，它提供了更灵活的折扣方式，适用于不同类型的计算资源和使用模式。</p><table><thead><tr><th>特征</th><th>EC2 Savings Plans</th><th>AWS Compute Savings Plans</th></tr></thead><tbody><tr><td>适用范围</td><td>EC2 实例</td><td>EC2 实例和 Fargate 任务</td></tr><tr><td>适用性灵活性</td><td>更大的实例选择</td><td>限于 EC2 实例</td></tr><tr><td>跨区域使用</td><td>可以在多个 AWS 区域使用</td><td>限于一个 AWS 区域</td></tr><tr><td></td><td><strong>在特定region内使用指定的instance family</strong></td><td>适用于您的 Fargate 和 Lambda 使用。</td></tr></tbody></table><h3 id="Compute-Savings-Plans"><a href="#Compute-Savings-Plans" class="headerlink" title="Compute Savings Plans"></a>Compute Savings Plans</h3><p>提供最大的灵活性和高达**66%**的按需价格折扣。这些计划会自动适用于您的 EC2 实例使用，不论实例类型大小区域、操作系统</p><p>它们还适用于您的 Fargate 和 Lambda 使用。</p><h3 id="EC2-instance-Savings-Plans"><a href="#EC2-instance-Savings-Plans" class="headerlink" title="EC2 instance Savings Plans"></a>EC2 instance Savings Plans</h3><p><strong>在特定region内使用指定的instance family</strong></p><p>可提供高达**72%**的按需折扣，以换取在选定的 AWS 区域（例如弗吉尼亚州的 M5）中对特定实例系列的承诺。这些计划会自动适用于使用情况，不论大小（例如 m5.xlarge、m5.2xlarge 等）、操作系统（例如 Windows、Linux 等）和租户（Host、Dedicated、Default）是否在指定的系列内。</p><p>通过 EC2 实例节省计划，您可以在实例系列内更改实例大小（例如从 c5.xlarge 到 c5.2xlarge）或操作系统（例如从 Windows 到 Linux），或从 Dedicated 租户切换到 Default，并继续获得 EC2 实例节省计划提供的折扣率。</p><h3 id="SageMaker-Savings-Plans"><a href="#SageMaker-Savings-Plans" class="headerlink" title="SageMaker Savings Plans"></a>SageMaker Savings Plans</h3><p>可提供高达64%的按需折扣。这些计划会自动适用于您的 SageMaker 实例使用，不论实例系列（例如 ml.m5、ml.c5 等）、实例大小（例如 ml.c5.large、ml.c5.xlarge 等）、区域（例如 us-east-1、us-east-2 等）或组件（例如 Notebook、Training 等）。使用 SageMaker 节省计划，您可以随时将工作负载从 ml.c5 切换到 ml.m5，将使用情况从 Europe（爱尔兰）切换到 Europe（伦敦），或将使用情况从 Training 切换到 Inference，并继续获得好处。</p><h3 id="EC2-Hibernate-休眠"><a href="#EC2-Hibernate-休眠" class="headerlink" title="EC2 Hibernate -休眠"></a>EC2 <strong>Hibernate -休眠</strong></h3><p><img src="/images/Untitled%205.png" alt="Untitled"></p><p>hibernate会将实例内存 (RAM) 中的内容保存到Amazon EBS root volume。</p><blockquote><p><strong>Use cases:</strong></p><p>long-running processing</p><p>saving the RAM state</p><p>services that take time to initialize</p></blockquote><h3 id="EC2-Hibernate-–-Good-to-know"><a href="#EC2-Hibernate-–-Good-to-know" class="headerlink" title="EC2 Hibernate – Good to know"></a><strong>EC2 Hibernate – Good to know</strong></h3><ul><li><strong>Supported instance families</strong> - C3, C4, C5, M3, M4, M5, R3, R4, and R5</li><li><strong>Instance RAM size</strong> - must be less than 150 GB</li><li><strong>Instance size</strong> - not supported for bare metal instances</li><li><strong>AMI</strong>: Amazon Linux 2, Linux AMI, Ubuntu &amp; Windows…</li><li><strong>Root Volume</strong>: must be EBS, encrypted, not instance store, and large</li><li>Available for On-Demand and Reserved Instances</li><li>An instance cannot be hibernated more than 60 days</li></ul><h3 id="EC2-nitro"><a href="#EC2-nitro" class="headerlink" title="EC2 nitro"></a>EC2 nitro</h3><p>Nitro技术是Amazon Web Services（AWS）用于提供<strong>高性能、高可靠性</strong>和<strong>安全性</strong>的云计算服务的一项技术。</p><p>Nitro系统是基于Nitro技术构建的AWS的硬件和软件基础设施。它提供了直接访问计算、存储和网络资源的能力，同时隔离虚拟化实例，提供更好的性能和安全性。</p><p>Nitro技术是指AWS用于提供云计算服务的一项技术，而Nitro系统则是该技术的实际实施和基础设施。</p><h3 id="placement-groups-置放群组"><a href="#placement-groups-置放群组" class="headerlink" title="placement groups 置放群组"></a>placement groups <strong>置放群组</strong></h3><p>EC2 服务会通过一些策略<strong>将instance置放在硬件上</strong>，以便减少故障，满足负载需求。</p><ul><li><p><strong>cluster</strong> <strong>集群</strong> :将一个AZ中靠近的实例打包在一起。通过使用该策略，工作负载可以实现所需的低延迟网络性能，以满足高性能计算（HPC）应用程序.</p><ul><li><p>high performance but high risk高性能高风险</p></li><li><p>使用案例**:**</p><p>  <strong>big data</strong> job needs to complete fast</p><p>  application that needs extremely <strong>low latency</strong> and <strong>high network throughput</strong></p></li></ul><p>  <img src="/images/Untitled%206.png" alt="Untitled">  </p></li><li><p><strong>partiton 分区</strong> – 将实例分布在不同的逻辑分区上，以便一个分区中的实例组不会与不同分区中的实例组使用相同的基础硬件。该策略通常为大型分布式和重复的工作负载所使用，例如，Hadoop、Cassandra 和 Kafka。</p><p>  使用案例：</p><p>  HDFS, HBase, Cassandra, Kafka</p><p>  <img src="/images/Untitled%207.png" alt="Untitled"></p></li><li><p><strong>Spread 分布</strong> – 将实例分别置放在不同硬件上以减少相关的故障。</p><p>  机架分布置放群组可以跨越同一区域中的多个可用区。对于机架分布置放群组，每个群组在每个可用区中最多可以运行<strong>七个</strong>实例。</p><p>  应用案例：</p><ul><li>application that needs to maximize <strong>high availability</strong></li><li>重要关键应用，必须隔离失败实例</li></ul><p>  <img src="/images/Untitled%208.png" alt="Untitled"></p></li></ul><h3 id="scaling-strategies-扩展策略"><a href="#scaling-strategies-扩展策略" class="headerlink" title="scaling strategies-扩展策略"></a>scaling strategies-扩展策略</h3><p>根据资源的需求自动调整计算实例的数量</p><ol><li><strong>Target Tracking 扩展策略：</strong><ul><li>使用 CloudWatch 指标来跟踪资源的使用情况，如 CPU 使用率、网络流量等。</li><li>定义目标值，即您希望保持的指标水平。</li><li>系统将自动调整实例数量，以使跟踪的指标接近目标值。</li></ul></li><li><strong>Simple 扩展策略：</strong><ul><li>定义一个或多个阈值，用于触发扩展或缩减操作。</li><li>当某个指标达到或超过阈值时，系统将执行相应的自动扩展操作，例如增加实例数量。</li><li>当指标低于阈值时，系统将执行缩减操作，例如减少实例数量。</li></ul></li><li><strong>Step Scaling 扩展策略：</strong><ul><li>类似于 Simple 扩展策略，但您可以定义多个阶段，每个阶段都有一个阈值和扩展&#x2F;缩减操作。</li><li>这允许您在不同的资源使用水平上采取不同的扩展步骤。</li></ul></li></ol><h3 id="Auto-Scaling"><a href="#Auto-Scaling" class="headerlink" title="Auto Scaling"></a>Auto Scaling</h3><p><img src="/images/Untitled%209.png" alt="Untitled"></p><h4 id="EC2-auto-scaling"><a href="#EC2-auto-scaling" class="headerlink" title="EC2 auto scaling"></a>EC2 auto scaling</h4><p>Amazon EC2 Auto Scaling 帮助您确保具有正确数量的 Amazon EC2 实例以处理应用程序负载。<br><strong>ASG</strong>- Auto Scaling group</p><p>ASG（Auto Scaling Group）是一种用于自动扩展和管理云资源的服务，它能根据需求自动<strong>增加scale out</strong>或<strong>减少scale in</strong>实例数量，以适应应用程序的负载变化。</p><h5 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h5><p>Auto Scaling Group 可以实现以下功能：</p><ol start="4"><li><strong>自动扩展</strong>：ASG 可以根据负载情况自动增加或减少 EC2 实例的数量。当负载增加时，ASG 会自动启动新的 EC2 实例，以满足需求。当负载减少时，ASG 会自动终止多余的 EC2 实例，以节省成本。</li><li><strong>健康检查</strong>：ASG 可以定期检查 EC2 实例的健康状态，以确保它们正常工作。如果某个实例出现问题，ASG 可以自动替换该实例，以保持应用程序的可用性。</li><li><strong>负载均衡</strong>：ASG 可以与负载均衡器（如ELB）结合使用，以分发流量到不同的 EC2 实例。这有助于提高应用程序的可用性和性能。</li><li><strong>手动扩展</strong>：除了自动扩展外，您还可以手动调整 ASG 中的实例数量，以满足临时的或非常大的负载。</li><li><strong>细粒度控制</strong>：ASG 可以配置以自定义的方式来满足应用程序的需求，如设置最小和最大实例数量、扩展策略、启动配置等。</li></ol><h5 id="ASG拓展类型"><a href="#ASG拓展类型" class="headerlink" title="ASG拓展类型"></a>ASG拓展类型</h5><h6 id="手动-munual-scaling"><a href="#手动-munual-scaling" class="headerlink" title="手动-munual scaling"></a>手动-munual scaling</h6><p>通过修改 Auto Scaling 组的最大容量、最小容量或所需容量的配置，然后Auto Scaling 管理创建或终止实例的流程匹配修改后的容量。</p><h6 id="定时-scheduled-actions"><a href="#定时-scheduled-actions" class="headerlink" title="定时-scheduled actions"></a>定时-scheduled actions</h6><p>定时扩展允许您在特定时间或日期执行扩展或缩减操作，无需依赖于实际负载情况。这对于已知的预期负载变化很有用，例如每天的业务高峰期。</p><p>例如周末不允许，不需要实例</p><h6 id="按需-动态-dynamic-scaling-policies"><a href="#按需-动态-dynamic-scaling-policies" class="headerlink" title="按需&#x2F;动态-dynamic scaling policies:"></a>按需&#x2F;动态-dynamic scaling policies:</h6><p>动态扩缩会根据流量的变化扩展自动扩缩组的容量。</p><ol start="9"><li><p><strong>Target Tracking scaling-目标跟踪</strong></p><p> 没有固定阈值</p><p> 据目标指标来动态调整实例数量</p><p> 根据Amazon CloudWatch 指标和目标值增加或减少组的当前容量。</p></li><li><p><strong>Simple Scaling（简单扩展）：</strong></p><p>基于固定的阈值进行扩展或缩减<br>通过单次扩缩调整来增加和减少组的当前容量，每次扩缩活动之间有一个<strong>冷却时间</strong>。</p><p>例如在负载高峰时增加实例数量，在负载下降时减少实例数量。</p></li><li><p><strong>Step Scaling（阶梯扩展）</strong></p><p>设置阶梯，每个阶梯都有一个与之关联的触发条件<br>通过一系列扩缩调整（也称<em>步进调整</em>）来增加和减少组的当前容量，具体调整因警报严重程度而异</p></li></ol><h6 id="预测-predictive-scaling-policies"><a href="#预测-predictive-scaling-policies" class="headerlink" title="预测-predictive scaling policies"></a>预测-predictive scaling policies</h6><p>预测式扩展非常适合以下情况：</p><ul><li>周期性流量，例如正常营业时间内的高资源利用率以及晚上和周末的低资源利用率</li><li>重复 on-and-off 的工作负载模式，例如批处理、测试或定期数据分析</li><li>初始化需要很长时间的应用程序，从而在向外扩展事件期间对应用程序性能造成明显的延迟影响</li></ul><h3 id="Cross-Zone-Balancing"><a href="#Cross-Zone-Balancing" class="headerlink" title="Cross-Zone Balancing"></a>Cross-Zone Balancing</h3><p>Cross-Zone Balancing允许ASG在跨越多个AZ时，尽量均匀地分布实例，以确保各个可用区的负载相对平衡。</p><ul><li><strong>Application Load Balancer</strong><ul><li><strong>Always on</strong> (can’t be disabled)</li><li>No charges for inter AZ data</li></ul></li><li><strong>Network Load Balancer</strong><ul><li>Disabled by default</li><li>You pay charges ($) for inter AZ data if enabled</li></ul></li><li><strong>Classic Load Balancer</strong><ul><li>Disabled by default</li><li>No charges for inter AZ data if enabled</li></ul></li></ul><h3 id="ASG默认终止策略ASG-Default-Termination-Policy（简化版本）："><a href="#ASG默认终止策略ASG-Default-Termination-Policy（简化版本）：" class="headerlink" title="ASG默认终止策略ASG Default Termination Policy（简化版本）："></a><strong>ASG默认终止策略ASG Default Termination Policy（简化版本）：</strong></h3><ol start="12"><li>查找具有最多实例的可用区（AZ）。</li><li>如果在该可用区有多个实例可供选择，则删除具有最旧启动配置的实例。</li></ol><ul><li><strong>ASG默认尝试在可用区之间平衡实例数量</strong></li></ul><h3 id="Lifecycle-Hooks"><a href="#Lifecycle-Hooks" class="headerlink" title="Lifecycle Hooks"></a><strong>Lifecycle Hooks</strong></h3><p>Lifecycle Hooks允许您执行自定义脚本或操作。这使您能够在实例处于特定状态时执行额外的任务，如在实例启动前进行初始化操作，或在实例终止前执行清理任务。</p><p>Lifecycle Hooks有两种类型：</p><ol start="14"><li><strong>Lifecycle Hook for Instance Launch (启动实例生命周期挂钩)：</strong> 当新实例被添加到ASG并处于“Pending”状态时触发。您可以在此时执行一些初始化任务或验证操作。只有在完成这些任务后，实例才会被标记为“InService”状态并接收流量。</li><li><strong>Lifecycle Hook for Instance Termination (终止实例生命周期挂钩)：</strong> 当实例即将被终止时触发。您可以在此时执行清理任务或将实例从其他服务中解除绑定，以确保安全地终止实例。</li></ol><ul><li>默认情况下，一旦在ASG中启动实例，它就处于“in service”状态。</li><li>您有能力在实例进入“已服务”状态之前执行额外的步骤（“pending”状态）。</li><li>您有能力在实例终止之前执行一些操作（“terminating”状态）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-01【云计算基础】</title>
      <link href="/2023/08/01/AWS-01%E3%80%90%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E3%80%91/"/>
      <url>/2023/08/01/AWS-01%E3%80%90%E4%BA%91%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="云计算基础"><a href="#云计算基础" class="headerlink" title="云计算基础"></a><strong>云计算基础</strong></h1><h2 id="云计算定义与特点："><a href="#云计算定义与特点：" class="headerlink" title="云计算定义与特点："></a><strong>云计算定义与特点</strong>：</h2><ul><li>云计算是一种基于互联网的计算模型，通过共享的计算资源，提供按需获取、快速交付和灵活扩展的计算服务。它将计算、存储、网络和其他相关技术资源提供给用户，使他们能够在不需拥有实际硬件设备和基础设施的情况下，通过网络访问和使用这些资源。</li></ul><h2 id="云计算服务模型："><a href="#云计算服务模型：" class="headerlink" title="云计算服务模型："></a><strong>云计算服务模型</strong>：</h2><ul><li>1.2.1 <strong>IaaS（基础设施即服务）</strong>：<ul><li>熟悉 IaaS 提供的基础设施层，如 Amazon EC2 实例，允许用户管理操作系统、应用程序等。</li></ul></li><li>1.2.2 <strong>PaaS（平台即服务）</strong>：<ul><li>详细了解 PaaS 模型，如 AWS Elastic Beanstalk，它提供托管的平台，简化应用程序的开发和部署。</li></ul></li><li>1.2.3 <strong>SaaS（软件即服务）</strong>：<ul><li>了解 SaaS，如 Amazon S3、Amazon RDS 等，提供现成的软件和服务。</li></ul></li></ul><h2 id="部署模型："><a href="#部署模型：" class="headerlink" title="部署模型："></a><strong>部署模型：</strong></h2><p>云计算的部署模型描述了云服务的基础设施在何处部署以及如何访问。主要有以下四种部署模型：</p><ol><li><strong>公共云：</strong> 公共云是对外提供服务的云计算基础设施，由云服务提供商管理和维护。多个用户可以共享这些资源，如 AWS、Azure、Google Cloud。</li><li><strong>私有云：</strong> 私有云是一种在企业内部或特定组织中部署的云计算基础设施。资源在受限的范围内使用，提供更严格的安全性和隐私控制。</li><li><strong>社区云：</strong> 社区云是为特定行业、垂直市场或社区组织提供的云计算基础设施，资源可以由多个组织共享。这种模型可以满足共同需求，同时保持一定程度的独立性。</li><li><strong>混合云：</strong> 混合云结合了公共云和私有云，允许数据和应用程序在不同环境之间迁移。这使得用户能够在公共云中扩展或备份私有云中的资源。</li></ol><h2 id="AWS"><a href="#AWS" class="headerlink" title="AWS"></a><strong>AWS</strong></h2><h3 id="Amazon-Web-Services"><a href="#Amazon-Web-Services" class="headerlink" title="Amazon Web Services"></a>Amazon Web Services</h3><p>是由亚马逊公司提供的云计算平台和服务。它为个人、企业和组织提供了一系列基于云技术的计算、存储、数据库、网络、分析、机器学习等服务。AWS 的目标是帮助用户以高<strong>效、灵活和经济高效的方式构建和管理各种应用程序，而无需担心传统硬件基础设施的维护和管理。</strong></p><p>AWS 提供的服务涵盖了广泛的领域，包括但不限于：</p><ol><li><strong>计算服务：</strong> 包括弹性虚拟服务器 EC2，Lambda 无服务器计算，Elastic Beanstalk 应用托管等。</li><li><strong>存储和数据库：</strong> 包括S3（Simple Storage Service）对象存储，EBS（Elastic Block Store）块存储，RDS（Relational Database Service）关系数据库，DynamoDB NoSQL 数据库等。</li><li><strong>网络和内容分发：</strong> 包括Virtual Private Cloud（VPC）虚拟网络，CloudFront内容分发网络，Route 53 域名系统等。</li><li><strong>分析和大数据：</strong> 包括Redshift 数据仓库，Athena 查询服务，EMR（Elastic MapReduce）大数据处理等。</li><li><strong>人工智能和机器学习：</strong> 包括SageMaker 机器学习平台，Rekognition 图像和视频分析，Lex 自然语言处理等。</li><li><strong>安全和身份管理：</strong> 包括IAM 身份和访问管理，Key Management Service（KMS）数据加密，WAF（Web Application Firewall）应用程序防火墙等。</li><li><strong>开发工具和集成：</strong> 包括CodeCommit 代码托管，CodeBuild 构建工具，CodeDeploy 部署工具，API Gateway 管理 API 等。</li><li><strong>物联网：</strong> 包括IoT Core 物联网核心，Greengrass 物联网设备本地运算等。</li></ol><p>AWS 为用户提供了按需使用、灵活扩展的计算资源，以及一系列强大的工具和服务，使用户能够根据业务需求进行快速创新和发展。作为全球领先的云计算服务提供商，AWS 在各种行业和规模的项目中广泛应用。</p><h1 id="AWS-全球基础设施"><a href="#AWS-全球基础设施" class="headerlink" title="AWS 全球基础设施"></a><strong>AWS 全球基础设施</strong></h1><h2 id="AZ-可用区"><a href="#AZ-可用区" class="headerlink" title="AZ-可用区"></a>AZ-可用区</h2><ul><li>Availability Zone</li><li>一个独立的数据中心或机房</li><li>AWS基础设施中的<strong>物理实际存在</strong>，代表独立的数据中心或机房，具有独立的电力、网络和故障隔离机制。用户可以利用可用区的设置来实现高可用性、容错和地理分布。</li><li>每个可用区被分配了唯一的标识符（例如：<strong>us-east-1a、us-east-1b</strong>），以区分不同的可用区。</li></ul><h2 id="Region-区域"><a href="#Region-区域" class="headerlink" title="Region-区域"></a>Region-区域</h2><ul><li>AWS区域是指AWS基础设施中的一个**物理地理区域，**具有自己的电力、网络和数据中心设施。</li><li>AWS全球基础设施由多个区域组成，每个区域可以包含多个可用区。</li></ul><h2 id="AWS-Edge-Locations-边缘位置"><a href="#AWS-Edge-Locations-边缘位置" class="headerlink" title="AWS Edge Locations-边缘位置"></a>AWS Edge Locations-边缘位置</h2><p>在全球多个城市和地区战略性地分布，以使内容更接近终端用户，从而减少延迟并提高内容传递的整体性能。</p><h2 id="AWS-Global-Accelerator"><a href="#AWS-Global-Accelerator" class="headerlink" title="AWS Global Accelerator"></a>AWS Global Accelerator</h2><ul><li><p>将用户的请求从全球各地路由到距离最近的可用源终端。</p></li><li><p>它通过使用全球分布的边缘位置（Edge Locations）和<em><strong>Anycast IP地址【任意播地址】</strong></em>，将用户的请求导向到距离最近的可用终端，从而实现更快的访问速度和更低的延迟。</p></li><li><p>Global Accelerator 非常适用于<strong>非 HTTP 情况</strong>，如游戏 (UDP)、物联网 (MQTT) 或 VoIP，</p><pre><code>          HTML</code></pre><p>  ​<br>  ​<br>  ​<br>  ​<br>  ​<br>  ​</p></li></ul><p>🐳 anycast IP-多个设备共享相同IP地址，数据包将传输到最近的设备​</p><pre><code>HTML</code></pre><p>​<br>​<br>​<br>​<br>​<br>​<br>➡️ <strong>Endpoint终端节点</strong>​</p><pre><code>HTML</code></pre><p>​<br>​<br>​<br>​<br>​<br>​<br>➡️ 终端节点是全局加速器将流量定向到的资源。<br>标准加速器的终端节点可以是NLB、ALB、EC2 实例或弹性 IP 地址。​</p><pre><code>HTML</code></pre><p>​<br>​<br>​<br>​<br>​<br>​<br>➡️ 对于每个端点，您可以配置权重，这些权重是可用于指定路由到每个端点的流量比例的数字。例如，这对于在区域内进行性能测试非常有用。​</p><ul><li>利用AWS内部网络将请求路由到您的应用程序</li><li>适用于Elastic IP、EC2实例、ALB、NLB、公共或私有资源</li><li>稳定的性能<ul><li><strong>智能路由选择最低延迟和failover快速区域故障转移</strong></li><li><strong>不会出现客户端缓存问题（因为IP不会改变）</strong></li><li>使用AWS内部网络传输数据</li></ul></li><li>健康检查<ul><li>全球加速器对您的应用程序进行健康检查</li><li>有助于使您的应用程序具备全球性（对于不健康的应用程序，<strong>故障转移时间小于1分钟）</strong></li><li>适用于灾难恢复（得益于健康检查功能）</li></ul></li><li>安全性<ul><li><em>只<strong>需将2个外部IP地址加入白名单</strong></em></li><li>得益于AWS Shield，具备DDoS防护功能</li></ul></li></ul><h2 id="CloudFront"><a href="#CloudFront" class="headerlink" title="CloudFront"></a>CloudFront</h2><p>![Untitled](D:&#x2F;hexo&#x2F;source&#x2F;_posts&#x2F;&#x2F;images&#x2F;Untitled 1.png)</p><ul><li>AWS的 CloudFront 是一个内容分发网络（Content Delivery Network，CDN）服务</li><li>它通过在<strong>全球范围</strong>内建立边缘节点，将网站的内容复制并缓存到离用户最近的服务器上，以加速网站的加载，提供更好的用户体验。</li><li>一项加快<em><strong>将静态和动态</strong></em> Web 内容（例如 .html、.css、.js 和图像文件）分发给用户的速度的 Web 服务。</li></ul><ol><li><p>静态内容（Static Content）：</p><ul><li>图像、CSS 样式表、JavaScript 文件、HTML 页面等。</li><li>静态内容不会因用户请求的不同而改变，因此可以被缓存以提高加载速度和性能。</li></ul></li><li><p>动态内容（Dynamic Content）：</p><ul><li><p>动态内容可以根据用户的输入、状态、权限等不同情况来生成不同的响应。例如，根据用户的搜索查询生成的搜索结果页面、用户个人资料页面等都是动态内容。</p><pre><code>          HTML</code></pre><p>  ​<br>  ​<br>  ​<br>  ​<br>  ​<br>  ​</p></li></ul><p>➡️ 在电子商务网站中，通常会有一些页面和资源是相对不变的，例如公司的标志、产品图片、网站样式表等，这些属于静态内容。而用户的购物车、订单历史、产品库存状态等可能因用户请求或时间变化而产生不同的数据，这些属于动态内容。​</p></li></ol><h2 id="CloudFront的运作过程："><a href="#CloudFront的运作过程：" class="headerlink" title="CloudFront的运作过程："></a><strong>CloudFront的运作过程：</strong></h2><ol><li><strong>内容上传：</strong> 首先，网站的所有内容（如图片、视频、CSS样式、JavaScript脚本等）都需要上传到亚马逊S3（Simple Storage Service）存储桶、Elastic Load Balancer、EC2（Elastic Compute Cloud）实例或其他支持的<strong>源服务器</strong>上。这些服务器被称为源服务器，它们存储着网站的原始内容。</li><li><strong>内容缓存：</strong> 一旦内容上传到源服务器，CloudFront 会将这些内容复制到全球各地的边缘节点（Edge Locations）。这些边缘节点通常位于不同的城市和国家，离用户更近，从而减少了用户与源服务器之间的距离和网络延迟。</li><li><strong>用户请求：</strong> 当有用户想要访问网站时，他们的请求会被发送到离他们最近的 CloudFront 边缘节点。</li><li><strong>边缘节点响应：</strong> 边缘节点会检查用户请求所需的内容是否已经缓存在本地。如果缓存中有，它会立即将内容返回给用户，不需要再向源服务器发送请求。这就大大加快了网站内容的加载速度。</li><li><strong>源服务器请求：</strong> 如果边缘节点上没有所需的内容（或者内容过期了），边缘节点会代表用户向源服务器发送请求，从源服务器获取内容。</li><li><strong>内容更新：</strong> 如果网站的内容在源服务器上发生了更改，CloudFront 会自动检测到并更新边缘节点上的缓存，以确保用户获取到最新的内容。</li></ol><h2 id="CloudFront-Geo-Restriction地理限制"><a href="#CloudFront-Geo-Restriction地理限制" class="headerlink" title="CloudFront Geo Restriction地理限制"></a><strong>CloudFront Geo Restriction地理限制</strong></h2><ul><li>您可以通过白名单或黑名单限制用户从哪个国家访问您的分发</li><li>用例：版权法律</li></ul><h2 id="Cache-Invalidation缓存失效"><a href="#Cache-Invalidation缓存失效" class="headerlink" title="Cache Invalidation缓存失效"></a><strong>Cache Invalidation缓存失效</strong></h2><ul><li>当您更新原始内容并希望刷新全球边缘位置中的所有缓存内容时</li><li>您可以强制刷新整个或部分缓存</li><li>您可以使所有文件 (<em>) 或特殊路径（&#x2F;images&#x2F;</em>）失效</li></ul><h2 id="Lambda-Edge"><a href="#Lambda-Edge" class="headerlink" title="Lambda@Edge:"></a><strong>Lambda@Edge:</strong></h2><p> Lambda@Edge 是在 CloudFront 边缘节点上运行的 AWS Lambda 函数，用于在请求和响应的不同阶段执行自定义逻辑。</p><h2 id="origin-servers-源服务器"><a href="#origin-servers-源服务器" class="headerlink" title="origin servers-源服务器"></a>origin servers-源服务器</h2><ol><li><strong>Amazon S3 bucket：</strong> 您可以将 Amazon S3 存储桶作为 CloudFront 的源服务器，以将静态内容（如图片、CSS、JavaScript 等）分发到全球边缘位置。</li><li><strong>（Custom Origins）：</strong> 这包括多种类型的自定义源服务器，可以通过 CloudFront 配置将内容从这些源分发到边缘位置。自定义源类型包括：<ul><li><strong>Amazon EC2 实例：</strong> 您可以将运行在 Amazon EC2 上的应用程序作为源服务器，将动态内容分发到全球边缘位置。</li><li><strong>Amazon Elastic Load Balancer（ELB）：</strong> 将位于 Elastic Load Balancer 后面的应用程序作为源服务器，以实现负载均衡和高可用性。</li><li><strong>Amazon API Gateway：</strong> 将托管在 API Gateway 上的 RESTful API 作为源服务器，以加速 API 请求的响应速度。</li><li><strong>非 AWS 源服务器：</strong> 您还可以将位于其他云提供商或自己托管的服务器作为 CloudFront 的源服务器。</li></ul></li></ol><h2 id="价格类别"><a href="#价格类别" class="headerlink" title="价格类别"></a><strong>价格类别</strong></h2><ul><li>全部价格类别：所有地区-最佳性能</li><li>价格类200：大多数地区，但不包括最昂贵的地区</li><li>价格类100：仅最便宜的地区</li></ul><p>![Untitled](D:&#x2F;hexo&#x2F;source&#x2F;_posts&#x2F;&#x2F;images&#x2F;Untitled 2.png)</p><h2 id="CloudFront-V-S-S3-Cross-Region-Replication"><a href="#CloudFront-V-S-S3-Cross-Region-Replication" class="headerlink" title="CloudFront V.S. S3 Cross Region Replication"></a>CloudFront V.S. S3 Cross Region Replication</h2><ul><li><p>CloudFront</p><ul><li>CloudFront uses global edge network</li><li>files are cached for a TTL(like a day)</li><li>greate for static content that must be available everywhere</li></ul></li><li><p>S3 Cross Region Replication</p><ul><li>must be setup for each region you want replication</li><li>files are updated in near real-time</li><li>read only</li><li>great for dynamic content that needs to be available at low-latency regions</li></ul><p>CloudFront V.S. S3跨区域复制</p><ul><li>CloudFront<ul><li>CloudFront使用全球边缘网络</li><li>文件被缓存TTL（如一天）</li><li>适用于必须在任何地方提供的静态内容</li></ul></li><li>S3跨区域复制<ul><li>必须为您想要复制的每个区域设置</li><li>文件实时更新</li><li>只读</li><li>适用于需要在低延迟区域提供的动态内容</li></ul></li></ul></li></ul><h2 id="AWS-Global-Accelerator-V-S-CloudFront"><a href="#AWS-Global-Accelerator-V-S-CloudFront" class="headerlink" title="AWS Global Accelerator V.S.  CloudFront"></a>AWS Global Accelerator V.S.  CloudFront</h2><p>它们都使用AWS全球网络和世界各地的<strong>边缘位置（Edge Locations）</strong>。<br>这两项服务都与AWS Shield集成，提供DDoS防护。</p><p>CloudFront：</p><ul><li>优化<strong>缓存</strong>内容（如图像和视频）和动态内容（如API加速和动态网站交付）的性能。</li><li>内容在边缘位置（Edge Locations）上提供服务。</li></ul><p>Global Accelerator：</p><ul><li><strong>适用于需要确定性、快速区域故障转移的HTTP用例</strong>。</li><li><strong>适用于非HTTP用例，例如游戏（UDP）、物联网（MQTT）或VoIP（Voice over IP）。</strong></li><li>适用于<strong>需要静态IP地址的HTTP用例</strong>。</li><li>提升在TCP或UDP上运行的广泛应用程序的性能。</li><li>在边缘位置代理数据包到运行在一个或多个AWS区域的应用程序。</li></ul><p>简而言之，AWS Global Accelerator 主要用于提高广泛应用程序的性能，包括非HTTP用例，而 CloudFront 则主要用于优化缓存和动态内容的性能，以及适用于 HTTP 用例的加速和交付。</p><ul><li><p>They both use the AWS global network and its edge locations around the world</p></li><li><p>Both services integrate with AWS Shield for DDoS protection</p></li><li><p>CloudFront</p><ul><li>Improves performance for both cacheable content (such as images and videos)</li><li>Dynamic content (such as API acceleration and dynamic site delivery)</li><li>Content is served at the edge</li></ul></li><li><p>Global Accelerator</p><ul><li><p>Improves performance for a wide range of applications over TCP or UDP</p></li><li><p>Proxying packets at the edge to applications running in one or more AWS Regions</p></li><li><p>Good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP</p></li><li><p>Good for HTTP use cases that require static IP addresses</p></li><li><p>Good for HTTP use cases that required deterministic, fast regional failover</p><h1 id="concepts-you-need-to-know"><a href="#concepts-you-need-to-know" class="headerlink" title="concepts you need to know"></a>concepts you need to know</h1><h5 id="AMI-Amazon-Machine-Image"><a href="#AMI-Amazon-Machine-Image" class="headerlink" title="AMI (Amazon Machine Image)"></a>AMI (Amazon Machine Image)</h5><ol><li>AMI是一种EC2 instance的snapshot</li><li>AMI是一种包含软件配置的模板。</li><li>AMI 包括以下内容：<ul><li>一个或多个 Amazon Elastic Block Store (Amazon EBS) 快照；对于由实例存储支持的 AMI，包括一个用于实例（例如，操作系统、应用程序服务器和应用程序）根卷的模板。</li><li>控制可以使用 AMI 启动实例的 AWS 账户的启动许可。</li><li>数据块设备映射，指定在实例启动时要附加到实例的卷</li></ul></li></ol><p>通过 AMI，您可以<em><strong>启动实例</strong></em>，实例是作为云中虚拟服务器运行的 AMI 的副本。</p><ul><li>AMI are a <strong>customization</strong> of an EC2 instance<ul><li>You add your own software, configuration, operating system, monitoring…</li><li>Faster boot &#x2F; configuration time ，因为所有软件都是预打包的</li></ul></li><li>AMI are built for a <strong>specific region</strong> (and can be copied across regions)</li><li>您可以从以下位置启动 EC2 实例：<ul><li><strong>公共 AMI</strong>：由 AWS 提供。</li><li><strong>您自己的 AMI</strong>：您自己创建和维护的 AMI。</li><li><strong>AWS Marketplace AMI</strong>：其他人创建（并有可能销售）的 AMI。</li></ul></li></ul><h5 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h5><p>**Uniform Resource Locator（**统一资源定位符）</p><p>用于在网络上标识和定位资源的地址。</p><p>通常，一个URL由以下几个部分组成：</p><ol><li><strong>协议（Protocol）：</strong> URL的协议部分指定了用于访问资源的协议或协议方案，如HTTP、HTTPS、FTP等。例如，在”<a href="http://www.example.com/">http://www.example.com</a>“中，”http”就是协议。</li><li><strong>域名（Domain Name）：</strong> URL的域名部分是用于标识网络上资源所在的主机名。域名是由一系列标签和点号组成，例如”<a href="http://www.example.com/">www.example.com</a>“就是一个域名。</li><li><strong>端口号（Port）：</strong> URL的端口号部分是可选的，它指定了要访问资源的目标端口。如果未指定端口号，则使用协议的默认端口。例如，在”<a href="http://www.example.com/">http://www.example.com:80</a>“中，”:80”是端口号，表示要使用HTTP协议的默认端口80。</li><li><strong>路径（Path）：</strong> URL的路径部分指定了资源在服务器上的位置和名称。路径由斜杠”&#x2F;“分隔的字符串组成，用于标识资源在服务器文件系统中的位置。例如，在”<a href="http://www.example.com/index.html%22%E4%B8%AD%EF%BC%8C%22/index.html">http://www.example.com/index.html&quot;中，&quot;/index.html</a>“就是路径。</li><li><strong>查询字符串（Query String）：</strong> URL的查询字符串部分是可选的，用于向服务器传递参数。查询字符串由问号”?”开始，后面跟着一系列用”&amp;”连接的参数键值对。例如，在”<a href="http://www.example.com/search?query=apple%22%E4%B8%AD%EF%BC%8C%22?query=apple%22%E5%B0%B1%E6%98%AF%E6%9F%A5%E8%AF%A2%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%8C%E8%A1%A8%E7%A4%BA%E6%90%9C%E7%B4%A2%E5%8F%82%E6%95%B0%22query%22%E7%9A%84%E5%80%BC%E6%98%AF%22apple">http://www.example.com/search?query=apple&quot;中，&quot;?query=apple&quot;就是查询字符串，表示搜索参数&quot;query&quot;的值是&quot;apple</a>“。</li></ol><h5 id="“Redirect”（重定向）"><a href="#“Redirect”（重定向）" class="headerlink" title="“Redirect”（重定向）"></a>“Redirect”（重定向）</h5><p>将一个请求从一个URL地址重定向到另一个URL地址的操作。</p><p>重定向通常是在应用层（Layer 7）处理的</p><p> 常见的应用场景包括：</p><ul><li>强制使用HTTPS：将HTTP请求重定向到相应的HTTPS地址，以确保通信的安全性。</li><li>域名变更：将旧域名重定向到新域名，确保用户访问的是最新的域名。</li><li>路径重定向：根据URL路径将请求重定向到不同的资源或页面上。</li><li>主机名重定向：根据URL中的主机名将请求重定向到不同的主机或子域名上。</li><li>移动设备重定向：根据用户设备类型将请求重定向到适合其设备的移动版本或桌面版本的网站。</li><li>广告跟踪重定向：通过重定向用户点击的广告，进行广告效果跟踪和转化追踪。</li></ul><h5 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h5><p>数据信息，类型为“<strong>小型文本文件</strong>”，存储于电脑上的文本文件中。</p><p>客户端请求服务器，如果服务器需要记录该用户状态就使用response向客户端浏览器颁发一个Cookie。客户端游览器就会把Cookie保存起来。当浏览器在请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态，服务器还可以根据需要修改Cookie的内容。</p><h5 id="SSL-TLS"><a href="#SSL-TLS" class="headerlink" title="SSL &#x2F; TLS"></a>SSL &#x2F; TLS</h5><p>安全套接层（Secure Sockets Layer），它是一种用于确保网络通信安全的加密协议。</p><p>SSL通常被称为传输层安全性协议（TLS，Transport Layer Security）</p><p>SSL协议旨在通过在客户端和服务器之间建立加密连接来保护敏感数据的传输。它使用公钥加密和对称加密算法来确保数据的机密性、完整性和身份验证。</p><p>SSL位于<strong>传输层和应用层</strong>之间的协议。</p><p>SSL&#x2F;TLS协议通过在传输层建立一个安全的通信通道来保护数据的安全性，以确保在应用程序之间传输的数据在传输过程中受到保护。因此，SSL&#x2F;TLS协议在传输层和应用层之间发挥了重要的作用。</p><h5 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h5><ol><li><p><strong>可用性（Availability）</strong>：指系统或应用程序持续可用的程度，通常以百分比来衡量。在AWS中，服务级别协议（SLA）是一个衡量可用性的重要指标。常见的目标是“99.99%可用性”或更高。</p></li><li><p><strong>可扩展性（Scalability）</strong>：指系统或应用程序可以在需要时进行扩展，以满足不断增长的需求。AWS提供了自动扩展功能，如Auto Scaling，可以根据负载情况自动增加或减少资源。</p></li><li><p><strong>弹性（Elasticity）</strong>：与可扩展性类似，但更强调系统可以快速适应变化，并且可以自动调整资源以满足需求。弹性系统能够根据负载情况自动调整容量。</p></li><li><p><strong>持久性（Durability）</strong>：指数据的持久性和不易丢失。AWS存储服务（如S3）提供了高持久性，确保数据不会轻易丢失。</p></li><li><p><strong>安全性（Security）</strong>：指保护系统和数据免受未经授权访问、攻击和泄漏的能力。AWS提供多种安全性功能和服务，如身份和访问管理（IAM）、虚拟专用云（VPC）等。</p></li><li><p><strong>成本效益（Cost Efficiency）</strong>：指在满足需求的同时，最大限度地降低成本。AWS提供计算、存储和其他资源的付费方式，使用户只需支付实际使用的资源。</p></li><li><p><strong>可管理性（Manageability）</strong>：指系统的易管理性和监控性能。AWS提供云监控、自动化和管理工具，以帮助用户管理和监控他们的资源。</p></li><li><p><strong>灵活性（Flexibility）</strong>：指能够选择不同的计算、存储和网络选项，以满足不同需求。AWS提供多种服务和配置选项，以适应各种应用场景。</p><pre><code>         HTML</code></pre><p> ​<br> ​<br> ​<br> ​<br> ​<br> ​</p></li></ol><p>🍋 “Decoupling applications” 是一种架构设计的概念，它指的是将应用程序的各个组件解耦，使它们之间的交互变得灵活、松散，从而提高应用程序的可伸缩性、可靠性和可维护性。​</p><h5 id="NoSQL-数据库-Not-Only-SQL"><a href="#NoSQL-数据库-Not-Only-SQL" class="headerlink" title="NoSQL 数据库-Not Only SQL"></a>NoSQL 数据库-<strong>Not Only SQL</strong></h5><p>是一类非关系型数据库，与传统的关系型数据库（SQL 数据库）相对应。</p><p><strong>NoSQL 是 “Not Only SQL” 的缩写</strong>，强调它们不仅仅是 SQL 数据库的替代品，而是一组使用不同数据模型和查询语言的数据库技术。</p><p>NoSQL 数据库的主要特点包括：</p><ol><li><strong>非关系型数据模型：</strong> NoSQL 数据库使用不同的数据模型来存储和组织数据，而不是传统的表格结构。常见的 NoSQL 数据模型包括键值对、文档、列族（列存储）和图形模型。</li><li><strong>灵活的模式：</strong> NoSQL 数据库通常没有固定的模式（schema），这意味着您可以在数据库中存储不同结构和格式的数据，而无需预先定义表结构。</li><li><strong>水平扩展性：</strong> NoSQL 数据库通常设计为可以无缝水平扩展，即通过添加更多的节点和服务器来处理大规模数据和负载，而无需单一的昂贵服务器。</li><li><strong>高性能和低延迟：</strong> NoSQL 数据库的设计目标之一是提供高吞吐量和低延迟的读写操作，使其适用于大量实时应用和高并发环境。</li><li><strong>去中心化分布式架构：</strong> 许多 NoSQL 数据库是分布式的，数据可以复制和存储在多个节点上，提高数据的可用性和容错性。</li><li><strong>CAP 定理：</strong> NoSQL 数据库通常遵循 CAP 定理原则，即在分布式系统中，无法同时满足一致性（Consistency）、可用性（Availability）和分区容忍性（Partition Tolerance）这三个特性，需要在这三者之间做出权衡。</li></ol><p>NoSQL 数据库适用于许多不同类型的应用场景，特别是对于需要大规模数据存储和处理的现代应用程序。由于其灵活的模式和分布式架构，NoSQL 数据库在 Web 应用程序、移动应用程序、实时分析、物联网（IoT）和大数据等领域得到广泛应用。一些著名的 NoSQL 数据库包括 MongoDB、Cassandra、DynamoDB、Couchbase 和 Redis 等。</p><h5 id="Application-Programming-Interface-API"><a href="#Application-Programming-Interface-API" class="headerlink" title="Application Programming Interface-API"></a>Application Programming Interface-API</h5><p>API可以被看作是一个桥梁，它允许开发人员使用已有的代码、服务或功能，而无需重新编写或重新创建这些内容。通过API，开发人员可以访问和操作其他软件组件的功能，就像使用构建块一样，从而加快开发过程并提高代码的可重用性。</p><p>API可以有不同的形式，包括：</p><ul><li><strong>Web API：</strong> 基于HTTP协议的API，通常通过URL进行访问，返回数据以JSON或XML等格式。</li><li><strong>库（Library）API：</strong> 提供编程语言特定的函数和方法，以供开发人员在自己的代码中使用。</li><li><strong>操作系统API：</strong> 允许应用程序与操作系统进行交互，访问底层功能。</li><li><strong>硬件API：</strong> 允许软件与硬件设备进行交互，如打印机、摄像头等。</li></ul><h5 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h5><p>是一个开源的关系型数据库管理系统（RDBMS），它提供了高度可靠性、可扩展性和丰富的功能集。以下是一些关于PostgreSQL的重要信息：</p><ol><li><strong>关系型数据库管理系统（RDBMS）：</strong> PostgreSQL是一种关系型数据库，它使用表格来存储数据，并支持SQL（Structured Query Language）查询语言。</li><li><strong>开源：</strong> PostgreSQL是一个开源项目，这意味着它的源代码是公开的并且可以被任何人查看、使用和修改。</li><li><strong>高度可靠性：</strong> PostgreSQL被设计为具有高度可靠性和稳定性。它支持事务、ACID（原子性、一致性、隔离性、持久性）属性，确保数据的完整性和可靠性。</li><li><strong>可扩展性：</strong> PostgreSQL具有良好的可扩展性，它可以处理大量的数据和高并发访问。通过分区、复制、集群等方式，可以将系统的性能和容量扩展到更高的水平。</li><li><strong>丰富的功能：</strong> PostgreSQL提供了丰富的功能集，包括复杂的数据类型、外键约束、触发器、视图、存储过程、全文搜索、地理空间支持等。它也支持JSON和其他非结构化数据类型。</li><li><strong>扩展性：</strong> PostgreSQL支持扩展，允许用户添加自定义的扩展模块来增加数据库功能。</li><li><strong>多种操作系统支持：</strong> PostgreSQL可以在多种操作系统上运行，包括Linux、Windows、macOS等。</li><li><strong>社区支持：</strong> PostgreSQL拥有一个活跃的全球社区，提供支持、文档、教程和插件，帮助用户更好地使用和管理数据库。</li><li><strong>安全性：</strong> PostgreSQL提供了强大的安全功能，包括用户认证、访问控制、数据加密等，以保护数据库中的敏感信息。</li></ol><p>总之，PostgreSQL是一个功能强大且可靠的开源关系型数据库管理系统，适用于各种规模的应用程序和项目。它在企业和开发者社区中都享有广泛的使用和认可。</p><pre><code>            HTML</code></pre><p>​<br>​<br>​<br>​<br>​<br>​<br>➡️ unicast IP-每个设备有唯一的IP地址，数据包从源设备直接传输到目标设备。​</p><pre><code>            HTML</code></pre><p>​<br>​<br>​<br>​<br>​<br>​<br>🐳 anycast IP-多个设备共享相同IP地址，数据包将传输到最近的设备​</p><h5 id="OLTP"><a href="#OLTP" class="headerlink" title="OLTP"></a>OLTP</h5><p><strong>Online Transaction Processing”（在线事务处理）</strong></p><p>它是一种数据库处理方式，用于处理实时交易和事务。OLTP系统旨在支持并发的数据库操作，通常用于处理大量短期和频繁的交易请求，例如在线购买、银行交易、航班预订等。</p><p>OLTP系统通常具有以下特点：</p><ul><li>快速的读写操作：用于处理实时交易，需要快速响应和处理数据库记录的插入、更新和查询操作。</li><li>事务支持：OLTP系统必须支持ACID属性（原子性、一致性、隔离性和持久性），确保数据库的完整性和一致性。</li><li>高并发性：OLTP系统通常面对许多用户同时进行交易，需要能够处理高并发的请求。</li><li>精细的数据模型：OLTP系统的数据模型通常是规范化的，以减少数据冗余并提高查询性能。</li><li>实时数据访问：OLTP系统提供实时数据访问，允许用户即时获取最新的交易信息。</li></ul><h5 id="适用于OLTP的AWS服务："><a href="#适用于OLTP的AWS服务：" class="headerlink" title="适用于OLTP的AWS服务："></a>适用于OLTP的AWS服务：</h5><ol><li><strong>Amazon RDS</strong>（Relational Database Service）：支持多种关系型数据库引擎，适用于在线交易处理和实时事务。</li><li><strong>Amazon Aurora</strong>：是RDS的一个变种，专为OLTP工作负载而设计，具有高性能和高可用性。</li><li><strong>Amazon DynamoDB</strong>：全托管的NoSQL数据库，适用于高度可扩展的实时交易处理和高并发操作。</li><li><strong>Amazon ElastiCache</strong>：提供托管的内存缓存服务，加速读取操作，适用于缓存频繁读取的交易数据。</li></ol><h5 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h5><p><strong>“Online Analytical Processing”（在线分析处理）</strong></p><p>它是一种数据库处理方式，用于支持复杂的数据分析和查询。OLAP系统旨在帮助用户从大量数据中获取洞察力和业务智能，进行决策支持和战略规划。</p><p>OLAP系统具有以下特点：</p><ol><li>多维数据模型：OLAP系统使用多维数据模型，通常称为立方体（cube），将数据组织成多个维度和度量，方便进行多维度的数据分析。</li><li>高性能查询：OLAP系统优化了查询性能，能够快速处理复杂的数据查询，包括聚合、切片、切块、钻取等操作。</li><li>聚合功能：OLAP系统支持对数据进行聚合计算，能够快速计算汇总数据，例如总和、平均值、最大值、最小值等。</li><li>决策支持：OLAP系统帮助用户发现数据中的模式和趋势，用于决策支持和业务智能。</li><li>历史数据：OLAP系统通常存储历史数据，可以进行时间序列分析和回顾性分析。</li></ol><p>OLAP系统通常用于商业智能（BI）应用程序，帮助企业管理层和决策者从大量数据中获取洞察力，了解业务情况，并做出基于数据的决策。与OLAP相对的是OLTP（Online Transaction Processing），后者用于处理实时交易和事务。两者分别优化了不同类型的数据库处理，以满足不同的应用场景和需求。</p><h5 id="适用于OLAP的AWS服务："><a href="#适用于OLAP的AWS服务：" class="headerlink" title="适用于OLAP的AWS服务："></a>适用于OLAP的AWS服务：</h5><ol><li>Amazon Redshift：完全托管的数据仓库服务，专为大规模数据分析和查询而设计，适用于复杂的多维度分析。</li><li>Amazon Athena：用于查询存储在S3中的大规模数据集的无服务器查询服务，适用于交互式数据分析。</li><li>Amazon EMR（Elastic MapReduce）：大数据处理服务，用于在分布式环境中进行复杂的数据分析和计算。</li><li>Amazon Quicksight：商业智能工具，用于可视化和分析数据，适用于OLAP数据的交互式分析和报表制作。</li></ol><h5 id="DNS-域名解析系统：域名解析为IPudp53"><a href="#DNS-域名解析系统：域名解析为IPudp53" class="headerlink" title="DNS 域名解析系统：域名解析为IPudp53"></a>DNS 域名解析系统：域名解析为IP<code>udp53</code></h5><p>Domain Name System，将域名解析为IP地址</p><p>UDP 53</p><table><thead><tr><th>A</th><th>域名解析为IP地址</th></tr></thead><tbody><tr><td>PTR</td><td>解析IP地址到主机名   反向查询</td></tr><tr><td>CNAME</td><td>允许多名称对应同一主机</td></tr><tr><td>MX</td><td>指定邮件服务器优先级</td></tr><tr><td>NS</td><td>指明域名由哪一台服务器来解析</td></tr></tbody></table><ul><li><p><strong>DNS命名</strong></p><p>主机…+三级域名+二级域名+顶级域名</p><p>主机名：www,ftp,mail</p><p>域名：com,cn,edu</p></li></ul><p>客户端进行DNS查询步骤</p><p>DNS缓存——（找不到）——host文件 or  DNS服务器</p><p>没有得到解析结果，则使用NETBIOS名字解析</p><p>DNS术语解释</p><ul><li><strong>域名注册商</strong>：Amazon Route 53、GoDaddy等公司。</li><li><strong>DNS记录</strong>：A记录、AAAA记录、CNAME记录、NS记录等。</li><li><strong>区域文件</strong>：包含DNS记录的文件。</li><li><strong>root domain</strong></li><li><strong>顶级域名（TLD）</strong></li><li><strong>二级域名（SLD</strong></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> lifelong learning </category>
          
          <category> 技术 </category>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DevOps </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/08/01/hello-world/"/>
      <url>/2021/08/01/hello-world/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello World</span><br></pre></td></tr></table></figure><p>Welcome to the fountainhead! This is my very first post.</p><p>无论学的是C、Python、Java，还是某种冷门语言，第一件事总是：让语言“说出”它的第一句话。编程界的初心，或许只是一段代码中最纯粹的问候。</p><p>对世界保持好奇心，不断探索新世界！</p>]]></content>
      
      
      <categories>
          
          <category> 关于对世界的好奇心 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
