<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The Fountainhead</title>
  <icon>https://www.gravatar.com/avatar/5b3fe3154f9feca5494c1336bceab02e</icon>
  <subtitle>flee as a bird to your blue sea</subtitle>
  <link href="https://sosocrown.github.io/atom.xml" rel="self"/>
  
  <link href="https://sosocrown.github.io/"/>
  <updated>2025-08-05T09:06:30.533Z</updated>
  <id>https://sosocrown.github.io/</id>
  
  <author>
    <name>niki</name>
    <email>zn40489@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>薛定谔，你在吗？</title>
    <link href="https://sosocrown.github.io/2025/08/05/%E8%96%9B%E5%AE%9A%E8%B0%94%EF%BC%8C%E4%BD%A0%E5%9C%A8%E5%90%97%EF%BC%9F/"/>
    <id>https://sosocrown.github.io/2025/08/05/%E8%96%9B%E5%AE%9A%E8%B0%94%EF%BC%8C%E4%BD%A0%E5%9C%A8%E5%90%97%EF%BC%9F/</id>
    <published>2025-08-04T16:00:00.000Z</published>
    <updated>2025-08-05T09:06:30.533Z</updated>
    
    <content type="html"><![CDATA[<p>最近的新闻频繁上演诡谲的话题：宛如《哭悲》里面异化的世界。</p><p>极端的焦虑、不安、困惑和痛苦，我想要呕吐，恐惧自己马上成为刀刃下的腐骨，更恐惧的是我甚至发不出愤怒的声音，就此寂静下去。</p><p>当然，这是一篇2025过半的回顾，我控制自己不要呕吐出太多负面的情绪。</p><hr><p>打字的时候是八月，年中已经过去了整整两个月，我却几乎毫无察觉。身体还滞留在年初的某个时间点。<br>工作后一个问题产生了：<br><strong>把成长感和价值感全押在工作上，是不是一种错？  工作是不是就该只是一个赚钱的工具？</strong><br>从更换项目以来，这个疑问宛如缠绕我的恶鬼，时时刻刻将我逼迫到崩溃的边缘。</p><p>说实话，我的第一个项目环境挺轻松，领导同事也都很好。但就算这样，我还是能从中榨出一些痛苦，那种现在看来已经算奢侈的痛苦：比如工作一段时间后就觉得自己学习的速度减慢了，不再像刚入职那样快速吸收新东西。<br>但那个项目起码流程清晰、可追溯、标准化，领导给的权限是有限但稳定的。更重要的是，同事的工作方式彻底改变了我对技术的理解和看法。</p><p>可惜，当时我也开始感到不安。生活很美好，甚至可以说无聊，而我却因此感到恐惧：<br>“要是一直这样，我是不是就停滞不前了？是不是成长得太慢了？”</p><p>于是我去了另一个项目。搬家的琐碎、通勤时间成本增加、生活成本增加、居住环境质量下降、新环境、新同事……</p><p>决定的时候很纠结。但对我来说，“纠结”往往不是因为我不知道选哪条路，而是我心里已经有答案了，但需要一些成熟的逻辑和可信任的理论来支撑。</p><p>第一天我就有即将不幸的预感，如同宿命论的舞台上最后一幕的雨，象征着悲剧。<br>第一周我就开始不安。<br>第一个半月我崩溃了。</p><p>然后前文所说的疑问就开始唱歌，无时无刻我质询自己，观察别人，试图获得答案。<br>我还开始写职场七宗罪，^ ^<br>叙述那些经历和感受都是一种痛，跳过。</p><p>疑问没有答案。<br>为了不把自己拖死，我开始自我保护，也就是彻底摆烂。上班带上耳机听犯罪播客，看罪案（倾情推荐xinklings，我超喜欢的一个写罪案的女博主）。<br>我不再提出疑问，不再思考如何更好解决工作中出现的问题，不再积极跟进问题。甲领导说A好，我就照着A做，即使A根本没有道理。</p><p>就这样摆烂了一个月。<br>我和领导五月argue过，直到八月才调整工作重点。<br><img src="/images/sky.jpg" alt="EC2"><br>漫长的时间里，对工作本体的不满已经蔓延升维成为对领导能力、甲方、客户、公司制度、公司属性的多面一体不满了。<br>工作一步一步侵占我的自由，管理者满不在乎：“不就几分钟嘛，到底是有多难？”<br>打卡，日报，周报，工作量汇总，服装，工牌……<br>一切永无止境。</p><p>疑问还是没有答案，我还是时常愤怒和痛苦，目前还在寻找解决方式。<br>顺便一提，职场七宗罪已经写道第六条了。</p><blockquote><p>任何一个在普世登本位里给上级打工的feminist，基本上没有不反思自己、不为工作的组织框架下被管理、被训诫、被规训而痛苦的。</p></blockquote><hr><p>第一个问题浮现后，第二个也紧随其后：我是否真的适合做技术工作。<br>有时候过渡思考某个问题会陷入深渊。</p><p>我的解决方式是：</p><blockquote><p>不要在不会某件事情的时候断言自己不喜欢不适合。<br><img src="/images/tree.jpg" alt="EC2"></p></blockquote><hr><p>今年搬家后，我和这个城市遇到的一个同期同事，成为了朋友，我们一起过了生日。</p><p>灵感终于落实成文字，虽然因为工作中断了，但至少5W字了。</p><p>本来年初写下阅读目标是30本，现在已经读完24本，得益于每天通勤时间的变长。</p><p>开始建设自己的Linkedin，封了两次号，现在终于正常运行。</p><p>有了第一个文身。</p><p>公众号邀请我写了技术分享文章</p><p>虽然还是没有去学自由泳。&gt;_&lt;</p><p>奇怪，怎么写得像是年终总结。工作，你毁了我！！！<br><img src="/images/w1.jpg" alt="EC2"></p><p>所谓“时代变局”不只是新闻用语，它正在一点点渗进我的日常。<br>命运的诡谲之处就在于，没有是非题，只要我骗过自己，就能皆大欢喜。<br>可我并不想欺骗自己：我过得幸福。</p><p>我忍不住朝虚空大喊：“薛定谔，你在吗？”<br><img src="/images/xde.jpg" alt="EC2"><br>可事实上，在盒子里我注定只是工具，想要摆脱黑暗，只能逃出去，顺便咬薛定谔一口。</p><p><img src="/images/taluo.jpg" alt="EC2"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近的新闻频繁上演诡谲的话题：宛如《哭悲》里面异化的世界。&lt;/p&gt;
&lt;p&gt;极端的焦虑、不安、困惑和痛苦，我想要呕吐，恐惧自己马上成为刀刃下的腐骨，更恐惧的是我甚至发不出愤怒的声音，就此寂静下去。&lt;/p&gt;
&lt;p&gt;当然，这是一篇2025过半的回顾，我控制自己不要呕吐出太多负面的</summary>
      
    
    
    
    <category term="flee as a bird to your mountain" scheme="https://sosocrown.github.io/categories/flee-as-a-bird-to-your-mountain/"/>
    
    
    <category term="life" scheme="https://sosocrown.github.io/tags/life/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://sosocrown.github.io/2025/07/15/K8S-/"/>
    <id>https://sosocrown.github.io/2025/07/15/K8S-/</id>
    <published>2025-07-15T09:44:56.574Z</published>
    <updated>2025-07-15T09:44:56.574Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>AWS-SAA认证全攻略</title>
    <link href="https://sosocrown.github.io/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/"/>
    <id>https://sosocrown.github.io/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/</id>
    <published>2025-07-14T16:00:00.000Z</published>
    <updated>2025-08-05T06:27:30.640Z</updated>
    
    <content type="html"><![CDATA[<p>此篇文章源自我在WomenStack 百栈百胜公众号的一次分享，公众号文章链接附下，欢迎大家关注微信公众号WomenStack 百栈百胜<br><a href="https://mp.weixin.qq.com/s?__biz=Mzk4ODQ2NzkxOQ==&mid=2247485911&idx=1&sn=82f2435d9600c3b4be6aa200df2c1d7a&chksm=c4d61b2fafa6e6642660c64001f4dd53009cd7a998e79f94e9ff68accda2572c47d9ea51f575&mpshare=1&scene=1&srcid=0729ZToFy994c5rHOusSlaqM&sharer_shareinfo=8993ec30eec70b4e1b042681f1ed1f18&sharer_shareinfo_first=cc8c545add2d44d6f5095cb1a0818068#rd">https://mp.weixin.qq.com/s?__biz=Mzk4ODQ2NzkxOQ==&amp;mid=2247485911&amp;idx=1&amp;sn=82f2435d9600c3b4be6aa200df2c1d7a&amp;chksm=c4d61b2fafa6e6642660c64001f4dd53009cd7a998e79f94e9ff68accda2572c47d9ea51f575&amp;mpshare=1&amp;scene=1&amp;srcid=0729ZToFy994c5rHOusSlaqM&amp;sharer_shareinfo=8993ec30eec70b4e1b042681f1ed1f18&amp;sharer_shareinfo_first=cc8c545add2d44d6f5095cb1a0818068#rd</a></p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我学云计算的第一步，是靠考下 <strong>AWS Certified Solutions Architect – Associate（简称 SAA</strong><strong>）</strong> 完成的。</p><p>AWS（Amazon Web Services）是亚马逊（Amazon）旗下的云计算平台，与 Microsoft Azure、Google Cloud Platform（GCP）并称全球三大云服务商。 国内则有阿里巴巴、腾讯、华为等公司提供各自的云服务，分别是阿里云、腾讯云和华为云。</p><p>虽然各家厂商均推出自有认证体系，但AWS的很多架构与服务都是云计算的行业标准。即便考完很久，大部分知识都忘记了，但现在无论使用哪家厂商的云服务，我都能将其对应到 AWS 的服务。</p><p>这并不意味着考试万能，对我的职业路径也没有巨大增益，但在学习过程中，通过将零散的服务组件系统性地整合为完整的架构体系，重新审视并理解传统IT架构的本质特征与运行逻辑，这些对我而言是非常宝贵的经历。</p><p>我学习到的，<strong>不只是“该用哪个服务”，而是“如何思考”。<strong>它帮我建立了</strong>云原生****的思维方式</strong>，让我在后续的实际项目、技术决策中，能更清晰地分析问题、设计架构。</p><p>AWS提供非常多的认证，可以通过官网查看。大致分为入门、助理、专业、专项。详细认证信息可通过文末链接[2]查看。</p><p>作为初学者，应该选择<strong>入门级</strong>的Cloud Practitioner还是<strong>助理级</strong>的Solutions Architect Associate呢？</p><p>Cloud Practitioner（云计算从业者）更加关注云服务本身，适合没有技术背景的人员，需要知道有哪些产品、能做什么、大概怎么用即可，无需深究架构原理。</p><p>Solutions Architect Associate（解决方案架构师助理级）适合开发者、运维工程师、系统工程师，更加侧重云服务在架构中如何发挥作用，更要掌握它们如何组合成高可用、可扩展、成本优化的整体解决方案。</p><p>我本身是计算机专业背景，玩过虚拟机、搭过服务，对 Linux 、计算机网络不陌生，但不了解云原生云计算，当时的职业规划也更倾向于建立系统的云架构设计能力，所以选择SAA而非CP（Cloud Practitioner）。当然，国内的云认证更方便，如阿里云的ACP（阿里云云计算高级工程师Alibaba Cloud Certified Professional - Cloud Computing），资源更加好获取，语言也没有门槛，怎么选看个人倾向。</p><p>本文主要分享AWS-SAA（解决方案架构师助理级）的认证经验。</p><h1 id="个人情况"><a href="#个人情况" class="headerlink" title="个人情况"></a>个人情况</h1><p>背景：计算机专业，对云服务完全不了解</p><p>备考时长时间：48天左右</p><ul><li>学习：35天，每天有效学习时长3~5小时（其中可能有1-3天去玩了）</li><li>刷题：13天</li></ul><p>刷题来源：ExamTopics</p><h1 id="关于-AWS-SAA-考试："><a href="#关于-AWS-SAA-考试：" class="headerlink" title="关于 AWS SAA 考试："></a>关于 AWS SAA 考试：</h1><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>SAA-C03 是 <strong>AWS SAA</strong> 认证考试的最新版本代码，于 2022 年 8 月 30 日正式启用，替代旧版 SAA-C02。在获取资料、学习、刷题过程中请认准最新代码。</li><li>认证常见问题（重考政策等）见文末[3]。</li><li>考前、考中和考后的流程与要求见文末[4]。</li></ul><h2 id="折扣与报名"><a href="#折扣与报名" class="headerlink" title="折扣与报名"></a>折扣与报名</h2><ul><li>官方价格150 USD（约1085元），AWS官方提供多种活动获取折扣优惠。此外，通过任何一项认证后能够领取五折优惠券。</li><li>考试方式：线下考试中心或在线监考考试。</li><li>考试语言：推荐选<strong>中文</strong>，因为选了中文之后也可以查看英文考题，反之则不行。</li><li>提前 1 周预约即可，如果需要更改预约时间，在<strong>考试时间至少 24 小时之前</strong>取消或重新预约。</li><li>报考链接见文末[5]。</li></ul><hr><h2 id="题目结构"><a href="#题目结构" class="headerlink" title="题目结构"></a>题目结构</h2><ul><li>一共 <strong>65 道题。</strong></li><li>其中有15道为不计分试题。AWS 收集这些不计分试题的 答题情况以进行评估，以便将来将这些试题作为计分试题。在考试中不会标明不计分试题。</li><li>全部为 <strong>单选 &#x2F; 多选。</strong></li><li>题目比较长，包含场景描述、业务背景、架构限制等。</li></ul><hr><h2 id="考试时间与结果"><a href="#考试时间与结果" class="headerlink" title="考试时间与结果"></a>考试时间与结果</h2><ul><li>考试时长：130 分钟，非英语母语者申请 Exam Accommodations将考试时间延长 30 分钟。</li><li>考试结果换算分数为 100 – 1000 分。最低及格分数为 720 分。</li><li>完成考试后，不会立马在屏幕上看到考试结果。</li><li>未通过考试，需要 14 天后才能重考。重考次数没有限制，但每次重考都必须全额支付报名费。</li></ul><h1 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h1><h2 id="官方学习资料——AWS-白皮书"><a href="#官方学习资料——AWS-白皮书" class="headerlink" title="官方学习资料——AWS 白皮书"></a>官方学习资料——AWS 白皮书</h2><p>白皮书提供非常详细的文档支持，大部分疑问都可以得到答案。学会熟练查阅白皮书，从官方文档获取最全面的云产品信息。白皮书链接见文末[6]。</p><h2 id="考点知识大纲"><a href="#考点知识大纲" class="headerlink" title="考点知识大纲"></a>考点知识大纲</h2><p>AWS目前有近百项服务，不过如果想通过AWS的助理级认证，只需要熟悉掌握主要的服务即可。对其他服务只需要明白其使用场景以及一些应用限制。官方提供的大纲更加详细，但是以<strong>设计架构</strong>的角度出发。官方大纲pdf可通过文末[7]获取。</p><p>我的大纲是从学习者角度出发整理的，这里只作为补充参考。一部分内容如机器学习几乎不占比重，不是考试重点，但偶尔也会出现在考题中，你只需要大概知道即可。</p><ol><li>计算服务（Compute）<br> EC2：需掌握启动、配置、安全组、弹性 IP、Auto Scaling<br> Lambda：事件驱动的无服务器计算服务<br> Elastic Beanstalk：自动化部署与管理<br> ECS &#x2F; EKS（容器服务）</li><li>存储服务（Storage）<br> S3：存储桶、存储类别、生命周期管理、版本控制、加密等<br> EBS：卷类型（gp3、io2）、快照、加密<br> EFS：适用于多个 EC2 实例共享访问的文件存储<br> FSx：适用于 Windows 文件服务器或高性能计算（Lustre）</li><li>数据库服务（Database）：<br> RDS：托管版数据库</li></ol><p>Aurora：兼容 MySQL&#x2F;PostgreSQL，比 RDS 更快更贵</p><p>DynamoDB：NoSQL 数据库</p><p>ElastiCache：托管版 Redis 或 Memcached</p><p>Redshift：数据仓库，跑大规模分析 SQL，适合 BI 报表</p><p>Transfer Family：用 SFTP&#x2F;FTP&#x2F;FTPS 把数据安全地迁到 AWS 上</p><p>Snow Family：实体硬件设备，用来物理迁移海量数据进云</p><ol start="4"><li>网络（Networking）<br> VPC：包含子网（公有&#x2F;私有）、路由表、安全组（SG）与网络ACL<br> IGW NAT Gateway：分别用于公网访问与私网出站访问<br> Bastion Host：跳板机，用于安全访问私有子网<br> Route 53：DNS 服务<br> CloudFront：CDN 加速服务<br> Direct Connect &#x2F; Transit Gateway</li><li>Serverless 、应用解耦与集成<br> Lambda + API Gateway<br> Kinesis<br> SNS（发布&#x2F;订阅）<br> SQS（消息队列）<br> EventBridge：事件总线，支持跨服务事件驱动架构<br> Step Functions：状态管理 + 工作流编排</li><li>灾难恢复与数据迁移（DR &amp; Migration）<br> 灾难恢复方案<br> 数据迁移工具<br> 备份策略</li><li>安全与权限控制（Security &amp; Identity）<br> IAM：身份与访问管理（用户、组、角色、策略）<br> Organizations &#x2F; SCP：多账户管理与集中策略控制<br> KMS：密钥管理服务（对数据加密解密）<br> CloudTrail &#x2F; Config：操作记录审计与合规性监控<br> CloudWatch：监控服务，含日志、指标、报警、仪表板</li></ol><h2 id="Udemy课程"><a href="#Udemy课程" class="headerlink" title="Udemy课程"></a>Udemy课程</h2><p>Udemy平台Stephane Maarek的《Ultimate AWS Certified Solutions Architect Associate》，官方链接见文末[8]。</p><p>该课程面向初学者，无需了解任何 AWS 知识，提供完整的学习路径，包括：</p><ul><li>完整的模拟考试，包括解释！</li><li>所有 800 多张幻灯片均以可下载的 PDF 形式提供</li><li>实操部分的详细讲解，包括Troubleshooting</li><li>了解 AWS 基础知识：计算服务（EC2&#x2F;Lambda&#x2F;EKS、存储体系（S3&#x2F;EBS&#x2F;EFS）、 网络架构（VPC&#x2F;Route53&#x2F;CloudFront）、数据库服务（RDS&#x2F;DynamoDB&#x2F;ElastiCache）</li><li>解决方案架构：架构设计原则、高性能架构、安全合规、成本优化</li></ul><p>最重要的几个产品讲解得非常细，搭配动手操作。对于云计算小白来说很不错，加深理解，巩固记忆。课程为英文，前期我挂了翻译，我后期基本就不需要翻译也能够看懂。</p><h1 id="学习路径"><a href="#学习路径" class="headerlink" title="学习路径"></a>学习路径</h1><h2 id="动手实践——理论与实操相结合"><a href="#动手实践——理论与实操相结合" class="headerlink" title="动手实践——理论与实操相结合"></a>动手实践——理论与实操相结合</h2><p>注册 AWS <strong>全球区</strong>账号，绑定信用卡即可激活一年的 Free Tier。免费额度覆盖大部分备考所需资源。</p><p>针对重要服务可以多练手，如EC2，S3，网络部分的服务。例如：</p><ul><li>启动EC2实例、配置安全组、SSH 连接、安装 web server；</li><li>S3： 上传下载对象、设置 bucket policy、版本控制等 ；</li><li>VPC + EC2 + S3 组合</li></ul><h2 id="高效笔记策略——记录与知识内化"><a href="#高效笔记策略——记录与知识内化" class="headerlink" title="高效笔记策略——记录与知识内化"></a>高效笔记策略——记录与知识内化</h2><p>入门阶段，你会被大量缩写词包围，各个云厂商的命名也不尽相同。例如，AWS 把云服务器叫作 EC2（Elastic Compute Cloud），阿里云则叫 ECS（Elastic Compute Service）。</p><p>网上中英文备考笔记俯拾皆是，官方白皮书更是全面，Stephane Maarek课程所提供的PPT干货满满。</p><p>但我仍强烈建议——<strong>用自己的话再写一遍</strong>。把别人的知识先嚼碎，再用自己的逻辑吐出来，记忆最深，理解也最透彻。</p><p>每个人的习惯不同，我习惯抓住几个点进行衍射：</p><h3 id="服务理解"><a href="#服务理解" class="headerlink" title="服务理解"></a>服务理解</h3><ul><li>是什么，有什么用？</li><li>在传统架构中对应什么服务？（这一步只是在初期帮助小白建立云原生的基础认知，后期应建立纯粹的云原生思维就不需要这一步骤了）</li><li>和别的服务如何组合，和其他服务的区别是什么？</li></ul><p>比如<strong>EC2</strong></p><ul><li>是什么：服务器，不过是在云上的服务器，你不需要再关注传统服务器的硬件等问题。</li><li>有什么用：跑网站、跑脚本、部署程序，物理服务器能干的它就能，物理服务器不能干的它也能，而且更加灵活。</li><li>之后再衍生到EC2的细节。</li></ul><h3 id="结构化记录"><a href="#结构化记录" class="headerlink" title="结构化记录"></a>结构化记录</h3><p>阶段性整理笔记，填充到学习大纲中。</p><h3 id="可视化输出"><a href="#可视化输出" class="headerlink" title="可视化输出"></a>可视化输出</h3><p>用一张图理清架构，用一张表分清差异</p><p>等你大致知道每个服务“干啥用”的时候，就要开始想它们<strong>怎么组合</strong>，以及两个相似产品的<strong>差异</strong>。 这里推荐draw.io绘制架构图，它提供了很多厂商的图标，如AWS、Cisco、Azure、Google等。</p><p>当你学习到网络这一部分时：</p><p>怎样做才能实现私有子网的 Internet 访问？</p><p>VPC和Internet之间相互通信可以用什么服务？</p><p>区域到区域、 可用区到可用区、私有到公有间的通信方式？</p><p>这时候，你可以通过架构图来帮助自己理解。</p><p><img src="/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/AWS-%E7%BD%91png.png" title="null"><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744653217-7fd7970f-3bd9-4e4c-bd8d-233e0d4504ba.png" title="我绘制的网络部分架构图"></p><p>那SG和NACL有什么区别，你可以通过表格来直观感受他们的相似和不同：</p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>特点 &#x2F; 注意事项</td><td>安全组 (SG)</td><td>网络访问控制列表 (NACL)</td></tr><tr><td>类型</td><td>instance级别防火墙</td><td>subnet级别防火墙</td></tr><tr><td>方向</td><td>可以配置入站和出站规则</td><td><strong>必须</strong>同时配置入站和出站规则</td></tr><tr><td>默认规则</td><td>拒绝所有流量</td><td>允许所有流量</td></tr><tr><td>有状态性</td><td>有状态，自动允许相关回复流量</td><td>无状态，入站和出站流量的状态是分开维护</td></tr><tr><td>数量限制</td><td>一个实例可以关联多个SG</td><td>一个子网只能关联一个NACL</td></tr><tr><td>功能</td><td>简单，易于使用</td><td>较为复杂，可用于更细粒度的控制</td></tr></tbody></table><h2 id="刷题"><a href="#刷题" class="headerlink" title="刷题"></a>刷题</h2><p><strong>懂产品 ≠ 会做题</strong>。传统选择题往往是选择正确答案，但AWS-SAA认证中，题干往往是：</p><ul><li>哪个服务在特定场景下最合适？</li><li>哪种方案最安全 &#x2F; 最省钱 &#x2F; 最少运维？</li></ul><p>许多考生常陷入一个认知误区：认为掌握AWS产品功能就等同于具备通过认证考试的能力。实际上，AWS认证考核的是一种更高阶的架构思维。考试设计的深层逻辑：</p><ul><li>场景化决策</li><li>可能没有绝对”正确”的答案，只有针对特定约束条件的”最优解”</li></ul><h3 id="刷题资源"><a href="#刷题资源" class="headerlink" title="刷题资源"></a>刷题资源</h3><p>主要使用 <strong>ExamTopics</strong>，官方目前题量超 1000 题。官方链接见文末[9]。</p><ul><li><strong>优点</strong>：<br>  题目质量接近考试真实难度，命中率高，国内大多数人选择该题库。我实际考试中碰到好几道原题。即使只刷了约 400 题精选题，收获也很大。国内也很容易找到整理好的中英双语版本，包括高频精选题、各种格式的 PDF 或表格，获取成本不高。</li><li><strong>缺点</strong>：<br>  个别题目存在答案争议，站内讨论和 AI 解读也无法统一。好在这类题占比极低，影响不大。</li></ul><p><strong>其他来源</strong><br>Udemy 的Practice Exams ：难度普遍高于真题，我评估后没有采用；</p><p>Whizlabs &#x2F; Tutorial Dojo（TD）： 解释详细，命中率略低于 ExamTopics ；</p><p>Ping-T：日语；</p><h3 id="刷题策略：高效规划你的学习路径"><a href="#刷题策略：高效规划你的学习路径" class="headerlink" title="刷题策略：高效规划你的学习路径"></a>刷题策略：高效规划你的学习路径</h3><p>个人刷题方法：每天 50 题左右，不求多但求精。做完一定会提炼每题的关键考点，错题或我觉得有意义的题进行归档，标注错因与正确思路；把相关知识点再复习一遍。我选择的是最适合自己的方式，也有很多人选择背题备考，速度更快。</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1753077463133-334e4d8b-3d34-4e65-89f7-106b9cc09867.png" title="当时的做题记录"></p><h3 id="刷题精髓：掌握这些技巧让效率倍增"><a href="#刷题精髓：掌握这些技巧让效率倍增" class="headerlink" title="刷题精髓：掌握这些技巧让效率倍增"></a>刷题精髓：掌握这些技巧让效率倍增</h3><p><strong>使用 AI 辅助学习：</strong><br>当你学完课程开始做题，最开始可能完全看不懂题干。不用担心，这很正常。此时你可以借助AI，让它向你解释。你需要10-20题的适应期来理解出题逻辑。</p><p><strong>适当总结记忆：</strong></p><ul><li><p>EBS 加密 → 想到 <strong>KMS</strong></p></li><li><p>移动&#x2F;网络应用程序身份验证 → 想到 <strong>Cognito</strong> 和 <strong>MFA</strong></p></li><li><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1753112096433-c0311260-b1ca-4687-9dfb-1df87d8f04f0.png" title="不同服务的延迟时间"></p></li></ul><p><strong>关键词识别技巧：</strong><br>当题目中出现 <strong>“细粒度”</strong> 时，要特别关注：</p><ul><li>是否仅授予特定实体（用户、角色、服务）<strong>最小必要权限</strong></li><li>是否限定权限只作用于<strong>特定资源</strong>，而不是整块服务或整个 bucket</li></ul><h3 id="实例解析：手把手教你做题"><a href="#实例解析：手把手教你做题" class="headerlink" title="实例解析：手把手教你做题"></a>实例解析：手把手教你做题</h3><p>一家公司使用在 Amazon EC2 实例上运行的 RESTful Web 服务应用程序从数千个远程设备收集数据。 EC2 实例接收原始数据，转换原始数据，并将所有数据存储在 Amazon S3存储桶中。远程设备的数量很快将增加到数百万。该公司需要一个<strong>高度可扩展</strong>的解决方案，<strong>最大限度地减少运维开销</strong>。</p><p>解决方案架构师应该采取哪些步骤<strong>组合</strong>来满足这些要求？ （选择两个。）</p><p>A. 使用 AWS Glue 处理 Amazon S3 中的原始数据。</p><p>B. 使用 Amazon Route 53 将流量路由到不同的 EC2 实例。</p><p>C. 添加更多 EC2 实例以适应不断增加的传入数据量。</p><p>D. 将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。</p><p>E. 使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流。配置 Amazon Kinesis Data Firehose 以使用数据流作为源将数据传输到 Amazon S3</p><p>简单来说就是有家公司将 Web 服务部署在 EC2 （云服务器）上，它会接收大量数据，然后做些处理，最后把结果存到 S3（一个对象存储服务），现在数据开始变多。</p><p>等你开始学习课程，你一定会捕捉到题干中很关键的两点：</p><ul><li><strong>高度可扩展， highly scalable,：需要能自动扩容的架构</strong></li><li><strong>减少运维开销：优先选择Serverless（无服务器）方案</strong></li></ul><p>目前业务架构：EC2 接收数据，EC2 处理数据，EC2 存入 S3</p><p><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744723175-04471ffc-e54e-490b-a6f1-3a1c98e45993.png" title="公司当前的业务架构"></p><p>接着我们了解一下选项中的服务：</p><ul><li>AWS Glue ：集成、转换和加载数据的服务。scalable，severless</li><li>Amazon Route 53：DNS 服务，用来解析域名</li><li>Amazon SQS：消息队列服务，缓冲流量、解耦系统。 scalable，severless</li><li>Amazon API Gateway：并将不同的后端服务整合到一个统一的接口中。自动扩容能力，无需关心并发数severless</li><li>Amazon Kinesis：<strong>完全托管</strong>的流数据处理服务。 scalable，severless</li></ul><p>这时候我们需要考虑，如何高效接收海量数据，如何处理这些数据。</p><ul><li><p>B选项：使用 Amazon Route 53 将流量路由到不同的 EC2 实例。</p></li><li><p>Amazon Route 53是 DNS 路由服务，不能直接处理请求或做负载均衡</p></li><li><p>C选项： 添加更多 EC2 实例以适应不断增加的传入数据量。</p></li><li><p>可扩展是可扩展，但搭 Auto Scaling之后，管理大量 EC2 实例会带来高昂的运维成本</p></li><li><p>D选项：将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。</p></li><li><p>SQS虽然解耦了流量，但仍然要运维 EC2实例</p></li></ul><p>现在我们来看一下选择AE之后，业务架构变成下图：</p><p><img src="/2025/07/15/AWS-SAA%E8%AE%A4%E8%AF%81%E5%85%A8%E6%94%BB%E7%95%A5/question.drawio.png" title="null"><img src="https://cdn.nlark.com/yuque/0/2025/png/58720042/1752744740911-0f5b4518-68d2-4203-ba5e-2856a6dd92c6.png" title="AE选项组合后的业务架构"></p><p>这时候，API Gateway 作为流量入口，<strong>动态应对高并发</strong>；</p><p>Kinesis Data Stream可<strong>动态扩展</strong>应对激增的请求量；</p><p>Firehose 从数据流中读取数据，然后写入 S3，<strong>无需人工干预，全自动交付</strong>；</p><p>S3存储原始数据，AWS Glue处理数据，<strong>完全托管无需运维</strong>。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>以上内容都是我的个人经验分享，不具备权威性，也可能因时间推移而有所滞后，仅供参考。</p><p>最后私心放上Stephane Maarek的几句话：</p><p>当开始学习并使用云服务时，你会遇到一些困难，你会尖叫：</p><p>Nothing is working - “aaaahhhhhh”</p><p>Don’t panic.</p><p>If you still don’t understand it, no worries, this is not a blocker for the course.</p><p>Keep on going, and come back to this concept towards the end.</p><p>这不仅是我入门云原生的起点，更让我切实感受到学习的快乐、魅力，还有一种近乎狂喜的兴奋。希望你也能够获得！</p><p>Happy learning!</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p>[1]AWS官网</p><p>aws.amazon.com</p><p>[2]AWS的认证信息</p><p><a href="https://aws.amazon.com/cn/certification/?nc2=h_ql_le_tc_c&ams%23interactive-card-vertical%23pattern-data.filter=%257B%2522filters%2522%253A%255B%255D%257D">https://aws.amazon.com/cn/certification/?nc2=h_ql_le_tc_c&amp;ams%23interactive-card-vertical%23pattern-data.filter=%257B%2522filters%2522%253A%255B%255D%257D</a></p><p>[3]AWS认证常见问题（包括重考政策，考试更新频率等）</p><p><a href="https://aws.amazon.com/cn/certification/faqs/">https://aws.amazon.com/cn/certification/faqs/</a></p><p>[4]考前、考中和考后的流程与要求</p><p><a href="https://aws.amazon.com/cn/certification/policies/">https://aws.amazon.com/cn/certification/policies/</a></p><p>[5]AWS-SAA的报考链接</p><p><a href="https://aws.amazon.com/cn/certification/certified-solutions-architect-associate/">https://aws.amazon.com/cn/certification/certified-solutions-architect-associate/</a></p><p>[6]AWS白皮书文档</p><p><a href="https://docs.aws.amazon.com/zh_cn/">https://docs.aws.amazon.com/zh_cn/</a></p><p>[7]官方提供的大纲（链接可直接下载PDF）</p><p><a href="https://d1.awsstatic.com/zh_CN/training-and-certification/docs-sa-assoc/">https://d1.awsstatic.com/zh_CN/training-and-certification/docs-sa-assoc/</a></p><p>[8]demy平台Stephane Maarek的《Ultimate AWS Certified Solutions Architect Associate》课程链接</p><p><a href="https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03/?couponCode=KEEPLEARNING">https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03/?couponCode=KEEPLEARNING</a></p><p>[9]examtopics链接</p><p><a href="https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/">https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;此篇文章源自我在WomenStack 百栈百胜公众号的一次分享，公众号文章链接附下，欢迎大家关注微信公众号WomenStack 百栈百胜&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzk4ODQ2NzkxOQ==&amp;mid=22</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>K8S-day1-初始化安装k8s集群的环境</title>
    <link href="https://sosocrown.github.io/2025/07/15/K8S-day1-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E7%9A%84%E7%8E%AF%E5%A2%83/"/>
    <id>https://sosocrown.github.io/2025/07/15/K8S-day1-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4%E7%9A%84%E7%8E%AF%E5%A2%83/</id>
    <published>2025-07-14T16:00:00.000Z</published>
    <updated>2025-07-15T09:54:19.412Z</updated>
    
    <content type="html"><![CDATA[<h1 id="初始化安装k8s集群的环境"><a href="#初始化安装k8s集群的环境" class="headerlink" title="初始化安装k8s集群的环境"></a>初始化安装k8s集群的环境</h1><h2 id="环境与注意事项"><a href="#环境与注意事项" class="headerlink" title="环境与注意事项"></a>环境与注意事项</h2><table><thead><tr><th>主机名</th><th>ip地址</th></tr></thead><tbody><tr><td>master</td><td>172.20.196.17</td></tr><tr><td>node1</td><td>172.20.196.18</td></tr><tr><td>node2</td><td>172.20.196.19</td></tr></tbody></table><ul><li>我用的是云服务器，故一部分操作不需要做。<br><img src="/images/ecs.png" alt="EC2"></li><li>操作过程可以通过ansible减少重复操作。</li><li>在每台机器安装基础软件包</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y device-mapper-persistent-data lvm2 wget net-tools nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel  python-devel epel-release openssh-server socat  ipvsadm conntrack telnet ipvsadm</span><br></pre></td></tr></table></figure><h2 id="1-配置静态ip地址"><a href="#1-配置静态ip地址" class="headerlink" title="1.  配置静态ip地址"></a>1.  配置静态ip地址</h2><p>  修改配置文件后重启网络服务</p><h2 id="2-修改主机名"><a href="#2-修改主机名" class="headerlink" title="2. 修改主机名"></a>2. 修改主机名</h2><p>分别修改三台主机名称</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname master &amp;&amp; bash </span><br></pre></td></tr></table></figure><h2 id="3-配置hosts文件"><a href="#3-配置hosts文件" class="headerlink" title="3. 配置hosts文件"></a>3. 配置hosts文件</h2><p><strong>配置主机hosts文件，相互之间通过主机名互相访问</strong><br>分别修改每台机器的&#x2F;etc&#x2F;hosts文件增加如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.20.196.17 master</span><br><span class="line">172.20.196.18 node1</span><br><span class="line">172.20.196.19 node2</span><br></pre></td></tr></table></figure><h2 id="4-免密登录"><a href="#4-免密登录" class="headerlink" title="4. 免密登录"></a>4. 免密登录</h2><p><strong>方便相互之前传文件</strong><br>生成密钥</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">一路回车</span><br></pre></td></tr></table></figure><p>传输公钥（master传给node-1，node-2，other。依次传给初自己外的机器）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id node1</span><br></pre></td></tr></table></figure><p>测试登录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# ssh node1</span><br><span class="line">Last login: Tue Jul 15 16:58:01 2025 from 120.238.191.115</span><br><span class="line"></span><br><span class="line">Welcome to Alibaba Cloud Elastic Compute Service !</span><br></pre></td></tr></table></figure><h2 id="5-关闭selinux"><a href="#5-关闭selinux" class="headerlink" title="5. 关闭selinux"></a>5. 关闭selinux</h2><p><strong>为什么要关闭selinux？</strong><br><strong>SELinux 是 Linux 系统的一种安全机制，可以限制系统资源（如文件、网络等）的访问，提高系统的安全性。在 Kubernetes 运行过程中，需要访问系统资源，但 SELinux 可能会限制访问，从而影响 Kubernetes 的运行。因此，在安装 Kubernetes 时，需要关闭 SELinux，以避免它对 Kubernetes 的影响。</strong></p><p>修改&#x2F;etc&#x2F;selinux&#x2F;config</p><h2 id="6-关闭swap分区"><a href="#6-关闭swap分区" class="headerlink" title="6. 关闭swap分区"></a>6. 关闭swap分区</h2><p>**Swap交换分区是一种在计算机中使用的虚拟内存技术。当物理内存不足以容纳当前运行的程序时，操作系统将会把一部分内存空间暂时转移到硬盘上，以便为当前程序提供运行所需的内存空间。这个过程就称为交换。**<strong>交换分区（Swap Partition）就是硬盘上专门预留给操作系统进行交换的一块空间。</strong></p><p><strong>交换分区的使用可以有效避免程序因为内存不足而崩溃或运行缓慢的问题，但是硬盘的读写速度比内存要慢得多，因此交换分区的使用会对系统的性能产生一定的影响。</strong></p><p><strong>在 Kubernetes 运行过程中，需要频繁地使用内存和磁盘等系统资源。如果使用了交换分区，会导致 Kubernetes 的运行速度变慢，从而影响整个集群的性能。因此，在安装 Kubernetes 时，通常会建议关闭交换分区。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# swapoff -a</span><br><span class="line"></span><br><span class="line">#永久关闭：注释swap挂载，给swap这行开头加注释</span><br><span class="line">[root@master ~]# vim /etc/fstab </span><br><span class="line">#/dev/mapper/centos-swap swap      swap    defaults        0 0</span><br></pre></td></tr></table></figure><h2 id="7-修改机器内核参数"><a href="#7-修改机器内核参数" class="headerlink" title="7. 修改机器内核参数"></a>7. 修改机器内核参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# modprobe br_netfilter</span><br><span class="line"></span><br><span class="line">#modprobe br_netfilter 的作用是将 br_netfilter 模块添加到 Linux 内核中。这个模块是 Linux 网桥的核心模块，它提供了网络包转发和过滤的功能</span><br><span class="line"></span><br><span class="line">[root@master ~]# vim /etc/sysctl.d/k8s.conf </span><br><span class="line">输入如下内容：</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1    #启用ipv6数据包的过滤和处理</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1   #启用ipv4数据包的过滤和处理</span><br><span class="line">net.ipv4.ip_forward = 1   #启用了  IP 转发功能</span><br><span class="line"></span><br><span class="line">[root@master ~]# sysctl -p /etc/sysctl.d/k8s.conf</span><br></pre></td></tr></table></figure><h2 id="8-关闭防火墙"><a href="#8-关闭防火墙" class="headerlink" title="8. 关闭防火墙"></a>8. 关闭防火墙</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# systemctl stop firewalld</span><br><span class="line">[root@master ~]# systemctl disable firewalld</span><br></pre></td></tr></table></figure><h2 id="9-配置repo源"><a href="#9-配置repo源" class="headerlink" title="9. 配置repo源"></a>9. 配置repo源</h2><h2 id="10-时间同步"><a href="#10-时间同步" class="headerlink" title="10. 时间同步"></a>10. 时间同步</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#安装ntpdate命令</span><br><span class="line">[root@master ~]# yum install ntpdate -y</span><br><span class="line">#跟网络时间做同步</span><br><span class="line">[root@master ~]# ntpdate cn.pool.ntp.org</span><br><span class="line">#把时间同步做成计划任务</span><br><span class="line">[root@master ~]# crontab -e</span><br><span class="line">* *  * * * /usr/sbin/ntpdate   cn.pool.ntp.org</span><br><span class="line">[root@master ~]# systemctl restart crond</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;初始化安装k8s集群的环境&quot;&gt;&lt;a href=&quot;#初始化安装k8s集群的环境&quot; class=&quot;headerlink&quot; title=&quot;初始化安装k8s集群的环境&quot;&gt;&lt;/a&gt;初始化安装k8s集群的环境&lt;/h1&gt;&lt;h2 id=&quot;环境与注意事项&quot;&gt;&lt;a href=&quot;#环境</summary>
      
    
    
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="k8s" scheme="https://sosocrown.github.io/categories/%E6%8A%80%E6%9C%AF/k8s/"/>
    
    
    <category term="kubenates" scheme="https://sosocrown.github.io/tags/kubenates/"/>
    
    <category term="运维" scheme="https://sosocrown.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>WSL-Windows Subsystem for Linux</title>
    <link href="https://sosocrown.github.io/2025/05/06/WSL/"/>
    <id>https://sosocrown.github.io/2025/05/06/WSL/</id>
    <published>2025-05-05T16:00:00.000Z</published>
    <updated>2025-08-05T06:28:08.429Z</updated>
    
    <content type="html"><![CDATA[<h1 id="WSL-Windows-Subsystem-for-Linux"><a href="#WSL-Windows-Subsystem-for-Linux" class="headerlink" title="WSL-Windows Subsystem for Linux"></a>WSL-Windows Subsystem for Linux</h1><h4 id="wsl是什么？"><a href="#wsl是什么？" class="headerlink" title="wsl是什么？"></a>wsl是什么？</h4><p>适用于Windows的Linux子系统，可以在windows下运行linux操作系统。</p><ol><li>轻量：不像虚拟机那样吃内存，不跑完整 Linux 系统，运行速度快，资源占用少</li><li>无缝：能和 Windows 系统共享文件、剪贴板、网络</li><li>无需虚拟机：不需要装 VMware、VirtualBox，也不用重启，直接在 Win 下跑 Linux</li><li>开发友好：支持绝大多数 Linux 工具链（如 apt、git、docker、conda 等），尤其适合开发者</li></ol><h4 id="wsl用来干什么"><a href="#wsl用来干什么" class="headerlink" title="wsl用来干什么"></a>wsl用来干什么</h4><h4 id="安装教程"><a href="#安装教程" class="headerlink" title="安装教程"></a>安装教程</h4><p><a href="https://blog.csdn.net/u011119817/article/details/130745551?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522ae299346a694700a68e917c31739a4f5%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=ae299346a694700a68e917c31739a4f5&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-130745551-null-null.142%5Ev102%5Epc_search_result_base3&utm_term=wsl%E5%AE%89%E8%A3%85&spm=1018.2226.3001.4187">windows11 安装WSL2全流程_wsl2安装-CSDN博客</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;WSL-Windows-Subsystem-for-Linux&quot;&gt;&lt;a href=&quot;#WSL-Windows-Subsystem-for-Linux&quot; class=&quot;headerlink&quot; title=&quot;WSL-Windows Subsystem for Linu</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>a glass of Baileys</title>
    <link href="https://sosocrown.github.io/2025/05/06/a%20glass%20of%20Baileys/"/>
    <id>https://sosocrown.github.io/2025/05/06/a%20glass%20of%20Baileys/</id>
    <published>2025-05-05T16:00:00.000Z</published>
    <updated>2025-05-06T10:23:38.366Z</updated>
    
    <content type="html"><![CDATA[<p>The Labor Day holiday ended.<br>I was on a delayed flight back to Guangzhou when I saw the news—Joan had passed away.<br>She chose to leave before summer even began.</p><p>The meaninglessness of work, of career, of life itself—and the grief of her death—<strong>haunt me.</strong></p><p>A line from a movie has been echoing in my head:</p><blockquote><p><em>Is life always this hard, or is it just when you’re a kid?</em><br><em>Always like this.</em></p></blockquote><p>I rewrote it into something that belongs to me now:</p><blockquote><p><em>Is work always this hard, or is it just because I’m in this place?</em></p></blockquote><p>I’ve been enduring.<br>Enduring the performance of working life.<br>Enduring the unspoken rule that <em>if you’re not exhausted, you’re not working hard enough.</em><br>I’m anxious. I’m overwhelmed. I’m becoming unrecognizable to myself.</p><p>And still, people keep telling me,</p><blockquote><p><em>“You’re already so lucky.”</em></p></blockquote><p>Just like the comments under Joan’s old videos:</p><blockquote><p><em>“You’re so beautiful, so talented, so brilliant.”</em></p></blockquote><p>But none of those words can save you.<br>They can’t protect you from the quiet truth that <strong>some of us simply can’t live in blurred, diluted versions of life.</strong><br>That clarity—too much of it—hurts.</p><p>Sometimes I wonder:<br>Is it naïve to still want growth, meaning, and selfhood through work?</p><p>I don’t know.</p><p>But I do know this:</p><p>This job, this system, this culture—<br>is not where my soul belongs.</p><p>Summer has come, Joan<br>And I want to drink a glass of Baileys </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;The Labor Day holiday ended.&lt;br&gt;I was on a delayed flight back to Guangzhou when I saw the news—Joan had passed away.&lt;br&gt;She chose to lea</summary>
      
    
    
    
    <category term="flee as a bird to your mountain" scheme="https://sosocrown.github.io/categories/flee-as-a-bird-to-your-mountain/"/>
    
    
    <category term="life" scheme="https://sosocrown.github.io/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>git</title>
    <link href="https://sosocrown.github.io/2025/02/08/git-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"/>
    <id>https://sosocrown.github.io/2025/02/08/git-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/</id>
    <published>2025-02-08T07:48:57.013Z</published>
    <updated>2025-05-07T02:38:47.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Git-是分布式版本控制系统。"><a href="#Git-是分布式版本控制系统。" class="headerlink" title="Git 是分布式版本控制系统。"></a>Git 是分布式版本控制系统。</h1><p><img src="/images/git.png" alt="Untitled"></p><h1 id="版本控制-Revision-control"><a href="#版本控制-Revision-control" class="headerlink" title="版本控制-Revision control"></a>版本控制-Revision control</h1><p>在开发的过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份以便恢复以前的版本的软件工程技术。</p><p>主流的版本控制器有如下这些：</p><ul><li><strong>Git</strong></li><li><strong>SVN</strong>（Subversion）</li><li><strong>CVS</strong>（Concurrent Versions System）</li><li><strong>VSS</strong>（Micorosoft Visual SourceSafe）</li><li><strong>TFS</strong>（Team Foundation Server）</li><li>Visual Studio Online</li></ul><h2 id="版本控制分类"><a href="#版本控制分类" class="headerlink" title="版本控制分类"></a>版本控制分类</h2><h3 id="1、本地版本控制"><a href="#1、本地版本控制" class="headerlink" title="1、本地版本控制"></a><strong>1、本地版本控制</strong></h3><p>记录文件每次的更新，可以对每个版本做一个快照，或是记录补丁文件，适合个人用，如RCS。</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0Dg3fHrbPqbNEOMO9GTjFhVaukMZWx54icS7eS2x8A7BEu0VB9ibwEhzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0Dg3fHrbPqbNEOMO9GTjFhVaukMZWx54icS7eS2x8A7BEu0VB9ibwEhzQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><h3 id="2、集中版本控制-SVN"><a href="#2、集中版本控制-SVN" class="headerlink" title="2、集中版本控制  SVN"></a><strong>2、集中版本控制  SVN</strong></h3><p>所有的版本数据都保存在服务器上，协同开发者从服务器上同步更新或上传自己的修改</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p00V4uLaibxtZI9RLpq7tkSdlWiaF92AVeZ0ib9DicqBkS2poo5u8sEU2mCQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p00V4uLaibxtZI9RLpq7tkSdlWiaF92AVeZ0ib9DicqBkS2poo5u8sEU2mCQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><p>所有的版本数据都存在服务器上，用户的本地只有自己以前所同步的版本，如果不连网的话，用户就看不到历史版本，也无法切换版本验证问题，或在不同分支工作。</p><p>而且，所有数据都保存在单一的服务器上，有很大的风险这个服务器会损坏，这样就会丢失所有的数据，当然可以定期备份。代表产品：SVN、CVS、VSS</p><h3 id="3、分布式版本控制-Git"><a href="#3、分布式版本控制-Git" class="headerlink" title="3、分布式版本控制 Git"></a><strong>3、分布式版本控制 Git</strong></h3><h3 id="服务器断网也可以开发，且每个客户端都保存着完整代码"><a href="#服务器断网也可以开发，且每个客户端都保存着完整代码" class="headerlink" title="服务器断网也可以开发，且每个客户端都保存着完整代码"></a>服务器断网也可以开发，且每个客户端都保存着完整代码</h3><p>每个人都拥有全部的代码！安全隐患！</p><p>所有版本信息仓库全部同步到本地的每个用户，这样就可以在本地查看所有版本历史，可以离线在本地提交，只需在连网时push到相应的服务器或其他用户那里。由于每个用户那里保存的都是所有的版本数据，只要有一个用户的设备没有问题就可以恢复所有的数据，但这增加了本地存储空间的占用。</p><p>不会因为服务器损坏或者网络问题，造成不能工作的情况！</p><p><a href="https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0ev8Q7qXjsTfeSwFexdA4tGjFAiaVEKQzAHdGcINXILKflI2cfk9BiawQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">https://mmbiz.qpic.cn/mmbiz_png&#x2F;uJDAUKrGC7Ksu8UlITwMlbX3kMGtZ9p0ev8Q7qXjsTfeSwFexdA4tGjFAiaVEKQzAHdGcINXILKflI2cfk9BiawQ&#x2F;640?wx_fmt&#x3D;png&amp;wxfrom&#x3D;5&amp;wx_lazy&#x3D;1&amp;wx_co&#x3D;1</a></p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h1><h2 id="三个区域"><a href="#三个区域" class="headerlink" title="三个区域"></a>三个区域</h2><ul><li><p><strong>工作区（Working Directory或Workspace）</strong>：看到的目录，平时存放项目代码的地方</p></li><li><p><strong>暂存区（Stage&#x2F;Index）</strong>：英文名stage或者index，用于准备提交的文件区域。</p><ul><li>一般存放在**<code>.git</code>**目录下index文件中，所以也称为索引index</li></ul></li><li><p><strong>仓库（Repository或Git Directory）</strong>：用于存储项目的所有文件和历史记录。</p><ul><li>通常存储在项目根目录的 <strong><code>.git</code></strong> 子目录中。</li><li>其中**<code>HEAD</code>**指向最新放入仓库的版本</li></ul><p>  <img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/627d280e-15d4-47b3-997b-8a0ec484a12d/Untitled.png" alt="Untitled"></p></li></ul><p>**远程的git仓库(Remote Directory)：**存储在远程服务器上的仓库副本，用于多人协作和备份。你可以使用 <strong><code>git push</code></strong> 命令将本地仓库的内容推送到远程仓库，也可以使用 <strong><code>git pull</code></strong> 命令从远程仓库拉取最新的更改。</p><h2 id="git-工作流程"><a href="#git-工作流程" class="headerlink" title="git 工作流程"></a>git <strong>工作流程</strong></h2><ul><li><p><strong>工作区 -&gt; 暂存区 -&gt; 本地仓库 -&gt; 远程仓库</strong></p></li><li><p>工作区：代码存放的位置。在工作区可以修改代码，且没有历史记录；</p></li><li><p>暂存区：将工作区的代码 添加(<code>git add</code>) 到暂存区，也可以修改代码并且没有历史记录；</p></li><li><p>本地库：将暂存区的代码提交 (<code>git commit</code>) 到本地库，就会生成历史版本。在本地库的版本不能修改。若发现代码不尽人意，只能在工作区修改后再次提交，此时本地库同时存在这两个版本。例如，先提交了 v1 版本，发现不好，则只能在 v1 版本基础上修改然后提交为 v2；</p></li><li><p>代码托管中心（远程库）：将本地库的代码推送 (<code>git push</code>) 至远程库。</p><p>  <img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/108604d8-e083-4eee-87e5-aae75338e618/Untitled.png" alt="Untitled"></p></li></ul><p>文件在这四个区域之间的转换关系如下：</p><h2 id="git-文件状态"><a href="#git-文件状态" class="headerlink" title="git 文件状态"></a>git 文件状态</h2><p><strong>查看工作区的文件状态</strong><code>git status</code></p><ol><li><strong>未追踪（Untracked）</strong>：<ul><li>这是指在Git仓库中没有记录的文件。这些文件存在于工作区中，但尚未被添加到Git的版本控制中。</li></ul></li><li><strong>已暂存（Staged）</strong>：<ul><li>这是指将工作区中的文件添加到了暂存区（也叫索引）中，表示你打算在下一次提交中包括这些更改。</li></ul></li><li><strong>已修改（Modified）</strong>：<ul><li>这是指已经修改了某个文件，但尚未将这些更改添加到暂存区。</li></ul></li><li><strong>已提交（Committed）</strong>：<ul><li>这是指已经将文件的更改保存到了本地版本库中。</li></ul></li></ol><h2 id="git分支-Branch"><a href="#git分支-Branch" class="headerlink" title="git分支-Branch"></a>git<strong>分支-Branch</strong></h2><p>分支（Branch）是用来开发新功能或修复错误的独立工作流。它允许你将工作从主线（通常是**<code>master</code>**分支）中分离出来，以便不会影响到主线上的其他开发工作。</p><p>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作</p><p>工作一般情况下在新建的dev分支上工作，dev分支代码稳定后可以合并到主分支master上来。</p><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/38ae47d3-468a-4d9a-9bda-71a05d71ccfa/Untitled.png" alt="Untitled"></p><p>多个分支：用户分支，测试分支，开发分支…… 不同分支互不干扰，可以同时推进，完成开发后就可以进行分支合并（在用户看来就是更新）。分支底层就是指针的引用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出所有本地分支</span></span><br><span class="line">git branch</span><br><span class="line"><span class="comment">#这会列出所有可用的分支，并用一个**星号标记当前所在的分支**。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有远程分支</span></span><br><span class="line">git branch -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支</span></span><br><span class="line">git branch [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，并切换到该分支</span></span><br><span class="line">git checkout -b [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment">#切换分支</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并指定分支到当前分支</span></span><br><span class="line">$ git merge [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment">#将dev分支合并到master分支</span></span><br><span class="line">git merge dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除分支</span></span><br><span class="line">$ git branch -d [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">$ git push origin --delete [branch-name]</span><br><span class="line">$ git branch -dr [remote/branch]</span><br></pre></td></tr></table></figure><h2 id="解决冲突"><a href="#解决冲突" class="headerlink" title="解决冲突"></a><strong>解决冲突</strong></h2><ul><li>在合并分支时，如果Git无法自动合并，会产生冲突。需要手动解决冲突后再提交。</li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="创建仓库"><a href="#创建仓库" class="headerlink" title="创建仓库"></a>创建仓库</h3><ol><li><p>本地仓库搭建</p></li><li><p>克隆远程仓库：克隆远程目录，由于是将远程服务器上的仓库完全镜像一份至本地</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1.初始化</span><br><span class="line"></span><br><span class="line">git init <span class="comment"># 初始化仓库</span></span><br><span class="line">git <span class="built_in">clone</span> <span class="comment"># 拷贝一份远程仓库，也就是下载一个项目</span></span><br><span class="line"></span><br><span class="line">git init --bare shell.git</span><br><span class="line">git init 是 Git 的一个命令，用于初始化一个新的 Git 仓库。</span><br><span class="line">--bare 是一个选项，它告诉 Git 创建一个裸仓库</span><br><span class="line">  也就是不包含工作区（Working Directory）的仓库。**裸仓库只包含版本历史记录。**</span><br><span class="line">shell.git 是你为新仓库选择的名称，实际上就是仓库的目录名。</span><br><span class="line"></span><br><span class="line">2.克隆</span><br><span class="line">git <span class="built_in">clone</span> &lt;https://github.com/repository.git&gt;</span><br><span class="line"><span class="comment">#URL克隆</span></span><br><span class="line">git <span class="built_in">clone</span> git@github.com:username/repository.git</span><br><span class="line"><span class="comment">#SSH协议来进行克隆</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="提交与修改"><a href="#提交与修改" class="headerlink" title="提交与修改"></a>提交与修改</h3><p>在工作区commit</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">git add <span class="comment"># 添加文件到暂存区</span></span><br><span class="line">git status <span class="comment"># 查看仓库当前的状态，显示有变更的文件</span></span><br><span class="line"></span><br><span class="line">git diff <span class="comment"># 比较文件的不同，即暂存区和工作区的差异</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">&quot;commit message&quot;</span> <span class="comment"># 提交暂存区到本地仓库</span></span><br><span class="line"></span><br><span class="line">git reset <span class="comment"># 回退版本</span></span><br><span class="line">git <span class="built_in">rm</span> <span class="comment"># 删除工作区文件</span></span><br><span class="line">git <span class="built_in">mv</span> <span class="comment"># 移动或重命名工作区文件</span></span><br></pre></td></tr></table></figure><p>提交日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span> <span class="comment"># 查看历史提交记录</span></span><br><span class="line">git blame&lt;file&gt; <span class="comment"># 以列表形式查看指定文件的历史修改记录</span></span><br><span class="line">远程操作</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Git-是分布式版本控制系统。&quot;&gt;&lt;a href=&quot;#Git-是分布式版本控制系统。&quot; class=&quot;headerlink&quot; title=&quot;Git 是分布式版本控制系统。&quot;&gt;&lt;/a&gt;Git 是分布式版本控制系统。&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux 内核--Cgroup与namespace</title>
    <link href="https://sosocrown.github.io/2025/02/08/Linux%20%E5%86%85%E6%A0%B8--Cgroup%E4%B8%8Enamespace/"/>
    <id>https://sosocrown.github.io/2025/02/08/Linux%20%E5%86%85%E6%A0%B8--Cgroup%E4%B8%8Enamespace/</id>
    <published>2025-02-08T07:43:55.000Z</published>
    <updated>2025-05-07T02:38:58.078Z</updated>
    
    <content type="html"><![CDATA[<h2 id="容器-cgroup-namespace-rootfs-容器引擎"><a href="#容器-cgroup-namespace-rootfs-容器引擎" class="headerlink" title="容器 &#x3D; cgroup + namespace + rootfs + 容器引擎"></a>容器 &#x3D; cgroup + namespace + rootfs + 容器引擎</h2><p>容器的核心技术是 <strong>Cgroup</strong> + <strong>Namespace</strong></p><ul><li>​Cgroup： 资源控制 </li><li>​namespace： 访问隔离</li><li>​rootfs：文件系统隔离。镜像的本质就是一个rootfs文件</li><li>​容器引擎：生命周期控制</li></ul><p><strong>cgroup（控制组）和namespace（命名空间）</strong> 是 Linux 内核中的两个核心技术，主要用于实现<strong>资源管理</strong>和<strong>环境隔离</strong>，它们是容器技术（如 Docker）的底层基础。</p><hr><h3 id="cgroup（控制组）："><a href="#cgroup（控制组）：" class="headerlink" title="cgroup（控制组）："></a><strong>cgroup（控制组）：</strong></h3><p><strong>核心作用</strong>：<strong>限制、分配和监控进程的资源使用</strong>，比如 CPU、内存、磁盘 I&#x2F;O 等。</p><ul><li><strong>作用：</strong> 通过cgroup，系统管理员可以为一组进程分配资源，并限制它们对系统资源的使用。这对于实现资源隔离和管理是很有用的，特别是在容器化环境中，可以确保容器之间不会相互干扰，同时允许对资源进行有效的分配和控制。</li></ul><h3 id="namespace（命名空间）："><a href="#namespace（命名空间）：" class="headerlink" title="namespace（命名空间）："></a><strong>namespace（命名空间）：</strong></h3><p>命名空间是 Linux 内核提供的一种隔离机制，用于<strong>隔离</strong>容器的进程和文件系统等。</p><ul><li><strong>作用：</strong> 命名空间提供了一种隔离的手段，使得进程可以在一个独立的环境中运行，与其他命名空间中的进程隔离开。常用的命名空间包括 PID（进程 ID）、NET（网络）、UTS（主机名和域名）、IPC（进程间通信）、MNT（挂载点）等。在容器技术中，命名空间是实现容器隔离的基础，使得容器内的进程和资源与主机及其他容器隔离开。</li></ul><hr><h3 id="cgroup-vs-namespace-的区别"><a href="#cgroup-vs-namespace-的区别" class="headerlink" title="cgroup vs namespace 的区别"></a>cgroup vs namespace 的区别</h3><table><thead><tr><th><strong>特性</strong></th><th><strong>cgroup</strong></th><th><strong>namespace</strong></th></tr></thead><tbody><tr><td><strong>核心目标</strong></td><td>限制资源用量（如 CPU、内存）</td><td>隔离资源视图（如进程、网络）</td></tr><tr><td><strong>关注点</strong></td><td><strong>资源控制</strong></td><td><strong>环境隔离</strong></td></tr><tr><td><strong>类比</strong></td><td>给进程分配“资源配额”</td><td>给进程创造一个“独立房间”</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;容器-cgroup-namespace-rootfs-容器引擎&quot;&gt;&lt;a href=&quot;#容器-cgroup-namespace-rootfs-容器引擎&quot; class=&quot;headerlink&quot; title=&quot;容器 &amp;#x3D; cgroup + namespace +</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/linux/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
    <category term="容器" scheme="https://sosocrown.github.io/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>SElinux-安全上下文</title>
    <link href="https://sosocrown.github.io/2025/01/21/SElinux-%E5%AE%89%E5%85%A8%E4%B8%8A%E4%B8%8B%E6%96%87/"/>
    <id>https://sosocrown.github.io/2025/01/21/SElinux-%E5%AE%89%E5%85%A8%E4%B8%8A%E4%B8%8B%E6%96%87/</id>
    <published>2025-01-21T08:59:08.643Z</published>
    <updated>2025-05-07T02:39:16.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SElinux-Security-Enhanced-Linux-安全增强型-linux"><a href="#SElinux-Security-Enhanced-Linux-安全增强型-linux" class="headerlink" title="SElinux-Security-Enhanced Linux 安全增强型 linux"></a>SElinux-Security-Enhanced Linux 安全增强型 linux</h2><p>Linux系统安全的强制访问控制体系</p><h3 id="三种配置模式"><a href="#三种配置模式" class="headerlink" title="三种配置模式"></a>三种配置模式</h3><ol><li>selinux的配置文件：&#x2F;etc&#x2F;sysconfig&#x2F;selinux</li></ol><table><thead><tr><th>状态</th><th>含义</th></tr></thead><tbody><tr><td>enforcing</td><td>级别为强制</td></tr><tr><td>permissive</td><td>级别为警告</td></tr><tr><td>disable</td><td>关闭</td></tr></tbody></table><ol start="2"><li>模式管理</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看当前工作模式</span></span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line"></span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Enforcing</span><br><span class="line"><span class="comment"># 临时关闭进入宽容模式</span></span><br><span class="line">[root@server ~]# setenforce  0  </span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Permissive</span><br><span class="line"> <span class="comment"># 临时开启</span></span><br><span class="line">[root@server ~]# setenforce  1 </span><br><span class="line">[root@server ~]# getenforce</span><br><span class="line">Enforcing</span><br><span class="line"></span><br><span class="line"><span class="comment">#永久性关闭</span></span><br><span class="line">[root@server ~]# vim  /etc/selinux/config </span><br><span class="line">SELINUX=disabled    </span><br></pre></td></tr></table></figure><p><code>注意</code>：enforceing与permissive二者可以直接进行切换，但是关闭selinux（disabled）进行切换时要重启reboot</p><h3 id="安全上下文（security-context）"><a href="#安全上下文（security-context）" class="headerlink" title="安全上下文（security context）"></a><strong>安全上下文（security context）</strong></h3><ul><li>所有进程、文件和目录都有自己的安全上下文</li><li>进程是否能够访问文件或目录，就要其安全上下文是否匹配</li></ul><p><strong>安全上下文用冒号分为四个字段：Identify：role：type：</strong></p><ul><li>身份标识（Identify）：相当于账号方面的身份标识，主要有以下三种常见的类型：<ul><li>root：表示root的账号身份；</li><li>system_u：表示程序方面的标识，通常就是进程</li><li>unconfined_u：代表的是一般用户账号相关的身份。</li></ul></li><li>角色（role）：通过角色字段，可知道这个数据是属于程序、文件资源还是代表用户。一般角色有：<ul><li>object_r：代表的是文件或目录等文件资源；</li><li>system_r：代表的是进程。</li></ul></li><li><strong>类型（type）：</strong><ul><li>type：在文件资源上面称为类型。</li><li>domain：在主体程序中则称为域。domain需要与type搭配，则该程序才能够顺利读取文件资源。</li></ul></li><li>最后一个字段是和MLS和MCS相关的东西，代表灵敏度，一般用s0、s1、s2来命名，数字代表灵敏度的分级。数值越大、灵敏度越高。</li></ul><p><strong>查看安全上下文</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> -Z</span><br></pre></td></tr></table></figure><p><strong>chcon手动修改文件的SELinux类型</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chcon</span> [-R] [-t <span class="built_in">type</span>] [-u user] [-r role] 文件</span><br><span class="line"><span class="built_in">chcon</span> [-R] --reference=范例文件 文件</span><br><span class="line">选项：</span><br><span class="line">-R：连同该目录下的子目录也同时修改</span><br><span class="line">-t：后面接安全上下文的类型栏位，例如httpd_sys_content_t</span><br><span class="line">-u：后面接身份识别，例如system_u</span><br><span class="line">-r：后面接角色，例如 system_r</span><br><span class="line">-v：若有变化成功，请将变动的结果列出来</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>restorecon让文件恢复正确的SELinux类型</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">restorecon [-Rv] 文件目录</span><br><span class="line">选项：</span><br><span class="line">-R：连同子目录一起修改</span><br><span class="line">-v：将过程显示到屏幕</span><br></pre></td></tr></table></figure><p><strong>semanage默认目录的安全上下文查询与修改</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# yum -y install policycoreutils-python semanage</span><br><span class="line"></span><br><span class="line">semanage 选项 参数  文件</span><br><span class="line"></span><br><span class="line">选项：</span><br><span class="line">login</span><br><span class="line">user</span><br><span class="line">port</span><br><span class="line">interface</span><br><span class="line">fcontext  <span class="comment">#注意：fcontext查询默认安全上下文（重要）</span></span><br><span class="line">translation</span><br><span class="line">boolean</span><br><span class="line">参数：</span><br><span class="line"> -l :查询；</span><br><span class="line"> -a :添加</span><br><span class="line"> -m :修改</span><br><span class="line"> -d :删除</span><br><span class="line"> -t :类型</span><br><span class="line"> -r :角色</span><br><span class="line"> -s :用户</span><br><span class="line"> -f :文件</span><br><span class="line">文件：</span><br><span class="line">文件或目录</span><br><span class="line"></span><br><span class="line">semanage  fcontext  -l |  grep  文件名</span><br><span class="line">semanage  port  -l  |  grep  协议</span><br><span class="line">semanage port -a -t http_port_t  -p  tcp  7777 <span class="comment"># 添加新端口</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例1 查询一下/etc/  /etc/cron.d默认的SELinux类型是什么</span></span><br><span class="line">[root@chenshiren ~]# semanage  fcontext -l |grep -E <span class="string">&#x27;^/etc|^/etc/cron&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>实验1</strong></li></ul>]]></content>
    
    
    <summary type="html">&quot;Linux系统安全的强制访问控制体系&quot;</summary>
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/linux/"/>
    
    
    <category term="运维" scheme="https://sosocrown.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>文件系统与磁盘管理</title>
    <link href="https://sosocrown.github.io/2025/01/21/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"/>
    <id>https://sosocrown.github.io/2025/01/21/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/</id>
    <published>2025-01-21T08:59:08.631Z</published>
    <updated>2025-05-07T02:39:09.625Z</updated>
    
    <content type="html"><![CDATA[<p><strong>disk -&gt; partition -&gt; PV -&gt; VG -&gt; LV -&gt; fs</strong></p><p><strong>磁盘-&gt;分区-&gt;物理卷-&gt;卷组-&gt;逻辑卷-&gt;文件系统。</strong><br>![[&#x2F;images&#x2F;disk.drawio.png]]</p><h4 id="文件系统-File-System"><a href="#文件系统-File-System" class="headerlink" title="文件系统 File System"></a>文件系统 <strong>File System</strong></h4><ol><li>EXT4：EXT4是Linux默认文件系统</li><li>XFS</li><li><strong>SWAP</strong>：交换文件系统，相当于虚拟内存</li></ol><h4 id="df"><a href="#df" class="headerlink" title="df"></a>df</h4><p>列出文件系统的整体磁盘使用量</p><p>df -h</p><h4 id="du"><a href="#du" class="headerlink" title="du"></a>du</h4><p>检查磁盘空间使用量</p><h4 id="lsblk"><a href="#lsblk" class="headerlink" title="lsblk"></a>lsblk</h4><ul><li>列出块设备的信息，包括磁盘和分区。它以树状结构显示</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出当前系统所有磁盘与磁盘内的分区信息</span></span><br><span class="line">[root@master ~]# lsblk</span><br><span class="line">NAME              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                 8:0    0   20G  0 disk</span><br><span class="line">├─sda1              8:1    0    1G  0 part /boot</span><br><span class="line">└─sda2              8:2    0   19G  0 part</span><br><span class="line">  ├─centos-root   253:0    0   17G  0 lvm  /</span><br><span class="line">  └─centos-swap   253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">sdb                 8:16   0  100G  0 disk</span><br><span class="line">├─datavg-data1_lv 253:2    0   45G  0 lvm</span><br><span class="line">└─datavg-data2_lv 253:3    0  200M  0 lvm</span><br><span class="line">sr0                11:0    1  9.5G  0 rom</span><br><span class="line"></span><br><span class="line"><span class="comment">#sda1：sd代表SCSI磁盘，a代表第一块磁盘，1代表第一个分区</span></span><br><span class="line"><span class="comment">#sdb：sd代表SCSI磁盘，b代表第二块磁盘，1代表第一个分区</span></span><br><span class="line"><span class="comment">#解释：</span></span><br><span class="line">NAME <span class="comment">#设备名称</span></span><br><span class="line">MAJ:MIN <span class="comment">#主设备号:次设备号，内核通过主次设备号识别磁盘</span></span><br><span class="line">RM <span class="comment">#是否为可卸载设备，1可卸载，0不可卸载</span></span><br><span class="line">SIZE <span class="comment">#设备的容量大小</span></span><br><span class="line">RO <span class="comment">#表示设备是否为只读，0非只读设备，1只读设备</span></span><br><span class="line">TYPE <span class="comment">#表示设备类型（disk为磁盘，part为分区，lvm逻辑卷，rom只读）</span></span><br><span class="line">MOUNTPOINT <span class="comment">#设备挂载点（SWAP没有挂载点）</span></span><br><span class="line"></span><br><span class="line">lsblk -f <span class="comment">##列出所有磁盘分区内使用的文件系统类型</span></span><br></pre></td></tr></table></figure><h2 id="磁盘分区"><a href="#磁盘分区" class="headerlink" title="磁盘分区"></a>磁盘分区</h2><ul><li>**分区过程：**添加新硬盘–分区–格式化文件系统–挂载使用</li></ul><h3 id="1-fdisk-磁盘分区"><a href="#1-fdisk-磁盘分区" class="headerlink" title="1.fdisk-磁盘分区"></a>1.fdisk-磁盘分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br><span class="line">**m <span class="comment">#获取命令帮助 ※**</span></span><br><span class="line">**p <span class="comment">#显示磁盘分区表 ※**</span></span><br><span class="line">**n <span class="comment">#新增加一个分区 ※**</span></span><br><span class="line">q <span class="comment">#不保存分区退出 ※</span></span><br><span class="line">d <span class="comment">#删除一个分区 ※</span></span><br><span class="line">**w <span class="comment">#保存分区退出 ※  记得保存**   </span></span><br><span class="line">a <span class="comment">#设置可引导标记</span></span><br><span class="line">b <span class="comment">#编辑bsd磁盘标签</span></span><br><span class="line">c <span class="comment">#设置DOS操作系统兼容标记</span></span><br><span class="line">l <span class="comment">#显示已知的文件系统类型，82为swap交换分区，83为Linux分区</span></span><br><span class="line">o <span class="comment">#建立空白DOS分区表</span></span><br><span class="line">s <span class="comment">#新建空白SUN磁盘标签</span></span><br><span class="line">t <span class="comment">#改变分区的系统ID</span></span><br><span class="line">u <span class="comment">#改变显示记录单位</span></span><br><span class="line">v <span class="comment">#验证分区表</span></span><br><span class="line">x <span class="comment">#附加功能</span></span><br></pre></td></tr></table></figure><ul><li><p>示例</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# fdisk /dev/sdb   **#*对sdb进行分区***   </span><br><span class="line">Welcome to fdisk (util-linux 2.23.2).</span><br><span class="line"></span><br><span class="line">Changes will remain <span class="keyword">in</span> memory only, <span class="keyword">until</span> you decide to write them.</span><br><span class="line">Be careful before using the write <span class="built_in">command</span>.</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n  **#增加分区**  </span><br><span class="line">Partition <span class="built_in">type</span>:</span><br><span class="line">   p   primary (2 primary, 0 extended, 2 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p):  <span class="comment">#**回车选择默认主分区**    </span></span><br><span class="line">Using default response p</span><br><span class="line">Partition number (2,4, default 2): 2   **#输入分区号为2**    </span><br><span class="line">First sector (4097-209715199, default 26624):  **#回车选择默认起始位置**   </span><br><span class="line">Using default value 26624</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (26624-209715199, default 209715199): 409600</span><br><span class="line"><span class="comment">#**输入磁柱结束位置**  </span></span><br><span class="line">Partition 2 of <span class="built_in">type</span> Linux and of size 187 MiB is <span class="built_in">set</span></span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): </span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 107.4 GB, 107374182400 bytes, 209715200 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label <span class="built_in">type</span>: dos</span><br><span class="line">Disk identifier: 0xbf03ef25</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048        4096        1024+  83  Linux</span><br><span class="line">/dev/sdb2           26624      409600      191488+  83  Linux</span><br><span class="line">/dev/sdb3            6144       24689        9273   83  Linux</span><br><span class="line"></span><br><span class="line">Partition table entries are not <span class="keyword">in</span> disk order</span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w   **#保存分区并退出**    </span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br><span class="line">[root@master ~]# lsblk   **#查看磁盘信息，sdb分区2已经创建**    </span><br><span class="line">NAME              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                 8:0    0   20G  0 disk</span><br><span class="line">├─sda1              8:1    0    1G  0 part /boot</span><br><span class="line">└─sda2              8:2    0   19G  0 part</span><br><span class="line">  ├─centos-root   253:0    0   17G  0 lvm  /</span><br><span class="line">  └─centos-swap   253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">sdb                 8:16   0  100G  0 disk</span><br><span class="line">├─sdb1              8:17   0    1M  0 part</span><br><span class="line">├─sdb2              8:18   0  187M  0 part</span><br><span class="line">├─sdb3              8:19   0  9.1M  0 part</span><br><span class="line">├─datavg-data1_lv 253:2    0   45G  0 lvm</span><br><span class="line">└─datavg-data2_lv 253:3    0  200M  0 lvm</span><br><span class="line">sr0                11:0    1  9.5G  0 rom</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h3 id="2-mkxfs格式化分区为文件系统"><a href="#2-mkxfs格式化分区为文件系统" class="headerlink" title="2.mkxfs格式化分区为文件系统"></a>2.mkxfs<strong>格式化分区为文件系统</strong></h3><ul><li>mkfs命令用于在分区上建立文件系统</li><li>常用文件系统类型：ext4，xfs</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkfs -t 文件系统格式 /dev/sdb1</span><br><span class="line">mkfs.文件格式 /dev/sdb1  </span><br></pre></td></tr></table></figure><h3 id="3-mount挂载分区"><a href="#3-mount挂载分区" class="headerlink" title="3.mount挂载分区"></a>3.mount挂载分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建挂载点目录</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">mkdir</span> /mybak</span><br><span class="line"></span><br><span class="line"><span class="comment">#挂载文件系统</span></span><br><span class="line">[root@localhost ~]# mount /dev/sdb1 /mybak</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看正在使用中的分区信息</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">df</span> -Th</span><br></pre></td></tr></table></figure><h3 id="4-永久挂载"><a href="#4-永久挂载" class="headerlink" title="4.永久挂载"></a>4.永久挂载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">5. **永久挂载：** 更新 /etc/fstab 文件，以确保在系统重新启动时分区会自动挂载</span><br><span class="line"></span><br><span class="line"><span class="comment">#开机自动挂载</span></span><br><span class="line">[root@localhost ~]# vim /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment">#末行 添加  </span></span><br><span class="line">/dev/sdc1 /mnt/sdc_drive ext4 defaults 0 0</span><br><span class="line"><span class="comment">#设备 挂载点 文件类型 defaults 0 0    </span></span><br></pre></td></tr></table></figure><h2 id="SWAP"><a href="#SWAP" class="headerlink" title="SWAP"></a>SWAP</h2><p>在物理内存空间不足时，可以将物理内存中的一些不重要数据拷贝到磁盘的 swap 分区中，从而让出内存空间，并且在需要那些已被拷出数据时再从 swap 分区中拷回到内存。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看内存及swap</span></span><br><span class="line">free</span><br><span class="line">free -h</span><br><span class="line">free -m</span><br></pre></td></tr></table></figure><h3 id="增加swap分区"><a href="#增加swap分区" class="headerlink" title="增加swap分区"></a>增加swap分区</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">**方法一**</span><br><span class="line"><span class="comment">#创建分区</span></span><br><span class="line">[root@node2 ~]# fdisk /dev/vdb</span><br><span class="line"><span class="comment">#格式化为文件系统</span></span><br><span class="line">[root@node2 ~]# mkswap /dev/vdb3</span><br><span class="line"><span class="comment">#保存设置使其永久生效</span></span><br><span class="line">[root@node2 ~]# vim /etc/fstab</span><br><span class="line">/dev/vdb3 swap swap defaults 0 0</span><br><span class="line"><span class="comment"># 激活SWAP文件</span></span><br><span class="line">swapon -a</span><br><span class="line"><span class="comment">#查看交换分区组成</span></span><br><span class="line">swapon -s</span><br><span class="line">free -h</span><br><span class="line"></span><br><span class="line">**方法二**</span><br><span class="line"><span class="comment"># 在根目录创建分区路径</span></span><br><span class="line">$ <span class="built_in">mkdir</span> -p /swap/</span><br><span class="line"><span class="comment"># 设置分区的大小</span></span><br><span class="line"><span class="comment"># bs=64M是块大小，count=64是块数量，所以swap空间大小是bs*count=4096MB=4GB</span></span><br><span class="line">$ <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=/swap/swap0 bs=64M count=64</span><br><span class="line"><span class="comment"># 设置该目录权限</span></span><br><span class="line">$ <span class="built_in">chmod</span> 0600 /swap/swap0</span><br><span class="line"><span class="comment"># 创建SWAP文件</span></span><br><span class="line">$ mkswap /swap/swap0</span><br><span class="line"><span class="comment"># 激活SWAP文件</span></span><br><span class="line">$ swapon /swap/swap0</span><br><span class="line"><span class="comment"># 查看SWAP信息是否正确</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a>LVM</h2><table><thead><tr><th>PV</th><th>物理卷physical volume</th></tr></thead><tbody><tr><td>VG</td><td>卷组Volume Group</td></tr><tr><td>LV</td><td>逻辑卷logical volume</td></tr></tbody></table><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/3afe2fdd-cad2-43f1-8adc-f1d3b699ee5c/94a1f2ee-e740-44cf-bd2c-a6c21df5515a/image.png" alt="image.png"></p><h3 id="pv-物理卷"><a href="#pv-物理卷" class="headerlink" title="pv-物理卷"></a>pv-物理卷</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# pvcreate /dev/sdb1  /dev/sbd2</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看物理卷</span></span><br><span class="line">[root@newrain ~]# pvs</span><br></pre></td></tr></table></figure><h3 id="vg-卷组"><a href="#vg-卷组" class="headerlink" title="vg-卷组"></a>vg-卷组</h3><p>将创建好的物理卷组成卷组</p><p>直接创建卷组(系统会先将分区或磁盘创建为PV再创建卷组）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vgcreate vg1 /dev/sdb1</span><br><span class="line"> Volume group <span class="string">&quot;vg1&quot;</span> successfully created</span><br><span class="line">  </span><br><span class="line"> vgcreate -s [PE大小] </span><br><span class="line">  </span><br><span class="line">[root@localhost ~]# vgs</span><br></pre></td></tr></table></figure><h3 id="lv-逻辑卷"><a href="#lv-逻辑卷" class="headerlink" title="lv-逻辑卷"></a>lv-逻辑卷</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#创建逻辑卷</span></span><br><span class="line">[root@localhost ~]# lvcreate -L 10G -n mylv vg1</span><br><span class="line">Logical volume <span class="string">&quot;mylv&quot;</span> created.</span><br><span class="line"></span><br><span class="line">-L：指定逻辑卷的大小，如 -L 10G 表示 10GB。</span><br><span class="line">-l [PE个数] PE物理拓展块</span><br><span class="line"></span><br><span class="line">查看逻辑卷信息：</span><br><span class="line">lvs       //显示有关逻辑卷的信息</span><br><span class="line">lvscan     //扫描并显示LVM逻辑卷</span><br><span class="line">lvdisplay   //显示LVM逻辑卷属性</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="格式化并挂载使用"><a href="#格式化并挂载使用" class="headerlink" title="格式化并挂载使用"></a><strong>格式化并挂载使用</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#格式化文件系统</span></span><br><span class="line">[root@localhost ~]# mkfs.xfs /dev/vg1/mylv</span><br><span class="line"></span><br><span class="line"><span class="comment">#挂载使用</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">mkdir</span> /mount</span><br><span class="line">[root@localhost ~]# mount /dev/vg1/mylv /mount</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="拓展空间"><a href="#拓展空间" class="headerlink" title="拓展空间"></a>拓展空间</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#拓展卷组  </span></span><br><span class="line">[root@localhost ~]# vgextend vg1 /dev/sdb5 </span><br><span class="line"></span><br><span class="line"><span class="comment">#扩容逻辑卷</span></span><br><span class="line">[root@localhost ~]# lvextend -L +9G /dev/vg1/mylv</span><br><span class="line"></span><br><span class="line">扩展文件系统：当逻辑卷扩大以后，也需要对逻辑卷的文件系统进行扩展</span><br><span class="line">扩展文件系统容量：</span><br><span class="line">xfs_growfs <span class="comment">#用于扩容XFS设备</span></span><br><span class="line">resize2fs <span class="comment">#用于扩容EXT3/EXT4设备</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#扩展文件系统</span></span><br><span class="line"> xfs_growfs /dbbak</span><br><span class="line"> resize2fs /dev/myvol/vo</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&quot;FS文件系统与磁盘管理&quot;</summary>
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/linux/"/>
    
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux-文件的访问控制列表facl</title>
    <link href="https://sosocrown.github.io/2025/01/21/%E6%96%87%E4%BB%B6%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E5%88%97%E8%A1%A8facl/"/>
    <id>https://sosocrown.github.io/2025/01/21/%E6%96%87%E4%BB%B6%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E5%88%97%E8%A1%A8facl/</id>
    <published>2025-01-21T08:59:08.627Z</published>
    <updated>2025-05-07T09:52:42.995Z</updated>
    
    <content type="html"><![CDATA[<p><code>setfacl</code>工具： 设置和修改文件或目录的访问控制列表（ACLs）的命令行工具。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setfacl -m option:name[:permission] file</span><br></pre></td></tr></table></figure><ul><li><code>-m</code> 表示修改现有的 ACL 条目。</li><li><code>option</code> 可以是 <code>u</code>（用户）、<code>g</code>（组）、<code>o</code>（其他）、<code>d</code>（默认）、<code>-</code>（掩码，用于限制通过 ACL 授予的权限）。</li><li><code>name</code> 是用户或组的名称。</li><li><code>permission</code> 是逗号分隔的权限列表，可以是 <code>r</code>（读）、<code>w</code>（写）、<code>x</code>（执行）、<code>R</code>（读，但不允许执行）、<code>W</code>（写，但不允许执行）、<code>X</code>（执行，但不允许写）。</li></ul>]]></content>
    
    
    <summary type="html">&quot;更细粒度地控制文件和目录的访问权限&quot;</summary>
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/linux/"/>
    
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://sosocrown.github.io/2024/10/30/ansible/"/>
    <id>https://sosocrown.github.io/2024/10/30/ansible/</id>
    <published>2024-10-30T06:47:12.000Z</published>
    <updated>2025-05-07T01:34:22.738Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、安装与配置"><a href="#一、安装与配置" class="headerlink" title="一、安装与配置"></a><span style>一、安装与配置</span></h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#yum安装</span></span><br><span class="line">yum install epel-release -y</span><br><span class="line">yum install ansible –y</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看ansible版本</span></span><br><span class="line">ansible --version</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-管理节点与被管理节点建⽴SSH信任关系"><a href="#2-管理节点与被管理节点建⽴SSH信任关系" class="headerlink" title="2.管理节点与被管理节点建⽴SSH信任关系"></a>2.管理节点与被管理节点建⽴SSH信任关系</h2><pre><code>2.1.生成私钥[root@server ~]# ssh-keygen   2.2.向主机分发私钥[root@server ~]# ssh-copy-id root@192.168.37.122[root@server ~]# ssh-copy-id root@192.168.37.133</code></pre><h2 id="3-ansible配置文件"><a href="#3-ansible配置文件" class="headerlink" title="3. ansible配置文件"></a>3. ansible配置文件</h2><p>修改配置文件，创建主机清单文件 ：写在[]里的是组名，[ ]下面的是组内的主机名<br>[root@server ~]# vim &#x2F;etc&#x2F;ansible&#x2F;hosts<br>[web]<br>192.168.37.122<br>192.168.37.133</p><h1 id="二、核心组件"><a href="#二、核心组件" class="headerlink" title="二、核心组件"></a>二、核心组件</h1><p>主机清单（Inventory）<br>模块（Modules）<br>任务（Tasks）和剧本（Playbooks）<br>角色（Roles）</p><h1 id="三、ansible-doc-命令行模块"><a href="#三、ansible-doc-命令行模块" class="headerlink" title=" 三、ansible-doc 命令行模块"></a><span style> 三、ansible-doc 命令行模块</span></h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ansible &lt;ip组&gt; -m &lt;模块&gt; -a &lt;argument参数&gt; [options]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ansible dev,<span class="built_in">test</span>,prod -a <span class="string">&#x27;getenforce&#x27;</span> </span><br></pre></td></tr></table></figure><p>命令的工作目录默认是远程用户的主目录（~），command 模块不会保留shell的环境状态（包括当前工作目录）</p><p> ansible-doc -l  #列出当前系统中ansible的所有模块<br>ansible-doc  -s  模块名   #查看模块的参数<br>ansible-doc  模块名   #查看模块的详细信息包括用法</p><h3 id="1-ping模块"><a href="#1-ping模块" class="headerlink" title="1.ping模块"></a>1.ping模块</h3><p><code>ansible all -m ping</code></p><h3 id="2-command模块"><a href="#2-command模块" class="headerlink" title="2.command模块"></a>2.command模块</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chdir=/etc/sysconfig  ---执行命令前先切换到指定目录</span><br><span class="line">creates=/doc/1.txt：判断指定文件是否存在，如果存在，不执行后面的操作</span><br><span class="line">removes：判断指定文件是否存在，如果存在，执行后面的操作</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>注意，该命令不支持&#x3D;&#x3D;<code>| 管道命令</code>&#x3D;&#x3D;。</li></ul><p><code>ansible all -m command -a ‘removes=/etc/sysconfig/network-scripts/ifcfg-ens33 ip addr ’</code></p><h3 id="3-shell模块"><a href="#3-shell模块" class="headerlink" title="3.shell模块"></a>3.shell模块</h3><p>ansible all -m shell -a ‘echo “niki_ansible” |cat &gt;&gt;1.txt&#96;</p><p>ansible webservers -m shell -a ‘ifconfig | grep ens33’</p><p>ansible webservers -m shell -a ‘ifconfig &gt; &#x2F;opt&#x2F;kx.txt’</p><h3 id="4-file模块"><a href="#4-file模块" class="headerlink" title="4.file模块"></a>4.file模块</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">state　　#状态，有以下选项：</span><br><span class="line"></span><br><span class="line">directory：如果目录不存在，就创建目录</span><br><span class="line">file：文件不存在，不会被创建</span><br><span class="line">touch：文件不存在，创建新文件，如果文件或目录已存在，则更新其最后修改时间</span><br><span class="line">absent：删除目录、文件或者取消链接文件</span><br><span class="line">link：创建软链接，hard：创建硬链接</span><br></pre></td></tr></table></figure><p><code>ansible web -m file -a &#39;path=/data/app state=directory’</code>   创建目录</p><p><code>ansible web -m file -a &#39;path=/data/a state=absent’</code>      删除文件</p><p><code>ansible dbservers -m file -a &#39; group=root mode=644 path=/opt/host_ansible&#39;</code> #修改文件的属主属组权限等</p><h3 id="5-copy模块-将文件复制到远程主机"><a href="#5-copy模块-将文件复制到远程主机" class="headerlink" title="5.copy模块-将文件复制到远程主机"></a>5.copy模块-将文件复制到远程主机</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">src　　　　<span class="comment">#被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于&quot;rsync&quot;</span></span><br><span class="line">content　　　<span class="comment">#用于替换&quot;src&quot;，可以直接指定文件的值</span></span><br><span class="line">dest　　　　<span class="comment">#必选项，将源文件复制到的远程主机的绝对路径</span></span><br><span class="line">backup　　　<span class="comment">#当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息</span></span><br><span class="line">directory_mode　　　　<span class="comment">#递归设定目录的权限，默认为系统默认权限</span></span><br></pre></td></tr></table></figure><p> <code>ansible web -m copy -a &#39;src=~/hello dest=/data/hello&#39;</code> </p><p><code>ansible web -m copy -a &#39;content=&quot;I am keer\n&quot; dest=/data/name mode=666’</code></p><h3 id="6-fetch-模块-从远程主机获取文件到本地"><a href="#6-fetch-模块-从远程主机获取文件到本地" class="headerlink" title="6.fetch 模块-从远程主机获取文件到本地"></a>6.<strong>fetch 模块-从远程主机获取文件到本地</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dest：用来存放文件的目录</span><br><span class="line">src：在远程拉取的文件，**并且必须是一个file**，不能是目录</span><br></pre></td></tr></table></figure><p><code>ansible web -m fetch -a &#39;src=/data/hello dest=/data&#39;</code>  </p><h3 id="7-yum-apt-模块"><a href="#7-yum-apt-模块" class="headerlink" title="7.yum&#x2F;apt 模块"></a>7.<strong>yum&#x2F;apt 模块</strong></h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">name：要管理的包名</span></span><br><span class="line"><span class="string">state：#present---&gt;安装</span> <span class="string">latest---&gt;安装最新的,</span> <span class="string">absent---&gt;</span> <span class="string">卸载软件。</span></span><br></pre></td></tr></table></figure><hr><h3 id="8-service-模块"><a href="#8-service-模块" class="headerlink" title="8. service 模块"></a>8. service 模块</h3><p>　　该模块用于服务程序的管理。<br>　　其主要选项如下：</p><blockquote><p><code>arguments</code> #命令行提供额外的参数<br><code>enabled</code> #设置开机启动。<br><code>name=</code> #服务名称<br><code>runlevel</code> #开机启动的级别，一般不用指定。<br><code>sleep</code> #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)<br><code>state</code> #有四种状态，分别为：<code>started</code>—&gt;启动服务， <code>stopped</code>—&gt;停止服务， <code>restarted</code>—&gt;重启服务， <code>reloaded</code>—&gt;重载配置</p></blockquote><p>　　下面是一些例子：<br><strong>① 开启服务并设置自启动</strong></p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@server</span> ~]# ansible web -m service -a <span class="string">&#x27;name=nginx state=started enabled=true&#x27;</span> </span><br><span class="line"><span class="number">192.168</span>.<span class="number">37.122</span> | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">&quot;changed&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;enabled&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;nginx&quot;</span>, </span><br><span class="line">    <span class="string">&quot;state&quot;</span>: <span class="string">&quot;started&quot;</span>, </span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br><span class="line"><span class="number">192.168</span>.<span class="number">37.133</span> | SUCCESS =&gt; &#123;</span><br><span class="line">    <span class="string">&quot;changed&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;enabled&quot;</span>: <span class="keyword">true</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;nginx&quot;</span>, </span><br><span class="line">    <span class="string">&quot;state&quot;</span>: <span class="string">&quot;started&quot;</span>, </span><br><span class="line">    ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="firewalld-模块"><a href="#firewalld-模块" class="headerlink" title="firewalld 模块"></a>firewalld 模块</h2><p>一个动态防火墙管理工具<br><strong>1. <strong>state</strong>：设置规则的状态。<br>    - <code>enabled</code>：启用规则。<br>    - <code>disabled</code>：禁用规则。<br>2. <strong>permanent</strong>：设置规则是否永久生效。<br>    - <code>yes</code>：规则永久生效，重启后依然有效。<br>    - <code>no</code>：规则临时生效，重启后失效。<br>3. <strong>immediate</strong>：是否立即应用规则变更。<br>    - <code>yes</code>：立即应用规则变更。<br>    - <code>no</code>：规则变更将在下一次 <code>firewalld</code> 重启时生效。<br>4. <strong>service</strong>：指定要允许或拒绝的服务名称，例如 <code>http</code>、<code>https</code>、<code>ssh</code> 等。<br>5. <strong>port</strong>：指定要允许或拒绝的端口，可以是单个端口（如 <code>8080/tcp</code>）或端口范围（如 <code>1024-2048/tcp</code>）。</strong></p><pre><code><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#启动 firewalld 服务**：</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Start</span> <span class="string">firewalld</span> <span class="string">service</span></span><br><span class="line">  <span class="attr">ansible.builtin.firewalld:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">    <span class="string">enabled：</span> <span class="literal">yes</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#添加允许规则：</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Open</span> <span class="string">port</span> <span class="number">80</span> <span class="string">in</span> <span class="string">firewalld</span></span><br><span class="line">  <span class="attr">ansible.builtin.firewalld:</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">permanent:</span> <span class="literal">yes</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">enabled</span></span><br><span class="line">    <span class="attr">immediate:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></code></pre><h2 id="Setup模块"><a href="#Setup模块" class="headerlink" title="Setup模块"></a>Setup模块</h2><p>使用<strong>setup模块</strong>获取被管理主机的所有facts信息，可以使用filter来查看指定的信息。setup模块获取的整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最外层的值。我们可以通过以下Ansible Ad-Hoc命令查看facts信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m setup | grep hostname</span><br><span class="line"></span><br><span class="line"> ansible all -m setup -a &#x27;filter=&quot;ansible_nodename&quot;&#x27;   </span><br></pre></td></tr></table></figure><h1 id="四、playbook-剧本"><a href="#四、playbook-剧本" class="headerlink" title="四、playbook-剧本"></a>四、playbook-剧本</h1><h3 id="playbook格式"><a href="#playbook格式" class="headerlink" title="playbook格式"></a>playbook格式</h3><p><strong>playbook 是 ansible 用于配置，部署，和管理被控节点的剧本。</strong><code>类似于脚本</code></p><ol><li><code>-</code>和<code>:</code>后必须<font color="#ff0000">空一格</font></li><li>大小写敏感,使用缩进表示层级关系</li><li>缩进时不允许使用tab键、只允许使用空格</li><li>缩进的空格数目不重要，只要相同层级的元素左侧对齐即可</li><li><strong>任务列表</strong>：每个任务前使用<code>-</code> 表示一个新的任务。</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---   </span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">playbook</span>  </span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">web：test</span>  <span class="comment"># 指定此 Play 将在哪些主机上运行</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line">  </span><br><span class="line">  <span class="attr">tasks:</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">connect</span> <span class="string">test</span>  </span><br><span class="line">      <span class="attr">ping:</span>    </span><br><span class="line">  </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">new</span> <span class="string">file</span>  </span><br><span class="line">      <span class="attr">file:</span> </span><br><span class="line">        <span class="attr">group:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">mode:</span> <span class="number">744</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/niki1/file1</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">touch</span> </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="comment">#以上为普通形式，行数较多，但更容易操作。任务的关键字垂直堆叠，更容易区分。</span></span><br><span class="line">    <span class="comment">#以下可以运行但不推荐</span></span><br><span class="line">    <span class="attr">tasks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shorthand</span> <span class="string">form</span></span><br><span class="line">        <span class="attr">service:</span> <span class="string">name=httpd</span> <span class="string">enabled=true</span> <span class="string">state=started</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure><h3 id="运行剧本"><a href="#运行剧本" class="headerlink" title="运行剧本"></a>运行剧本</h3><p>空运行 <code>ansible-playbook -C pb.yml</code></p><p>直接运行 <code>ansible-playbook pb.yml</code></p><p>语法验证 <strong><code>ansible-playbook --syntax-check pb.yml</code></strong></p><p>指定从某个task开始运行<code>ansible-playbook pb.yml --start-at-task=&#39;xxx&#39;</code>  </p><p><font color="#00b050">| 绿色代表执行成功，系统保持原样</font></p><p><font color="#ffff00">| 黄色代表系统代表系统状态发生改变</font></p><p><font color="#ff0000">| 红色代表执行失败，显示错误输出</font></p><h4 id="ansible-navigator容器中运行剧本"><a href="#ansible-navigator容器中运行剧本" class="headerlink" title="ansible-navigator容器中运行剧本"></a>ansible-navigator容器中运行剧本</h4><p>ansible-navigator 利用容器化的执行环境，用于与 Ansible Playbooks、Roles、Collections 等交互。<br>ansible-navigator run playbook.yml <span style="background:rgba(173, 239, 239, 0.55)">-m stdout</span><br>-<code>-m stdout</code>：这个选项指定输出模式为 <code>stdout</code>，即将执行结果输出到标准输出（终端），而不是使用交互式界面。</p><h3 id="Handler-notify-触发器"><a href="#Handler-notify-触发器" class="headerlink" title="Handler+notify-触发器"></a><strong>Handler+notify-触发器</strong></h3><p>在特定条件下触发；接收到其它任务的通知<code>notify</code>时被触发</p><p>Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了.</p><h3 id="Tag-标签"><a href="#Tag-标签" class="headerlink" title="Tag-标签"></a>Tag-标签</h3><p>为tasks或play添加标记，选择性地执行playbook的特定部分。</p><h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>如果命令或脚本的退出码不为零，可以使用如下方式替代</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line">  <span class="string">-name:</span> <span class="string">run</span> <span class="string">this</span> <span class="string">command</span> <span class="string">and</span> <span class="string">ignore</span> <span class="string">the</span> <span class="string">result</span></span><br><span class="line">   <span class="attr">shell:</span> <span class="string">/usr/bin/somecommand</span> <span class="string">||</span> <span class="string">/bin/true</span></span><br><span class="line"><span class="string">转错为正</span> <span class="string">如果命令失败则执行</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="string">或者使用ignore_errors来忽略错误信息</span></span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line"><span class="string">-name:</span> <span class="string">run</span> <span class="string">this</span> <span class="string">command</span> <span class="string">and</span> <span class="string">ignore</span> <span class="string">the</span> <span class="string">result</span></span><br><span class="line"> <span class="attr">shell:</span> <span class="string">/usr/bin/somecommand</span></span><br><span class="line"> <span class="attr">ignore_errors:</span> <span class="literal">True</span> <span class="string">忽略错误</span></span><br></pre></td></tr></table></figure><h3 id="Variable-变量"><a href="#Variable-变量" class="headerlink" title="Variable-变量"></a><strong>Variable-变量</strong></h3><p>变量名：仅能由字母、数字和下划线组成，且只能以字母开头<br>变量定义：直接定义  key&#x3D;value<br>根据变量的作⽤范围⼤体的将变量分为:</p><pre><code>全局变量剧本变量资产变量内置变量:内置变量⼏乎都是以 ansible_ 为前缀。系统自带事实变量facts：ansible setup模块   </code></pre><p>  ansible all -m setup -a ‘filter&#x3D;”ansible_nodename”‘     #查询主机名</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="string">.系统自带事实变量facts：ansible</span> <span class="string">setup模块</span>   </span><br><span class="line">  <span class="string">ansible</span> <span class="string">all</span> <span class="string">-m</span> <span class="string">setup</span> <span class="string">-a</span> <span class="string">&#x27;filter=&quot;ansible_nodename&quot;&#x27;</span>     <span class="comment">#查询主机名</span></span><br><span class="line">  </span><br><span class="line"><span class="number">2</span><span class="string">./etc/ansible/hosts(主机清单)中定义变量</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span><span class="string">.在playbook中定义</span></span><br><span class="line">       <span class="attr">vars:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">var1:</span> <span class="string">value1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">var2:</span> <span class="string">value2</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span><span class="string">.在独立的变量YAML文件中定义</span></span><br><span class="line"><span class="string">vim</span> <span class="string">vars.yml</span></span><br><span class="line"><span class="attr">pack:</span> <span class="string">vsftpd</span></span><br><span class="line"><span class="attr">service:</span> <span class="string">vsftpd</span></span><br><span class="line"></span><br><span class="line"><span class="string">引用变量文件</span></span><br><span class="line"><span class="attr">vars_files:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">vars.yml</span></span><br><span class="line">  </span><br></pre></td></tr></table></figure><p>变量调用：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">通过&#123;&#123;</span> <span class="string">variable_name</span> <span class="string">&#125;&#125;</span> <span class="string">调用变量</span></span><br><span class="line"><span class="string">通过-e指定</span>  </span><br><span class="line"><span class="string">ansible-playbook</span> <span class="string">test.yml</span> <span class="string">-e</span> <span class="string">&quot;hosts=123&quot;</span></span><br></pre></td></tr></table></figure><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用变量文件   </span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">vars_log</span> <span class="string">file</span></span><br><span class="line">  <span class="attr">vars_files:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">/niki2/vars.yml</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">new</span> <span class="string">file</span></span><br><span class="line">      <span class="attr">file:</span></span><br><span class="line">         <span class="attr">path:</span> <span class="string">/niki1/&#123;&#123;</span> <span class="string">name1</span> <span class="string">&#125;&#125;_log.txt</span></span><br><span class="line">         <span class="attr">mode:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; mode1 &#125;&#125;</span>&quot;</span></span><br><span class="line">         <span class="attr">state:</span> <span class="string">touch</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Template-模板"><a href="#Template-模板" class="headerlink" title="Template-模板"></a><strong>Template-模板</strong></h3><p>根据模板文件<strong>动态</strong>生成对应的配置文件，命名必须以 <strong>.j2</strong> 结尾（<code>Jinja2</code>：Jinja2是python的一种模板语言）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install</span> <span class="string">nginx</span>  <span class="comment">#安装nginx，若为centos7需要启用 EPEL 仓库</span></span><br><span class="line">      <span class="attr">yum:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">template</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">src:</span> <span class="string">/etc/ansible/templates/nginx.conf.j2</span> </span><br><span class="line">        <span class="comment">#nginx.conf.j2模板设置worker_processes 的值为   &#123;&#123; ansible_processor_vcpus*2&#125;&#125;;</span></span><br><span class="line">        <span class="attr">dest:</span> <span class="string">/etc/nginx/nginx.conf</span></span><br><span class="line">      <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">service</span></span><br><span class="line">      </span><br><span class="line">     </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service</span> <span class="string">start</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">started</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">yes</span> <span class="comment">#开机自启</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">handlers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">service</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">restarted</span></span><br></pre></td></tr></table></figure><h3 id="条件测试when与循环迭代-with-items"><a href="#条件测试when与循环迭代-with-items" class="headerlink" title="条件测试when与循环迭代  with_items"></a>条件测试when与循环迭代  with_items</h3><ul><li><p>when语句：在task中使用</p></li><li><p>循环：迭代，需要重复执行的任务；</p><p>  对迭代项的引用，固定变量名为”item”，而后，要在task中使用with_items给定要迭代的元素列表；</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">remote_user:</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">add</span> <span class="string">groups</span></span><br><span class="line">      <span class="attr">group:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item &#125;&#125;</span>&quot;</span></span><br><span class="line">      <span class="attr">with_items:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group1</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group2</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">group3</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">add</span> <span class="string">users</span></span><br><span class="line">      <span class="attr">user:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item.name &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">group:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item.group &#125;&#125;</span>&quot;</span></span><br><span class="line">      <span class="attr">with_items:</span></span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u1&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group1&#x27;</span>&#125;</span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u2&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group2&#x27;</span>&#125;</span><br><span class="line">        <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">&#x27;u3&#x27;</span>,<span class="attr">group:</span> <span class="string">&#x27;group3&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="五、roles-角色"><a href="#五、roles-角色" class="headerlink" title="五、roles-角色"></a>五、roles-角色</h1><p>用于<strong>层次性，结构化</strong>地组织playbook<br>roles通过分别将变量(vars)、文件(file)、任务(tasks)、模块(modules)及处理器(handlers)放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中。 </p><h3 id="创建role"><a href="#创建role" class="headerlink" title="创建role"></a>创建role</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible-galaxy init my_role</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="安装roels"><a href="#安装roels" class="headerlink" title="安装roels"></a>安装roels</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">直接从galaxy安装</span></span><br><span class="line">ansible-galaxy install &lt;role_name&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">从 requirements.yml 文件安装多个角色</span></span><br><span class="line">vim requirements.yml</span><br><span class="line"></span><br><span class="line">- src: geerlingguy.apache</span><br><span class="line">- src: geerlingguy.mysql</span><br><span class="line">- </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装</span></span><br><span class="line">ansible-galaxy install -r requirements.yml</span><br><span class="line">---</span><br><span class="line"> - name: webservers role</span><br><span class="line">   hosts: webservers</span><br><span class="line">   roles:</span><br><span class="line"> - apache</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="六、collection-集合"><a href="#六、collection-集合" class="headerlink" title="六、collection-集合"></a>六、collection-集合</h1><p>Collection 是一个更高级的封装，包含多个 Roles、模块、插件等，允许用户更全面地共享和分发自动化内容。它可以包含多个功能模块，适用于更复杂的项目。</p><h2 id="如何使用-Ansible-Collections"><a href="#如何使用-Ansible-Collections" class="headerlink" title="如何使用 Ansible Collections"></a>如何使用 Ansible Collections</h2><h3 id="1、安装-Collection"><a href="#1、安装-Collection" class="headerlink" title="1、安装 Collection"></a>1、安装 Collection</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可以从 Ansible Galaxy 或其他来源安装 Collection：</span></span><br><span class="line">ansible-galaxy collection install &lt;namespace&gt;.&lt;collection_name&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">也可以从本地目录或通过 requirements.yml 文件安装collection：</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2、Playbook-中使用-Collection"><a href="#2、Playbook-中使用-Collection" class="headerlink" title="2、Playbook 中使用 Collection"></a>2、Playbook 中使用 Collection</h3><p>在你的 playbook.yml 文件中，你可以指定要使用的 Collection：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">Playbook</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">collections:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">my_namespace.my_collection</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Example</span> <span class="string">task</span></span><br><span class="line">      <span class="attr">my_namespace.my_collection.my_module:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">example</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br></pre></td></tr></table></figure><h3 id="3、管理-Collection"><a href="#3、管理-Collection" class="headerlink" title="3、管理 Collection"></a>3、管理 Collection</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">列出已安装的 Collection：</span></span><br><span class="line">ansible-galaxy collection list</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">卸载 Collection：</span></span><br><span class="line">ansible-galaxy collection uninstall my_namespace.my_collection</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用-requirements-yml-文件管理-Collection"><a href="#使用-requirements-yml-文件管理-Collection" class="headerlink" title="使用 requirements.yml 文件管理 Collection"></a>使用 requirements.yml 文件管理 Collection</h3><blockquote><p>[!success] Title<br>创建一个 requirements.yml 文件来管理 Collection </p><p>collections模块中name通常为集合名字。<strong>如果直接提供 URL，格式为完整的链接。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">collections:</span><br><span class="line">  - name: my_namespace.my_collection</span><br><span class="line">    source: https://my.custom.repo/path/to/collection/</span><br><span class="line">    version: 1.0.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">然后使用以下命令安装所有 Collection：</span></span><br><span class="line">ansible-galaxy collection install -r requirements.yml </span><br><span class="line"></span><br><span class="line">-r, --requirements</span><br><span class="line">从指定的 requirements 文件中安装 Collections。</span><br><span class="line"></span><br><span class="line">-p, --collections-path</span><br><span class="line">指定安装 Collections 的目录。如果没有指定，默认安装到系统的 Ansible Collections 路径。</span><br></pre></td></tr></table></figure><h1 id="七、ansible-galaxy"><a href="#七、ansible-galaxy" class="headerlink" title="七、ansible galaxy"></a>七、ansible galaxy</h1><p><a href="https://galaxy.ansible.com/ui/search/">https://galaxy.ansible.com/ui/search/</a><br>Ansible Galaxy 是一个在线平台，提供一个广泛的 Ansible 资源库，包括 <strong>角色（roles）</strong>、<strong>集合（collections）</strong> 和其他自动化内容。用户可以通过 Galaxy 搜索、下载和分享这些资源。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装角色</span></span><br><span class="line">ansible-galaxy role install &lt;role_name&gt;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">列出已安装的角色或集合：</span></span><br><span class="line">ansible-galaxy role list</span><br></pre></td></tr></table></figure><h1 id="八、debug-msg"><a href="#八、debug-msg" class="headerlink" title="八、debug  msg"></a>八、debug  msg</h1><p>在Ansible中，<code>debug</code>模块是一个非常有用的工具，它允许你在执行任务时输出变量的值或执行过程中的信息。这对于调试和理解你的Ansible playbooks的执行流程非常有用。</p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ol><li><p><strong>基本用法</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">a</span> <span class="string">debug</span> <span class="string">message</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;This is a debug message&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>输出变量</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">the</span> <span class="string">value</span> <span class="string">of</span> <span class="string">a</span> <span class="string">variable</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;The value of my_var is <span class="template-variable">&#123;&#123; my_var &#125;&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>条件输出</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">a</span> <span class="string">message</span> <span class="string">if</span> <span class="string">a</span> <span class="string">condition</span> <span class="string">is</span> <span class="string">met</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">msg:</span> <span class="string">&quot;This will only print if the condition is true&quot;</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">my_condition</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">and</span> <span class="string">my_condition</span></span><br></pre></td></tr></table></figure></li><li><p><strong>输出变量内容</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">the</span> <span class="string">content</span> <span class="string">of</span> <span class="string">a</span> <span class="string">variable</span></span><br><span class="line">  <span class="attr">debug:</span></span><br><span class="line">    <span class="attr">var:</span> <span class="string">my_var</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="调试技巧"><a href="#调试技巧" class="headerlink" title="调试技巧"></a>调试技巧</h3><ul><li><strong>在每个任务后添加debug模块</strong>: 这可以帮助你跟踪变量的值和任务的执行状态。</li><li><strong>使用<code>when</code>条件</strong>: 只在特定条件下输出信息，避免不必要的输出。</li><li><strong>使用<code>verbosity</code></strong>: 通过增加verbosity级别，可以输出更多的调试信息。在命令行中使用<code>-v</code>或<code>-vv</code>参数。</li></ul><h1 id="九、ansible-vault"><a href="#九、ansible-vault" class="headerlink" title="九、ansible-vault"></a>九、ansible-vault</h1><p><code>ansible-vault</code> 是一个用于加密和解密敏感数据的工具。它允许你以加密的形式存储敏感信息，如密码、密钥或任何其他敏感数据，以确保这些信息在Playbooks和变量文件中不会被暴露。</p>]]></content>
    
    
    <summary type="html">&quot;开源的自动化工具，专门用于配置管理、应用程序部署以及 IT 基础设施的自动化。采用无代理（agentless）设计。Ansible 能够轻松地将系统或应用配置推送到多台机器上，确保一致性和可靠性。&quot;</summary>
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="运维" scheme="https://sosocrown.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="#Automation" scheme="https://sosocrown.github.io/tags/Automation/"/>
    
  </entry>
  
  <entry>
    <title>linux用户与组管理</title>
    <link href="https://sosocrown.github.io/2024/07/20/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%201/"/>
    <id>https://sosocrown.github.io/2024/07/20/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%201/</id>
    <published>2024-07-19T16:00:00.000Z</published>
    <updated>2025-05-07T09:51:43.347Z</updated>
    
    <content type="html"><![CDATA[<h2 id="用户与组管理"><a href="#用户与组管理" class="headerlink" title="用户与组管理"></a>用户与组管理</h2><h3 id="useradd创建用户"><a href="#useradd创建用户" class="headerlink" title="useradd创建用户"></a>useradd创建用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">常用选项：</span><br><span class="line">-u 指定用户UID</span><br><span class="line">-d 指定用户家目录</span><br><span class="line">-c --comment用户描述信息</span><br><span class="line">-g 指定用户gid</span><br><span class="line">-G 指定用户附加组（次要组）</span><br><span class="line">-s --shell指定用户的解释器程序   </span><br><span class="line">⽆权访问系统上的交互式shell：/sbin/noloogin   /bin/false</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建用户指定用户UID、描述信息、附加组</span></span><br><span class="line">[root@localhost ~]# useradd -u 1600 -c yunwei -G <span class="built_in">test</span> xiaozhang</span><br><span class="line">[root@localhost ~]# <span class="built_in">id</span> xiaozhang</span><br><span class="line">uid=1600(xiaozhang) gid=1600(xiaozhang) 组=1600(xiaozhang),1401(<span class="built_in">test</span>)</span><br></pre></td></tr></table></figure><h3 id="groupadd创建组"><a href="#groupadd创建组" class="headerlink" title="groupadd创建组"></a>groupadd创建组</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建组</span></span><br><span class="line"> groupadd -g GID   <span class="comment">#指定组的GID</span></span><br><span class="line">[root@localhost ~]# groupadd -g 1555 student</span><br></pre></td></tr></table></figure><h3 id="chgrp改变文件或目录所属组"><a href="#chgrp改变文件或目录所属组" class="headerlink" title="chgrp改变文件或目录所属组"></a>chgrp改变文件或目录所属组</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看文件或目录所属组</span></span><br><span class="line"><span class="built_in">ls</span> -l</span><br><span class="line"></span><br><span class="line"><span class="built_in">chgrp</span> [选项] [所属组] 文件/目录</span><br><span class="line">--reference=RFILE  使用参考文件的所属组</span><br><span class="line">-R  递归的更改目录下的所有目录以及文件</span><br><span class="line"></span><br><span class="line"><span class="built_in">chgrp</span> group1 /etc/niki</span><br><span class="line"></span><br><span class="line">sgid：给目录设置了sgid权限，在该目录下创建的文件或者目录的**属组**都与该目录一致</span><br><span class="line"></span><br><span class="line">授权格式：</span><br><span class="line"><span class="built_in">chmod</span> g+s 文件名称</span><br><span class="line">撤销格式：</span><br><span class="line"><span class="built_in">chmod</span> g-s 文件名称</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="chown归属关系管理"><a href="#chown归属关系管理" class="headerlink" title="chown归属关系管理"></a>chown归属关系管理</h3><p>chown（英文全拼：change owner）用于设置文件的所有者和所属组关系</p><ul><li>命令格式：<ul><li>chown [-选项] 所有者:所属组 文档</li><li>chown [-选项] 所有者 文档</li><li>chown [-选项] :所属组 文档</li></ul></li><li>常用选项:<ul><li><code>R</code> 递归地改变指定目录及其子目录和文件的所有者</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改文件所有者与所属组为lisi</span></span><br><span class="line">[root@localhost ~]# <span class="built_in">chown</span> lisi:lisi /hello.txt </span><br></pre></td></tr></table></figure><h3 id="id查看信息"><a href="#id查看信息" class="headerlink" title="id查看信息"></a>id查看信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# <span class="built_in">id</span> user1</span><br><span class="line">uid=1001(user1) gid=1001(user1) 组=1001(user1)</span><br></pre></td></tr></table></figure><h3 id="passwd修改密码"><a href="#passwd修改密码" class="headerlink" title="passwd修改密码"></a>passwd修改密码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置用户密码</span></span><br><span class="line">[root@localhost ~]# passwd user1</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 密码 |passwd --stdin user1</span><br></pre></td></tr></table></figure><h3 id="etc-passwd用户信息文件"><a href="#etc-passwd用户信息文件" class="headerlink" title="&#x2F;etc&#x2F;passwd用户信息文件"></a>&#x2F;etc&#x2F;passwd用户信息文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">**[root@localhost ~]# vim /etc/passwd</span><br><span class="line">root:x:0:0:root:/root:/bin/bash</span><br><span class="line"><span class="comment">#每个字段含义解释：用户名:密码占位符:UID:基本组GID:用户描述信息:家目录:解释器程序</span></span><br><span class="line">UID：0 超级用户</span><br><span class="line">UID：1-999 系统伪用户，不能登录系统</span><br><span class="line">UID：1000-65535 普通用户，管理员创建的用户**</span><br></pre></td></tr></table></figure><h3 id="wheel用户组"><a href="#wheel用户组" class="headerlink" title="wheel用户组"></a>wheel用户组</h3><p><a href="https://www.cnblogs.com/linuxshare/p/18609179">linux中的wheel用户 - 爱折腾的大臭臭 - 博客园</a></p>]]></content>
    
    
    <summary type="html">&quot;Linux 系统中用户和组管理的基本操作，包括如何创建用户和组、修改文件所属的用户和组，以及管理用户密码等。&quot;</summary>
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="linux" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/linux/"/>
    
    
    <category term="linux" scheme="https://sosocrown.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>docker</title>
    <link href="https://sosocrown.github.io/2023/10/20/docker/"/>
    <id>https://sosocrown.github.io/2023/10/20/docker/</id>
    <published>2023-10-20T06:47:12.000Z</published>
    <updated>2025-05-07T02:38:34.901Z</updated>
    
    <content type="html"><![CDATA[<h1 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h1><p><img src="/(/images/U1.png" alt="Untitled"></p><h2 id="一：Docker基础、"><a href="#一：Docker基础、" class="headerlink" title="一：Docker基础、"></a>一：Docker基础、</h2><h3 id="什么是Docker？"><a href="#什么是Docker？" class="headerlink" title="什么是Docker？"></a>什么是Docker？</h3><h3 id="Docker是什么？"><a href="#Docker是什么？" class="headerlink" title="Docker是什么？"></a><strong>Docker是什么？</strong></h3><p><strong>开源的容器化平台，用于构建、打包和运行应用程序和服务</strong></p><h3 id="架构：client-server"><a href="#架构：client-server" class="headerlink" title="架构：client-server"></a>架构：<strong>client-server</strong></h3><p><img src="/(/images/U2.png" alt="Untitled"></p><h3 id="Docker的优势和用途"><a href="#Docker的优势和用途" class="headerlink" title="Docker的优势和用途"></a>Docker的优势和用途</h3><ol><li><p><strong>轻量级容器：</strong> Docker容器相对于传统虚拟机更轻量，因为它们共享操作系统内核，而不是运行完整的操作系统。这使得容器更快速启动、更节省资源，并提高了可扩展性。</p></li><li><p><strong>一致性和可移植性：</strong> Docker容器封装了应用程序及其依赖，确保在不同环境中运行一致。这意味着你可以在开发、测试和生产环境之间轻松迁移应用程序。</p></li><li><p><strong>快速部署：</strong> Docker容器可以迅速启动和停止，因此可以更快速地部署和更新应用程序，有助于实现持续集成和持续交付（CI&#x2F;CD）。</p></li><li><p><strong>隔离性：</strong> Docker提供了强大的容器隔离，确保容器内的应用程序不会相互干扰，并提供了一定程度的安全性。</p></li><li><p><strong>生态系统和社区支持：</strong> Docker拥有广泛的生态系统和强大的社区支持，有大量的官方和第三方容器镜像，以及丰富的工具和插件，使得它更容易集成到不同的应用和基础架构中。</p></li></ol><p>📌 用途</p><ol start="6"><li><p><strong>微服务架构：</strong> Docker容器可用于构建和管理微服务，使每个微服务都运行在独立的容器中，有助于系统的模块化和可伸缩性。</p></li><li><p><strong>持续集成和持续交付（CI&#x2F;CD）：</strong> Docker容器在CI&#x2F;CD流程中扮演重要角色，帮助自动化构建、测试和部署过程，提高交付速度和可靠性。</p></li><li><p><strong>多云环境部署：</strong> Docker容器的可移植性使得在不同云服务提供商之间迁移应用程序变得更加容易，同时也有助于混合云和多云战略的实施。</p></li><li><p><strong>资源隔离和多租户环境：</strong> Docker容器可用于隔离不同租户或应用程序，确保资源分配和安全性。</p></li></ol><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>📌 Linux基础</p><p>📌 CentOS 7</p><p>基于开源 Linux 发行版 Red Hat Enterprise Linux (RHEL) 的免费、企业级操作系统。它采用了稳定性和可靠性为主要目标，适用于服务器环境和企业级应用程序。</p><p>📌 Xshell连接远程服务器进行操作</p><ol start="10"><li>环境查看：</li></ol><p>#系统内核<br> [root@iZ2vcet9lnxw7ajh08wb59Z ~]# uname -r<br> 4.18.0-305.3.1.el8.x86_64</p><p>#系统版本  </p><p> [root@iZ2vcet9lnxw7ajh08wb59Z ~]# cat &#x2F;etc&#x2F;os-release<br> NAME&#x3D;”CentOS Linux”<br> VERSION&#x3D;”8”<br> ID&#x3D;”centos”<br> ID_LIKE&#x3D;”rhel fedora”<br> VERSION_ID&#x3D;”8”<br> PLATFORM_ID&#x3D;”platform:el8”<br> PRETTY_NAME&#x3D;”CentOS Linux 8”<br> ANSI_COLOR&#x3D;”0;31”<br> CPE_NAME&#x3D;”cpe:&#x2F;o:centos:centos:8”<br> HOME_URL&#x3D;”<a href="https://centos.org/">https://centos.org/</a>“<br> BUG_REPORT_URL&#x3D;”<a href="https://bugs.centos.org/">https://bugs.centos.org/</a>“<br> CENTOS_MANTISBT_PROJECT&#x3D;”CentOS-8”<br> CENTOS_MANTISBT_PROJECT_VERSION&#x3D;”8”  </p><ol start="11"><li>安装</li></ol><p> # 1、卸载旧的版本<br> sudo yum remove docker \<br>                   docker-client \<br>                   docker-client-latest \<br>                   docker-common \<br>                   docker-latest \<br>                   docker-latest-logrotate \<br>                   docker-logrotate \<br>                   docker-engine<br>​<br> # 2、需要的安装包<br> sudo yum install -y yum-utils  </p><p> # 3、设置镜像的仓库<br> yum-config-manager –add-repo <a href="http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a>  </p><p> # 更新yum软件包索引<br> yum makecache fast  </p><p> # 4、安装docker相关的源 docker-ce 社区 ee 企业版<br> yum install docker-ce docker-ce-cli containerd.io  </p><p> # 5、启动docker<br> systemctl start docker  </p><p> # 6、使用docker version 查看是否安装成功  </p><p> # 7、docker run hello-world  </p><p> # 8、查看下载的这个 hello-world 镜像  </p><h3 id="Docker基本概念"><a href="#Docker基本概念" class="headerlink" title="Docker基本概念"></a>Docker基本概念</h3><p>🪞 image-镜像</p><p>Docker 镜像是容器的模板</p><p>它包含了运行容器所需的文件系统、库和配置等。</p><p>tomat镜像—–&gt;run—–&gt;Tomcat01 容器（提供服务器）</p><p>🧂 container-容器</p><p>Docker 容器是基于 Docker 镜像创建的运行<strong>实例</strong></p><ul><li>容器可以看做简易的Linux系统</li></ul><p>🈁 repository-仓库</p><p>存放镜像的地方</p><p>分为公有仓库和私有仓库</p><h3 id="镜像（Images）和容器（Containers）的区别"><a href="#镜像（Images）和容器（Containers）的区别" class="headerlink" title="镜像（Images）和容器（Containers）的区别"></a>镜像（Images）和容器（Containers）的区别</h3><p>镜像（Images）和容器（Containers）是Docker中两个关键的概念，它们在Docker生态系统中有不同的角色和用途。以下是镜像和容器之间的主要区别：</p><p><strong>1. 定义和用途：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像是一个只读的文件，其中包含了应用程序、运行时环境、系统工具和库等的静态快照。镜像可以看作是应用程序的构建模块，它包含了所有启动容器所需的文件系统和配置信息。镜像通常用于创建容器。</p></li><li><p><strong>容器（Containers）：</strong> 容器是基于镜像运行的实例。它是镜像的一个运行时环境，包括正在运行的应用程序和其依赖的进程。容器是可读写的，并且可以与主机系统和其他容器进行交互。容器是实际运行和执行应用程序的实体。</p></li></ul><p><strong>2. 可变性：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像是不可变的，一旦创建，其内容不会改变。如果需要对应用程序进行更新或修改，通常需要创建一个新的镜像。</p></li><li><p><strong>容器（Containers）：</strong> 容器是可变的，可以在容器内部运行应用程序，进行文件操作、修改配置等。容器的状态可以随着应用程序的运行而改变。</p></li></ul><p><strong>3. 生命周期：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像的生命周期是静态的，它存在于Docker主机上，可以被多个容器实例引用。镜像通常是持久的，直到手动删除。</p></li><li><p><strong>容器（Containers）：</strong> 容器的生命周期是动态的，它可以被创建、启动、停止和删除。容器是短暂的，存在于需要运行应用程序的时候，然后可以被销毁。</p></li></ul><p><strong>4.资源消耗：</strong></p><ul><li><p><strong>镜像（Images）：</strong> 镜像通常占用较大的磁盘空间，因为它包含了应用程序的完整静态快照。</p></li><li><p><strong>容器（Containers）：</strong> 容器通常比镜像占用更少的磁盘空间，因为容器只包含运行应用程序所需的可写层，并且可以共享底层镜像的内容。</p></li></ul><p>总之，镜像是Docker中的静态构建块，用于创建容器的基础，而容器是运行时实体，代表一个应用程序的运行实例。理解镜像和容器之间的区别对于有效使用Docker和容器化应用程序非常重要。容器化技术使得应用程序更容易管理、部署和扩展。</p><p>DockerFile : 构建文件，定义了一切的步骤，源代码</p><p>DockerImages ： 通过DokerFile构建生成的镜像，是最终发布和运行的产品</p><p>Docker容器：容器就是镜像运行起来提供服务器</p><p><img src="/(/images/U3.png" alt="Untitled"></p><h1 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h1><h3 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a><strong>镜像命令</strong></h3><ul><li><p>查看所有本地主机上的镜像：<code>docker images</code></p><blockquote><p>REPOSITORY：镜像的仓库源TAG：镜像的标签IMAGE ID：镜像的IDCREATED：镜像的创建时间</p></blockquote></li><li><p>搜索镜像：<code>docker search 镜像名</code></p><blockquote><p>–filter, -f：根据提供的条件筛选输出</p></blockquote></li><li><p>下载镜像：<code>docker pull 镜像名[:tag]</code></p><blockquote><p>docker pull mysql:5.7</p></blockquote></li><li><p>删除镜像：<code>docker rmi</code></p><ul><li><p>删除指定的容器：<code>docker rmi -f 容器id</code></p></li><li><p>删除多个容器：<code>docker rmi -f 容器id1 容器id2 ...</code></p></li><li><p>删除全部容器：<code>docker rmi -f $(docker images -aq)</code></p></li></ul></li></ul><h3 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a><strong>容器命令</strong></h3><ul><li><p><strong>新建容器并启动：</strong><code>docker run 镜像名</code></p><table><thead><tr><th>可选参数</th><th>说明</th></tr></thead><tbody><tr><td>-p</td><td>设置端口映射，宿主机端口:容器端口</td></tr><tr><td>-P</td><td>随机分配端口</td></tr><tr><td>-i</td><td>前台交互式启动，通常与 -t 配合使用</td></tr><tr><td>-t</td><td>启动容器内的伪终端，通常与 -i 配合使用</td></tr><tr><td>-d</td><td>后台守护式启动</td></tr><tr><td>–name</td><td>为容器命名</td></tr></tbody></table><blockquote><p>-可选参数：</p><ul><li><p>name&#x3D;”Name”：容器名字，用于区分容器</p></li><li><p>d：后台方式运行</p></li><li><p>it：使用交互方式运行</p></li><li><p>p：指定容器的端口映射&lt;主机端口&gt;:&lt;容器内部端口&gt;</p></li><li><p>v：挂载数据卷</p></li></ul></blockquote><hr><p>  注意 -d后台方式运行<br>  docker run -d centos<br>  ​<br>  #但docker ps后发现 centos 停止了<br>  ​  </p><h1 id="docker容器使用后台运行，就必须要有一个前台进程，"><a href="#docker容器使用后台运行，就必须要有一个前台进程，" class="headerlink" title="docker容器使用后台运行，就必须要有一个前台进程，"></a>docker容器使用后台运行，就必须要有一个前台进程，</h1><p>  docker发现没有应用，就会自动停止<br>  nginx,容器启动后，发现自己没有提供服务，就会立刻停止，就是没有程序了</p><hr></li><li><p><strong>列出所有运行中的容器：<code>docker ps</code></strong></p><blockquote><p>可选项：</p><ul><li><p>a：列出所有容器（包括历史运行过的）</p></li><li><p>n&#x3D;?：显示最近创建的容器</p></li><li><p>q：只显示容器的编号</p></li></ul></blockquote><ul><li><p>进入一个正在运行的Docker容器:<code>docker exec</code></p></li><li><p><strong>docker exec -it &lt;容器名称或容器ID&gt; &lt;shell命令&gt;</strong></p><blockquote><p>-it：这是两个选项的组合，</p><p><code>-i</code>表示交互式</p><p><code>-t</code>表示分配一个终端（TTY）。这允许您与容器进行交互，就像您在本地计算机上使用终端一样。</p><p><code>&lt;shell命令&gt;</code>：这是您要在容器内执行的shell命令。通常，您可以使用<code>/bin/bash</code>或<code>/bin/sh</code>来启动一个shell会话。</p></blockquote></li></ul></li><li><p><strong>退出容器：exit</strong></p><blockquote><p>直接容器停止并退出：exit</p><p>容器不停止退出：<code>Ctrl + P + Q</code></p></blockquote></li><li><p>**删除容器：**docker rm 容器id</p><blockquote><p>删除指定容器：docker rm 容器id</p><p>删除所有容器：<code>docker rm -f $(docker ps -aq)</code> 或 <code>docker ps -aq | xargs docker rm</code></p></blockquote></li><li><p><strong>启动、重启和停止容器：</strong></p><blockquote><p>启动容器：docker start 容器id</p><p>重启容器：<code>docker restart 容器id</code></p><p>停止容器：<code>docker stop 容器id</code></p><p>强制停止容器：<code>docker kill 容器id</code></p></blockquote></li></ul><h3 id="其他常用命令"><a href="#其他常用命令" class="headerlink" title="其他常用命令"></a><strong>其他常用命令</strong></h3><ul><li><p>后台启动容器：<code>docker run -d 镜像名</code></p></li><li><p>查看容器日志：<code>docker logs -f -t --tail 容器id</code></p></li><li><p>查看容器中的进程信息：<code>docker top 容器id</code></p></li><li><p>查看容器源数据：<code>docker inspect 容器id</code></p></li><li><p>进入当前正在运行的容器：<code>docker exec -it 容器id 命令</code></p></li><li><p><code>docker run</code>：运行容器</p></li><li><p><code>docker pull</code>：拉取镜像</p></li><li><p><code>docker ps</code>：查看运行中的容器</p></li><li><p><code>docker images</code>：查看镜像列表</p></li><li><p><code>docker stop</code> 和 <code>docker rm</code>：停止和删除容器</p></li></ul><h3 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a><strong>帮助命令</strong></h3><ul><li><p>显示Docker版本信息：<code>docker version</code></p></li><li><p>显示Docker系统信息，包括镜像和容器的数量：<code>docker info</code></p></li><li><p>获取Docker命令的帮助：<code>docker 命令 --help</code></p></li><li><p>帮助文档地址：<a href="https://docs.docker.com/reference/">Docker官方文档</a></p></li><li><p>重启docker服务<code>systemctl restart docker</code></p></li></ul><h1 id="dickerfile-创建自定义镜像"><a href="#dickerfile-创建自定义镜像" class="headerlink" title="dickerfile-创建自定义镜像"></a>dickerfile-创建自定义镜像</h1><p><strong>Docker image由只读层组成，每个层代表一条 Dockerfile 指令。这些层是堆叠在一起的，每一层都是与前一层的变化的增量</strong></p><p><strong>dockerfile—&gt;文本文件</strong>，用于定义Docker镜像的构建过程。它包含一系列的指令和参数，这些指令告诉Docker引擎如何从一个基础镜像构建一个新的镜像，包括如何添加应用程序代码、依赖项、配置文件等。</p><ul><li><input disabled type="checkbox"> <strong>注意事项</strong><ul><li><input disabled type="checkbox"> 保留关键字都必须大写！</li><li><input disabled type="checkbox"> 执行顺序：从上到下</li><li><input disabled type="checkbox"> 每个指令都创建提交一个新的镜像层</li><li><input disabled type="checkbox"> dockerfile是面向开发的</li></ul></li></ul><h3 id="dockerfile的指令"><a href="#dockerfile的指令" class="headerlink" title="dockerfile的指令"></a>dockerfile的指令</h3><p><strong>FROM</strong>         #指定基础镜像<br><strong>MAINTAINER</strong>   #指定维护者信息：姓名+邮箱<br><strong>RUN         #每执行一条RUN命令,镜像添加新的一层.  <br>ADD</strong>          #将文件或目录复制到容器中，自动解压<br><strong>WORKDIR</strong>      #工作目录，类似于 cd 命令，即切换目录<br>通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、 COPY等命令都会在该目录下执行。  </p><p><strong>VOLUNME</strong>      #创建一个挂载点，<br><strong>EXPOSE</strong>       #指定容器监听的端口<br>ENV # 构建的时候设置环境变量！<br>VOLUME [“volume01”,”volume02”]   # 定义一个挂载点,用于持久化数据</p><p><strong>CMD :设置容器启动后默认执行的命令和参数ENTRYPOINT :设置容器启动时运行的命令</strong></p><p>ADD带有自动解压功能 COPY没有自动解压功能</p><p>构建镜像</p><h1 id="命令-docker-build-f-文件路径-t-镜像名-tag"><a href="#命令-docker-build-f-文件路径-t-镜像名-tag" class="headerlink" title="命令 docker build -f 文件路径 -t 镜像名:[tag]"></a>命令 docker build -f 文件路径 -t 镜像名:[tag]</h1><p><code>docker buildx build -t nikicentos:1.0 -f mydockerfile</code> <em>#用于构建一个名为 nikicentos，标签为 1.0 的 Docker 镜像 #使用名为 mydockerfile 的 Dockerfile，并且<strong>构建上下文路径是当前目录（.）</strong>。</em></p><h3 id="docker-history"><a href="#docker-history" class="headerlink" title="docker history &lt;镜像ID或名称&gt;-"></a><code>docker history &lt;镜像ID或名称&gt;</code>-</h3><p><strong>查看 Docker 镜像的构建历史</strong></p><p><code>CMD</code><em>指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代。</em></p><p><code>ENTRYPOINT</code> <em>指定这个容器启动的时候要运行的命令，可以追加命令</em></p><ul><li><p>如果你只关心容器的默认命令，使用 <strong><code>CMD</code></strong> 即可。</p></li><li><p>如果你希望容器的默认命令可以接受参数，使用 <strong><code>ENTRYPOINT</code></strong>。</p></li></ul><p><a href="https://www.notion.so/test-centOS-e15001a2ff8944258855e5d810b7cd16?pvs=21">test-构建自己的centOS</a></p><p><a href="https://www.notion.so/test2-Tomcat-dfabe04415fa4501934d91f827a00469?pvs=21">test2-Tomcat镜像</a></p><h3 id="1-容器数据卷（Container-Volumes）："><a href="#1-容器数据卷（Container-Volumes）：" class="headerlink" title="1. 容器数据卷（Container Volumes）："></a><strong>1. 容器数据卷（Container Volumes）：</strong></h3><h3 id="容器之间共享和持久化数据的机制"><a href="#容器之间共享和持久化数据的机制" class="headerlink" title="容器之间共享和持久化数据的机制"></a>容器之间共享和持久化数据的机制</h3><ul><li><p>容器数据卷是Docker容器内部的目录或文件，它们映射到宿主机的文件系统目录，或者可以共享给其他容器使用。</p></li><li><p>容器数据卷可以包含应用程序数据、配置文件、日志文件等。这些数据卷可以在容器之间传递信息，以及在容器的生命周期内保持数据的一致性。</p></li><li><p>创建容器数据卷的方法包括在容器启动命令中使用<code>v</code>或<code>-volume</code>选项，或在Docker Compose文件中定义<code>volumes</code>部分。</p></li><li><p>示例：创建一个容器并将它的<code>/data</code>目录映射到宿主机的<code>/var/data</code>目录，以实现数据持久化和共享。</p><p>  docker run -v &#x2F;var&#x2F;data:&#x2F;data my-container<br>  ​</p></li></ul><h3 id="具名挂载-匿名挂载"><a href="#具名挂载-匿名挂载" class="headerlink" title="具名挂载 &amp; 匿名挂载"></a>具名挂载 &amp; 匿名挂载</h3><p>在Docker中，有两种主要的数据卷挂载方式：具名挂载（named volumes）和匿名挂载（anonymous volumes）。这些挂载方式允许容器与主机之间共享数据，但它们在用法和管理上有一些区别。</p><p><strong>1. 具名挂载（Named Volumes）：</strong></p><ul><li><p>具名挂载是通过为数据卷指定名称来创建的。</p></li><li><p>这些数据卷的名称对用户可见，可以随时引用和管理。</p></li><li><p>具名挂载通常用于保存应用程序的数据，例如数据库数据、配置文件等。</p></li><li><p>创建具名挂载可以使用<code>docker volume create</code>命令，或者在容器运行时通过<code>v</code>标志来指定。</p></li><li><p>例子：<code>docker run -v mydata:/app/data myapp</code>，其中<code>mydata</code>是具名挂载的名称。</p></li></ul><p><strong>2. 匿名挂载（Anonymous Volumes）：</strong></p><ul><li><p>匿名挂载是未命名的，不需要为其指定名称。</p></li><li><p>这些数据卷的名称由Docker自动生成，用户通常不需要直接操作它们。</p></li><li><p>匿名挂载通常用于容器内部的临时数据，例如日志文件或运行时状态。</p></li><li><p>匿名挂载通常在容器运行时通过<code>v</code>标志来创建，但不指定具体的卷名称。</p></li><li><p>例子：<code>docker run -v /app/data myapp</code>，其中<code>/app/data</code>是匿名挂载。</p></li></ul><p>无论使用具名挂载还是匿名挂载，数据卷都允许容器之间或容器与主机之间共享数据，并且在容器之间启动、停止和删除时，数据都会得到保留。这使得容器可以更灵活地管理和存储数据，而不受容器生命周期的限制。</p><p> # 匿名挂载<br> -v 容器内路径!<br> docker run -d -P –name nginx01 -v &#x2F;etc&#x2F;nginx nginx  </p><p> # 查看所有的volume的情况<br> ➜  ~ docker volume ls<br> DRIVER              VOLUME NAME<br> local               33ae588fae6d34f511a769948f0d3d123c9d45c442ac7728cb85599c2657e50d<br> local<br> # 这里发现，这种就是匿名挂载，我们在 -v只写了容器内的路径，没有写容器外的路劲！  </p><p> # 具名挂载<br> ➜  ~ docker run -d -P –name nginx02 -v juming-nginx:&#x2F;etc&#x2F;nginx nginx<br> ➜  ~ docker volume ls<br> DRIVER              VOLUME NAME<br> local               juming-nginx  </p><p> # 通过 -v 卷名：容器内路径<br> # 查看一下这个卷  </p><h3 id="2-数据卷容器（Data-Volume-Containers）："><a href="#2-数据卷容器（Data-Volume-Containers）：" class="headerlink" title="2. 数据卷容器（Data Volume Containers）："></a><strong>2. 数据卷容器（Data Volume Containers）：</strong></h3><h3 id="管理和存储数据卷的特殊容器"><a href="#管理和存储数据卷的特殊容器" class="headerlink" title="管理和存储数据卷的特殊容器"></a>管理和存储数据卷的特殊容器</h3><ul><li><p>数据卷容器是一种特殊类型的<strong>Docker容器</strong>，其主要目的是提供数据卷的存储和管理。它不运行应用程序，而只包含数据卷。</p></li><li><p>你可以创建一个数据卷容器，然后在其他容器中使用<code>-volumes-from</code>选项来共享这个数据卷容器的数据卷。</p></li><li><p>数据卷容器可以用于集中管理多个容器之间共享的数据，使得备份、恢复和数据共享更加方便。</p></li><li><p>示例：创建一个数据卷容器，然后在另一个容器中使用它的数据卷。</p><p>  docker create -v &#x2F;data –name my-data-container my-data-image<br>  docker run –volumes-from my-data-container my-app-container<br>  ​</p></li></ul><h3 id="docker-网络"><a href="#docker-网络" class="headerlink" title="docker 网络"></a>docker 网络</h3><h3 id="Docker网络是Docker容器之间通信的一种方式。"><a href="#Docker网络是Docker容器之间通信的一种方式。" class="headerlink" title="Docker网络是Docker容器之间通信的一种方式。"></a>Docker网络是Docker容器之间通信的一种方式。</h3><p><img src="/(/images/U4.png" alt="Untitled"></p><ol start="12"><li><p><strong>lo (回环接口)</strong>:</p><ul><li>IP地址：<code>127.0.0.1/8</code> -</li></ul></li><li><p><strong>eth0(阿里云内网地址）</strong></p><ul><li>IP地址：<code>172.23.91.165/20</code></li></ul></li><li><p><strong>docker0</strong>:</p><ul><li><p>用于在同一主机上的Docker容器之间进行通信。</p></li><li><p>IP地址：<code>172.17.0.1/16</code></p></li></ul><h3 id="veth-pair"><a href="#veth-pair" class="headerlink" title="veth-pair"></a>veth-pair</h3><p><code>veth</code> 是 Linux 中的虚拟以太网设备。它通常以对成对出现，每对之间存在一个虚拟的连接。这种连接一端被连接到宿主机的网络命名空间中，另一端被连接到一个容器的网络命名空间中。</p><p>具体来说：</p><ul><li><p>一端的 <code>veth</code> 设备（通常以 <code>vethXXXXXX</code> 的形式命名）会被放置在宿主机的网络命名空间中。</p></li><li><p>另一端会被分配给容器，并以另一个名称（通常是 <code>ethX</code>）存在于容器的网络命名空间中。</p></li></ul><p>这两端的 <code>veth</code> 设备相互连接，形成一个虚拟的以太网链路。这样，宿主机和容器就可以通过这个虚拟链路进行通信。</p></li></ol><p>Docker提供了多种网络模式，可以根据需要选择适合的网络配置。以下是一些常用的Docker网络概念和操作：</p><ol start="15"><li><p><strong>默认网络（bridge）</strong>:</p><ul><li><p>这是Docker的默认网络模式。在这种模式下，Docker容器可以相互通信，但通常不能直接从主机外部访问。默认情况下，容器会通过NAT方式连接到宿主机的网络。</p></li><li><p>创建一个容器并且默认会连接到这个网络：</p></li></ul><p>docker run -d –name my_container nginx<br>​</p><ul><li>默认网络的子网和网关可以通过以下命令查看：</li></ul><p>docker network inspect bridge<br>​</p></li><li><p><strong>主机网络（host）</strong>:</p><ul><li><p>使用主机网络模式，容器将直接共享主机的网络命名空间，这意味着容器将可以使用宿主机的网络接口，并且不会进行端口映射。</p></li><li><p>使用主机网络模式启动容器：</p></li></ul><p>docker run -d –network host nginx<br>​</p></li><li><p><strong>用户定义网络</strong>:</p><ul><li><p>用户可以创建自己的自定义网络，可以在这个网络上创建容器，并且容器可以相互通信。</p></li><li><p>创建一个自定义网络：</p></li></ul><p>docker network create my_network<br>​</p><ul><li>在自定义网络上运行容器：</li></ul><p>docker run -d –network my_network –name container1 nginx<br>docker run -d –network my_network –name container2 nginx<br>​</p></li><li><p><strong>覆盖网络（overlay）</strong>:</p><ul><li><p>覆盖网络允许在不同主机上的Docker守护程序之间创建跨主机的容器通信。这在Docker集群中很有用。</p></li><li><p>创建覆盖网络：</p></li></ul><p>docker network create –driver overlay my_overlay_network<br>​</p><ul><li>在覆盖网络上启动容器：</li></ul><p>docker service create –network my_overlay_network –name my_service nginx<br>​</p></li><li><p><strong>Macvlan网络</strong>:</p><ul><li><p>Macvlan网络允许将容器直接连接到物理网络，每个容器都有自己的MAC地址。</p></li><li><p>创建Macvlan网络：</p></li></ul><p>docker network create -d macvlan –subnet&#x3D;192.168.1.0&#x2F;24 –gateway&#x3D;192.168.1.1 -o parent&#x3D;eth0 my_macvlan_network<br>​</p><ul><li>在Macvlan网络上运行容器：</li></ul><p>docker run -d –network my_macvlan_network –name container1 nginx<br>​</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;docker&quot;&gt;&lt;a href=&quot;#docker&quot; class=&quot;headerlink&quot; title=&quot;docker&quot;&gt;&lt;/a&gt;docker&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/(/images/U1.png&quot; alt=&quot;Untitled&quot;&gt;&lt;/p&gt;
&lt;h2 id</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    
    <category term="运维" scheme="https://sosocrown.github.io/tags/%E8%BF%90%E7%BB%B4/"/>
    
    <category term="容器" scheme="https://sosocrown.github.io/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>AWS-SAA-C03题解思路</title>
    <link href="https://sosocrown.github.io/2023/09/01/AWS-SAA-C03%E9%A2%98%E8%A7%A3%E6%80%9D%E8%B7%AF/"/>
    <id>https://sosocrown.github.io/2023/09/01/AWS-SAA-C03%E9%A2%98%E8%A7%A3%E6%80%9D%E8%B7%AF/</id>
    <published>2023-08-31T16:00:00.000Z</published>
    <updated>2025-05-07T02:37:31.848Z</updated>
    
    <content type="html"><![CDATA[<h2 id="422-D"><a href="#422-D" class="headerlink" title="422-D"></a>422-D</h2><p>  一家公司正在 AWS 上开发新的机器学习 (ML) 模型解决方案。这些模型被开发为独立的微服务，在启动时从 Amazon S3 获取大约 1 GB 的模型数据并将数据加载到内存中。</p><p>  用户通过<strong>异步</strong> API 访问模型。用户可以发送一个请求或一批请求，并指定结果应发送到何处。该公司为数百名用户提供模型。模型的使用模式是不规则的。某些型号可能会闲置数天或数周。其他模型可以一次接收数千个批次的请求。<br>  解决方案架构师应该推荐哪种设计来满足这些要求？</p><p>  <strong>A</strong>. 将来自 API 的请求定向到NLB</p><p>  将模型部署为 NLB 调用的 AWS Lambda 函数。</p><p>  <strong>B</strong>. 将请求从 API 定向到ALB。将模型部署为从SQS 队列读取的  ECS 服务</p><pre><code> 使用 AWS App Mesh 根据 SQS 队列大小扩展 ECS 集群的实例。</code></pre><p>  <strong>C</strong>. 将来自 API 的请求定向到 SQS队列。将模型部署为由 SQS 事件调用的 AWS Lambda 函数</p><p>  使用 AWS Auto Scaling <strong>根据 SQS 队列大小</strong>增加 Lambda 函数的 vCPU 数量。</p><p>  <strong>D</strong>. 将来自 API 的请求定向到 SQS队列。将模型部署为从队列中读取的  ECS 服务。</p><p>  根据<strong>队列大小</strong>为集群和服务副本在 Amazon ECS 上启用 AWS Auto Scaling。</p><p>  <img src="/images/aws1.png" alt="在这里插入图片描述"></p><p>  ➡️ SQS队列是一种适用于<strong>异步</strong>消息传递的服务，可以帮助解耦和分离不同部分的系统，从而提高可靠性和弹性。</p><p>  ➡️ ALB非常适用于<strong>微服务</strong>和基于<strong>容器</strong>的应用程序,，但ALB和NLB更适合处理<strong>实时性请求</strong>，而不是异步处理。它们适用于传统的请求-响应式Web应用程序，其中客户端发出请求，然后期望快速获得响应。</p><p>  ➡️ ALB和NLB具有一些高级的负载均衡和路由功能，可以确保请求被迅速传递到后端实例并返回响应。</p><p>  Lambda函数通常用于处理短暂的、事件驱动的任务，在这个问题中，由于模型数据较大，需要在启动时从S3中加载，而且需要长时间运行，使用Lambda可能会受到限制，因为Lambda的运行时间有限制，而且加载1 GB的模型数据可能会造成延迟。</p><h2 id="330-A"><a href="#330-A" class="headerlink" title="330-A"></a>330-A</h2><p>  公司计划在Amazon RDS数据库实例上存储数据。公司必须对<strong>静态数据</strong>进行加密。解决方案架构师应采取什么措施来满足这个要求？</p><p>  A. 在AWS Key Management Service（<strong>AWS KMS</strong>）中创建一个密钥。启用数据库实例的加密。</p><p>  B. 创建一个加密密钥。将密钥存储在AWS Secrets Manager中。使用该密钥加密数据库实例。</p><p>  C. 在AWS Certificate Manager（ACM）中生成证书。使用该证书在数据库实例上启用SSL&#x2F;TLS。</p><p>  D. 在AWS Identity and Access Management（IAM）中生成证书。使用该证书在数据库实例上启用SSL&#x2F;TLS。</p><p>  当需要在Amazon RDS数据库实例上存储数据时，要求对这些数据进行加密，以保护数据的安全。在这种情况下，最适合的方法是：</p><p>  A. 在AWS Key Management Service（AWS KMS）中创建一个密钥，并启用数据库实例的加密。</p><p>  解释：</p><ul><li>AWS Key Management Service（KMS）是用于管理加密密钥的服务。</li><li>通过在AWS KMS中创建一个密钥并在数据库实例上启用加密，数据库实例中存储的数据将使用AWS KMS密钥进行自动加密，以确保数据在存储时得到加密保护。</li><li>这是<strong>在Amazon RDS实例上加密静态数据的标准和推荐方法</strong>。</li></ul><p>  AWS Secrets Manager用于管理敏感信息，但不推荐将其用于在Amazon RDS实例上对数据进行静态加密。</p><p>   AWS Certificate Manager（ACM）用于管理用于保护网络通信的SSL&#x2F;TLS证书，但与在Amazon RDS实例上对数据进行静态加密无直接关系。</p><p>  AWS Identity and Access Management（<strong>IAM</strong>）用于管理对AWS资源的访问，但在IAM中生成证书并不是对Amazon RDS实例上的数据进行静态加密的方法。</p><h2 id="338-D"><a href="#338-D" class="headerlink" title="338-D"></a>338-D</h2><p>  解决方案架构师必须为<strong>大容量</strong>软件即服务 (SaaS) 平台创建灾难恢复 (DR) 计划。该平台的<br>  所有数据都存储在 Amazon Aurora MySQL 数据库集群中。DR 计划必须将数据复制到辅助 AWS 区域。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <strong>A.</strong> 使用 MySQL 二进制日志复制到辅助区域中的 Aurora 集群。为辅助区域中的 Aurora<br>  集群配置一个数据库实例。</p><p>  <code>需要手动配置和管理二进制日志复制，可能需要更多的操作和维护。另外，如果主区域出现问题，需要手动干预来切换到辅助区域。</code></p><p>  <strong>B</strong>. 为数据库集群设置 Aurora global数据库。设置完成后，从辅助区域中删除数据库实例。</p><p>  <code>涉及更高的成本，因为需要在两个区域都配置 Aurora 数据库实例。</code></p><p>  <strong>C.</strong> 使用 AWS Database Migration Service (AWS DMS) 将数据持续复制到次要区域中的Aurora 集群。从次要区域中删除数据库实例。</p><p>  <code>与选项 A 类似，需要管理复制过程和可能的切换过程。</code></p><p>   <strong>D.</strong> 为数据库集群设置 Aurora global数据库。在次要区域中指定至少一个数据库实例</p><ul><li><p>343-C</p><p>解决方案架构师正在设计公司的灾难恢复 (DR) 架构。该公司拥有一个 MySQL 数据库，该数据库在私有子网中的 Amazon EC2 实例上运行，并具有计划备份。灾难恢复设计需要包括<strong>多个 AWS 区域multiple AWS Regions.</strong>。<br>哪种解决方案能够以最少的运营开销满足这些要求？</p><p><strong>A.</strong> 将 MySQL 数据库迁移到多个 EC2 实例。在 DR 区域配置备用 EC2 实例。打开复<br>制。</p><p><code>Multiple EC2 instances to be configured and updated manually手动地 in case of DR.</code></p><p><code>需要手动配置</code></p><p><strong>B.</strong> 将 MySQL 数据库迁移到 Amazon RDS。使用多可用区部署。为不同可用区中的主数据<br>库实例启用读取复制。<code>multi-AZ,题目要求multi region</code></p><p><strong>C.</strong> 将 MySQL 数据库迁移到 Amazon Aurora global数据库。在主区域中托管主数据库集群。<br>在 DR 区域中托管辅助数据库集群。</p><p><strong>D.</strong> 将 MySQL 数据库的计划备份存储在为 S3 跨区域复制 (CRR) 配置的 Amazon S3 存<br>储桶中。使用数据备份恢复灾备区域的数据库。</p><p><code>需要手动配置</code></p></li></ul><h2 id="348-B"><a href="#348-B" class="headerlink" title="348-B"></a>348-B</h2><p>  一家公司从大量使用可穿戴设备的参与者那里收集数据。该公司将数据存储在 Amazon<br>  DynamoDB 表中，并使用应用程序分析数据。数据工作量是<em><strong>恒定且可预测</strong></em>的。该公司希望将DynamoDB 的预算保持在或低于其预测。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <strong>A.</strong> 使用provisioned mode和 DynamoDB Standard-<strong>Infrequent Access</strong> (DynamoDB Standard-IA)。为预测的工作负载预留容量。</p><p>  <code>题目“使用应用程序分析数据”表明可能需要经常访问数据，不频繁访问不适合</code></p><p>  <strong>B</strong>. 使用provisioned mode模式。指定读取容量单位 (RCU) 和写入容量单位 (WCU)。</p><p>  <strong>C.</strong> 使用on-demand mode。将读取容量单位 (RCU) 和写入容量单位 (WCU) 设置得足够高，以适<br>  应工作负载的变化。</p><p>  <strong>D.</strong> 使用on-demand mode。指定具有保留容量的读取容量单位 (RCU) 和写入容量单位 (WCU)。</p><p>  <code>provisioned mode允许您为读取和写入容量单元（RCUs 和 WCUs）预先配置容量，适用于数据工作负载是持续且可预测的情况。</code></p><p>  <code>按需容量模式适用于具有*不稳定和不可预测*流量的应用程序</code></p><ul><li><p>357-A</p><p>一家游戏公司正在将其公共记分牌从<strong>数据中心迁移到 AWS 云</strong>。该公司在ALB后面使用 Amazon EC2 <strong>Windows Server</strong> 实例来托管其动态应用程序。该公司需要为应用程序提供高度可用的存储解决方案。该应用程序由<strong>静态文件</strong>和<strong>动态服务器端代码</strong>组成。解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p><strong>A.</strong> 将静态文件存储在 Amazon S3 上。使用 Amazon CloudFront 在边缘缓存对象。</p><p> B. 将静态文件存储在 Amazon S3 上。使用 Amazon ElastiCache 在边缘缓存对象。</p><p><code>ElastiCache 主要用于存储缓存数据，不适合存储静态文件。</code></p><p> C. 将服务器端代码存储在 Amazon Elastic File System (Amazon EFS) 上。在每个 EC2 实例上挂载<br>EFS 卷以共享文件。</p><p><code>EFS不适用于 Windows 实例。</code></p><p><strong>D.</strong> 将服务器端代码存储在 Amazon FSx for Windows File Server 上。在每个 EC2 实例上挂<br>载 FSx for Windows File Server 卷以共享文件。</p><p>E. 将服务器端代码存储在通用 SSD (gp2) Amazon Elastic Block Store (Amazon EBS) 卷上。<br>在每个 EC2 实例上挂载 EBS 卷以共享文件</p><p><code>EBS，用于块存储，不适合共享文件系统</code></p></li><li><p>359-C</p><p>医院需要将患者记录存储在 Amazon S3 存储桶中。医院的合规团队必须确保所有受保护的<br>健康信息 (PHI) <strong>encrypted in transit and at rest</strong>。合作<em><strong>团队必须管理静态数据的加密密钥</strong></em>。<br>哪种解决方案可以满足这些要求？</p><p>A. 在 AWS Certificate Manager (ACM) 中创建公共 SSL&#x2F;TLS 证书。将证书与 Amazon S3<br>关联。配置每个 S3 存储桶的默认加密，以使用带有 AWS KMS 密钥(SSE-KMS）的服务器端加密。分配合规团队来管理 KMS 密钥。</p><p><code>在桶策略上使用“aws:SecureTransport”条件---无法使用非加密的连接来访问存储桶内的数据，从而确保数据在传输过程中是安全加密的。</code></p><p><code>强制只有通过加密的连接（如 HTTPS/TLS）才能访问存储桶中的数据。</code><br>B. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 的加密连接。配置每个 S3 存储桶的默认加密，以使用带有 S3 托管加密密钥 (SSE-S3) 的服务器端加密。分配合规团队来管理 SSE-S3 密钥。</p><p><code>(SSE-S3) 是AWS来管理密钥</code></p><p>C. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 的加密连接。配置每个 S3 存储桶的默认加密，以使用带有 AWS KMS 密钥的服务器端加密(SSE-KMS)。分配合规团队来管理 KMS 密钥。</p><p><code>SSE-KMS是KMS管理密钥</code></p><p>D. 在 S3 存储桶策略上使用 aws:SecureTransport 条件以仅允许通过 HTTPS (TLS) 进行加密连接。使用 Amazon Macie 保护存储在 Amazon S3 中的敏感数据。分配合规团队来管理</p><p><code>Macie只保护不加密</code></p></li><li><p>372-B</p><p>一家公司想要将 Oracle 数据库迁移到 AWS。该数据库由一个表组成，其中包含数百万张高分辨率的地理信息系统 (GIS) 图像，并通过地理代码进行识别。当自然灾害发生时，<strong>每隔几分钟就会更新数万张图像。每个地理代码都有一个与之相关联的图像或行<code>暗示着数据的频繁更新和变化</code>。</strong>。该公司希望有一个在此类事件期间具有高可用性和可扩展性的解决方案。<br>哪种解决方案最经济高效地满足这些要求？</p><p>A. 将图像和地理代码存储在数据库表中。使用在 Amazon RDS 多可用区数据库实例上运行的 Oracle。</p><p>B. 将图像存储在 Amazon S3 存储桶中。使用 Amazon DynamoDB，将地理代码作为键，将图像 S3 URL 作为值。</p><p><code>您可以将图像存储在高度可扩展的 Amazon S3 中，同时使用 DynamoDB 来快速检索地理代码和图像的映射关系。这种方式可以处理数据的频繁更新，同时也确保数据的可用性和可靠性。</code></p><p>C. 将图像和地理代码存储在 Amazon DynamoDB 表中。在高负载期间配置 DynamoDB<br>Accelerator (DAX)。</p><p><code>DAX没必要</code></p><p>D. 将图像存储在 Amazon S3 存储桶中。将地理代码和图像 S3 URL 存储在数据库表中。使用在 Amazon RDS 多可用区数据库实例上运行的 Oracle</p><p><code>将地理代码和图像 S3 URL 存储在数据库表中可能会导致**数据库过于庞大**，**降低性能和可维护性。**</code></p></li><li><p>379-B</p><p>一家公司托管一个使用与 AWS Lambda 集成的 Amazon API Gateway API 后端的前端应用程序.当 API 收到请求时，<strong>the Lambda function loads many libraries-Lambda 函数会加载许多库</strong>。然后，Lambda 函数连接到Amazon RDS 数据库，处理数据，并将数据返回到前端应用程序。该公司希望确保所有用户的响应延迟尽可能低，同时对公司运营的更改最少。<br>哪种解决方案可以满足这些要求？</p><aside>➡️ 在 AWS Lambda 中，当一个函数实例首次启动时，它需要加载执行所需的运行时环境、代码和依赖项（例如库、模块等）。这个过程被称为 "冷启动"。</aside><p>A. 在前端应用程序和数据库之间建立连接，绕过 API 使查询速度更快。</p><p><code>建议使用 API Gateway 来处理前端应用程序和数据库之间的交互。直接连接前端应用程序和数据库可能导致安全性和性能问题。</code></p><p>B. 配置处理请求的 Lambda 函数的并发性。</p><p>Congure <strong>provisioned concurrency</strong> for the Lambda function that handles the requests</p><p>确保有足够数量的 Lambda 函数实例一直处于活动状态，从而减少冷启动延迟，提高响应时间并降低用户的等待时间。</p><p>C. 在 Amazon S3 中缓存查询结果，以便更快地检索类似数据集。</p><p><code>Lambda 函数在每次请求时需要从数据库获取数据，然后进行处理，这可能会导致缓存的效果有限。</code></p><p>D. 增加数据库的大小以增加 Lambda 一次可以建立的连接数。</p><p><code>增加连接数并不一定会直接解决延迟问题</code></p></li><li><p>385-C</p><p>解决方案架构师正在创建新的 VPC 设计。有两个用于负载均衡器的公有子网、两个用于Web 服务器的私有子网和两个用于 MySQL 的私有子网。 Web 服务器仅使用 HTTPS。解决方案架构师已经为负载均衡器创建了一个安全组，允许来自 0.0.0.0&#x2F;0 的端口 443。公司政策要求每个资源具有仍能够执行其任务所需的<em><strong>最少访问权限</strong></em>。<br>解决方案架构师应使用哪种附加配置策略来满足这些要求？</p><p>A. 为 Web 服务器创建<strong>security group</strong>并允许来自 0.0.0.0&#x2F;0 的端口 443。为 MySQL 服务器创建<strong>security group</strong>，并允许 Web 服务器安全组的端口 3306。 </p><p>B. 为 Web 服务器创建<strong>NACL</strong>，并允许来自 0.0.0.0&#x2F;0 的端口 443。为 MySQL 服务器创建<strong>NACL</strong>，并允许来自 Web 服务器安全组的端口 3306。 </p><p>C. 为 Web 服务器创建<strong>security group</strong>并允许来自负载均衡器的端口443。为 MySQL 服务器创建<strong>security group</strong>,并允许 Web 服务器安全组的端口 3306。</p><p>D. 为 Web 服务器创建<strong>NACL</strong>，并允许来自负载均衡器的端口 443。为 MySQL 服务器创建<strong>NACL</strong>，并允许来自 Web 服务器安全组的端口 3306。</p><p>**<code>最少访问权限**：根据公司政策，每个资源应具有执行其任务所需的最少访问权限。因此，应该限制不必要的公开访问。安全组是在instance level控制流量的一种有效方式。</code></p><p><code>私有子网中Web,mysql需要从负载均衡器接收 HTTPS 流量。因此，为 Web 服务器创建一个安全组，仅允许来自负载均衡器的端口 443 的流量。</code></p></li></ul><h2 id="210-D"><a href="#210-D" class="headerlink" title="210-D"></a>210-D</h2><p>  一家公司提供的食品配送服务发展迅速。由于业务增长，该公司的订单处理系统在高峰时<br>  段遇到了扩展问题。当前的架构包括以下内容：<br>  • 在 Amazon EC2 Auto Scaling 组中运行的一组 Amazon EC2 实例，用于从应用程序收集订单 </p><p>  • 在 Amazon EC2 Auto Scaling 组中运行的另一组 EC2 实例，用于完整订单</p><p>  订单收集过程发生得很快，<strong>但订单履行过程可能需要更长的时间</strong>。数据不得因缩放事件而丢失。<br>  解决方案架构师必须确保订单收集流程和订单履行流程都可以在高峰时段适当扩展。该解决方案必须优化公司 AWS 资源的利用率。<br>  哪种解决方案满足这些要求？</p><p>  A. 使用 Amazon CloudWatch 指标监控 Auto Scaling 组中每个实例的 CPU。根据峰值工作<br>  负载值配置每个 Auto Scaling 组的最小容量。</p><p>  B. 使用 Amazon CloudWatch 指标监控 Auto Scaling 组中每个实例的 CPU。配置CloudWatch 警报以调用 Amazon Simple Notication Service (Amazon SNS) 主题，该主题根据需要创建其他 Auto Scaling 组。</p><p>  C. 预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例以轮询其各自的队列。根据队列发送的通知扩展 Auto Scaling 组。</p><p>  D. 预置两个 Amazon Simple Queue Service (Amazon SQS) 队列：一个用于订单收集，另一个用于订单履行。配置 EC2 实例以轮询其各自的队列。根据每个实例的积压计算创建一个指标<strong>Create a metric based on a backlog per instance calculation</strong>, 根据此指标扩展 Auto Scaling 组&#x2F;</p><p>  <code>在每个 Amazon EC2 实例上计算一个指标，该指标反映了待处理的消息数量（即积压）。然后，根据这个指标来动态地调整 Auto Scaling 组中的实例数量。</code></p><p>  <code>SQS 队列充当订单收集流程和订单处理流程之间的缓冲，使系统能够更有效地处理突发的订单流量。</code></p><h2 id="218-AE"><a href="#218-AE" class="headerlink" title="218-AE"></a>218-AE</h2><p>  一家公司拥有一个在具有弹性 IP 地址的公有子网中的 Amazon EC2 实例上运行的 Web服务器。默认安全组分配给 EC2 实例。默认网络 ACL 已修改为阻止所有 trac。</p><p>  解决方案架构师需要使 Web 服务器可以<strong>通过端口 443 从任何地方访问</strong>。<br>  哪种步骤组合可以完成此任务？ （选择两个。）</p><p>  A. 创建一个安全组，其中包含允许来自源 0.0.0.0&#x2F;0 的 TCP 端口 443 的规则。</p><p>  B. 创建一个安全组，其中包含允许 TCP 端口 443 到达目标 0.0.0.0&#x2F;0 的规则。</p><p>  C. 更新网络 ACL 以允许来自源 0.0.0.0&#x2F;0 的 TCP 端口 443。</p><p>  D. 更新网络 ACL 以允许从源 0.0.0.0&#x2F;0 到目标 0.0.0.0&#x2F;0 的入站&#x2F;出站 TCP 端口 443。</p><p>  E. 更新网络 ACL 以允许从源 0.0.0.0&#x2F;0 的入站 TCP 端口 443 和到目标 0.0.0.0&#x2F;0 的出站<br>  TCP 端口 32768-65535。</p><p>  NACL是stateless，<strong>必须</strong>同时配置入站和出站规则。例如，如果你允许某个端口的入站流量，但没有相应的出站规则，那么服务器可能会接收请求，但由于出站规则的限制，无法正常发送响应。</p><ul><li><p>224-CE</p><p>一家公司最近通过在单个 AWS 区域的 Amazon EC2 实例上重新托管应用程序，将其 Web应用程序迁移到 AWS。该公司希望重新设计其应用程序架构，以实现高可用性和容错能力。 Trac 必须随机到达所有正在运行的 EC2 实例。<br>公司应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>A. 创建 Amazon Route 53 故障转移路由策略。<br>B. 创建 Amazon Route 53 加权路由策略。<br>C. 创建 Amazon Route 53 多值应答路由策略。</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td><em><strong>故障转移路由策略（Failover）</strong></em></td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td><em><strong>权重路由策略（Weighted）</strong></em></td><td>- 按照权重分配到不同资源</td></tr><tr><td><em><strong>多值路由策略（Multivalue）</strong></em></td><td>- 用于将流量路由到多个资源</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr></tbody></table><p>D. 启动三个 EC2 实例：两个实例位于一个可用区，一个实例位于另一个可用区。</p><p><code>考虑以下情况：</code></p><ul><li><code>如果一个可用区中的实例出现问题（如硬件故障），那么该可用区中的所有实例都将受到影响。</code></li><li><code>当只有一个实例在一个可用区中时，如果该可用区出现故障，会导致流量不能被完全分配。</code></li></ul><p>E. 启动四个 EC2 实例：一个可用区中的两个实例和另一个可用区中的两个实例。</p><p><code>这样做的好处在于：</code></p><ul><li><code>如果一个可用区中的一个实例出现问题，该可用区的另一个实例仍然可以处理流量，确保服务的持续可用性。</code></li><li><code>即使一个可用区完全失效，另一个可用区中的两个实例仍然可以处理流量，保证了更高的容错性和可用性。</code></li><li><code>由于每个可用区都有两个实例，流量在可用区之间更均匀地分布，从而提供更好的负载均衡。</code></li></ul></li></ul><h2 id="226-AE"><a href="#226-AE" class="headerlink" title="226-AE"></a>226-AE</h2><p>  一家公司使用在 Amazon EC2 实例上运行的 <strong>RESTful Web 服务应用程序</strong>从数千个远程设备收集数据。 EC2 实例<strong>接收</strong>原始数据，<strong>转换</strong>原始数据，并将所有数据存储在 Amazon S3存储桶中。远程设备的数量很快将增加到数百万。该公司需要一个高度可扩展的解决方案，最大限度地减少运营开销。<br>  解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>  <strong>A.</strong> 使用 AWS Glue 处理 Amazon S3 中的原始数据。</p><p>  <code>可扩展、无服务器的托管式数据集成、转换和加载服务。</code><br>  <strong>B.</strong> 使用 Amazon Route 53 将 trac 路由到不同的 EC2 实例。<br>  <strong>C.</strong> 添加更多 EC2 实例以适应不断增加的传入数据量。</p><p>  <strong>D.</strong> 将原始数据发送到 Amazon Simple Queue Service (Amazon SQS)。使用 EC2 实例来处理数据。<br>  <strong>E.</strong> 使用 Amazon API Gateway 将原始数据发送到 Amazon Kinesis 数据流。配置 Amazon Kinesis Data Firehose 以使用数据流作为源将数据传输到 Amazon S3</p><p>  <code>Amazon API Gateway 是 AWS 提供的一项托管服务，用于创建、部署和管理 API。它可以用于实现 **RESTful web services**，即基于 REST 原则的应用程序架构风格。</code></p><h2 id="273-B"><a href="#273-B" class="headerlink" title="273-B"></a>273-B</h2><p>  一家快速发展的电子商务公司正在单个 AWS 区域中运行其工作负载。解决方案架构师必须创建包含**不同 AWS 区域【看清楚！是区域region，不是AZ可用区】**的灾难恢复 (DR) 策略。该公司希望其数据库在灾难恢复区域保持最新状态，并尽可能减少延迟。灾难恢复地区的剩余基础设施需要以减少的容量运行，并且必须能够在必要时扩大规模。<br>  哪种解决方案能够以最低的恢复时间目标 (RTO) 满足这些要求？</p><p>  <strong>A.</strong> 使用 Amazon Aurora 全局数据库进行pilot light deployment.。<br>  <strong>B.</strong> 使用具有warm standby deployment的 Amazon Aurora 全局数据库。</p><p>  <strong>C</strong>. 将 Amazon RDS 多<em><strong>可用区</strong></em>数据库实例与pilot light deployment.结合使用。<br>  <strong>D</strong>. 将 Amazon RDS 多<em><strong>可用区</strong></em>数据库实例与warm standby deployment结合使用</p><p>  <code>multi-AZ而不是cross region</code></p><blockquote><p><strong>Pilot Light</strong></p><ul><li>仅创建必需的基础设施</li><li>在灾难发生时，扩展这些核心组件以支持完整环境的恢复。</li></ul></blockquote><blockquote><p><strong>Warm Standby 温备策略</strong>：</p><ul><li><em><strong>部署比Pilot Light更多的基础设施</strong></em>，以便可以更快地切换为活动状态。在DR区域中维护一个较大的读副本，以减少灾难恢复时的启动时间。</li><li>可以快速扩展并恢复到完整环境。</li></ul></blockquote><h2 id="247-CE"><a href="#247-CE" class="headerlink" title="247-CE"></a>247-CE</h2><p>  一家公司在 Amazon RDS for MySQL 中部署了数据库。由于事务增加，数据库支持团队报告数据库实例读取速度缓慢，并建议添加只读副本。<br>  在实施此更改之前，解决方案架构师应采取哪些操作组合？ （选择两个。）</p><p>  A. 在 RDS 主节点上启用 binlog 复制。</p><p>  <code>确保主数据库的更改在各个实例间进行同步。</code></p><p>  B. 为源数据库实例选择故障转移优先级。</p><p>  <strong>C. 允许长时间运行的事务在源数据库实例上完成。</strong></p><p>  <code>确保在添加只读副本之前，所有事务都已经完成</code></p><p>  D. 创建全局表并指定该表可用的 AWS 区域。</p><p>  <strong>E. 通过将备份保留期设置为 0 以外的值，在源实例上启用自动备份。</strong></p><p>  <code>启用自动备份并设置备份保留期可以确保有备份可供恢复，以防在添加只读副本期间出现问题。</code></p><ul><li><p>289-B</p><p>一家公司有一个 AWS Lambda 函数，需要对位于同一 AWS 账户中的 Amazon S3 存储桶进行读取访问。<br>哪种解决方案能够以最安全的方式满足这些要求？</p><p>A. 应用授予对 S3 存储桶的读取访问权限的 S3 存储桶策略。</p><p><strong>B. 将 IAM 角色应用于 Lambda 函数。将 IAM 策略应用于角色以授予对 S3 存储桶的<br>读取访问权限。</strong></p><p><code>选项 B 使用更精细的权限控制方法，仅允许特定 Lambda 函数访问资源，而选项 A 是在存储桶级别上设置权限，可能不如选项 B 提供的安全性高。</code></p><p>C. 在 Lambda 函数的代码中嵌入访问密钥和秘密密钥，以授予对 S3 存储桶进行读取访问<br>所需的 IAM 权限。</p><p><code>将访问密钥和秘密密钥嵌入代码中是不安全的做法，因为这会暴露凭证并增加泄露风险，从而可能导致安全漏洞。</code></p><p>D. 将 IAM 角色应用于 Lambda 函数。将 IAM 策略应用于角色以授予对账户中<strong>所有 S3</strong><br>存储桶的读取访问权限。</p><p><code>提供了对**所有 S3 存储桶**的读取权限</code></p></li></ul><h2 id="3-A"><a href="#3-A" class="headerlink" title="3-A"></a>3-A</h2><p>  一家公司使用 AWS Organizations 管理不同部门的多个 AWS 账户。管理账户有一个包含项目报告的 Amazon S3 存储桶。该公司希望仅限 AWS Organizations 中组织内账户的用户访问此 S3 存储桶。哪种解决方案能够以最少的<em><strong>运营开销</strong></em>满足这些要求？</p><p>  <strong>A. 将 aws PrimaryOrgID  global condition key以及对organization ID 的引用添加到 S3 存储桶策略。</strong></p><p>  <code>在Condition元素中指定组织ID，而不是列出作为组织成员的所有帐户</code></p><p>  B. 为每个部门<em><strong>创建</strong></em>一个组织单位 (OU)。将 aws:PrincipalOrgPaths  global condition key添加到 S3存储桶策略。</p><p>  <code>基于AWS Organizations的组织结构来控制访问权限。您可以定义哪些部门、组织单元【OU】或账户可以访问特定资源。</code></p><p>  C. 使用 AWS CloudTrail 监控CreateAccount、InviteAccountToOrganization、LeaveOrganization 和RemoveAccountFromOrganization 事件。相应地更新 S3 存储桶策略。</p><p>  D. 标记需要访问 S3 存储桶的每个用户。将 aws:PrincipalTag  global condition key添加到 S3 存储桶策略。</p><p>  <code>它允许您根据附加到身份的标签（Tag）来控制访问权限。这可以用于根据用户、角色或实体的标签来限制访问。</code></p><h3 id="条件键【condition-keys】"><a href="#条件键【condition-keys】" class="headerlink" title="条件键【condition keys】"></a>条件键【condition keys】</h3><p>   **IAM advanced：**条件（Conditions）是一种用于增强访问策略的机制。通过在策略中添加条件，你可以进一步限制对 AWS 资源的访问，使访问控制更加精细和灵活。</p><h2 id="5-C"><a href="#5-C" class="headerlink" title="5-C"></a>5-C</h2><p>  一家公司使用单个 Amazon EC2 实例在 AWS 上托管 Web 应用程序，该实例将用户上传的文档存储在 Amazon EBS 卷中。为了获得更好的可扩展性和可用性，该公司复制了架构，并在<strong>另一个可用区中</strong>创建了第二个 EC2 实例和 EBS 卷，将两者放置在应用程序负载均衡器后面。完成此更改后，用户报告说，每次刷新网站时，他们都可以看到文档的一个子集或另一个子集，但永远不会同时看到所有文档。解决方案架构师应该提出什么建议来确保用户立即看到他们的所有文档？</p><h3 id="EBS不支持跨AZ共享文件"><a href="#EBS不支持跨AZ共享文件" class="headerlink" title="EBS不支持跨AZ共享文件"></a><code>EBS不支持跨AZ共享文件</code></h3><h3 id="只支持multi-attach-多重附加：Attach-the-same-EBS-volume-to-multiple-EC2-instances-in-the-same-AZ"><a href="#只支持multi-attach-多重附加：Attach-the-same-EBS-volume-to-multiple-EC2-instances-in-the-same-AZ" class="headerlink" title="只支持multi attach -多重附加：Attach the same EBS volume to multiple EC2 instances in the same AZ"></a>只支持multi attach -多重附加：Attach the same EBS volume to multiple EC2 instances <strong>in the same AZ</strong></h3><p>  Attach the same EBS volume to multiple EC2 instances <strong>in the same AZ</strong></p><p>  A. 复制数据，使两个 EBS 卷都包含所有文档</p><p>  B. 配置应用程序负载均衡器以将用户定向到包含文档的服务器 </p><p>  C. 将数据从两个 EBS 卷复制到 Amazon EFS。修改应用程序以将新文档保存到 Amazon EFS</p><p>  D. 配置应用程序负载均衡器以将请求发送到两台服务器。从正确的服务器返回每个文档</p><ul><li><p>12-A</p><p>一家跨国公司将其 Web 应用程序托管在应用程序负载均衡器 (<strong>ALB</strong>) 后面的 Amazon EC2实例上。 Web 应用程序有静态数据和动态数据。该公司将其静态数据存储在 Amazon S3存储桶中。该公司希望提高静态数据和动态数据的性能并减少延迟。该公司正在使用自己在 Amazon Route 53上注册的域名。解决方案架构师应该如何做才能满足这些要求？</p><p><code>ALB→ HTTP</code></p><p><code>Global Accelerator → 非HTTP</code><br>A. 创建以 S3 存储桶和 ALB 作为源的 Amazon CloudFront 分配。配置 Route 53 将 trac<br>路由到 CloudFront 分配。</p><p>ALB适用于HTTP流量，而global accelerator更适用于<em><strong>非HTTP</strong></em>,或者<em><strong>静态IP的HTTP流量</strong></em></p><p><img src="/images/aws2.png" alt="在这里插入图片描述"></p><p>B. 创建以 ALB 作为源的 Amazon CloudFront 分配。创建一个 AWS <strong><del>Global Accelerator</del></strong> 标准加速器，将 S3 存储桶作为终端节点 配置 Route 53 以将 trac 路由到 CloudFront 分配。</p><p>C. 创建以 S3 存储桶作为源的 Amazon CloudFront 分配。创建一个以 ALB 和 CloudFront分配作为终端节点的 AWS <strong><del>Global Accelerator</del></strong> 标准加速器。创建指向加速器 DNS 名称的自定义域名。使用自定义域名作为 Web 应用程序的端点。</p><p>D. 创建以 ALB 作为源的 Amazon CloudFront 分配。创建一个以 S3 存储桶作为终端节点的 AWS <strong><del>Global Accelerator</del></strong> 标准加速器。创建两个域名。将一个域名指向动态内容的CloudFront DNS 名称。将另一个域名指向静态内容的加速器 DNS 名称。使用域名作为<br>Web 应用程序的端点</p></li></ul><h2 id="51-BD"><a href="#51-BD" class="headerlink" title="51-BD"></a>51-BD</h2><p>  一家公司正在开发一个应用程序，该应用程序提供订单运输统计信息以供 REST API 检索。该公司希望提取运输统计数据，将数据组织成易于阅读的 HTML 格式，并每天早上同时将报告发送到多个电子邮件地址。解决方案架构师应该采取哪些步骤组合来满足这些要求？（选择两个。）</p><p>  A. 配置应用程序以将数据发送到 Amazon Kinesis Data Firehose。</p><p>  <code>Firehose =&gt; 流式传输</code></p><p>  B. 使用 Amazon Simple Email Service (Amazon <strong>SES</strong>) 格式化数据并通过电子邮件发送报告。</p><p>  C. 创建一个 Amazon EventBridge (Amazon CloudWatch Events) 计划事件，该事件调用<br>  <strong>AWS Glue</strong> 作业来查询应用程序的 API 中的数据。</p><p>  <code>Glue = ETL 服务：数据抽取、转换和加载不能查询</code></p><p>  D. 创建一个 Amazon EventBridge (Amazon CloudWatch Events) 计划事件，该事件调用AWS <strong>Lambda 函数</strong>来查询应用程序的 API 中的数据。 </p><p>  <code>EventBridge = 定时事件，Lambda = 查询 API 获取数据的函数</code></p><p>  E. 将应用程序数据存储在 Amazon S3 中。创建 Amazon Simple Notation Service (Amazon <strong>SNS</strong>) 主题作为 S3 事件目标以通过电子邮件发送报告。</p><p>  <code>SNS只可以发送简单文本邮件，HTML email需要通过SES</code></p><h2 id="56-C"><a href="#56-C" class="headerlink" title="56-C"></a>56-C</h2><p>  一家公司已在 Amazon Route 53 中注册了其域名。该公司使用 ca-central-1 区域中的Amazon API Gateway 作为其后端微服务 API 的公共接口。第三方服务安全地使用 API。该公司希望使用该公司的域名和相应的证书来设计其 API 网关 URL，以便第三方服务可以使用 HTTPS。哪种解决方案可以满足这些要求？</p><blockquote><p>当我在一个电商公司工作时，我们有一个复杂的在线商城应用。这个应用包含了很多功能，比如用户注册、浏览商品、下订单、付款等等。为了让开发和维护变得更容易，我们采用了后端微服务 API 的架构。</p></blockquote><p>  <strong>Amazon API Gateway可以帮助管理和保护API，并将不同的后端服务整合到一个统一的接口中。</strong></p><blockquote><p>每个功能模块都被拆分成独立的微服务，比如有一个用户服务处理用户注册和登录，有一个订单服务处理订单的创建和查询，有一个支付服务处理付款操作等等。每个微服务都有自己的数据库和逻辑，它们可以独立开发和部署。</p></blockquote><blockquote><p>现在，为了使我们的电商应用更加安全和高效，我们决定要求<strong>所有的请求都通过 HTTPS 进行安全通信</strong>，并<strong>使用我们公司的域名来访问这些微服务</strong>。我们已经在 Amazon Route 53 注册了公司域名，比如 “<a href="http://example.com/">example.com</a>“。我们<strong>希望用户能够通过类似 “<a href="http://api.example.com/">api.example.com</a>“ 的 URL 访问我们的后端微服务。</strong></p></blockquote><hr><p>  为了实现这个目标，我们采用了选项 C 的解决方案：</p><ol><li>在 AWS 的 “ca-central-1” 区域创建了一个 API Gateway 终端节点，作为我们后端微服务的入口。</li><li>然后，我们将 “<a href="http://api.example.com/">api.example.com</a>“ 域名与这个 API Gateway 终端节点关联起来，这样用户就可以通过这个自定义的域名来访问我们的 API。</li><li>我们导入了<strong>与 “<a href="http://api.example.com/">api.example.com</a>“ 域名关联的公共 SSL&#x2F;TLS 证书</strong>到 AWS Certificate Manager（ACM）中。</li><li>我们将这个证书附加到了 API Gateway 终端节点，从而确保通过 HTTPS 实现了安全的通信。</li><li>最后，我们使用 Amazon Route 53 配置 DNS 记录，将流量从 “<a href="http://api.example.com/">api.example.com</a>“ 域名路由到我们的 API Gateway 终端节点，这样用户就可以使用这个域名来访问我们的微服务，并享受到 HTTPS 提供的安全通信。</li></ol><p>  A. 在 API Gateway 中创建 Name&#x3D;”Endpoint-URL” 和 Value&#x3D;”公司域名” 的阶段变量以覆盖默认 URL。将与公司域名关联的公共证书导入到 AWS Certicate Manager (ACM)。</p><p>  B. 使用公司域名创建 Route 53 DNS 记录。将别名记录指向区域 API 网关阶段端点。将与公司域名关联的公共证书导入到 <strong>us-east-1</strong> 区域中的 AWS Certicate Manager (ACM) 中。</p><p>  C. 创建区域 API 网关端点。将 API 网关端点与公司域名关联。将与公司域名关联的公共证书导入到<strong>同一区域中</strong>的 AWS Certicate Manager (ACM) 中。将证书附加到 API 网关端点。配置 Route 53 将 trac 路由到 API 网关终端节点。</p><p>  D. 创建区域 API 网关端点。将 API 网关端点与公司域名关联。将与公司域名关联的公共证书导入到 <strong>us-east-1</strong> 区域中的 AWS Certicate Manager (ACM) 中。将证书附加到 API 网关 API。使用公司的域名创建 Route 53 DNS 记录。将 A 记录指向公司的域名。</p><h2 id="74-AC"><a href="#74-AC" class="headerlink" title="74-AC"></a>74-AC</h2><p>  解决方案架构师正在设计一个两层 Web 应用程序。该应用程序由托管在公有子网中的Amazon EC2 上的<strong>面向公众的 Web 层</strong>组成。数据库层由在<strong>私有子网</strong>中的 Amazon EC2 上运行的 Microsoft SQL Server 组成。安全是公司的重中之重。在这种情况下应该如何配置安全组？ （选择两个。）<br>  <strong>A. 配置 Web 层的安全组以允许端口 443 上来自 0.0.0.0&#x2F;0 的入站跟踪。</strong></p><p>  Web Server Rules: Inbound traffic from 443 (HTTPS) Source 0.0.0.0&#x2F;0 - Allows inbound HTTPS access from any IPv4 address</p><p>  B. 配置 Web 层的安全组以允许端口 443 上来自 0.0.0.0&#x2F;0 的出站跟踪。</p><p>  <strong>C. 配置数据库层的安全组以允许端口 1433 上来自 Web 层的安全组的入站跟踪。</strong></p><p>  Database Rules : 1433 (MS SQL)The default port to access a Microsoft SQL Server database, for example, on an Amazon RDS instance</p><p>  D. 配置数据库层的安全组以允许端口 443 和 1433 上的出站跟踪到 Web 层的安全组。</p><p>  E. 配置数据库层的安全组以允许来自 Web 层安全组的端口 443 和 1433 上的入站跟踪。</p><h2 id="95-D"><a href="#95-D" class="headerlink" title="95-D"></a>95-D</h2><p>  应用程序允许公司总部的用户访问产品数据。产品数据存储在 Amazon RDS MySQL 数据库实例中。运营团队<strong>已隔离应用程序性能下降问题</strong>，并<strong>希望将读取跟踪与写入跟踪分开</strong>。解决方案架构师需要快速优化应用程序的性能。解决方案架构师应该推荐什么？</p><p>  A. 将现有数据库更改为多可用区部署。服务来自the primary Availability Zone.的读取请求。<br>  B. 将现有数据库更改为多可用区部署。服务来自the secondary Availability Zone的读取请求。</p><p>  <code>A+B out this is not Aurora</code></p><p>  <strong>Aurora全球数据库（推荐）：</strong></p><ul><li>1个primary <strong>region</strong>（读&#x2F;写）</li><li>最多5个secondary region (read-only），复制延迟(replication lag)小于1秒</li></ul><p>  C. 为数据库创建只读副本。将一半计算和存储资源的只读副本配置为源数据库。<br>  D. 为数据库创建只读副本。为只读副本配置与源数据库相同的计算和存储资源。</p><p>  <code>D seems ok   D. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.</code></p><h2 id="97-D"><a href="#97-D" class="headerlink" title="97-D"></a>97-D</h2><p>  一家公司有一个在本地运行的大型 Microsoft SharePoint 部署，需要 Microsoft Windows <strong>共享文件存储</strong>。该公司希望将此工作负载迁移到 AWS 云，并正在考虑各种存储选项。存储解决方案必须具有高可用性，并与 Active Directory 集成以进行访问控制。哪种解决方案可以满足这些要求？</p><p>  <del>A.</del> 配置 Amazon EFS 存储并设置用于身份验证的 Active Directory 域。</p><p>  <code>EFS is for Linux</code></p><p>  <code>没有专门针对 Windows 文件共享进行优化,而是多个instance之间共享</code></p><p>  B. 在两个可用区的 AWS Storage Gateway 文件网关上创建 SMB 文件共享。</p><p>  <code>适合需要较低要求的文件存储工作负载</code></p><p>  <del>C.</del> 创建Amazon S3 存储桶并配置 Microsoft Windows Server 以将其挂载为卷。</p><p>  <code>S3 存储桶虽然也可以用来存储文件，但它不是直接提供 Windows 文件共享功能的解决方案。</code></p><p>  <strong>D. 在 AWS 上创建 Amazon FSx for Windows File Server 文件系统并设置用于身份验证的<br>  Active Directory 域。</strong></p>  <aside>  📌 Active Directory 域是一种用于管理和组织网络资源的目录服务，它提供了对用户、计算机和其他资源的统一身份验证和访问控制。  </aside><h2 id="101-A"><a href="#101-A" class="headerlink" title="101-A"></a>101-A</h2><p>  解决方案架构师正在设计具有公有子网和私有子网的 VPC。 VPC 和子网使用 IPv4 CIDR块。三个可用区 (AZ) 中各有 1 个公有子网和 1 个私有子网，以实现高可用性。 Internet网关用于为公共子网提供 Internet 访问。私有子网需要访问互联网才能允许 Amazon EC2实例下载软件更新。解决方案架构师应该怎样做才能实现私有子网的 Internet 访问？</p><p>  非VPC（公共互联网）流量<br>  A. 创建三个 <strong>NAT 网关</strong>，每个可用区中的每个公有子网一个。为每个可用区创建私有路由<br>  表，将非 VPC trac 转发到其可用区中的 NAT 网关。</p><p>  B. 创建三个 <strong>NAT 实例</strong>，每个可用区中的每个私有子网一个。为每个可用区创建私有路由<br>  表，将非 VPC trac 转发到其可用区中的 NAT 实例。</p><p>  <code>NAT实例较旧，可扩展性较差</code></p><p>  C. 在其中一个私有子网上创建第二个 <strong>Internet 网关</strong>。更新将非 VPC 跟踪转发到私有<br>  Internet 网关的私有子网的路由表。</p><p>  <code>不安全，导致整个私有子网的流量直接流向互联网</code></p><p>  D. 在公共子网上之一创建egress-only internet gateway<strong>仅出口 Internet 网关</strong>。更新将非 VPC 跟踪转发到仅出口 Internet网关的私有子网的路由表</p><p>  <code>出站专用互联网网关是为IPv6-only VPC设计的，不适用于基于IPv4的资源实现出站互联网连接。</code></p><h2 id="108-A"><a href="#108-A" class="headerlink" title="108-A"></a>108-A</h2><p>  一家公司拥有一个汽车销售网站，该网站将其列表存储在 Amazon RDS 的数据库中。当汽车出售时，需要从网站上删除列表，并且数据必须发送到多个目标系统。解决方案架构师应该推荐哪种设计？</p><p>  <strong>A. 创建一个在 Amazon RDS 上的数据库更新时触发的 AWS Lambda 函数，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) 队列以供目标使用。</strong></p><p>  B. 创建一个 AWS Lambda 函数，该函数在 Amazon RDS 上的数据库更新时触发，以将信息发送到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列以供目标使用。</p><p>  <code>不需要顺序处理</code></p><p>  C. 订阅 <strong>RDS 事件通知</strong>并将 Amazon Simple Queue Service (Amazon SQS) 队列发送到多个Amazon Simple Notication Service (Amazon SNS) 主题。使用 AWS Lambda 函数更新目标。</p><p>  <code>RDS 事件通知主要适用于数据库的操作事件（例如快照、参数组更改等），不适用于数据**修改**事件。</code></p><p>  D. 订阅 RDS 事件通知并将 Amazon Simple Notication Service (Amazon SNS) 主题发送到多个 Amazon Simple Queue Service (Amazon SQS) 队列。使用 AWS Lambda 函数更新目标。</p><p>  <code>Amazon RDS事件通知主要用于通知与数据库管理和运维相关的事件，如数据库实例的创建、启动、停止、备份完成等。</code></p><p>  <code>数据库 内容更改无法通知</code></p><h2 id="131-D"><a href="#131-D" class="headerlink" title="131-D"></a>131-D</h2><p>  一家公司正在开发一个文件共享应用程序，该应用程序将使用 Amazon S3 存储桶进行存储。该公司希望通过 Amazon CloudFront 发行版提供所有文件。该公司不希望通过直接导航到 S3 URL 来访问这些文件。解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 为每个 S3 存储桶编写单独的策略，以仅授予 CloudFront 访问的读取权限。<br>  B. 创建 IAM 用户。授予用户对 S3 存储桶中对象的读取权限。将用户分配到CloudFront。<br>  C. 编写一个 S3 存储桶策略，将 CloudFront 分配 ID 分配为主体，并将目标 S3 存储桶分配为 Amazon 资源名称 (ARN)。</p><p>  D. 创建源访问身份 (OAI)。将 OAI 分配给 CloudFront 分配。配置 S3 存储桶权限，仅OAI 具有读取权限。<br>  正确答案：D</p><h2 id="132-A"><a href="#132-A" class="headerlink" title="132-A"></a>132-A</h2><p>  一家公司的网站为用户提供可下载的<strong>历史</strong>绩效报告。该网站需要一个能够扩展的解决方案，以满足公司在全球范围内的网站需求。该解决方案应该具有成本效益，限制基础设施资源的配置，并提供尽可能最快的响应时间。解决方案架构师应该推荐哪种组合来满足这些要求？</p><p>  <code>historical reports ⇒ static content ⇒ S3</code></p><p>  A. Amazon CloudFront 和 Amazon S3<br>  B.AWS Lambda 和 Amazon DynamoDB<br>  C. 使用 Amazon EC2 Auto Scaling 的应用程序负载均衡器<br>  D. 具有内部应用程序负载均衡器的 Amazon Route 53</p><h2 id="133-C"><a href="#133-C" class="headerlink" title="133-C"></a>133-C</h2><p>  一家公司在本地运行 Oracle 数据库。作为公司迁移到 AWS 的一部分，该公司希望将数据库升级到最新的可用版本。该公司还希望为数据库设置灾难恢复（DR）。公司需要最大限度地减少正常运营和灾难恢复设置的运营开销。<em><strong>该公司还需要维护对数据库底层操作系统的访问</strong></em>。哪种解决方案可以满足这些要求？</p><p>  A. 将 Oracle 数据库迁移到 Amazon <del>EC2 实例</del>。设置数据库复制到不同的 AWS 区域。</p><p>  B. 将 Oracle 数据库迁移到 Amazon RDS for Oracle。激活跨区域自动备份以将快照复制到<br>  另一个 AWS 区域。</p><p>  C. 将 Oracle 数据库迁移到 Amazon RDS Custom for Oracle。为另一个 AWS <strong>区域</strong>中的数<br>  据库创建只读副本。</p><p>  **<code>*RDS Custom***可以访问底层操作系统，并且提供较少的操作开销。另一个 region的读副本也可以用于容灾活动</code></p><p>  <code>只读副本可以晋升为独立的数据库</code></p><p>  D. 将 Oracle 数据库迁移到 Amazon RDS for Oracle。在另一个可用区创建备用数据库。</p><h2 id="136-AC"><a href="#136-AC" class="headerlink" title="136-AC"></a>136-AC</h2><p>  一家公司正在将其本地 PostgreSQL 数据库迁移到 Amazon Aurora PostgreSQL。<strong>本地数据库必须在迁移期间保持在线且可访问</strong>。 Aurora 数据库必须与本地数据库<strong>保持同步</strong>。解决方案架构师必须采取哪些操作组合才能满足这些要求？ （选择两个。）</p><p>  A. 创建<strong>持续复制任务ongoing replication task</strong>。</p><p>  <code>设置一种机制来持续地将源数据库的变更（如新增、更新、删除等操作）复制到目标数据库中，以保持两个数据库之间的数据**同步**。</code><br>  B. 创建本地数据库的数据库备份。<br>  C. 创建 AWS Database Migration Service (AWS DMS) 复制服务器。</p><p>  <code>迁移过程始终可用</code><br>  D. 使用 AWS Schema Conversion Tool (AWS SCT) 转换数据库架构。<br>  E. 创建 Amazon EventBridge (Amazon CloudWatch Events) 规则来监控数据库同步。</p><h2 id="301-C"><a href="#301-C" class="headerlink" title="301-C"></a>301-C</h2><p>  某大学研究实验室需要将 30 TB 数据从本地 Windows 文件服务器迁移到 Amazon FSx for<br>  Windows File Server。该实验室拥有 1 Gbps 的网络链路，与大学的许多其他部门共享。该实验室希望实施一项数据迁移服务，以最大限度地提高数据传输的性能。然而，实验室需要能够控制服务使用的带宽量，以尽量减少对其他部门的影响。数据迁移必须在接下来的 5 天内进行。<br>  哪种 AWS 解决方案能够满足这些要求？</p><p>  <del>A.AWS Snowcone</del></p><p>  B.Amazon FSx 文件网关</p><p>  <strong>C.AWS 数据同步</strong></p><p>  D. AWS 传输系列</p><p>  <code>不支持Windows</code></p><h2 id="308-BD"><a href="#308-BD" class="headerlink" title="308-BD"></a>308-BD</h2><p>  一家公司拥有多个使用合并账单的 AWS 账户。该公司为 Oracle 按需数据库实例运行多<br>  个活动高性能 Amazon RDS 90 天。该公司的财务团队可以访问<strong>合并计费账户</strong>和所有其他<br>  AWS 账户中的 AWS Trusted Advisor。<br>  财务团队需要使用适当的 AWS 账户来访问 RDS 的 Trusted Advisor 检查建议。财务团队<br>  必须审查适当的 Trusted Advisor 检查以降低 RDS 成本。<br>  财务团队应采取哪些步骤组合来满足这些要求？ （选择两个。）<br>  A. 使用运行 RDS 实例的账户中的 Trusted Advisor 建议。<br>  B. 使用合并计费帐户中的 Trusted Advisor 建议同时查看所有 RDS 实例检查。<br>  C. 查看 Trusted Advisor 检查 Amazon RDS 预留实例优化。<br>  D. 查看 Trusted Advisor 检查 Amazon RDS 空闲数据库实例。 </p><p>  E. 查看 Trusted Advisor 检查 Amazon Redshift 预留节点优化。</p><h2 id="309-A"><a href="#309-A" class="headerlink" title="309-A"></a>309-A</h2><p>  解决方案架构师需要优化存储成本。解决方案架构师必须识别不再被访问或很少访问的任何 Amazon S3 存储桶。<br>  哪种解决方案能够以最少的运营开销实现这一目标？</p><p>  <strong>A. 使用 S3 Storage Lens 仪表板来分析存储桶访问模式以获取高级活动指标。</strong><br>  B. 使用 AWS 管理控制台中的 S3 仪表板分析存储桶访问模式。<br>  C. 打开存储桶的 Amazon CloudWatch BucketSizeBytes 指标。通过使用 Amazon Athena 的<br>  指标数据来分析存储桶访问模式。<br>  D. 打开 AWS CloudTrail 以进行 S3 对象监控。使用与 Amazon CloudWatch Logs 集成的<br>  CloudTrail 日志分析存储桶访问模</p><h2 id="310-B"><a href="#310-B" class="headerlink" title="310-B"></a>310-B</h2><p>  一家公司向从事人工智能和机器学习 (AI&#x2F;ML) 研究的客户出售数据集。数据集是大型格式化文件，存储在 us-east-1 区域的 Amazon S3 存储桶中。该公司托管一个 Web 应用程序，客户可以使用该应用程序购买给定数据集的访问权限。 Web 应用程序部署在应用程序负载均衡器后面的多个 Amazon EC2 实例上。购买后，客户会收到一个 S3 签名的 URL，允许访问这些文件。</p><p>  客户遍布北美和欧洲。该公司希望<strong>降低与数据传输相关的成本，并希望维持或提高性能</strong>。<br>  解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 在现有 S3 存储桶上配置 <del>S3 传输加速</del>。将客户请求定向到 S3 Transfer Acceleration 端点。继续使用 S3 签名 URL 进行访问控制。</p><p>  <strong>B. 使</strong>用现有 S3 存储桶作为源部署 Amazon CloudFront 分配。将客户请求定向到CloudFront URL。切换到 CloudFront 签名 URL 进行访问控制。</p><p>  C. 在 eu-central-1 区域中设置第二个 S3 存储桶，并在存储桶之间进行 S3 <strong>跨区域复制</strong>。将客户请求直接发送至最近的区域。继续使用 S3 签名 URL 进行访问控制。</p><p>  <code>跨区域复制（CRR）或同区域复制（SRR），只有在激活复制后**创建的新对象会被复制**到目标存储桶，而不会追溯复制旧对象。</code></p><p>  D. 修改 Web 应用程序以<del>将数据集流式传输给最终用户</del>。配置 Web 应用程序以从现有 S3<br>  存储桶读取数据。直接在应用程序中实施访问控制。</p><h2 id="314-B"><a href="#314-B" class="headerlink" title="314-B"></a>314-B</h2><p>  一家公司拥有一个本地 MySQL 数据库，供全球销售团队使用，且访问模式不频繁。销售团队要求数据库的停机时间最少。数据库管理员希望将此数据库迁移到 AWS，<strong>而不选择特定实例类型</strong>，以应对未来更多用户的需求。<br>  解决方案架构师应该推荐哪种服务？</p><p>  A. Amazon Aurora MySQL<br>  B. 适用于 MySQL 的 Amazon Aurora Serverless</p><p>  <strong><code>&quot;without selecting a particular instance type&quot; = serverless</code></strong><br>  C.Amazon Redshift Spectrum<br>  D. 适用于 MySQL 的 Amazon RDS</p><h2 id="319-A"><a href="#319-A" class="headerlink" title="319-A"></a>319-A</h2><p>  一家公司在 AWS 云中拥有数百个基于 Linux 的 Amazon EC2 实例。系统管理员使用共<br>  享 SSH 密钥来管理实例。经过最近的审计后，该公司的安全团队要求删除所有共享密钥。<br>  解决方案架构师必须设计一个能够提供对 EC2 实例的安全访问的解决方案。<br>  哪种解决方案能够以最少的管理开销满足此要求？</p><p>  A. 使用 AWS Systems Manager 会话管理器连接到 EC2 实例。<br>  B. 使用 AWS Security Token Service (AWS STS) 按需生成一次性 SSH 密钥。<br>  C. 允许对一组堡垒实例进行共享 SSH 访问。将所有其他实例配置为仅允许来自堡垒实例<br>  的 SSH 访问。<br>  D. 使用 Amazon Cognito 自定义授权方对用户进行身份验证。调用 AWS Lambda 函数来<br>  生成临时 SSH 密钥。</p><h2 id="325-A"><a href="#325-A" class="headerlink" title="325-A"></a>325-A</h2><p>  一家公司正在托管 Amazon S3 存储桶中的 Web 应用程序。该应用程序使用 Amazon Cognito 作为身份提供商来对用户进行身份验证并返回 JSON Web 令牌 (JWT)，该令牌提供对存储在另一个 S3 存储桶中的受保护资源的访问权限。<br>  部署应用程序后，用户报告错误并且无法访问受保护的内容。解决方案架构师必须通过提<br>  供适当的权限来解决此问题，以便用户可以访问受保护的内容。<br>  哪种解决方案满足这些要求？</p><p>  <strong>A.</strong> 更新 Amazon Cognito 身份池以承担适当的 IAM 角色来访问受保护的内容。</p><p>  <code>在 Amazon Cognito 身份池中配置一个 IAM 角色，该角色具有访问另一个 S3 存储桶中资源所需的权限。</code></p><p>  B. 更新 S3 ACL 以允许应用程序访问受保护的内容。</p><p>  C. 将应用程序重新部署到 Amazon S3，以防止 S3 存储桶中的最终一致性读取影响用户访问受保护内容的能力。</p><p>  D. 更新 Amazon Cognito 池以使用身份池中的自定义属性映射，并授予用户访问受保护内容的适当权限。</p><p>  <code>即使使用了自定义属性映射，也需要通过适当的 IAM 角色来管理访问权限，以确保一致的身份验证和授权过程。</code></p><h2 id="454-C"><a href="#454-C" class="headerlink" title="454-C"></a>454-C</h2><p>  一家公司拥有<strong>跨多个 AWS 区域和账户</strong>的资源。新雇用的解决方案架构师发现以前的员工没有提供有关资源库存的详细信息。解决方案架构师需要构建和映射所有帐户中各种工作负载的关系详细信息。<br>  哪种解决方案能够以最高效的方式满足这些要求？</p><p>  A. 使用 AWS Systems Manager Inventory 从详细视图报告生成地图视图。</p><p>  <code>用于收集关于操作系统和应用程序的信息，不适用于构建工作负载关系图。</code></p><p>   B. 使用 AWS Step Functions 收集工作负载详细信息。手动构建工作负载的架构图。</p><p>  <code>Step Functions 可用于编排和协调不同服务的工作流</code><br>  <strong>C. 使用 AWS 上的工作负载发现生成工作负载的架构图。</strong></p><p>  <code>在跨多个 AWS 区域和账户拥有资源的情况下，最高效的方法是使用 AWS 上的工作负载发现来生成工作负载的架构图。</code><br>  D. 使用 AWS X-Ray 查看工作负载详细信息。构建具有关系的架构图。<br>  <code>AWS X-Ray 是用于分析和调试分布式应用程序的服务</code></p><h2 id="455-ADF"><a href="#455-ADF" class="headerlink" title="455-ADF"></a>455-ADF</h2><p>  一家公司使用 AWS Organizations。该公司希望以不同的预算来运营其一些 AWS 账户。该公司希望在特定时间段内达到分配的预算阈值时接收警报并自动阻止在 AWS 账户上配置额外资源。<br>  哪种解决方案组合可以满足这些要求？ （选择三项。）</p><p>  A. 使用 AWS Budgets 创建预算。在所需 AWS 账户的成本和使用情况报告部分下设置预<br>  算金额。</p><p>  B. 使用 AWS Budgets 创建预算。在所需 AWS 账户的账单仪表板下设置预算金额。</p><p>  C. 为 AWS Budgets 创建 IAM **用户，**以使用所需权限运行预算操作。</p><p>  D. 为 AWS Budgets创建 IAM <strong>角色</strong>，以使用所需权限运行预算操作。 </p><p>  E. 添加警报，以便在每个帐户达到其预算阈值时通知公司。添加预算操作，选择使用适当的 cong 规则创建的 IAM 身份，以防止配置额外资源。</p><p>  F. 添加警报，以便在每个帐户达到其预算阈值时通知公司。添加预算操作，选择使用适当<br>  的服务控制策略 (SCP) 创建的 IAM 身份，以防止配置额外资源。<br>   <code>Organizations中SCP</code></p><h2 id="457-C"><a href="#457-C" class="headerlink" title="457-C"></a>457-C</h2><p>  一家使用 AWS 的公司正在构建一个应用程序来将数据传输给产品制造商。该公司拥有自<br>  己的身份提供商 (IdP)。该公司希望 IdP 在用户使用应用程序传输数据时对应用程序用户<br>  进行身份验证。公司必须使用适用性声明 2 <strong><code>(AS2)</code></strong> 协议。<br>  哪种解决方案可以满足这些要求？</p><p>  A. 使用 AWS DataSync 传输数据。创建用于 IdP 身份验证的 AWS Lambda 函数。<br>  B. 使用 Amazon AppFlow 流传输数据。创建用于 IdP 身份验证的 Amazon Elastic Container<br>  Service (Amazon ECS) 任务。<br>  C. 使用 AWS Transfer Family 传输数据。创建用于 IdP 身份验证的 AWS Lambda 函数。</p><p>   <strong><code>(AS2)</code></strong><br>  D. 使用 AWS Storage Gateway 传输数据。创建用于 IdP 身份验证的 Amazon Cognito 身份池。<br>  正确答案：C</p><h2 id="458-BC"><a href="#458-BC" class="headerlink" title="458-BC"></a>458-BC</h2><p>  解决方案架构师正在 Amazon API Gateway 中设计 RESTAPI 以实现现金回报服务。该应用程序需要 1 GB 内存和 2 GB 存储空间用于其计算资源。</p><p>  <strong>应用程序将要求数据采用关系格式The application will require that the data is in a relational format.</strong>。<br>  哪种额外的 AWS 服务组合能够以最少的管理工作满足这些要求？ （选择两个。）</p><p>  A、亚马逊 EC2</p><p>  B.AWS Lambda</p><p>  <code>serverless</code></p><p>  C.亚马逊 RDS</p><p>  D.亚马逊 DynamoDB</p><p>  <code>NoSQL database - 不是关系型数据库</code> </p><p>  E.Amazon Elastic Kubernetes 服务 (Amazon EKS)</p><h2 id="459-A"><a href="#459-A" class="headerlink" title="459-A"></a>459-A</h2><p>  一家公司使用 AWS Organizations 在多个 AWS 账户中运行工作负载。当公司创建标签时，标记策略会将部门标签添加到 AWS 资源。<br>  会计团队需要确定 Amazon EC2 消耗的支出。会计团队必须确定哪些部门负责成本，无论AWS 账户如何。会计团队可以访问组织内所有 AWS 账户的 AWS Cost Explorer，并且需要访问 Cost Explorer 中的所有报告。<br>  哪种解决方案以最高效的方式满足这些要求？</p><p>  <strong>A.</strong> From the Organizations <strong>management account</strong> billing console, activate a <strong>user-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  <code>管理账户具有***付款人账户***的责任，并负责支付成员账户产生的所有费用。您无法更改一个组织的管理账户。</code><br>  <strong>B.</strong> From the Organizations <strong>management account</strong> billing console, activate an <strong>AWS-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  <strong>C.</strong> From the Organizations <strong>member account</strong> billing console, activate a <strong>user-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, and lter by EC2.</p><p>  <strong>D.</strong> From the Organizations <strong>member account</strong> billing console, activate an <strong>AWS-dened</strong> cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and lter by EC2.</p><p>  A. 从组织管理帐户计费控制台中，激活名为“部门”的用户定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  B. 从组织管理账户计费控制台中，激活名为“部门”的 AWS 定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  C. 从组织成员帐户计费控制台，激活名为“部门”的用户定义成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 进行过滤。<br>  D. 从组织成员账户计费控制台中，激活名为“部门”的 AWS 定义的成本分配标签。在 Cost<br>  Explorer 中创建一份成本报告，按标签名称分组，并按 EC2 过滤。<br>  正确答案：A</p><h2 id="464-A"><a href="#464-A" class="headerlink" title="464-A"></a>464-A</h2><p>  一家公司托管一个在线购物应用程序，该应用程序将所有订单存储在 Amazon RDS for<br>  PostgreSQL 单可用区数据库实例中。管理层希望消除单点故障，并要求解决方案架构师推<br>  荐一种方法来最大限度地<strong>减少数据库停机时间，而无需对应用程序代码进行任何更改</strong>。<br>  哪种解决方案满足这些要求？</p><p>  <code>与涉及创建新实例、恢复快照或手动设置复制的其他解决方案相比，转换到Multi-AZ部署是一种更简单、更精简的方法，开销更低。总的来说，选项A提供了一种经济有效的方法来最小化数据库停机时间，而不需要进行重大更改或增加复杂性</code><br>  A. 通过修改数据库实例并指定多可用区选项，将现有数据库实例转换为多可用区部署。</p><p>  B. 创建新的 RDS 多可用区部署。拍摄当前 RDS 实例的快照并使用该快照恢复新的多可<br>  用区部署。</p><p>  C. 在另一个可用区中创建 PostgreSQL 数据库的只读副本。使用 Amazon Route 53 加权记<br>  录集在数据库之间分配请求。</p><p>  D. 将 RDS for PostgreSQL 数据库放入 Amazon EC2 Auto Scaling 组中，组大小至少为 2。使用 Amazon Route 53 加权记录集跨实例分配请求。</p><h2 id="478-B"><a href="#478-B" class="headerlink" title="478-B"></a>478-B</h2><p>  律师事务所需要与公众共享信息。该信息包括数百个必须公开可读的文件。<strong>禁止任何人在指定的未来日期之前修改或删除文件。</strong><br>  哪种解决方案能够以最安全的方式满足这些要求？</p><p>  启用版本控制会跟踪每个对象的多个版本，这意味着当您上传新的版本时，旧版本不会被删除。</p><p>  <del>A. 将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。向在指定日期之前访问S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。</del></p><p>  B. 创建启用 S3 <strong>版本控制</strong>的新 Amazon S3 存储桶。使用 S3 对象锁，并根据指定日期保留期限。配置静态网站托管的 S3 存储桶。设置 S3 存储桶策略以允许对对象进行只读访问。</p><p>  C. 创建启用 S3 版本控制的新 Amazon S3 存储桶。配置事件触发器以在对象修改或删除时运行AWS Lambda 函数。配置 Lambda 函数以将对象替换为私有 S3 存储桶中的原始</p><p>  D. 将所有文件上传到配置为静态网站托管的 Amazon S3 存储桶。选择包含文件的文件夹。使用S3 对象锁，并根据指定日期保留期限。<strong>向访问 S3 存储桶的任何 AWS 委托人授予只读 IAM 权限。</strong></p><p>  <code>未启用versioning</code></p><h2 id="479-B"><a href="#479-B" class="headerlink" title="479-B"></a>479-B</h2><p>  一家公司正在通过手动配置必要的基础设施来为其新网站制作基础设施原型。该基础设施包括 Auto Scaling 组、Application Load Balancer 和 Amazon RDS 数据库。配置经过彻底验证后，该公司希望能够<strong>立即以自动化方式</strong>在两个可用区中部署基础设施以供开发和生产使用。<br>  解决方案架构师应该建议什么来满足这些要求？</p><p>  A. 使用 AWS Systems Manager 在两个可用区中复制和配置原型基础设施</p><p>  <code>它通常用于管理运行中的资源状态和配置，而不是用于部署基础设施。</code></p><p>  B. 使用原型基础设施作为指导，将基础设施定义为模板。使用 AWS CloudFormation 部署基础设施。<br>  C. 使用 AWS Cong 记录原型基础设施中使用的资源清单。使用 AWS Cong 将原型基础设施部署到两个可用区。<br>  D. 使用 AWS Elastic Beanstalk 并将其配置为使用对原型基础设施的自动引用来自动在两个可用区中部署新环境。</p><p>  <code>AWS Elastic Beanstalk 是一种托管服务，用于部署和管理应用程序。</code></p><p>  <code>需求是部署基础设施，而不仅仅是应用程序。</code></p><h2 id="481-B"><a href="#481-B" class="headerlink" title="481-B"></a>481-B</h2><p>  一家公司在 AWS 云中托管一个三层 Web 应用程序。多可用区 Amazon RDS for MySQL服务器构成数据库层 Amazon ElastiCache 构成缓存层。该公司需要一种缓存策略，当客户将项目添加到数据库时，该策略可以添加或更新缓存中的数据。缓存中的数据必须始终与数据库中的数据匹配。<br>  哪种解决方案可以满足这些要求？<br>  A. 实现延迟加载缓存策略</p><p>  <code>延迟加载通常是指在数据被请求时才将其加载到缓存中</code></p><p>  B. 实现直写式缓存策略</p><p>  <code>直写式缓存策略是指在更新数据库数据时，首先更新数据库，然后再更新缓存，以确保缓存中的数据始终与数据库中的数据匹配。这种方法可以保持数据的一致性，因为先更新数据库可以确保缓存中的数据不会过时或不准确。</code></p><p>  C. 实现添加 TTL 缓存策略</p><p>  <code>添加 TTL（生存时间）缓存策略可以在一段时间后从缓存中删除数据，以确保数据不会太旧。</code></p><p>  D. 实施 AWS AppCong 缓存策略</p><p>  <code>AWS AppCong 是用于自动化调整容量的服务，与缓存策略无关。</code></p><p>  正确答案：B</p><h2 id="482-B"><a href="#482-B" class="headerlink" title="482-B"></a>482-B</h2><p>  一家公司希望将 100 GB 的历史数据从本地位置迁移到 Amazon S3 存储桶。该公司拥有每秒 100 兆比特 (Mbps) 的内部互联网连接。该公司需要对传输到 S3 存储桶的数据进行加密。该公司将把新数据直接存储在 Amazon S3 中。<br>  哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 在 AWS CLI 中使用 s3sync 命令将数据直接移动到 S3 存储桶</p><p>  <code>不支持自动加密</code></p><p>  B. 使用 AWS DataSync 将数据从本地位置迁移到 S3 存储桶</p><p>  <code>本地到 AWS 以及 AWS 之间的数据传输</code></p><p>  <code>它会处理数据的加密，确保数据安全性。</code></p><p>  C. 使用 AWS Snowball 将数据移动到 S3 存储桶</p><p>  <strong><code>TB级别</code></strong></p><p>  D. 设置从本地位置到 AWS 的 IPsec VPN。使用 AWS CLI 中的 s3 cp 命令将数据直接移动到 S3 存储桶</p><p>  <code>复杂和昂贵</code></p><p>  正确答案：B</p><h2 id="483-B"><a href="#483-B" class="headerlink" title="483-B"></a>483-B</h2><p>  一家公司对在 Windows 容器下的 .NET 6 Framework 上运行的 Windows 作业进行了容器<br>  化。该公司希望在 AWS 云中运行此作业。该作业每 10 分钟运行一次。作业的运行时间<br>  在 1 分钟到 3 分钟之间变化。<br>  哪种解决方案能够最具成本效益地满足这些要求？</p><p>  <code>AWS Lambda 和 Amazon EventBridge 可能更适用于事件驱动型的任务，而选项 C 和 D 中的 ECS 和计划任务可能需要更多的配置和管理。</code><br>  A. 根据作业的容器映像创建 AWS Lambda 函数。配置 Amazon EventBridge 以每 10 分<br>  钟调用该函数。</p><p>  <code>更多手动配置</code><br>  <strong>B. 使用 AWS Batch 创建使用 AWS Fargate 资源的作业。将作业调度配置为每 10 分钟运<br>  行一次。</strong></p><p>  <code>AWS Batch 允许您以成本效益的方式在 AWS 上执行大量的计算工作负载，可以自动为您管理和调度容器化作业。</code><br>  C. 在 AWS Fargate 上使用 Amazon Elastic Container Service (Amazon ECS) 运行作业。根<br>  据作业的容器镜像创建计划任务，每 10 分钟运行一次。</p><p>  D. 在 AWS Fargate 上使用 Amazon Elastic Container Service (Amazon ECS) 运行作业。根<br>  据作业的容器镜像创建独立任务。使用 Windows 任务计划程序每 10 分钟运行一次作业。</p><h2 id="484-AE"><a href="#484-AE" class="headerlink" title="484-AE"></a>484-AE</h2><p>  一家公司希望从许多独立的 AWS 账户迁移到整合的多账户架构。该公司计划为不同的业务部门创建许多新的 AWS 账户。该公司需要使用集中式企业目录服务来验证对这些 AWS账户的访问权限。<br>  解决方案架构师应该推荐哪种操作组合来满足这些要求？ （选择两个。）<br>  A. 在 AWS Organizations 中创建一个新组织并启用所有功能。在组织中创建新的 AWS 账户。</p><p>  B. 设置 Amazon Cognito 身份池。配置 AWS IAM Identity Center (AWS Single Sign-On)以接受 Amazon Cognito 身份验证。</p><p>  C. 配置服务控制策略 (SCP) 来管理 AWS 账户。将 AWS IAM Identity Center（AWS Single  Sign-On）添加到 AWS Directory Service。</p><p>  D. 在 AWS Organizations 中创建一个新组织。配置组织的身份验证机制以直接使用 AWS Directory Service。</p><p>  E. 在组织中设置 AWS IAM Identity Center (AWS Single Sign-On)。配置IAM Identity Center，并将其与公司的企业目录服务集成。</p><p>  正确答案：AE</p><h2 id="486-A"><a href="#486-A" class="headerlink" title="486-A"></a>486-A</h2><p>  一家公司正在 AWS 上构建三层应用程序。表示层将服务于静态网站。逻辑层是容器化应用程序。该应用程序将数据存储在关系数据库中。该公司希望简化部署并降低运营成本。哪种解决方案可以满足这些要求？</p><p>  A. 使用 Amazon S3 托管静态内容。将ECS与AWS Fargate 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。 </p><ul><li>**<code>Amazon S3 托管静态内容**：Amazon S3 是一种高度可扩展的对象存储服务，适用于托管静态网站的静态内容。这将提供可靠的、低延迟的内容传送。</code></li><li>**<code>ECS 与 AWS Fargate**：无需管理底层基础设施</code></li></ul><p>  B. 使用 Amazon CloudFront 托管静态内容。将ECS与 Amazon EC2 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  <code>S3 更简单、成本效益更高。</code></p><p>  C. 使用 Amazon S3 托管静态内容。将  EKS与AWS Fargate 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  <code>EKS比ECS贵</code></p><p>  D. 使用 Amazon EC2 预留实例托管静态内容。将EKS与 Amazon EC2 结合使用以获得计算能力。使用托管 Amazon RDS 集群作为数据库。</p><p>  正确答案：A</p><h2 id="496-BD"><a href="#496-BD" class="headerlink" title="496-BD"></a>496-BD</h2><p>  一家公司使用本地服务器来托管其应用程序。该公司的存储容量即将耗尽。这些应用程序同时使用<strong>块存储和 NFS 存储</strong>。该公司需要一个高性能的解决方案，支持本地缓存，而无需重新构建现有应用程序。<br>  解决方案架构师应该采取哪些操作组合来满足这些要求？ （选择两个。）</p><p>  A. 将 Amazon S3 作为文件系统安装到本地服务器。<br>  <strong>B. 部署 AWS Storage Gateway file网关来替换 NFS 存储</strong>。<br>  C. 部署 AWS Snowball Edge 以将 NFS 挂载配置到本地服务器。</p><p>  <code>AWS Snowball Edge 是一种用于数据迁移和边缘计算的设备</code><br>  <strong>D. 部署 AWS Storage Gateway volume网关来替换块存储。</strong> </p><p>  E. 部署 Amazon Elastic File System(Amazon EFS) 卷并将其挂载到本地服务器。</p><h2 id="498-A"><a href="#498-A" class="headerlink" title="498-A"></a>498-A</h2><p>  一家公司使用 Amazon S3 将高分辨率图片存储在 S3 存储桶中。为了最大限度地减少应用程序更改，该公司将图片存储为 S3 对象的最新版本。该公司只需保留图片的两个最新版本。<br>  该公司希望降低成本。该公司已将 S3 存储桶视为一项巨额开支。<br>  哪种解决方案能够以最少的运营开销降低 S3 成本？</p><p>  <strong>A. 使用 S3 Lifecycle 删除过期的对象版本并保留两个最新版本。</strong></p><p>  B. 使用 AWS Lambda函数检查旧版本并删除除两个最新版本之外的所有版本。</p><p>  C. 使用 S3 批量操作删除非当前对象版本并仅保留两个最新版本。</p><p>  D. 停用 S3 存储桶上的版本控制并保留两个最新版本。</p><h2 id="154-B"><a href="#154-B" class="headerlink" title="154-B"></a>154-B</h2><p>  公司需要将医学试验的结果保存到 Amazon S3 存储库。存储库必须允许少数科学家添加新文件，并且必须限制所有其他用户的只读访问权限。<strong>任何用户都无法修改或删除存储库中的任何文件</strong>。公司必须将每个文件在创建之日起至少保留 1 年。哪种解决方案可以满足这些要求？</p><p>  A. 在治理模式下使用 S3 对象锁，合法持有期为 1 年。</p><p>  B. 在合规模式下使用 S3 对象锁，保留期为 365 天。</p><p>  **<code>合规模式（Compliance Mode）**：</code></p><p>  <code>对象一旦被锁定，即使具有管理权限的用户（**包括 root** 用户）也无法删除或更改对象，直到锁定期结束。</code></p><p>  C. 使用 IAM 角色限制所有用户删除或更改 S3 存储桶中的对象。使用 S3 存储桶策略仅<br>  允许 IAM 角色。</p><p>  D. 配置 S3 存储桶以在每次添加对象时调用 AWS Lambda 函数。配置该函数来跟踪已保<br>  存对象的哈希值，以便可以相应地标记修改的对象。</p><p>  正确答案：B</p><h2 id="155-C"><a href="#155-C" class="headerlink" title="155-C"></a>155-C</h2><p>  一家大型媒体公司在 AWS 上托管 Web 应用程序。该公司希望开始<strong>缓存</strong>机密媒体文件，以便世界各地的用户能够可靠地访问这些文件。内容存储在 Amazon S3 存储桶中。公司必须快速交付内容，无论请求来自何处。哪种解决方案可以满足这些要求？</p><p>  A. 使用 AWS DataSync 将 S3 存储桶连接到 Web 应用程序。</p><p>  B. 部署 AWS Global Accelerator 以将 S3 存储桶连接到 Web 应用程序。</p><p>  <code>BC都使用**边缘位置（Edge Locations**</code><br>  C. 部署 Amazon CloudFront 以将 S3 存储桶连接到 CloudFront 边缘服务器。</p><p>  <code>C, Caching == Edge location == CloudFront</code></p><p>  D. 使用 Amazon Simple Queue Service (Amazon SQS) 将 S3 存储桶连接到 Web 应用程序。</p><h2 id="157-DE"><a href="#157-DE" class="headerlink" title="157-DE"></a>157-DE</h2><p>  一家公司将数据存储在 Amazon Aurora PostgreSQL 数据库集群中。公司必须将所有数据保<br>  存 5 年，并在 5 年后删除所有数据。公司还必须永久保存在数据库中执行的操作的审核日<br>  志。目前，该公司已为 Aurora 配置了自动备份。<br>  解决方案架构师应该采取哪些步骤组合来满足这些要求？ （选择两个。）</p><p>  A. 拍摄数据库集群的手动快照。</p><p>  <code>手动快照需要手动管理，并且在 5 年后可能会变得非常繁琐且不可行。</code></p><p>  B. 为<strong>自动备份</strong>创建生命周期策略。</p><p>  C. 配置<strong>自动备份</strong>保留 5 年。</p><p>  <code>最长35天</code></p><p>  D. 为数据库集群配置 Amazon CloudWatch Logs 导出。</p><p>  E. 使用 AWS Backup 进行备份并将备份保留 5 年。</p><p>  <code>配置备份策略以保留备份至少 5 年，以满足长期数据保留的需求。</code></p><h2 id="158-A"><a href="#158-A" class="headerlink" title="158-A"></a>158-A</h2><p>  解决方案架构师正在为即将举行的音乐活动优化网站。表演视频将实时传输，然后按需提供。该活动预计将吸引全球在线观众。</p><p>  哪种服务可以提高实时流媒体和点播流媒体的性能？</p><p>  A. 亚马逊 CloudFront</p><p>  <code>use CloudFront to deliver video on demand (VOD) or live streaming video using any HTTP origin</code><br>  B.AWS 全球加速器</p><p>  更适合非HTTP<br>  C. 亚马逊 53 号公路<br>  D. Amazon S3 传输加速</p><h2 id="159"><a href="#159" class="headerlink" title="159"></a>159</h2><p>  一家公司正在运行一个使用 Amazon API Gateway 和 AWS Lambda 的可公开访问的无服务<br>  器应用程序。由于来自僵尸网络的欺诈请求，该应用程序的访问量最近激增。<br>  解决方案架构师应采取哪些步骤来阻止未经授权用户的请求？ （选择两个。）</p><p>  <strong>A. 使用仅与真实用户共享的 API 密钥创建使用计划。</strong></p><p>  B. 在 Lambda 函数中集成逻辑以忽略来自欺诈性 IP 地址的请求。</p><p>  <code>比较繁琐</code></p><p>  <strong>C. 实施 AWS WAF 规则来定位恶意请求并触发操作以将其过滤掉。</strong></p><p>  D. 将现有的公共 API 转换为私有 API。更新 DNS 记录以将用户重定向到新的 API 端点。</p><p>   E. 为每个尝试访问 API 的用户创建一个 IAM 角色。用户在进行 API 调用时将承担该角色。</p><p>  正确答案：A C</p><h2 id="160-C"><a href="#160-C" class="headerlink" title="160-C"></a>160-C</h2><p>  一家电子商务公司在 AWS 云中托管其分析应用程序。该应用程序每月生成约 300 MB 的数据。数据以 JSON 格式存储。该公司正在评估备份数据的<strong>灾难恢复解决方案</strong>。如果需要，数据必须可以在毫秒内访问，并且数据必须保留 30 天。<br>  哪种解决方案最经济高效地满足这些要求？</p><p>  A. Amazon OpenSearch 服务（Amazon Elasticsearch 服务）</p><p>  <code>适用于搜索和分析数据，但不是最经济的存储选择，而且可能超过需求。</code></p><p>  B. 亚马逊 S3 Glacier</p><p>  <code>适用于存档和长期保存数据，但数据恢复可能需要数分钟到数小时，不符合毫秒级访问要求</code></p><p>  C. Amazon S3 标准</p><p>  <code>JSON is object notation. S3 stores objects</code></p><p>  D. 适用于 PostgreSQL 的 Amazon RDS</p><p>  <code>关系型数据库服务，不太适合存储大量的 JSON 格式数据，</code></p><h2 id="161-B"><a href="#161-B" class="headerlink" title="161-B"></a>161-B</h2><p>  一家公司有一个小型 Python 应用程序，用于处理 <strong>JSON 文档</strong>并将结果输出到本地 SQL数据库。该应用程序每天运行数千次。该公司希望将应用程序迁移到 AWS 云。该公司需要一个高度可用的解决方案，最大限度地提高可扩展性并最大限度地减少运营开销。<br>  哪种解决方案可以满足这些要求？</p><p>  <code>JSON is object notation. S3 stores objects</code></p><p>  A. 将 JSON 文档放入 Amazon S3 存储桶中。在多个 Amazon EC2 实例上运行 Python 代码以处理文档。将结果存储在 Amazon Aurora 数据库集群中。</p><p>  <code>涉及到自己管理 EC2 实例，并需要设置自动扩展</code></p><p>  B. 将 JSON 文档放入 Amazon S3 存储桶中。创建一个 AWS Lambda 函数，该函数运行Python 代码以在文档到达 S3 存储桶时对其进行处理。将结果存储在 Amazon Aurora 数据库集群中。</p><p>  C. 将 JSON 文档放入 Amazon Elastic Block Store (Amazon EBS) 卷中。使用 EBS 多重附加功能将卷附加到多个 Amazon EC2 实例。在 EC2 实例上运行 Python 代码来处理文档。将结果存储在 Amazon RDS 数据库实例上。</p><p>  D. 将 JSON 文档作为消息放入 Amazon Simple Queue Service (Amazon SQS) 队列中。将Python 代码部署为配置了 Amazon EC2 启动类型的 Amazon Elastic Container Service(Amazon ECS) 集群上的容器。使用容器来处理 SQS 消息。将结果存储在 Amazon RDS 数<br>  据库实例上。</p><h2 id="165"><a href="#165" class="headerlink" title="165"></a>165</h2><p>  解决方案架构师必须设计一个使用 Amazon CloudFront 和 Amazon S3 源来存储静态网站<br>  的解决方案。该公司的安全策略要求所有网站跟踪均由 AWS WAF 检查。<br>  解决方案架构师应该如何满足这些要求？<br>  A. 配置 S3 存储桶策略以仅接受来自 AWS WAF Amazon 资源名称 (ARN) 的请求。<br>  B. 配置 Amazon CloudFront 以在从 S3 源请求内容之前将所有传入请求转发到 AWS<br>  WAF。<br>  C. 配置一个安全组，仅允许 Amazon CloudFront IP 地址访问 Amazon S3。将 AWS WAF<br>  关联到 CloudFront。<br>  D. 配置 Amazon CloudFront 和 Amazon S3 以使用源访问身份 (OAI) 来限制对 S3 存储<br>  桶的访问。在分配上启用 AWS WAF。<br>  正确答案：D</p><h2 id="167-D"><a href="#167-D" class="headerlink" title="167-D"></a>167-D</h2><p>  一家公司在一组 Amazon EC2 实例上运行生产应用程序。该应用程序从 Amazon SQS 队<br>  列读取数据并<em><strong>并行</strong></em>处理消息。消息量是不可预测的，并且经常有间歇性的踪迹。</p><p>  <strong>该应用程序需要持续处理消息而不会造成任何停机。</strong></p><p>  <strong>This application should continuallyprocess messages without any downtime.</strong></p><p>  哪种解决方案最经济高效地满足这些要求？<br>  A. 仅使用 Spot 实例来处理所需的最大容量。<br>  B. 仅使用预留实例来处理所需的最大容量。</p><p>  C. 使用预留实例作为基准容量，并使用 Spot 实例来处理额外容量。</p><p>  <code>SPOT适用于可以容忍实例终止的工作负载</code><br>  D. 使用预留实例作为基准容量，并使用按需实例来处理额外容量。</p><h2 id="170-C"><a href="#170-C" class="headerlink" title="170-C"></a>170-C</h2><p>  一家公司的 Web 应用程序在应用程序负载均衡器后面的 Amazon EC2 实例上运行。该公司最近改变了政策，现在要求只能从一个特定的国家&#x2F;地区访问该应用程序。<br>  哪种配置可以满足这个要求？</p><p>  A. 配置 EC2 实例的安全组。<br>  B. 在应用程序负载均衡器上配置安全组。</p><p>  <code>AB仅限于控制流量进出实例或负载均衡器，而无法实现特定国家/地区的访问控制。</code><br>  C. 在 VPC 中的 Application Load Balancer 上配置 AWS WAF。</p><p>  <code>AWS WAF可以用于实现Web应用程序的访问控制和保护，包括基于IP地址的访问限制。</code><br>  D. 配置包含 EC2 实例的子网的网络 ACL。</p><p>  <code>子网级别的流量控制</code><br>  正确答案：C</p><h2 id="172-C"><a href="#172-C" class="headerlink" title="172-C"></a>172-C</h2><p>  解决方案架构师正在为应用程序创建新的 Amazon CloudFront 发行版。用户提交的一些信息属于敏感信息。该应用程序使用 HTTPS，但需要另一层安全性。敏感信息应在整个应用程序堆栈中受到保护，并且对信息的访问应仅限于某些应用程序。<br>  解决方案架构师应该采取哪些行动？</p><p>  A. 配置 CloudFront 签名 URL。<br>  B. 配置 CloudFront 签名 cookie。</p><p>  <code>选项A和选项B中的CloudFront签名URL和签名Cookie用于验证请求的来源和完整性，但并不涉及字段级加密或敏感信息的保护。</code><br>  C. 配置 CloudFront 字段级加密配置文件。<br>  D. 配置 CloudFront 并将查看器协议策略的源协议策略设置为仅 HTTPS。</p><p>  <code>为了强制CloudFront仅接受HTTPS连接，但并不涉及字段级加密或敏感信息的保护。</code><br>  正确答案：C</p><h2 id="176-A"><a href="#176-A" class="headerlink" title="176-A"></a>176-A</h2><p>  应用程序在私有子网中的 Amazon EC2 实例上运行。应用程序需要访问 Amazon<br>  DynamoDB 表。在确保 <strong>trac 不会离开 AWS 网络</strong>的同时访问表的最安全方法是什么？</p><p>  A. 使用 DynamoDB 的 VPC 终端节点。</p><p>  <code>VPC终端节点是一种允许您的VPC中的资源与支持的AWS服务（例如DynamoDB）进行私有连接的方式。</code><br>  B. 在公共子网中使用 NAT 网关。</p><p>  <code>NAT gateway使私有实例访问互联网</code></p><p>  <code>NAT实例和NAT网关都应该放置在公共子网</code><br>  C. 在私有子网中使用 NAT 实例。<br>  D. 使用连接到 VPC 的<del>互联网网关</del>。</p><h2 id="180-BC"><a href="#180-BC" class="headerlink" title="180-BC"></a>180-BC</h2><p>  一家公司正在设计一个由 API 驱动的云通信平台。该应用程序托管在网络负载均衡器(NLB) 后面的 Amazon EC2 实例上。该公司使用 Amazon API Gateway 为外部用户提供通过 API 访问应用程序的权限。该公司希望保护平台免受 <strong>SQL 注入</strong>等 Web 攻击，<strong>还希望检测和缓解大型、复杂的DDoS 攻击。</strong></p><p>  哪种解决方案组合可提供最强的保护？ （选择两个。）</p><p>  <strong>AWS WAF来路由和保护服务中任务中的 HTTP (S) 第 7 层流量。</strong></p><p>  <strong>Shield - Load Balancer, CF, Route53<br>  AWF - CF, ALB, API Gateway</strong></p><p>  A. 使用 AWS WAF 保护 NLB。</p><p>  <code>NLB是TCP,UDP</code></p><p>  B. 将 AWS Shield Advanced 与 NLB 结合使用。</p><p>  C. 使用 AWS WAF 保护 Amazon API Gateway。</p><p>  D. 将 Amazon GuardDuty 与 AWS Shield Standard 结合使用 </p><p>  E. 将 AWS Shield Standard与 Amazon API Gateway 结合使用。</p><h2 id="183-A"><a href="#183-A" class="headerlink" title="183-A"></a>183-A</h2><p>  一家公司正在构建一个新的动态订购网站。该公司希望最大限度地减少服务器维护和修补。网站必须具有高可用性，并且必须<strong>尽快扩展读写容量</strong>，以满足用户需求的变化。哪种解决方案可以满足这些要求？<br>  A. 在 Amazon S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动<br>  态内容。使用具有<strong>按需</strong>数据库容量的 <strong>Amazon DynamoDB</strong>。配置 Amazon CloudFront 以交<br>  付网站内容。</p><p>  B. 在 Amazon S3 中托管静态内容。使用 Amazon API Gateway 和 AWS Lambda 托管动<br>  态内容。将 Amazon Aurora 与 Aurora Auto Scaling 结合使用作为数据库。配置 Amazon<br>  CloudFront 以交付网站内容。</p><p>  <code>Aurora auto scaling scales only read replicas</code></p><p>  <del>C. 在 Amazon EC2 实例上托管所有网站内容。创建 Auto Scaling 组以扩展 EC2 实例。使<br>  用应用程序负载均衡器来分发 trac。使用具有为数据库预置的写入容量的 Amazon<br>  DynamoDB。<br>  D. 在 Amazon EC2 实例上托管所有网站内容。创建 Auto Scaling 组以扩展 EC2 实例。<br>  使用应用程序负载均衡器来分发 trac。将 Amazon Aurora 与 Aurora Auto Scaling 结合使用<br>  作为数据库。</del></p><h2 id="184-A"><a href="#184-A" class="headerlink" title="184-A"></a>184-A</h2><p>  一家公司拥有一个用于软件工程的 AWS 账户。 AWS 账户可以通过一对 AWS Direct<br>  Connect 连接访问公司的本地数据中心。所有非 VPC trac 都会路由到虚拟专用网关。<br>  一个开发团队最近通过控制台创建了一个 AWS Lambda 函数。开发团队需要允许该函数访<br>  问在公司数据中心的私有子网中运行的数据库。<br>  哪种解决方案可以满足这些要求？<br>  <strong>A. 将 Lambda 函数配置为在具有适当安全组的 VPC 中运行。</strong><br>  B. 设置从 AWS 到数据中心的 VPN 连接。通过 VPN 从 Lambda 函数路由 trac。<br>  C. 更新 VPC 中的路由表，以允许 Lambda 函数通过 Direct Connect 访问本地数据中心。<br>  D. 创建弹性 IP 地址。配置 Lambda 函数以通过弹性 IP 地址发送 trac，无需弹性网络接</p><h2 id="185-B"><a href="#185-B" class="headerlink" title="185-B"></a>185-B</h2><p>  一家公司使用 Amazon ECS 运行应用程序。该应用程序创建原始图像的调整大小版本，然后进行 Amazon S3 API 调用以将调整大小的图像存储在 Amazon S3 中。<br>  解决方案架构师如何确保应用程序有权访问 Amazon S3？</p><p>  A. 更新 AWS IAM 中的 S3 角色以允许从 Amazon ECS 进行读&#x2F;写访问，然后重新启动容器。<br>  B. 创建具有 S3 权限的 IAM 角色，然后将该角色指定为任务定义中的 taskRoleArn。</p><p>  <code>通过创建具有适当的 Amazon S3 权限的 IAM 角色，并将该角色的 ARN（Amazon Resource Name）指定为任务定义的 taskRoleArn，容器就可以使用这个角色的权限来访问 Amazon S3。</code><br>  C. 创建一个允许从 Amazon ECS 访问 Amazon S3 的安全组，并更新 ECS 集群使用的启动配置。</p><p>  <code>安全组通常用于控制网络流量进出 EC2 实例，而不是用来控制应用程序对 AWS 服务的访问权限。</code><br>  D. 创建具有 S3 权限的 IAM 用户，然后在以此账户登录时重新启动 ECS 集群的 Amazon EC2 实例。</p><h2 id="193-B"><a href="#193-B" class="headerlink" title="193-B"></a>193-B</h2><p>  一家公司正在 Amazon EC2 实例上运行批处理应用程序。该应用程序由具有多个 Amazon<br>  RDS 数据库的后端组成。该应用程序导致对数据库的大量读取。解决方案架构师<strong>必须减少<br>  数据库读取次数</strong>，同时确保<strong>高可用性</strong>。<br>  解决方案架构师应该做什么来满足这个要求？</p><p>  A. 添加 Amazon RDS 只读副本。</p><p>  B. 使用 Amazon ElastiCache for Redis</p><p>  <code>redis 高可用</code></p><p>  <strong>Redis vs Memcached:<br>  The question states high availability which Memcached does not support.<br>  Redis supports Multi-AZ and therefore - ensures high availability.</strong></p><p>  C. 使用 Amazon Route 53 DNS 缓存</p><p>  D. 使用 Amazon ElastiCache for Memcached。</p><h2 id="64-D"><a href="#64-D" class="headerlink" title="64-D"></a>64-D</h2><p>  一家公司在本地运行的 Windows 文件服务器上拥有超过 5 TB 的文件数据。用户和应用程序每天都与数据进行交互。该公司正在将其 Windows 工作负载迁移到 AWS。随着公司继续这一流程，公司需要以最小的延迟<strong>访问 AWS 和本地文件存储</strong>。该公司需要一种能够最大限度地减少运营开销且无需对现有文件访问模式进行重大更改的解决方案。</p><p>  该公司使用AWS 站点到站点 VPN 连接来连接到 AWS。解决方案架构师应该怎样做才能满足这些要求？</p><p>  A. 在 AWS 上部署并配置 Amazon FSx for Windows File Server。将本地文件数据移动到FSx for Windows File Server。重新配置工作负载以使用 FSx for Windows File Server on AWS。</p><p>  B. 在本地部署并配置 Amazon S3 文件网关。将本地文件数据移动到 S3 文件网关。重新配置本地工作负载和云工作负载以使用 S3 文件网关</p><p>  C. 在本地部署并配置 Amazon S3 文件网关。将本地文件数据移动到 Amazon S3。重新配置工作负载以直接使用 Amazon S3 或 S3 文件网关。取决于每个工作负载的位置。</p><p>  D. 在 AWS 上部署并配置 Amazon FSx for Windows File Server。在本地部署和配置Amazon FSx 文件网关。将本地文件数据移动到 FSx 文件网关。配置云工作负载以使用FSx for Windows File Server on AWS。配置本地工作负载以使用 FSx 文件网关</p><h2 id="66-C"><a href="#66-C" class="headerlink" title="66-C"></a>66-C</h2><p>  问题 #66<br>  一家公司的应用程序会生成大量文件，每个文件大小约为 5 MB。这些文件存储在 Amazon<br>  S3 中。公司政策要求这些文件必须保存 4 年才能删除。<strong>始终需要立即可访问</strong>，因为文件<br>  包含不易复制的<strong>关键业务数据</strong>。这些文件在对象创建的前 30 天内经常被访问，但在前 30<br>  天之后很少被访问。哪种存储解决方案最具成本效益？</p><p>  A. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到S3 Glacier。对象创建 4 年后删除文件。</p><p>  <code>如果他们没有明确提到他们正在使用Glacier Instant Retrieval，我们应该假设冰川-&gt;需要更多的时间来检索，可能不符合要求</code></p><p>  B. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到<br>  S3 One Zone-Infrequent Access (S3 One Zone-IA)。对象创建 4 年后删除文件。</p><p>  <code>one zone-IA不适合关键性数据</code></p><p>  C. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到<br>  S3 Standard-Infrequent Access (S3 Standard-IA)。对象创建 4 年后删除文件。</p><p>  D. 创建 S3 存储桶生命周期策略，以便在对象创建后 30 天将文件从 S3 Standard 移动到S3 Standard-Infrequent Access (S3 Standard-IA)。在对象<del>创建 4 年后将文件移至 S3 Glacier。</del><br>  正确答案：C</p><h2 id="71-B"><a href="#71-B" class="headerlink" title="71-B"></a>71-B</h2><p>  一家公司运行一个使用 Amazon DynamoDB 存储客户信息的购物应用程序。在数据损坏的<br>  情况下，解决方案架构师需要设计一个满足恢复点目标（RPO）为 15 分钟和恢复时间目标<br>  （RTO）为 1 小时的解决方案。为了满足这些需求，解决方案架构师应该推荐什么？</p><p>  A.聚集 DynamoDB 全局表。对于 RPO 恢复，请将应用程序指向不同的 AWS 区域。</p><p>  <code>将应用程序指向不同的 AWS 区域可能会导致数据丢失，因为数据同步可能需要一些时间。</code></p><p>  <strong>B.拥塞动态数据库point-in-time recover。对于 RPO 恢复，请还原到所需的时间点。</strong></p><p>  C.出口每天将 DynamoDB 数据传输到 Amazon S3 Glacier。对于 RPO 恢复，请将数据从S3 Glacier 导入到 DynamoDB。</p><p>  <code>但在 RPO 恢复时，需要将数据从 S3 Glacier 恢复并导入 DynamoDB，可能会花费较长时间。</code></p><p>  D.计划每 15 分钟为 DynamoDB 表创建一次 Amazon EBS 快照。对于 RPO 恢复，可以使用EBS 快照恢复 DynamoDB 表。<br>  <code>DynamoDB是无服务器的…DynamoDB 并不支持 EBS 快照</code></p><h2 id="73-CD"><a href="#73-CD" class="headerlink" title="73-CD"></a>73-CD</h2><p>  一家公司最近在私有子网中的 Amazon EC2 上启动了基于 Linux 的应用程序实例，并在<br>  VPC 的公有子网中的 Amazon EC2 实例上启动了基于 Linux 的堡垒主机。解决方案架构<br>  师需要通过公司的 Internet 连接从本地网络连接到堡垒主机和应用程序服务器。解决方案<br>  架构师必须确保所有 EC2 实例的安全组都允许该访问。解决方案架构师应该采取哪些步骤<br>  组合来满足这些要求？ （选择两个。）</p><p>  A. 将堡垒主机的当前安全组替换为仅允许来自应用程序实例的入站访问的安全组。<br>  B. 将堡垒主机当前的安全组替换为仅允许来自公司内部 IP 范围的入站访问的安全组。<br>  C. 将堡垒主机当前的安全组替换为仅允许来自公司<strong>外部 IP 范围</strong>的入站访问的安全组。</p><p>  <code>从本地网络到堡垒通过互联网(使用本地资源的公共IP)</code><br>  D. 将应用程序实例的当前安全组替换为仅允许来自堡垒主机的私有 IP 地址的入站 SSH访问的安全组。 </p><p>  <code>堡垒和ec2在同一个VPC中，这意味着堡垒可以通过它的私有IP地址与ec2通信</code></p><p>  E. 将应用程序实例的当前安全组替换为仅允许从堡垒主机的公共 IP 地址进行入站 SSH 访问的安全组。</p><h2 id="87"><a href="#87" class="headerlink" title="87"></a>87</h2><p>  一家公司在由 Amazon API Gateway API 调用的 AWS Lambda 函数上托管应用程序。Lambda 函数将客户数据保存到 Amazon Aurora MySQL 数据库。<em><em>每当公司升级数据库时，Lambda 函数都无法建立数据库连接，直到升级完成。<strong>结果是某些事件的客户数据没有被记录。解决方案架构师需要设计一个解决方案来</strong></em>存储数据库升级期间创建的客户数据</em>**。哪种解决方案可以满足这些要求？</p><p>  A. 配置 Amazon RDS 代理以位于 Lambda 函数和数据库之间。配置 Lambda 函数以连接到 RDS 代理。</p><p>  **<code>可以处理与数据库的连接和请求**，从而减轻数据库的负担。</code></p><p>  <code>可以解决数据库升级期间的连接问题，但不直接解决存储升级期间创建的客户数据的需求。</code><br>  B. 将 Lambda 函数的运行时间增加到最大值。在将客户数据存储在数据库中的代码中创建重试机制。<br>  选项 C: 将客户数据持久化到 Lambda 本地存储。配置新的 Lambda 函数扫描本地存储以将客户数据保存到数据库。</p><p>  <code>Lambda 函数的本地存储是临时的，</code></p><p>  D. 将客户数据存储在 Amazon Simple Queue Service (Amazon SQS) FIFO 队列中。创建一个新的 Lambda 函数来轮询队列并将客户数据存储在数据库中。</p><h2 id="93-B"><a href="#93-B" class="headerlink" title="93-B"></a>93-B</h2><p>  一家公司运行由 MySQL 数据库提供支持的本地应用程序。该公司正在将应用程序迁移到<br>  AWS，以提高应用程序的弹性和可用性。当前的体系结构在正常操作期间显示数据库上的<br>  大量读取活动。每 4 小时，公司的开发团队就会完整导出生产数据库，以填充临时环境中<br>  的数据库。在此期间，用户会遇到不可接受的应用程序延迟。在该过程完成之前，开发团<br>  队无法使用暂存环境。解决方案架构师必须推荐可缓解应用程序延迟问题的替代架构。替<br>  换架构还必须使开发团队能够立即继续使用登台环境。哪种解决方案满足这些要求？、</p><p>  A. 将 Amazon Aurora MySQL 与多可用区 Aurora 副本结合使用进行生产。通过实施使用<br>  <em><strong>mysqldump</strong></em> 实用程序的备份和恢复过程来填充临时数据库。</p><p>  <code>涉及mysqldump实用程序来备份和恢复数据，这可能会在数据库很大的情况下导致较长的恢复时间。</code></p><p>  B. 使用 Amazon Aurora MySQL 和多可用区 Aurora 副本进行生产。使用<strong>数据库克隆</strong>按需<br>  创建临时数据库。</p><p>  <code>使用了数据库克隆，可以在需要时快速创建临时数据库，而不需要长时间的恢复过程</code>。</p><p>  C. 使用 Amazon RDS for MySQL 进行多可用区部署和生产只读副本。使用备用实例作为<br>  临时数据库。</p><p>  D. 使用 Amazon RDS for MySQL 进行多可用区部署和生产只读副本。通过实施使用<br>  mysqldump 实用程序的备份和恢复过程来填充临时数据库。</p><p>  <code>涉及mysqldump实用程序来备份和恢复数据，这可能会在数据库很大的情况下导致较长的恢复时间。</code><br>  正确答案：B</p><h2 id="94-C"><a href="#94-C" class="headerlink" title="94-C"></a>94-C</h2><p>  一家公司正在设计一个应用程序，用户可以将<strong>小文件</strong>上传到 Amazon S3。用户上传文件后，<br>  需要对文件进行一次性简单处理，将数据进行转换，并将数据保存为 JSON 格式以供后续<br>  分析。每个文件上传后必须尽快进行处理。需求会有所不同。有时，用户会上传大量文件。<br>  在其他日子里，用户会上传一些文件或不上传文件。哪种解决方案能够以最少的运营开销<br>  满足这些要求？</p><p>  <strong>JSON 文件适合存储在一些现代的NoSQL数据库, S3【key-value】</strong></p><p>  A. 配置 Amazon EMR 以从 Amazon S3 读取文本文件。运行处理脚本来转换数据。将生<br>  成的 JSON 文件存储在 Amazon Aurora 数据库集群中。</p><p>  <code>EMR来处理数据，但可能过于复杂和昂贵，尤其是针对简单的数据转换任务。</code></p><p>  B. 配置 Amazon S3 以将事件通知发送到 Amazon Simple Queue Service (Amazon SQS) 队<br>  列。使用 Amazon <strong>EC2 实例</strong>从队列中读取并处理数据。将生成的 JSON 文件存储在<br>  Amazon DynamoDB 中。</p><p>  <code>EC2实例需要管理</code></p><p>  C. 配置 Amazon S3 以将事件通知发送到 Amazon Simple Queue Service (Amazon SQS) 队<br>  列。使用 AWS Lambda 函数从队列中读取并处理数据。将生成的 JSON 文件存储在<br>  Amazon DynamoDB 中。</p><p>  D. 配置 Amazon EventBridge (Amazon CloudWatch Events) 以在上传新文件时将事件发送到<br>  Amazon Kinesis Data Streams。使用 AWS Lambda 函数使用流中的事件并处理数据。将生<br>  成的 JSON 文件存储在 Amazon Aurora 数据库集群中。</p><p>  <code>不必要的复杂，存储在Aurora中不适合</code><br>  正确答案：C</p><h2 id="107-B"><a href="#107-B" class="headerlink" title="107-B"></a>107-B</h2><p>  一家自行车共享公司正在开发一种多层架构，以在高峰运营时间跟踪其自行车的位置。该<br>  公司希望<strong>在其现有的分析平台中使用这些数据点</strong>。解决方案架构师必须确定最可行的多层<br>  选项来支持该架构。数据点必须可从 REST API 访问。哪种操作满足存储和检索位置数据<br>  的这些要求？</p><p>  A. 将 Amazon Athena 与 Amazon S3 结合使用。</p><p>  <strong>B.</strong> 将 Amazon API Gateway 与 AWS Lambda 结合使用</p><ul><li>**<code>Amazon API Gateway：** 它作为 REST API 请求的入口点，允许您创建和管理可以与各种后端服务集成的 API。它为客户端提供与之交互的 RESTful 接口。</code></li><li>**<code>AWS Lambda：** 可以用来实现存储和检索位置数据的后端逻辑。当从 API Gateway 收到请求时，可以调用 Lambda 来处理请求，处理数据，并与数据存储（如数据库或Amazon S3）交互。</code></li></ul><p>  C. 将 Amazon QuickSight 与 Amazon Redshift 结合使用。</p><p>  <strong>D.</strong> 将 Amazon API Gateway 与 Amazon Kinesis Data Analytics 结合使用。</p><h2 id="109-D"><a href="#109-D" class="headerlink" title="109-D"></a>109-D</h2><p>  公司需要将数据存储在 Amazon S3 中，并且必须防止数据被更改。该公司希望上传到<br>  Amazon S3 的新对象在一段非特定时间内保持不变，直到公司决定修改这些对象。只有公<br>  司 AWS 账户中的特定用户才可以删除对象。 10 解决方案架构师应该怎样做才能满足这<br>  些要求？</p><p>  <del>A. 创建 S3 Glacier 文件库</del>。对对象应用一次写入多次读取 (WORM) 保管库锁定策略。</p><p>  B. 创建启用了 S3 对象锁定的 S3 存储桶。启用版本控制。<del>设置保留期限为 100 年</del>。使用<strong>治理模式</strong>作为 S3 存储桶新对象的默认保留模式。 </p><p>  C. 创建 S3 存储桶。使用 AWSCloudTrail 跟踪修改对象的任何 S3 API 事件。收到通知后，从公司拥有的任何备份版本中恢复修改的对象。 </p><p>  D. 创建启用了 S3 对象锁定的 S3 存储桶。启用版本控制。为对象添加合法保留。将s3:PutObjectLegalHold 权限添加到需要删除对象的用户的 IAM 策略中。<br>  使用对象锁，您还可以在对象版本上放置<strong>legal hold合法的保留</strong>。与保留期一样，合法保留可以防止对象版本被覆盖或删除。然而，合法持有并没有相应的保留期限，在解除之前一直有效</p><h2 id="116-AD"><a href="#116-AD" class="headerlink" title="116-AD"></a>116-AD</h2><p>  一家公司为其公司网站使用流行的内容管理系统 (CMS)。然而，**所需的修补和维护是繁重<br>  的。**该公司正在重新设计其网站并需要新的解决方案。该网站每年更新四次，<strong>不需要提供<br>  任何动态内容</strong>。该解决方案必须提供高可扩展性和增强的安全性。哪种变更组合能够以最<br>  少的运营开销满足这些要求？ （选择两个。）</p><p>  A. 在网站前面配置 Amazon CloudFront 以使用 HTTPS 功能。</p><p>  B. 在网站前面部署 AWS <del>WAF Web ACL</del> 以提供 HTTPS 功能。</p><p>  C. 创建并部署 AWS Lambda 函数来<strong>管理</strong>和提供网站内容。</p><p>  D. 创建新网站和 Amazon S3 存储桶。在启用静态网站托管的 S3 存储桶上部署网站。</p><p>  E.创建新网站。使用 Application Load Balancer 后面的 <del>Amazon EC2 实例</del> Auto Scaling 组部<br>  署网站。</p><h2 id="119-B"><a href="#119-B" class="headerlink" title="119-B"></a>119-B</h2><p>  一家跨国公司正在使用 Amazon API Gateway 为其位于 us-east-1 区域和 ap-southeast-2 区<br>  域的忠诚俱乐部用户设计 REST API。解决方案架构师必须设计一个解决方案来保护这些<br>  <strong>跨多个帐户</strong>的 API Gateway 管理的 REST API 免受 SQL 注入和跨站点脚本攻击。哪种解<br>  决方案能够以最少的管理工作满足这些要求？<br>  A. 在两个区域中设置 AWS WAF。将区域 Web ACL 与 API 阶段关联。<br>  B. 在两个区域中设置 AWS Firewall Manager。集中配置 AWS WAF 规则。<br>  C. 在 Bath 区域设置 AWS Shield。将区域 Web ACL 与 API 阶段关联。<br>  D. 在其中一个区域设置 AWS Shield。将区域 Web ACL 与 API 阶段关联。</p><h2 id="121-A"><a href="#121-A" class="headerlink" title="121-A"></a>121-A</h2><p>  一家公司正在 AWS 上运行在线事务处理 (OLTP) 工作负载。此工作负载在多可用区部署<br>  中使用未加密的 Amazon RDS 数据库实例。每日数据库快照均从此实例中获取。解决方案<br>  架构师应该做什么来确保数据库和快照始终加密？</p><p>  A. 加密最新数据库快照的副本。通过恢复加密快照来替换现有数据库实例。</p><p>  <em>Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.</em><br>  B. 创建一个新的加密 Amazon Elastic Block Store (Amazon EBS) 卷并将快照复制到其中。<br>  在数据库实例上启用加密。</p><p>  C. 复制快照并使用 AWS Key Management Service (AWS KMS) 启用加密 将加密快照恢复<br>  到现有数据库实例。</p><p>  <em>Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS) Restore encrypted snapshot to an existing DB instance</em></p><p>  D. 将快照复制到使用 AWS Key Management Service (AWS KMS) 托管密钥 (SSE-KMS) 的<br>  服务器端加密进行加密的 Amazon S3 存储桶。<br>  正确答案：A</p><h2 id="123-D"><a href="#123-D" class="headerlink" title="123-D"></a>123-D</h2><p>  一家公司有一个动态 Web 应用程序托管在两个 Amazon EC2 实例上。该公司拥有自己的<br>  SSL 证书，该证书在每个实例上执行 SSL 终止。最近，trac 有所增加，运营团队确定 SSL<br>  加密和解密导致 Web 服务器的计算能力达到最大限制。解决方案架构师应该怎样做才能<br>  提高应用程序的性能？<br>  A. 使用 AWS Certicate Manager (ACM) 创建新的 SSL 证书。在每个实例上安装 ACM<br>  证书。<br>  B. 创建 Amazon S3 存储桶 将 SSL 证书迁移到 S3 存储桶。配置 EC2 实例以引用用于<br>  SSL 终止的存储桶。<br>  C. 创建另一个 EC2 实例作为代理服务器。将 SSL 证书迁移到新实例并将其配置为直接连<br>  接到现有 EC2 实例。<br>  D. 将 SSL 证书导入 AWS Certificate Manager (ACM)。创建具有 HTTPS 侦听器的应用程<br>  序负载均衡器，该侦听器使用来自 ACM 的 SSL 证书。</p><h2 id="125-AD"><a href="#125-AD" class="headerlink" title="125-AD"></a>125-AD</h2><p>  一家公司在 AWS 上运行其两层电子商务网站。 Web 层由一个负载均衡器组成，该负载<br>  均衡器将 trac 发送到 Amazon EC2 实例。数据库层使用 Amazon RDS 数据库实例。 EC2<br>  实例和 RDS 数据库实例不应暴露于公共互联网。 EC2 实例需要互联网访问才能通过第三<br>  方 Web 服务完成订单的支付处理。该应用程序必须具有高可用性。哪种配置选项组合可<br>  以满足这些要求？ （选择两个。）<br>  A. 使用 Auto Scaling 组启动私有子网中的 EC2 实例。在私有子网中部署 RDS 多可用区数据库实例。<br>  B. 在两个可用区中配置具有两个私有子网和两个 NAT 网关的 VPC。在私有子网中部署应用程序负载均衡器。<br>  C. 使用 Auto Scaling 组在两个可用区的公有子网中启动 EC2 实例。在私有子网中部署RDS 多可用区数据库实例。<br>  D. 跨两个可用区配置具有 1 个公有子网、1 个私有子网和 2 个 NAT 网关的 VPC。在公有子网中部署应用程序负载均衡器。<br>  E. 在两个可用区中配置具有两个公有子网、两个私有子网和两个 NAT 网关的 VPC。在公有子网中部署应用程序负载均衡器。</p><h2 id="127-D"><a href="#127-D" class="headerlink" title="127-D"></a>127-D</h2><p>  一家媒体公司正在评估将其系统迁移到 AWS 云的可能性。该公司需要至少 10 TB 的存储<br>  空间（具有最大可能的 I&#x2F;O 性能）用于视频处理，300 TB 的非常耐用的存储空间用于存储<br>  媒体内容，以及 900 TB 的存储空间以满足不再使用的存档媒体的要求。解决方案架构师<br>  应该推荐哪组服务来满足这些要求？<br>  A. Amazon EBS 用于实现最佳性能，Amazon S3 用于持久数据存储，Amazon S3 Glacier 用<br>  于归档存储<br>  B. Amazon EBS 用于实现最佳性能，Amazon EFS 用于持久数据存储，Amazon S3 Glacier<br>  用于归档存储<br>  C. Amazon EC2 实例存储可实现最佳性能，Amazon EFS 可实现持久数据存储，Amazon S3<br>  可实现归档存储<br>  D. Amazon EC2 实例存储可实现最佳性能，Amazon S3 可实现持久数据存储，Amazon S3<br>  Glacier 可实现归档存储</p><p>  <code>EC2 has newer feature to support video</code></p><h2 id="134-C"><a href="#134-C" class="headerlink" title="134-C"></a>134-C</h2><p>  一家公司希望将其应用程序迁移到无服务器解决方案。无服务器解决方案需要使用 SL 来<br>  分析<strong>现有数据和新数据</strong>。该公司将数据存储在 Amazon S3 存储桶中。数据需要加密并且必<br>  须复制到不同的 AWS 区域。哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制(CRR) 将加密对象复制到另一个区域中的 S3 存储桶。将服务器端加密与 AWS KMS 多区域密钥 (SSE-KMS) 结合使用。使用 Amazon Athena 查询数据。<br>  B. 创建一个新的 S3 存储桶。将数据加载到新的 S3 存储桶中。使用 S3 跨区域复制(CRR) 将加密对象复制到另一个区域中的 S3 存储桶。将服务器端加密与 AWS KMS 多区域密钥 (SSE-KMS) 结合使用。使用 Amazon RDS 查询数据。</p><p>  <strong>C. 将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域中的 S3 存储桶。使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。使用 Amazon Athena 查询数据。</strong> </p><p>  <code>SSE-S3会为每个对象使用唯一的加密密钥，并且由S3管理加密密钥的生命周期，从而减轻了密钥管理的负担。</code></p><p>  D. 将数据加载到现有的 S3 存储桶中。使用 S3 跨区域复制 (CRR) 将加密对象复制到另一个区域中的 S3 存储桶。使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。使用 Amazon RDS 查询数据。</p><h2 id="137-B"><a href="#137-B" class="headerlink" title="137-B"></a>137-B</h2><p>  一家公司使用 AWS Organizations 为每个业务部门创建专用 AWS 账户，以便根据请求独<br>  立管理每个业务部门的账户。根电子邮件收件人错过了发送到一个帐户的根用户电子邮件<br>  地址的通知。该公司希望确保不会错过所有未来的通知。未来的通知必须仅限于帐户管理<br>  员。哪种解决方案可以满足这些要求？</p><p>  A. 配置公司的电子邮件服务器，将发送到 AWS 账户根用户电子邮件地址的通知电子邮件转发给组织中的所有用户。</p><p>  <strong>B. 将所有 AWS 账户根用户电子邮件地址配置为分发列表，发送给少数可以响应警报的管<br>  理员。在 AWS Organizations 控制台中或以编程方式配置 AWS 账户备用联系人。</strong></p><p>  C. 将所有 AWS 账户根用户电子邮件配置为发送给一名管理员，该管理员负责监控警报并将这些警报转发到适当的组。</p><p>  D. 将所有现有 AWS 账户和所有新创建的账户配置为使用相同的根用户电子邮件地址。在<br>  AWS Organizations 控制台中或以编程方式配置 AWS 账户备用联系人。</p><h2 id="139-D"><a href="#139-D" class="headerlink" title="139-D"></a>139-D</h2><p>  报告团队每天都会在 Amazon S3 存储桶中收到文件。报告团队每天同时手动检查此初始S3 存储桶中的文件并将其复制到分析 S3 存储桶，以与 Amazon QuickSight 一起使用。更多团队开始将更多更大尺寸的文件发送到初始 S3 存储桶。报告团队希望在文件进入初始S3 存储桶时自动分析 S3 存储桶。报告团队还希望使用 AWS Lambda 函数对复制的数据运行模式匹配代码。此外，报告团队希望将数据文件发送到 Amazon SageMaker Pipelines中的管道。解决方案架构师应该如何做才能以最少的运营开销满足这些要求？</p><p>  <code>排除了A和B，因为它需要一个额外的Lambda作业来完成复制，而S3复制将以很少甚至没有开销来处理它。C是不正确的，因为S3通知不支持Sagemake管道</code></p><p>  &#96;&#96;A. 创建 Lambda 函数以将文件复制到分析 S3 存储桶。为分析 S3 存储桶创建 S3 事件通知。将Lambda 和 SageMaker Pipelines 配置为事件通知的目的地。配置s3:ObjectCreated:Put 作为事件类型。</p><p>  B. 创建 Lambda 函数以将文件复制到分析 S3 存储桶。配置分析 S3 存储桶以将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatchEvents) 中配置 ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为规则的目标。</p><p>  C. 配置 S3 存储桶之间的 S3 复制。为分析 S3 存储桶创建 S3 事件通知。将 Lambda 和SageMaker Pipelines 配置为事件通知的目的地。配置 s3:ObjectCreated:Put 作为事件类型</p><p>  D. 配置 S3 存储桶之间的 S3 复制。配置分析 S3 存储桶以将事件通知发送到 Amazon EventBridge (Amazon CloudWatch Events)。在 EventBridge (CloudWatch Events) 中配置ObjectCreated 规则。将 Lambda 和 SageMaker Pipelines 配置为规则的目标。</p><h2 id="140-AC"><a href="#140-AC" class="headerlink" title="140-AC"></a>140-AC</h2><p>  解决方案架构师需要帮助公司优化在 AWS 上运行应用程序的成本。该应用程序将使用Amazon EC2 实例、AWS Fargate 和 AWS Lambda 在架构内进行计算。 EC2 实例将运行应用程序的数据摄取层。 **EC2 的使用将是零星且不可预测的。**在 EC2 实例上运行的工作负载可以随时中断。应用程序前端将在 Fargate 上运行，Lambda 将服务于 API 层。**明年的前端利用率和 API 层利用率将是可预测的。**哪种购买选项组合将为托管此应用程序提供最具成本效益的解决方案？ （选择两个。）<br>  A. 使用 Spot 实例作为数据摄取层<br>  B. 对数据摄取层使用按需实例<br>  C. 为前端和 API 层购买 1 年compute节省计划。<br>  D. 为数据摄取层购买 1 年期的预付费用预留实例。 </p><table><thead><tr><th>特征</th><th>EC2 Savings Plans</th><th>AWS Compute Savings Plans</th></tr></thead><tbody><tr><td>适用范围</td><td>EC2 实例</td><td><strong>EC2 实例和 Fargate 任务</strong></td></tr><tr><td>适用性灵活性</td><td>更大的实例选择</td><td>限于 EC2 实例</td></tr><tr><td>跨区域使用</td><td>可以在多个 AWS 区域使用</td><td>限于一个 AWS 区域</td></tr></tbody></table><h2 id="141-A"><a href="#141-A" class="headerlink" title="141-A"></a>141-A</h2><p>  一家公司运营一个基于网络的门户网站，为用户提供全球突发新闻、本地警报和天气更新。<br>  该门户通过混合使用静态和动态内容为每个用户提供个性化视图。内容通过在应用程序负<br>  载均衡器 (ALB) 后面的 Amazon EC2 实例上运行的 API 服务器通过 HTTPS 提供。该公<br>  司希望该门户尽快向世界各地的用户提供此内容。解决方案架构师应如何设计应用程序以<br>  确保所有用户的延迟最少？</p><p>  <strong>A. 在单个 AWS 区域中部署应用程序堆栈。通过指定 ALB 作为源，使用 Amazon CloudFront 提供所有静态和动态内容。</strong></p><p>  B. 在两个 AWS 区域中部署应用程序堆栈。使用 Amazon Route 53 延迟路由策略提供来自最近区域中 ALB 的所有内容。</p><p>  C. 在单个 AWS 区域中部署应用程序堆栈。使用 Amazon CloudFront 提供静态内容。直接从 ALB 提供动态内容。</p><p>  D. 在两个 AWS 区域中部署应用程序堆栈。使用 Amazon Route 53 地理位置路由策略在最近的区域中提供来自 ALB 的所有内容。</p><h2 id="145-D、"><a href="#145-D、" class="headerlink" title="145-D、"></a>145-D、</h2><p>  一家公司在单个 Amazon EC2 按需实例上托管网站分析应用程序。该分析软件是用 PHP<br>  编写的，并使用 MySQL 数据库。分析软件、提供 PHP 的 Web 服务器以及数据库服务<br>  器都托管在 EC2 实例上。该应用程序在繁忙时间显示出性能下降的迹象，并出现 5xx 错<br>  误。公司需要使应用程序无缝扩展。哪种解决方案能够最具成本效益地满足这些要求？<br>  A. 将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。<br>  使用 AMI 启动第二个 EC2 按需实例。使用应用程序负载均衡器将负载分配到每个 EC2<br>  实例。<br>  B. 将数据库迁移到 Amazon RDS for MySQL 数据库实例。创建 Web 应用程序的 AMI。使用 AMI 启动第二个 EC2 按需实例。使用 Amazon Route 53 加权路由在两个 EC2 实例之间分配负载。</p><p>  C. 将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建 AWS Lambda 函数来停止<br>  EC2 实例并更改实例类型。创建 Amazon CloudWatch 警报以在 CPU 利用率超过 75% 时<br>  调用 Lambda 函数。</p><p>  D. 将数据库迁移到 Amazon Aurora MySQL 数据库实例。创建 Web 应用程序的 AMI。将<br>  AMI 应用到启动模板。使用启动模板创建 Auto Scaling 组 配置启动模板以使用 Spot 队<br>  列。将应用程序负载均衡器附加到 Auto Scaling 组。<br>  正确答案：D</p><h2 id="7-D"><a href="#7-D" class="headerlink" title="7-D"></a>7-D</h2><p>  一家公司有一个接收传入消息的应用程序。然后，数十个其他应用程序和微服务快速消耗<br>  这些消息。消息数量变化很大，有时突然增加到每秒 100,000 条。该公司希望解耦解决方<br>  案并提高可扩展性。哪种解决方案满足这些要求？<br>  A. 将消息保留到 Amazon Kinesis Data Analytics。配置消费者应用程序以读取和处理消息。</p><p>  B. 在 Auto Scaling 组中的 Amazon EC2 实例上部署提取应用程序，以根据 CPU 指标扩<br>  展 EC2 实例的数量。</p><p>  C. 使用单个分片将消息写入 Amazon Kinesis Data Streams。使用 AWS Lambda 函数预处<br>  理消息并将其存储在 Amazon DynamoDB 中。配置消费者应用程序以从 DynamoDB 读取<br>  数据来处理消息。</p><p>  D. 将消息发布到具有多个 Amazon Simple Queue Service (Amazon SOS) 订阅的 Amazon<br>  Simple Notication Service (Amazon SNS) 主题。配置使用者应用程序以处理来自队列的消息。</p><p>  <code>fan out</code></p><h2 id="16-B"><a href="#16-B" class="headerlink" title="16-B"></a>16-B</h2><p>  一家公司在 AWS 上托管数据湖。数据湖由 Amazon S3 和 Amazon RDS for PostgreSQL中的数据组成。该公司需要一个提供数据可视化并包含数据湖中所有数据源的报告解决方案。只有公司的管理团队才能完全访问所有可视化。公司的其他成员应该只有有限的访问权限。</p><p>  哪种解决方案可以满足这些要求？</p><p>  A. 在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以<br>  可视化数据。与适当的 <strong>IAM 角色</strong>共享仪表板。</p><p>  B. 在 Amazon QuickSight 中创建分析。连接所有数据源并创建新的数据集。发布仪表板以<br>  可视化数据。与适当的<strong>用户和组</strong>共享仪表板。</p><p>  <code>发布仪表板后，您可以将其与QuickSight账户中的其他**用户或群组**共享。</code><br>  C. 为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。创建 AWS Glue 提取、转换<br>  和加载 (ETL) 作业以生成报告。将报告发布到 Amazon S3。使用 <strong>S3 存储桶策略</strong>来限制对<br>  报告的访问。<br>  D. 为 Amazon S3 中的数据创建 AWS Glue 表和爬网程序。使用 Amazon Athena 联合查<br>  询访问 Amazon RDS for PostgreSQL 中的数据。使用 Amazon Athena 生成报告。将报告发<br>  布到 Amazon S3。使用 <strong>S3 存储桶策略</strong>来限制对报告的访问。</p><h2 id="21-D"><a href="#21-D" class="headerlink" title="21-D"></a>21-D</h2><p>  一家电子商务公司希望在 AWS 上推出每日一交易网站。每天 24 小时内都会有一款产品<br>  在促销。该公司希望能够在高峰时段以<strong>毫秒</strong>级延迟处理每小时数百万个请求。哪种解决方<br>  案能够以最少的运营开销满足这些要求</p><p>  A. 使用 Amazon S3 在不同的 S3 存储桶中托管完整网站。添加 Amazon CloudFront 发行<br>  版。将 S3 存储桶设置为分发的来源。将订单数据存储在 Amazon S3 中。</p><p>  not provide the required performance and scale for millions of requests each hour with millisecond latency.</p><p>  B. 在跨多个可用区的 Auto Scaling 组中运行的 <strong><del>Amazon EC2 实例</del></strong>上部署完整网站。添加<br>  应用程序负载均衡器 (ALB) 以分发网站 trac。为后端 API 添加另一个 ALB。将数据存储<br>  在 Amazon RDS for MySQL 中。</p><p>  C. <del>迁移完整应用程序以在容器中运行</del>。在 Amazon Elastic Kubernetes Service (Amazon EKS)<br>  上托管容器。使用 Kubernetes Cluster Autoscaler 增加和减少 trac 中处理突发的 pod 数量。<br>  将数据存储在 Amazon RDS for MySQL 中。</p><p>  D. 使用 Amazon S3 存储桶托管网站的静态内容。部署 Amazon CloudFront 发行版。将 S3<br>  存储桶设置为原点。使用 Amazon API Gateway 和 AWS Lambda 函数作为后端 API。将<br>  数据存储在 Amazon DynamoDB 中。</p><h2 id="24-B"><a href="#24-B" class="headerlink" title="24-B"></a>24-B</h2><pre><code>  问题＃24一家公司在最近的账单中发现 Amazon EC2 成本有所增加。计费团队注意到几个 EC2 实例的实例类型出现不必要的垂直扩展。解决方案架构师需要创建一个图表来比较过去 2 个月的 EC2 成本，并进行深入分析以确定垂直扩展的根本原因。解决方案架构师应如何以最少的运营开销生成信息？A. 使用 AWS Budgets 创建预算报告并根据实例类型比较 EC2 成本。`无法深入分析`**B. 使用 Cost Explorer 的粒度过滤功能根据实例类型对 EC2 成本进行深入分析。**C. 使用 AWS Billing and Cost Management 仪表板中的图表来比较过去 2 个月基于实例类型的 EC2 成本。`需要更多手动操作和配置`D. 使用 AWS 成本和使用情况报告创建报告并将其发送到 Amazon S3 存储桶。使用Amazon QuickSight 和 Amazon S3 作为源，根据实例类型生成交互式图表。`是一个可行的方法，但可能涉及更多的配置和复杂性。`</code></pre><h2 id="36-B"><a href="#36-B" class="headerlink" title="36-B"></a>36-B</h2><p>  一家公司正在 AWS 云中构建应用程序。该应用程序将数据存储在两个 AWS 区域的Amazon S3 存储桶中。公司必须使用 AWS Key Management Service (AWS KMS) <strong>客户托管密钥</strong>来加密存储在 S3 存储桶中的所有数据。**两个 S3 存储桶中的数据必须使用相同的KMS 密钥进行加密和解密。**数据和密钥必须存储在两个区域中的每一个中。</p><p>  哪种解决方案能够以最少的运营开销满足这些要求？</p><p>  A. 在每个区域创建一个 S3 存储桶。配置 S3 存储桶以使用带有 Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。</p><p>  <strong>B. 创建客户管理的多区域 KMS 密钥。在每个区域创建一个 S3 存储桶。配置 S3 存储桶之间的复制。配置应用程序以使用带有客户端加密的 KMS 密钥。</strong></p><p>  C. 在每个区域中创建客户管理的 KMS 密钥和 S3 存储桶。配置 S3 存储桶以使用带有Amazon S3 托管加密密钥 (SSE-S3) 的服务器端加密。配置 S3 存储桶之间的复制。</p><p>  D. 在每个区域中创建客户管理的 KMS 密钥和 S3 存储桶。配置 S3 存储桶以使用带有AWS KMS 密钥的服务器端加密 (SSE-KMS)。配置 S3 存储桶之间的复制。</p><h2 id="501-C"><a href="#501-C" class="headerlink" title="501-C"></a>501-C</h2><p>  一家公司希望将客户支付数据提取到公司的 Amazon S3 数据湖中。该公司平均每分钟都会<br>  收到付款数据。该公司希望实时分析支付数据。然后该公司希望将数据提取到数据湖中。<br>  哪种解决方案能够以最高的运营效率满足这些要求？<br>  A. 使用 Amazon Kinesis Data Streams 提取数据。使用 AWS Lambda 实时分析数据。<br>  B. 使用 AWS Glue 提取数据。使用 Amazon Kinesis Data Analytics 实时分析数据。</p><p>  C. 使用 Amazon Kinesis Data Firehose 提取数据。使用 Amazon Kinesis Data Analytics 实时<br>  分析数据。</p><p>  <code>Kinesis Data Firehose 可以从多个数据源（如日志、传感器数据、应用程序事件等）中收集实时数据流，将其传输到各种目标。</code><br>  D. 使用 Amazon API Gateway 提取数据。使用 AWS Lambda 实时分析数据。<br>  正确答案：C</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;422-D&quot;&gt;&lt;a href=&quot;#422-D&quot; class=&quot;headerlink&quot; title=&quot;422-D&quot;&gt;&lt;/a&gt;422-D&lt;/h2&gt;&lt;p&gt;  一家公司正在 AWS 上开发新的机器学习 (ML) 模型解决方案。这些模型被开发为独立的微服务，在启动时从 Am</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>AWS-16【 网络】Route 53-域名系统</title>
    <link href="https://sosocrown.github.io/2023/08/17/AWS-16%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91Route%2053-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F/"/>
    <id>https://sosocrown.github.io/2023/08/17/AWS-16%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91Route%2053-%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F/</id>
    <published>2023-08-16T16:00:00.000Z</published>
    <updated>2025-05-07T02:38:24.635Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Route-53"><a href="#Amazon-Route-53" class="headerlink" title="Amazon Route 53"></a><strong>Amazon Route 53</strong></h1><p><img src="/images/Untitled%20165.png" alt="Untitled"></p><ul><li>“Route 53”是指传统DNS使用的端口号（53）</li></ul><ol><li><strong>域名解析</strong>：Route 53 允许您将域名映射到各种 AWS 资源，如 **Amazon S3 存储桶、Amazon EC2 实例、Elastic Load Balancer（ELB）**等。您可以配置 DNS 记录，将用户输入的域名转换为 IP 地址，从而使用户能够通过域名访问您的资源。</li><li><strong>高可用和可靠性</strong>：Route 53 提供全球分布的 DNS 服务，具有高可用性和可靠性。它将自动将 DNS 记录分发到多个全球边缘位置，以确保用户能够就近访问资源，提高响应速度和可用性。</li><li><strong>负载均衡</strong>：Route 53 可与 Amazon Elastic Load Balancing 集成，实现负载均衡。您可以配置 DNS 记录，将流量分发到不同的负载均衡器，以实现高可用性和性能优化。</li></ol><ul><li>能够检查您的资源的健康状态</li><li><strong>100% SLA保证</strong>：Route 53是唯一一个AWS服务提供100%可用性的服务级别协议（SLA）。</li></ul><h3 id="“Route-53-Active-Passive”"><a href="#“Route-53-Active-Passive”" class="headerlink" title="“Route 53 Active-Passive”"></a>“Route 53 Active-Passive”</h3><p>是一种架构配置，主要用于实现高可用性和故障恢复。</p><p>在 Active-Passive 配置中，我们通常考虑系统中的两种状态：活动状态（Active）和待命状态（Passive）。</p><ul><li><strong>活动状态（Active）：</strong> 这是系统中当前正在提供服务的状态。在一个 “Route 53 Active-Passive” 配置中，活动状态通常指向一个实际提供服务的资源，比如一个服务器、虚拟机实例或应用程序。</li><li><strong>待命状态（Passive）：</strong> 这是系统中备用的、处于待命状态的资源。它不提供实际的服务，而是等待在活动状态不可用时接管服务。待命状态的资源会与活动状态资源保持同步，以确保数据的一致性。</li></ul><h3 id="Route-53故障转移的关键点如下："><a href="#Route-53故障转移的关键点如下：" class="headerlink" title="Route 53故障转移的关键点如下："></a><strong>Route 53故障转移</strong>的关键点如下：</h3><ol start="4"><li><strong>Failover Routing Policy</strong>：Route 53的Failover路由策略允许您配置主&#x2F;备份资源，以便在主资源不可用时自动将流量切换到备份资源。例如，您可以将流量引导到主要AWS区域中的资源，但如果该区域发生故障，Route 53可以将流量切换到另一个备份区域中的资源。</li><li><strong>Health Checks</strong>：您可以设置Route 53的健康检查来监控各个资源的可用性。当主资源不可用时，健康检查可以自动触发Route 53的Failover策略，将流量切换到备份资源。</li><li><strong>Global Accelerator Integration</strong>：Route 53可以与AWS Global Accelerator结合使用，以提供全球级别的流量管理和故障转移。Global Accelerator可以优化全球范围内的流量分发，确保将用户流量快速引导到最近的健康资源。</li><li><strong>Latency-Based Routing</strong>：虽然不直接是故障转移，但根据延迟的路由策略可以确保将用户流量引导到距离最近且延迟最低的资源，从而提高用户体验并减少延迟。</li></ol><h3 id="Routing-Policies-路由策略"><a href="#Routing-Policies-路由策略" class="headerlink" title="Routing Policies-路由策略"></a>Routing Policies-<strong>路由策略</strong></h3><ul><li><p>Defines how Route53 responds to DNS queries</p><p>  定义了如何将 DNS 查询路由到资源</p><p>  以下是展示 Amazon Route 53 不同路由策略及其特点和适用场景的表格：</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>权重路由策略（Weighted）</td><td>- 按照权重分配到不同资源</td></tr><tr><td>故障转移路由策略（Failover）</td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr><tr><td>多值路由策略（Multivalue）</td><td>- 用于将流量路由到多个资源</td></tr></tbody></table><p>  这个表格展示了 Amazon Route 53 不同的路由策略，以及每个策略的特点和适用场景。希望这能够帮助您更清楚地了解每种路由策略的用途和优势。</p></li></ul><h3 id="Simple-Routing（简单路由）"><a href="#Simple-Routing（简单路由）" class="headerlink" title="Simple Routing（简单路由）:"></a><strong>Simple Routing</strong>（简单路由）:</h3><ul><li>返回单个资源的所有记录</li><li>如果返回了多个相同记录的值，则客户端将随机选择一个</li><li>不能与健康检查相关联</li></ul><h3 id="Weighted-Routing（加权路由）"><a href="#Weighted-Routing（加权路由）" class="headerlink" title="Weighted Routing（加权路由）:"></a><strong>Weighted Routing</strong>（加权路由）:</h3><ul><li>control traffic by weight</li><li>can be associated with Health Checks</li><li>Assign a weight of 0 to a record to stop sending traffic to a resource • If all records have we</li><li><strong>按照权重分配到不同资源</strong></li><li>按权重控制流量</li><li>可以与健康检查相关联</li><li>将记录的权重分配为0，以停止向资源发送流量</li><li>如果所有记录的权重都为0，则不会向该资源发送流量</li></ul><h3 id="Failover-Routing（故障转移路由）"><a href="#Failover-Routing（故障转移路由）" class="headerlink" title="Failover Routing（故障转移路由）:"></a><strong>Failover Routing</strong>（故障转移路由）:</h3><ul><li>When an active instance failed the health check, the standby instance will failover and become active</li></ul><p>当<strong>活动实例未通过健康检查时，备用实例将接管并成为活动实例。</strong></p><h3 id="Latency-based-Routing（基于延迟的路由）"><a href="#Latency-based-Routing（基于延迟的路由）" class="headerlink" title="Latency-based Routing（基于延迟的路由）:"></a><strong>Latency-based Routing</strong>（基于延迟的路由）:</h3><ul><li>Redirect to the resource that has the least latency close to user</li><li>Latency is based on traffic between users and AWS Regions</li><li>Can be associated with Health Checks</li><li>重定向到距离用户最近的资源</li><li>延迟基于用户和AWS区域之间的流量</li><li>可以与健康检查相关联</li></ul><h3 id="Geolocation-Routing（地理位置路由）"><a href="#Geolocation-Routing（地理位置路由）" class="headerlink" title="Geolocation Routing（地理位置路由）:"></a><strong>Geolocation Routing</strong>（地理位置路由）:</h3><ul><li>This routing is based on user location</li><li>Can be associated with Health Checks</li></ul><h3 id="Multi-Value-Answer-Routing（多值回答路由）"><a href="#Multi-Value-Answer-Routing（多值回答路由）" class="headerlink" title="Multi-Value Answer Routing（多值回答路由）:"></a><strong>Multi-Value Answer Routing</strong>（多值回答路由）:</h3><ul><li>Use when routing traffic to multiple resources</li><li>Each resource receives a separate DNS response, and Route 53 responds to DNS queries with multiple IP addresses.</li><li>Can be associated with Health Checks (return only values for healthy resources)</li><li>用于将流量路由到多个资源</li><li>每个资源都会收到单独的 DNS 响应，并且 Route 53 会用多个 IP 地址响应 DNS 查询。</li><li>可以与健康检查相关联（仅返回健康资源的值）</li><li>有助于实现<strong>负载均衡</strong>和<strong>高可用性</strong>。</li></ul><h3 id="Geoproximity-Routing（地理接近路由）"><a href="#Geoproximity-Routing（地理接近路由）" class="headerlink" title="Geoproximity Routing（地理接近路由）:"></a><strong>Geoproximity Routing</strong>（地理接近路由）:</h3><ul><li>Route traffic to your resources based on the geographic location of users and resources</li><li>Ability to shift more traffic to resources based on the defined bias</li></ul><h3 id="Route-53-–-Records记录集"><a href="#Route-53-–-Records记录集" class="headerlink" title="Route 53 – Records记录集"></a><strong>Route 53 – Records</strong>记录集</h3><p>用于将域名映射到特定资源（例如IP地址、其他域名或负载均衡器）的信息</p><ul><li><strong>Domain&#x2F;subdomain Name</strong> – e.g., example.com</li><li><strong>Record Type</strong> – e.g., A or AAAA</li><li><strong>Value</strong> – e.g., 12.34.56.78</li><li><strong>Routing Policy</strong> – how Route 53 responds to queries</li><li><strong>TTL（time to live）</strong> – amount of time the record cached at DNS Resolvers</li></ul><h3 id="Record-Types-记录类型"><a href="#Record-Types-记录类型" class="headerlink" title="Record Types-记录类型"></a><strong>Record Types-记录类型</strong></h3><ul><li><strong>A</strong> – maps a hostname to IPv4</li><li><strong>AAAA</strong> – maps a hostname to IPv6</li><li><strong>CNAME</strong> – maps a hostname to another hostname<ul><li>The target is a domain name which must have an A or AAAA record</li><li>Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)</li><li>Example: you can’t create for example.com, but you can create for <a href="http://www.example.com/">www.example.com</a></li></ul></li><li><strong>NS</strong> – Name Servers for the Hosted Zone<ul><li>Control how traffic is routed for a domain</li></ul></li></ul><h3 id="hosted-zone-托管区域"><a href="#hosted-zone-托管区域" class="headerlink" title="hosted zone-托管区域"></a>hosted zone-托管区域</h3><p>Hosted Zone（托管区域）是一个与特定域名（例如 <a href="http://example.com/">example.com</a>）关联的 DNS 区域。它包含了该域名下所有 DNS 记录的信息，用于解析域名到相应的 IP 地址或其他资源。</p><p><strong>一个包含定义如何路由流量到域名及其子域名的记录的容器</strong></p><ul><li><strong>公有托管区域</strong><ul><li>包含指定如何在互联网上路由流量的记录</li></ul></li><li><strong>私有托管区域</strong><ul><li>包含指定如何在一个或多个VPC中路由流量的记录</li></ul></li><li>每个托管区域每月收取0.5美元的费用</li></ul><h3 id="Alias-Records-别名记录"><a href="#Alias-Records-别名记录" class="headerlink" title="Alias Records-别名记录"></a>Alias Records-<strong>别名记录</strong></h3><ul><li>将主机名映射到AWS资源</li><li>别名记录始终为AWS资源的类型A&#x2F;AAAA（IPv4&#x2F;IPv6）</li><li>您无法设置TTL, route53自动设置</li><li>您无法为EC2 DNS名称设置别名记录</li><li>You cannot set an ALIAS record for an EC2 DNS name</li></ul><h3 id="Health-Checks-健康检查"><a href="#Health-Checks-健康检查" class="headerlink" title="Health Checks-健康检查"></a>Health Checks-健康检查</h3><ul><li>HTTP Health Checks are only for public resources</li><li>Health Check &#x3D;&gt; Automated DNS Failover</li><li>健康检查与CloudWatch指标集成</li><li>配置路由器&#x2F;防火墙以允许来自Route 53 Health Checkers的传入请求</li></ul><h3 id="Health-checks-that-monitor-an-endpoint"><a href="#Health-checks-that-monitor-an-endpoint" class="headerlink" title="Health checks that monitor an endpoint"></a><strong>Health checks that monitor an endpoint</strong></h3><p>您可以配置运行状况检查来监控通过 IP 地址或域名指定的端点。Route 53 按照您指定的固定间隔，通过互联网向您的应用程序、服务器或其它资源自动提交请求，以验证其是否可到达、是否可用及功能是否正常。您也可以通过配置运行状况检查来发出与用户发出的请求类似的请求，如从特定 URL 请求网页。</p><h3 id="calculated-health-checks"><a href="#calculated-health-checks" class="headerlink" title="calculated health checks"></a><strong>calculated health checks</strong></h3><ul><li>Combine the results of multiple Health Checks into a single Health Check</li><li>You can use OR, AND, or NOT</li><li>Can monitor up to 256 Child Health Checks</li><li>Specify how many of the health checks need to pass to make the parent pass</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Route-53&quot;&gt;&lt;a href=&quot;#Amazon-Route-53&quot; class=&quot;headerlink&quot; title=&quot;Amazon Route 53&quot;&gt;&lt;/a&gt;&lt;strong&gt;Amazon Route 53&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>AWS-13【 网络】VPC</title>
    <link href="https://sosocrown.github.io/2023/08/16/AWS-14%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91VPC/"/>
    <id>https://sosocrown.github.io/2023/08/16/AWS-14%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91VPC/</id>
    <published>2023-08-15T16:00:00.000Z</published>
    <updated>2025-05-07T02:38:16.313Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VPC"><a href="#VPC" class="headerlink" title="VPC"></a><strong>VPC</strong></h1><h3 id="Virtual-Private-Cloud"><a href="#Virtual-Private-Cloud" class="headerlink" title="Virtual Private Cloud"></a>Virtual Private Cloud</h3><p><img src="/images/Untitled%20133.png" alt="Untitled"></p><h2 id="1-VPC-概述"><a href="#1-VPC-概述" class="headerlink" title="1. VPC 概述"></a>1. VPC 概述</h2><ul><li>VPC 是一个逻辑隔离的 AWS 云网络，允许您在自己定义的虚拟网络中运行 AWS 资源。</li><li>VPC 具有 IP 地址范围（CIDR 块）。</li><li>类似传统网络中的<strong>VLAN</strong></li><li>multiple VPCs  in a region(最多5个）</li><li>VPC的最大CIDR范围可以是&#x2F;16（65,536个IP地址）到&#x2F;28（16个IP地址）</li></ul><p><img src="/images/Untitled%20134.png" alt="Untitled"></p><h2 id="2-Subnets-子网"><a href="#2-Subnets-子网" class="headerlink" title="2. Subnets-子网"></a>2. Subnets-子网</h2><ul><li>Subnet 是 VPC IP 地址范围的一部分，用于在 VPC 内部划分不同的网络区域。</li></ul><p><img src="/images/Untitled%20135.png" alt="Untitled"></p><ul><li>子网必须位于单个可用区中</li><li>子网可以分配给不同的AZ，确保高可用性。<ul><li>保留5个IP地址，前四个和最后一个</li></ul></li><li><strong>公有子网（Public Subnet</strong>：与 Internet Gateway（IGW）关联，可以直接访问 Internet。</li><li><strong>私有子网（Private Subnet）</strong>：无法直接访问 Internet，通常用于安全敏感的工作负载。通过NAT网关或NAT实例来实现对Internet的有限访问</li></ul><h2 id="3-Route-Table-路由表"><a href="#3-Route-Table-路由表" class="headerlink" title="3.Route Table-路由表"></a>3.<strong>Route Table-路由表</strong></h2><p>路由表定义了网络流量如何在子网之间和VPC内部进行路由。每个子网都会关联一个路由表，该表指定了流量的目标以及如何将流量转发到目标。</p><h2 id="4-安全组-Security-Group-和NACL"><a href="#4-安全组-Security-Group-和NACL" class="headerlink" title="4. 安全组 (Security Group) 和NACL"></a>4. 安全组 (Security Group) 和NACL</h2><ul><li><p><strong>安全组（Security Group）</strong></p><ul><li><strong>层次： instance-level</strong>每个实例可以关联一个或多个安全组。它是第一层防御，应用在每个实例上。</li><li><strong>规则：</strong> 基于”allow”的原则。如果规则没有明确允许，那么它就会被隐式地拒绝。</li><li><strong>状态：stateful</strong></li><li><strong>应用：</strong> 用于实现实例级别的访问控制，通常用于控制实例之间的通信。</li></ul></li><li><p><strong>网络访问控制列表（NACL）-Network Access Control List</strong></p><p>  <strong>默认情况下，它允许所有入站和出站 IPv4 流量以及 IPv6 流量</strong></p><ul><li><p><strong>层次：</strong> NACL是在子网级别操作的，每个子网都有一个关联的NACL。它是第二层防御，应用在子网内。</p></li><li><p><strong>规则：</strong> 基于”allow”和”deny”。</p></li><li><p><strong>状态：</strong> <strong>stateless，如果您允许出站流量，入站回复流量不会自动被允许。<code>这意味着你需要同时考虑入站和出站规则，因为出站规则也会影响入站流量的回复。</code></strong></p><ul><li><strong><code>需要确保相关的出站规则允许响应的HTTPS流量返回</code></strong></li></ul></li><li><p><strong>应用：</strong> 用于实现子网级别的访问控制，通常用于控制子网之间的通信。</p></li><li><p>Default NACL</p><ul><li>Accepts everything inbound&#x2F;outbound with the subnets it’s associated with</li><li>Do NOT modify the Default NACL, instead create custom NACLs</li></ul><p>  <img src="/images/Untitled%20136.png" alt="Untitled"></p></li></ul></li></ul><table><thead><tr><th>特点 &#x2F; 注意事项</th><th>安全组 (SG)</th><th>网络访问控制列表 (NACL)</th></tr></thead><tbody><tr><td>类型</td><td>实例级别防火墙</td><td>子网级别防火墙</td></tr><tr><td>方向</td><td>可以配置入站和出站规则</td><td><strong>必须</strong>同时配置入站和出站规则</td></tr><tr><td>默认规则</td><td>拒绝所有流量</td><td>允许所有流量</td></tr><tr><td>有状态性</td><td>有状态，自动允许相关回复流量</td><td>无状态，入站和出站流量的状态是分开维护</td></tr><tr><td>数量限制</td><td>一个实例可以关联多个安全组</td><td>一个子网只能关联一个网络访问控制列表</td></tr><tr><td>功能</td><td>简单，易于使用</td><td>较为复杂，可用于更细粒度的控制</td></tr></tbody></table><p><strong>注意事项：</strong></p><p><strong>安全组 (SG)：</strong></p><ul><li>安全组适用于实例级别的访问控制，配置更简单，但只能定义基于协议、端口和IP范围的规则。</li><li>可以在安全组之间进行联动，一个实例可以关联多个安全组，规则叠加。</li><li>入站规则优先于出站规则，相关回复流量自动允许。</li></ul><p><strong>网络访问控制列表 (NACL)：</strong></p><ul><li>NACL 适用于子网级别的访问控制，可以更细粒度地定义入站和出站规则。</li><li>需要同时配置入站和出站规则，注意规则的顺序和编号。</li><li>无状态性意味着入站和出站流量的状态是分开维护的，需要确保出站规则允许相关回复流量。</li><li>更适合处理较复杂的网络策略，但需要更多的配置工作。</li></ul><p>请根据你的需求和网络架构，选择合适的访问控制方式。一般情况下，安全组用于基本的实例级别防火墙，而 NACL 则用于更细粒度的子网级别控制。</p><p><img src="/images/Untitled%20137.png" alt="Untitled"></p><p><strong>选择安全组还是NACL：</strong></p><ul><li>如果您需要更精细的控制，并且关注于实例级别的访问控制，使用安全组。</li><li>如果您需要更高层次的网络防御，以及控制子网之间的通信，使用NACL。</li><li>在复杂的网络环境中，通常会同时使用安全组和NACL来提供多层次的安全性。</li></ul><h2 id="5-VPC-Peering-对等连接"><a href="#5-VPC-Peering-对等连接" class="headerlink" title="5. VPC Peering-对等连接"></a>5. VPC Peering-<strong>对等连接</strong></h2><p>VPC Peering 允许在不同的 VPC 之间创建私有连接。</p><ul><li><strong>连接不同VPC：</strong> VPC Peering允许您将两个不同的VPC连接在一起，使它们之间可以进行安全的通信。</li><li><strong>不具备传递性</strong></li><li><strong>跨帐户&#x2F;区域：</strong> 您可以在不同的AWS帐户或不同的AWS区域之间创建VPC Peering连接，从而实现多个帐户或区域之间的私有通信。<ul><li>可以在不同 AWS 账户之间或同一账户下的不同 VPC 之间建立 VPC Peering。</li></ul></li><li><strong>引用安全组：</strong> 在同一区域的不同帐户之间，您可以通过VPC Peering引用另一个VPC中的安全组，以实现资源间的访问控制。</li><li><strong>路由表更新：</strong> 在建立VPC Peering后，您需要更新每个VPC子网的路由表，以确保VPC内的EC2实例可以通过Peering连接进行通信。</li></ul><h2 id="6-VPC-端点-Endpoints"><a href="#6-VPC-端点-Endpoints" class="headerlink" title="6. VPC 端点 (Endpoints)"></a>6. VPC 端点 (Endpoints)</h2><p>用于在 <strong>VPC 内部与 AWS 服务</strong>进行安全通信。</p><ul><li>VPC 端点允许 <strong>VPC 中的实例与 AWS 服务</strong>通信，而无需通过 Internet。</li><li>分为网关端点（Gateway Endpoint）和接口端点（Interface Endpoint）。</li><li>They’re redundant and scale horizontally冗余性并且水平扩展</li></ul><p><img src="/images/Untitled%20138.png" alt="Untitled"></p><ul><li><p><strong>类型：</strong> 有两种类型的VPC终端节点：</p><ul><li><strong>接口终端节点（Interface Endpoints）：</strong> 使用AWS PrivateLink提供支持，它为您的VPC分配一个Elastic Network Interface（<strong>ENI</strong>），作为访问AWS服务的入口点。支持大多数AWS服务，<strong>需要按小时计费并按数据处理量付费。</strong></li></ul><p>  <img src="/images/Untitled%20139.png" alt="Untitled"></p><ul><li><strong>网关终端节点（Gateway Endpoints）：</strong> 适用于S3和DynamoDB，可以将终端节点作为目标添加到VPC的路由表中。网关终端节点<strong>免费且不使用安全组。</strong></li></ul><p>  <img src="/images/Untitled%20140.png" alt="Untitled">  </p></li><li><p><strong>适用场景：</strong></p><ul><li>对于需要安全地连接到AWS服务的情况，如数据库、存储和计算资源，VPC终端节点是一个理想的选择。</li><li>接口终端节点适用于需要连接多种AWS服务的场景，而网关终端节点适用于S3和DynamoDB的访问</li></ul></li><li><p>Gateway or Interface Endpoint for <strong>S3</strong>?</p><ul><li>Gateway is most likely going to be preferred all the time at the exam</li><li>Unless, access is required from on premises (Site to Site VPN or Direct Connect), a different VPC or a different region</li><li>选择S3的网关终端节点还是接口终端节点？<br>  在考试中，gateway很可能会始终被优先选择<br>  除非需要从本地环境（站点到站点VPN或直接连接）、不同的VPC或不同的区域访问。</li></ul></li></ul><h2 id="7-VPC-流日志-Flow-Logs"><a href="#7-VPC-流日志-Flow-Logs" class="headerlink" title="7. VPC 流日志 (Flow Logs)"></a>7. VPC 流日志 (Flow Logs)</h2><ul><li>VPC 流日志可捕获 VPC 内部网络流量的详细信息，用于安全审计和网络监控。</li><li>流日志可以将数据发送到 Amazon S3、CloudWatch Logs 或 Amazon ES。</li></ul><h2 id="VPC-Flow-Logs"><a href="#VPC-Flow-Logs" class="headerlink" title="VPC Flow Logs"></a>VPC Flow Logs</h2><ul><li>Capture information about IP traffic going into your interfaces</li><li>Helps to monitor &amp; troubleshoot connectivity issues</li><li>Flow logs data can go to S3 &#x2F; CloudWatch Logs</li><li>Query VPC flow logs using Athena on S3 or CloudWatch Logs Insights</li><li>捕获进入接口的IP流量信息</li><li>有助于监视和解决连接问题</li><li>流日志数据可发送到S3 &#x2F; CloudWatch日志</li><li>使用Athena在S3上查询VPC流日志或CloudWatch日志洞察</li></ul><p><img src="/images/Untitled%20141.png" alt="Untitled"></p><h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><img src="/images/Untitled%20142.png" alt="Untitled"></p><p><img src="/images/Untitled%20143.png" alt="Untitled"></p><p><img src="/images/Untitled%20144.png" alt="Untitled"></p><p><img src="/images/Untitled%20145.png" alt="Untitled"></p><p><img src="/images/Untitled%20146.png" alt="Untitled"></p><p><img src="/images/Untitled%20147.png" alt="Untitled"></p><p><img src="/images/Untitled%20148.png" alt="Untitled"></p><p><img src="/images/Untitled%20149.png" alt="Untitled"></p><p><img src="/images/Untitled%20150.png" alt="Untitled"></p><p><img src="/images/Untitled%20151.png" alt="Untitled"></p><h1 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h1><h2 id="1-Internet-Gateway-IGW"><a href="#1-Internet-Gateway-IGW" class="headerlink" title="1. Internet Gateway (IGW)"></a>1. Internet Gateway (IGW)</h2><ul><li><strong>IGW（Internet gateway）是AWS提供的，用来实现VPC和Internet之间相互通信的高可用组件。</strong></li><li>IGW 是连接 VPC 内部<strong>私有子网</strong>和<strong>公共 Internet</strong> 的组件。</li><li>在公有子网中，IGW 允许实例与 Internet 通信，且可以使用公有 IP。</li><li>一个VPC只能连接到一个IGW，反之亦然</li></ul><h2 id="2-NAT"><a href="#2-NAT" class="headerlink" title="2. NAT"></a>2. NAT</h2><h3 id="NAT-Network-Address-Translation"><a href="#NAT-Network-Address-Translation" class="headerlink" title="NAT &#x3D; Network Address Translation"></a>NAT &#x3D; Network Address Translation</h3><p>NAT 网关主要用于<strong>私有子网中的实例</strong>访问互联网</p><p><strong><code>出站连接</code></strong></p><h3 id="NAT-instance"><a href="#NAT-instance" class="headerlink" title="NAT instance"></a><strong>NAT instance</strong></h3><p>需要手动配置，适用于小规模流量。Old, must be setup in a public subnet, disable Source &#x2F; Destination check flag</p><p><img src="/images/Untitled%20152.png" alt="Untitled"></p><h3 id="NAT-gateway"><a href="#NAT-gateway" class="headerlink" title="NAT gateway"></a>NAT gateway</h3><p>AWS 托管，适用于大规模流量和高可用性需求。</p><p>NAT Gateway由AWS管理，提供可扩展的IPv4私有EC2实例Internet访问。</p><p>性能和可用性较高，所以通常优于NAT Instance。</p><p><img src="/images/Untitled%20153.png" alt="Untitled"></p><h2 id="3-AWS-Direct-Connect-DX-直连"><a href="#3-AWS-Direct-Connect-DX-直连" class="headerlink" title="3. AWS Direct Connect (DX)-直连"></a>3. AWS Direct Connect (DX)-直连</h2><p><img src="/images/Untitled%20154.png" alt="Untitled"></p><ul><li><strong>专用的物理连接</strong></li><li>AWS Direct Connect 在您的本地部署网络和 AWS 之间建立专用网络连接。</li><li>可以实现更稳定、低延迟的连接，用于大数据传输和混合云架构。</li></ul><h2 id="Direct-Connect-DX"><a href="#Direct-Connect-DX" class="headerlink" title="Direct Connect (DX)"></a>Direct Connect (DX)</h2><ul><li>提供从远程网络到您的VPC的dedicated private专用私有连接。</li><li>Data Center and <em><strong>AWS Direct Connect locations</strong></em>之间设置专用连接。</li></ul><aside>💡 DX Location是AWS Direct Connect服务的实际物理位置，通过连接到这些位置，您可以建立专用的物理连接</aside><ul><li><p>可以在同一连接上访问公共资源（如S3）和私有资源（如EC2）。</p></li><li><p>支持IPv4和IPv6。</p><p>  <img src="/images/Untitled%20155.png" alt="Untitled"></p></li></ul><blockquote><p><strong>连接流程：</strong></p></blockquote><ol><li>您在AWS控制台中选择一个DX Location，这是您将要建立连接的物理位置。</li><li>在您的本地网络中，您配置一个CGW，以确保它能够连接到DX Location。</li><li>您在AWS中创建一个VGW，并分配一个公共IP地址。</li><li>您在CGW和VGW之间建立IPSec隧道，通过配置加密和认证参数，以建立安全的通信通道。</li><li>一旦隧道建立，数据可以通过VPN连接在CGW和VGW之间进行加密传输。</li></ol><h2 id="Direct-Connect-Gateway"><a href="#Direct-Connect-Gateway" class="headerlink" title="Direct Connect Gateway"></a>Direct Connect Gateway</h2><ul><li>如果您想要在许多不同的区域（同一账户）中设置与一个或多个VPC的Direct Connect连接，您必须使用Direct Connect网关。If you want to set up a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway</li><li>建立新连接需要一个月以上的时间。</li><li>在传输中的数据未加密，但是保持私密性。<ul><li>AWS Direct Connect + VPN提供了一个IPsec加密的私有连接。</li></ul></li><li>如果Direct Connect发生故障，您可以设置备份Direct Connect连接（费用较高），或者设置站点到站点VPN连接。In case Direct Connect fails, you can set up a backup Direct Connect connection (expensive), or a Site-to-Site VPN connection</li><li></li></ul><p><img src="/images/Untitled%20156.png" alt="Untitled"></p><p><img src="/images/Untitled%20157.png" alt="Untitled"></p><h2 id="4-Bastion-Hosts"><a href="#4-Bastion-Hosts" class="headerlink" title="4. Bastion Hosts"></a>4. Bastion Hosts</h2><ul><li>一个作为跳板的 EC2 instance</li><li>Bastion Host 是放置在公有子网中的实例，用于安全远程访问私有子网中的实例。</li><li>通常用于管理和维护私有子网中的实例，提供临时访问。</li></ul><p>访问跳板：在受保护的内部网络和外部网络之间进行访问的中间节点。</p><p>位于公共网络中</p><p>使用bastion hosts  to SSH into 私有EC2实例</p><p><img src="/images/Untitled%20158.png" alt="Untitled"></p><h2 id="5-Ephemeral-Ports"><a href="#5-Ephemeral-Ports" class="headerlink" title="5. Ephemeral Ports"></a>5. Ephemeral Ports</h2><p><code>临时端口，短暂端口或动态端口</code></p><ul><li>随机分配的临时端口</li><li>Ephemeral Ports（短暂端口）是客户端与服务器之间临时建立的端口，用于数据传输。</li><li>通常在连接时随机分配，并在连接终止后释放。</li><li>Clients connect to a defined port, and expect a response on this port</li></ul><h2 id="6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN"><a href="#6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN" class="headerlink" title="6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN"></a>6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN</h2><h2 id="Site-to-Site-VPN"><a href="#Site-to-Site-VPN" class="headerlink" title="Site-to-Site VPN"></a>Site-to-Site VPN</h2><p>将本地数据中心与 VPC 直接连接的方法，作为备份连接方式。</p><p><strong>建立本地到VPC的连接：</strong> VPC站点到站点VPN允许您在VPC和本地数据中心之间建立一个加密的连接，使您的本地资源可以与VPC中的资源进行通信。</p><aside>💡 **VPN Gateway：** 在云服务中和本地网络中分别创建VPN Gateway：<aside>💡 VGW表示VPC侧的VPN设备</aside><aside>💡 LWG表示本地数据中心侧的VPN设备。</aside></aside><h3 id="VGW（Virtual-Private-Gateway）："><a href="#VGW（Virtual-Private-Gateway）：" class="headerlink" title="VGW（Virtual Private Gateway）："></a><strong>VGW（Virtual Private Gateway）：</strong></h3><ul><li>VGW是云服务提供商（如AWS）中的虚拟设备，用于建立VPN连接并处理数据的传入和传出。</li><li>VGW is created and attached to the VPC from which you want to create the Site-to-Site VPN connection</li></ul><h3 id="CGW（Customer-Gateway）："><a href="#CGW（Customer-Gateway）：" class="headerlink" title="CGW（Customer Gateway）："></a><strong>CGW（Customer Gateway）：</strong></h3><ul><li>本地网络中的物理设备或虚拟设备</li><li>与VGW之间建立IPSec隧道来实现安全通信。</li></ul><p><img src="/images/Untitled%20159.png" alt="Untitled"></p><h2 id="Site-to-Site-VPN-connection-as-a-backup"><a href="#Site-to-Site-VPN-connection-as-a-backup" class="headerlink" title="Site-to-Site VPN connection as a backup"></a>Site-to-Site VPN connection as a backup</h2><p><img src="/images/Untitled%20160.png" alt="Untitled"></p><h2 id="AWS-VPN-CloudHub"><a href="#AWS-VPN-CloudHub" class="headerlink" title="AWS VPN CloudHub"></a>AWS VPN CloudHub</h2><p>AWS VPN CloudHub 允许多个站点通过 VPN 连接到 AWS。</p><p>集中式的解决方案</p><ul><li>Provide secure communication between multiple sites, if you have multiple VPN connections</li><li>Low-cost hub-and-spoke model for primary or secondary network connectivity between different locations (VPN only)</li><li>It’s a VPN connection so it goes over the public Internet</li><li>如果有多个 VPN 连接，可以在多个站点之间提供安全通信</li><li>低成本的枢纽-辐射模型，用于不同位置之间的主要或次要网络连接 (仅限 VPN)</li><li>这是一种 VPN 连接，因此它经过公共互联网传输</li></ul><ol start="6"><li><strong>多站点连接：</strong> AWS VPN CloudHub支持同时连接多个远程站点。这些站点可以是不同地理位置的办公室、数据中心等。</li><li><strong>中心式架构：</strong> CloudHub采用中心式架构，其中AWS云中的一个VPC被用作中心（hub），连接到多个远程站点（spokes）。</li><li><strong>单一VPN连接：</strong> 在CloudHub配置中，每个远程站点与AWS云中的中心VPC之间只需要一个VPN连接。</li></ol><h2 id="7-Transit-Gateway-中转网关"><a href="#7-Transit-Gateway-中转网关" class="headerlink" title="7. Transit Gateway-中转网关"></a>7. Transit Gateway-<strong>中转网关</strong></h2><ul><li>Transit Gateway 是中心化的路由交换设备，用于连接多个 VPC、VPN 和 Direct Connect。</li><li>它简化了大规模 VPC 网络的管理和扩展。</li></ul><h2 id="Transit-Gateway（中转网关）"><a href="#Transit-Gateway（中转网关）" class="headerlink" title="Transit Gateway（中转网关）"></a><em><strong>Transit Gateway（中转网关）</strong></em></h2><p><strong>support  IP Multicast</strong></p><p>Transit Gateway是一种网络服务，用于在成千上万个VPC和本地网络之间建立具有<strong>传递性</strong>的中心式（星型）连接。以下是Transit Gateway的关键概念：</p><ul><li><strong>传递性对等连接：</strong> Transit Gateway允许在多个VPC和本地网络之间建立传递性的对等连接，形成一个中心枢纽连接。</li><li>Regional resource**：** Transit Gateway是region级别的资源，可以cross-region工作，实现不同AWS区域的连接。</li><li>Share cross-account contents using Resource Access Manager (RAM)</li><li>**使用RAM（Resource Access Manager）**Share cross-account contents</li></ul><p><img src="/images/Untitled%20161.png" alt="Untitled"></p><h3 id="Site-to-Site-VPN-ECMP"><a href="#Site-to-Site-VPN-ECMP" class="headerlink" title="Site-to-Site VPN ECMP"></a>Site-to-Site VPN ECMP</h3><ul><li>ECMP &#x3D; Equal-cost multi-path routing</li><li>Routing strategy to allow to forward a packet over multiple best path</li><li>Use case: create multiple Site-To-Site VPN connections to increase the bandwidth of your connection to AWS</li><li>站点对站点 VPN ECMP<ul><li>ECMP &#x3D; 等价多路径路由</li><li>转发数据包的路由策略，允许通过多个最佳路径</li><li>使用场景：创建多个站点对站点 VPN 连接，以增加到 AWS 的带宽</li></ul></li></ul><p><img src="/images/Untitled%20162.png" alt="Untitled"></p><p><img src="/images/Untitled%20163.png" alt="Untitled"></p><p><img src="/images/Untitled%20164.png" alt="Untitled"></p><h2 id="8-Traffic-Mirroring"><a href="#8-Traffic-Mirroring" class="headerlink" title="8. Traffic Mirroring"></a>8. Traffic Mirroring</h2><ul><li><strong>流量镜像：</strong> 通过使用流量镜像，您可以将来自<strong>生产 VPC</strong> 的流量镜像到特定的目标（例如 EC2 实例或另一个 VPC），然后在目标上执行流量<strong>检查和过滤</strong>。</li><li><strong>将流量路由到安全设备：</strong> 以进行内容检查、威胁监控、故障排除等操作。</li><li><strong>源和目标位置：</strong> 流量镜像的源和目标可以在同一VPC内或不同VPC之间（通过VPC Peering）。</li><li><strong>应用场景：</strong> 使用Transit Gateway的流量镜像功能可以用于内容检查、威胁监控、故障排除等场景。</li></ul><h1 id="Route-53-域名系统"><a href="#Route-53-域名系统" class="headerlink" title="Route 53-域名系统"></a>Route 53-域名系统</h1><h3 id="Amazon-Route-53"><a href="#Amazon-Route-53" class="headerlink" title="Amazon Route 53"></a><strong>Amazon Route 53</strong></h3><p><img src="/images/Untitled%20165.png" alt="Untitled"></p><ul><li>“Route 53”是指传统DNS使用的端口号（53）</li></ul><ol start="9"><li><strong>域名解析</strong>：Route 53 允许您将域名映射到各种 AWS 资源，如 **Amazon S3 存储桶、Amazon EC2 实例、Elastic Load Balancer（ELB）**等。您可以配置 DNS 记录，将用户输入的域名转换为 IP 地址，从而使用户能够通过域名访问您的资源。</li><li><strong>高可用和可靠性</strong>：Route 53 提供全球分布的 DNS 服务，具有高可用性和可靠性。它将自动将 DNS 记录分发到多个全球边缘位置，以确保用户能够就近访问资源，提高响应速度和可用性。</li><li><strong>负载均衡</strong>：Route 53 可与 Amazon Elastic Load Balancing 集成，实现负载均衡。您可以配置 DNS 记录，将流量分发到不同的负载均衡器，以实现高可用性和性能优化。</li></ol><ul><li>能够检查您的资源的健康状态</li><li><strong>100% SLA保证</strong>：Route 53是唯一一个AWS服务提供100%可用性的服务级别协议（SLA）。</li></ul><h3 id="“Route-53-Active-Passive”"><a href="#“Route-53-Active-Passive”" class="headerlink" title="“Route 53 Active-Passive”"></a>“Route 53 Active-Passive”</h3><p>是一种架构配置，主要用于实现高可用性和故障恢复。</p><p>在 Active-Passive 配置中，我们通常考虑系统中的两种状态：活动状态（Active）和待命状态（Passive）。</p><ul><li><strong>活动状态（Active）：</strong> 这是系统中当前正在提供服务的状态。在一个 “Route 53 Active-Passive” 配置中，活动状态通常指向一个实际提供服务的资源，比如一个服务器、虚拟机实例或应用程序。</li><li><strong>待命状态（Passive）：</strong> 这是系统中备用的、处于待命状态的资源。它不提供实际的服务，而是等待在活动状态不可用时接管服务。待命状态的资源会与活动状态资源保持同步，以确保数据的一致性。</li></ul><h3 id="Route-53故障转移的关键点如下："><a href="#Route-53故障转移的关键点如下：" class="headerlink" title="Route 53故障转移的关键点如下："></a><strong>Route 53故障转移</strong>的关键点如下：</h3><ol start="12"><li><strong>Failover Routing Policy</strong>：Route 53的Failover路由策略允许您配置主&#x2F;备份资源，以便在主资源不可用时自动将流量切换到备份资源。例如，您可以将流量引导到主要AWS区域中的资源，但如果该区域发生故障，Route 53可以将流量切换到另一个备份区域中的资源。</li><li><strong>Health Checks</strong>：您可以设置Route 53的健康检查来监控各个资源的可用性。当主资源不可用时，健康检查可以自动触发Route 53的Failover策略，将流量切换到备份资源。</li><li><strong>Global Accelerator Integration</strong>：Route 53可以与AWS Global Accelerator结合使用，以提供全球级别的流量管理和故障转移。Global Accelerator可以优化全球范围内的流量分发，确保将用户流量快速引导到最近的健康资源。</li><li><strong>Latency-Based Routing</strong>：虽然不直接是故障转移，但根据延迟的路由策略可以确保将用户流量引导到距离最近且延迟最低的资源，从而提高用户体验并减少延迟。</li></ol><h3 id="Routing-Policies-路由策略"><a href="#Routing-Policies-路由策略" class="headerlink" title="Routing Policies-路由策略"></a>Routing Policies-<strong>路由策略</strong></h3><ul><li><p>Defines how Route53 responds to DNS queries</p><p>  定义了如何将 DNS 查询路由到资源</p><p>  以下是展示 Amazon Route 53 不同路由策略及其特点和适用场景的表格：</p><table><thead><tr><th>路由策略</th><th>特点和适用场景</th></tr></thead><tbody><tr><td>简单路由策略（Simple）</td><td>流量路由到一个资源</td></tr><tr><td>权重路由策略（Weighted）</td><td>- 按照权重分配到不同资源</td></tr><tr><td>故障转移路由策略（Failover）</td><td>- 当活动实例<strong>未通过健康检查</strong>时，备用实例将接管并成为活动实例</td></tr><tr><td>基于延迟的路由策略（Latency）</td><td>- 重定向到距离用户最近的资源，适用于要求<strong>低延迟的全球性应用</strong>。</td></tr><tr><td>地理位置路由策略（Geolocation）</td><td>- 基于用户位置进行路由</td></tr><tr><td>多值路由策略（Multivalue）</td><td>- 用于将流量路由到多个资源</td></tr></tbody></table><p>  这个表格展示了 Amazon Route 53 不同的路由策略，以及每个策略的特点和适用场景。希望这能够帮助您更清楚地了解每种路由策略的用途和优势。</p></li></ul><h3 id="Simple-Routing（简单路由）"><a href="#Simple-Routing（简单路由）" class="headerlink" title="Simple Routing（简单路由）:"></a><strong>Simple Routing</strong>（简单路由）:</h3><ul><li>返回单个资源的所有记录</li><li>如果返回了多个相同记录的值，则客户端将随机选择一个</li><li>不能与健康检查相关联</li></ul><h3 id="Weighted-Routing（加权路由）"><a href="#Weighted-Routing（加权路由）" class="headerlink" title="Weighted Routing（加权路由）:"></a><strong>Weighted Routing</strong>（加权路由）:</h3><ul><li>control traffic by weight</li><li>can be associated with Health Checks</li><li>Assign a weight of 0 to a record to stop sending traffic to a resource • If all records have we</li><li><strong>按照权重分配到不同资源</strong></li><li>按权重控制流量</li><li>可以与健康检查相关联</li><li>将记录的权重分配为0，以停止向资源发送流量</li><li>如果所有记录的权重都为0，则不会向该资源发送流量</li></ul><h3 id="Failover-Routing（故障转移路由）"><a href="#Failover-Routing（故障转移路由）" class="headerlink" title="Failover Routing（故障转移路由）:"></a><strong>Failover Routing</strong>（故障转移路由）:</h3><ul><li>When an active instance failed the health check, the standby instance will failover and become active</li></ul><p>当<strong>活动实例未通过健康检查时，备用实例将接管并成为活动实例。</strong></p><h3 id="Latency-based-Routing（基于延迟的路由）"><a href="#Latency-based-Routing（基于延迟的路由）" class="headerlink" title="Latency-based Routing（基于延迟的路由）:"></a><strong>Latency-based Routing</strong>（基于延迟的路由）:</h3><ul><li>Redirect to the resource that has the least latency close to user</li><li>Latency is based on traffic between users and AWS Regions</li><li>Can be associated with Health Checks</li><li>重定向到距离用户最近的资源</li><li>延迟基于用户和AWS区域之间的流量</li><li>可以与健康检查相关联</li></ul><h3 id="Geolocation-Routing（地理位置路由）"><a href="#Geolocation-Routing（地理位置路由）" class="headerlink" title="Geolocation Routing（地理位置路由）:"></a><strong>Geolocation Routing</strong>（地理位置路由）:</h3><ul><li>This routing is based on user location</li><li>Can be associated with Health Checks</li></ul><h3 id="Multi-Value-Answer-Routing（多值回答路由）"><a href="#Multi-Value-Answer-Routing（多值回答路由）" class="headerlink" title="Multi-Value Answer Routing（多值回答路由）:"></a><strong>Multi-Value Answer Routing</strong>（多值回答路由）:</h3><ul><li>Use when routing traffic to multiple resources</li><li>Each resource receives a separate DNS response, and Route 53 responds to DNS queries with multiple IP addresses.</li><li>Can be associated with Health Checks (return only values for healthy resources)</li><li>用于将流量路由到多个资源</li><li>每个资源都会收到单独的 DNS 响应，并且 Route 53 会用多个 IP 地址响应 DNS 查询。</li><li>可以与健康检查相关联（仅返回健康资源的值）</li><li>有助于实现<strong>负载均衡</strong>和<strong>高可用性</strong>。</li></ul><h3 id="Geoproximity-Routing（地理接近路由）"><a href="#Geoproximity-Routing（地理接近路由）" class="headerlink" title="Geoproximity Routing（地理接近路由）:"></a><strong>Geoproximity Routing</strong>（地理接近路由）:</h3><ul><li>Route traffic to your resources based on the geographic location of users and resources</li><li>Ability to shift more traffic to resources based on the defined bias</li></ul><h3 id="Route-53-–-Records记录集"><a href="#Route-53-–-Records记录集" class="headerlink" title="Route 53 – Records记录集"></a><strong>Route 53 – Records</strong>记录集</h3><p>用于将域名映射到特定资源（例如IP地址、其他域名或负载均衡器）的信息</p><ul><li><strong>Domain&#x2F;subdomain Name</strong> – e.g., example.com</li><li><strong>Record Type</strong> – e.g., A or AAAA</li><li><strong>Value</strong> – e.g., 12.34.56.78</li><li><strong>Routing Policy</strong> – how Route 53 responds to queries</li><li><strong>TTL（time to live）</strong> – amount of time the record cached at DNS Resolvers</li></ul><h3 id="Record-Types-记录类型"><a href="#Record-Types-记录类型" class="headerlink" title="Record Types-记录类型"></a><strong>Record Types-记录类型</strong></h3><ul><li><strong>A</strong> – maps a hostname to IPv4</li><li><strong>AAAA</strong> – maps a hostname to IPv6</li><li><strong>CNAME</strong> – maps a hostname to another hostname<ul><li>The target is a domain name which must have an A or AAAA record</li><li>Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)</li><li>Example: you can’t create for example.com, but you can create for <a href="http://www.example.com/">www.example.com</a></li></ul></li><li><strong>NS</strong> – Name Servers for the Hosted Zone<ul><li>Control how traffic is routed for a domain</li></ul></li></ul><h3 id="hosted-zone-托管区域"><a href="#hosted-zone-托管区域" class="headerlink" title="hosted zone-托管区域"></a>hosted zone-托管区域</h3><p>Hosted Zone（托管区域）是一个与特定域名（例如 <a href="http://example.com/">example.com</a>）关联的 DNS 区域。它包含了该域名下所有 DNS 记录的信息，用于解析域名到相应的 IP 地址或其他资源。</p><p><strong>一个包含定义如何路由流量到域名及其子域名的记录的容器</strong></p><ul><li><strong>公有托管区域</strong><ul><li>包含指定如何在互联网上路由流量的记录</li></ul></li><li><strong>私有托管区域</strong><ul><li>包含指定如何在一个或多个VPC中路由流量的记录</li></ul></li><li>每个托管区域每月收取0.5美元的费用</li></ul><h3 id="Alias-Records-别名记录"><a href="#Alias-Records-别名记录" class="headerlink" title="Alias Records-别名记录"></a>Alias Records-<strong>别名记录</strong></h3><ul><li>将主机名映射到AWS资源</li><li>别名记录始终为AWS资源的类型A&#x2F;AAAA（IPv4&#x2F;IPv6）</li><li>您无法设置TTL, route53自动设置</li><li>您无法为EC2 DNS名称设置别名记录</li><li>You cannot set an ALIAS record for an EC2 DNS name</li></ul><h3 id="Health-Checks-健康检查"><a href="#Health-Checks-健康检查" class="headerlink" title="Health Checks-健康检查"></a>Health Checks-健康检查</h3><ul><li>HTTP Health Checks are only for public resources</li><li>Health Check &#x3D;&gt; Automated DNS Failover</li><li>健康检查与CloudWatch指标集成</li><li>配置路由器&#x2F;防火墙以允许来自Route 53 Health Checkers的传入请求</li></ul><h3 id="Health-checks-that-monitor-an-endpoint"><a href="#Health-checks-that-monitor-an-endpoint" class="headerlink" title="Health checks that monitor an endpoint"></a><strong>Health checks that monitor an endpoint</strong></h3><p>您可以配置运行状况检查来监控通过 IP 地址或域名指定的端点。Route 53 按照您指定的固定间隔，通过互联网向您的应用程序、服务器或其它资源自动提交请求，以验证其是否可到达、是否可用及功能是否正常。您也可以通过配置运行状况检查来发出与用户发出的请求类似的请求，如从特定 URL 请求网页。</p><h3 id="calculated-health-checks"><a href="#calculated-health-checks" class="headerlink" title="calculated health checks"></a><strong>calculated health checks</strong></h3><ul><li>Combine the results of multiple Health Checks into a single Health Check</li><li>You can use OR, AND, or NOT</li><li>Can monitor up to 256 Child Health Checks</li><li>Specify how many of the health checks need to pass to make the parent pass</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;VPC&quot;&gt;&lt;a href=&quot;#VPC&quot; class=&quot;headerlink&quot; title=&quot;VPC&quot;&gt;&lt;/a&gt;&lt;strong&gt;VPC&lt;/strong&gt;&lt;/h1&gt;&lt;h3 id=&quot;Virtual-Private-Cloud&quot;&gt;&lt;a href=&quot;#Virtual-Pri</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>AWS-12【 architecture】选择合适database</title>
    <link href="https://sosocrown.github.io/2023/08/16/AWS-12%E3%80%90%20architecture%E3%80%91%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82database/"/>
    <id>https://sosocrown.github.io/2023/08/16/AWS-12%E3%80%90%20architecture%E3%80%91%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82database/</id>
    <published>2023-08-15T16:00:00.000Z</published>
    <updated>2025-05-07T02:38:08.763Z</updated>
    
    <content type="html"><![CDATA[<h1 id="选择合适database"><a href="#选择合适database" class="headerlink" title="选择合适database"></a>选择合适database</h1><p><img src="/images/Untitled%2050.png" alt="Untitled"></p><p><strong>Online Transaction Processing”（在线事务处理）</strong></p><p>它是一种数据库处理方式，用于处理实时交易和事务。OLTP系统旨在支持并发的数据库操作，通常用于处理大量短期和频繁的交易请求，例如在线购买、银行交易、航班预订等。</p><p>OLTP系统通常具有以下特点：</p><ul><li>快速的读写操作：用于处理实时交易，需要快速响应和处理数据库记录的插入、更新和查询操作。</li><li>事务支持：OLTP系统必须支持ACID属性（原子性、一致性、隔离性和持久性），确保数据库的完整性和一致性。</li><li>高并发性：OLTP系统通常面对许多用户同时进行交易，需要能够处理高并发的请求。</li><li>精细的数据模型：OLTP系统的数据模型通常是规范化的，以减少数据冗余并提高查询性能。</li><li>实时数据访问：OLTP系统提供实时数据访问，允许用户即时获取最新的交易信息。</li></ul><h3 id="适用于OLTP的AWS服务："><a href="#适用于OLTP的AWS服务：" class="headerlink" title="适用于OLTP的AWS服务："></a>适用于OLTP的AWS服务：</h3><ol><li><strong>Amazon RDS</strong>（Relational Database Service）：支持多种关系型数据库引擎，适用于在线交易处理和实时事务。</li><li><strong>Amazon Aurora</strong>：是RDS的一个变种，专为OLTP工作负载而设计，具有高性能和高可用性。</li><li><strong>Amazon DynamoDB</strong>：全托管的NoSQL数据库，适用于高度可扩展的实时交易处理和高并发操作。</li><li><strong>Amazon ElastiCache</strong>：提供托管的内存缓存服务，加速读取操作，适用于缓存频繁读取的交易数据。</li></ol><h3 id="RDBMS"><a href="#RDBMS" class="headerlink" title="RDBMS"></a>RDBMS</h3><p>代表关系数据库管理系统（Relational Database Management System），是一种基于关系型数据库模型的软件系统。它是用于管理和操作关系型数据库的专用软件。</p><p>在RDBMS中，数据以表格的形式组织，每个表格由行和列组成。每行代表一个记录，每列代表记录的属性或字段。RDBMS使用结构化查询语言（SQL）来操作和查询数据库中的数据。</p><p>RDBMS具有以下特点：</p><ol><li><strong>表格结构</strong>：数据以表格形式存储，每个表格有唯一的名称，并定义了数据的结构和约束。</li><li><strong>关系</strong>：不同表格之间可以建立关系，通过使用主键和外键来连接数据。</li><li><strong>数据完整性</strong>：RDBMS支持定义数据完整性规则，确保数据的一致性和准确性。</li><li><strong>事务支持</strong>：RDBMS支持事务处理，保证数据的原子性、一致性、隔离性和持久性（ACID属性）。</li><li><strong>并发控制</strong>：RDBMS能够处理多用户同时对数据库进行读写的情况，并确保数据的一致性和可靠性。</li><li><strong>查询语言</strong>：通过使用SQL，用户可以方便地查询和操作数据库中的数据。</li></ol><p>常见的RDBMS包括MySQL、Oracle Database、Microsoft SQL Server、PostgreSQL和IBM DB2等。RDBMS被广泛用于企业和组织中，用于管理和存储大量结构化数据，如业务数据、客户信息、交易记录等。</p><h2 id="Amazon-RDS"><a href="#Amazon-RDS" class="headerlink" title="Amazon RDS"></a>Amazon RDS</h2><ul><li>Managed PostgreSQL&#x2F; MySOL &#x2F; Oracle&#x2F; SOL Server&#x2F; MariaDB &#x2F; Custom<ul><li><p>Provisioned RDS Instance Size and EBS Volume Type &amp; Size</p></li><li><p>Auto-scaling capability for Storage</p></li><li><p>Support for Read Replicas and Multi AZ</p></li><li><p>Security through lAM, Security Groups, KMS, SSL in transit</p></li><li><p>Automated Backup with Point in time restore feature (up to 35 days)</p></li><li><p>Manual DB Snapshot for longer-term recovery</p></li><li><p>Managed and Scheduled maintenance (with downtime)</p></li><li><p>Support for IAM Authentication, integration with Secrets Manager</p></li><li><p>RDS Custom for access to and customize the underlying instance (Oracle &amp; SQL Server)</p></li><li><p>Use case: Store relational datasets (RDBMS &#x2F; OLTP), perform SQL queries, transactions</p></li></ul></li><li>为 RDS 实例大小和 EBS 卷类型和大小提供支持</li><li>存储Auto-scaling capability</li><li>支持 Read Replicas and Multi AZ</li><li>通过IAM、安全组、KMS,SSL实现安全性传输</li><li><strong>自动备份，具备点时间还原功能（长达35天）</strong></li><li>用于长期恢复的手动DB Snapshot</li><li>管理和定期维护（with downtime）</li><li>支持IAM认证，与Secrets Manager 集成</li><li>RDS Custom 用于访问和自定义底层实例（Oracle 和 SQL Server）</li></ul><aside>🍋 use case：存储关系数据集（RDBMS/ OLTP），执行SQL查询，事务</aside><h2 id="Amazon-Aurora"><a href="#Amazon-Aurora" class="headerlink" title="Amazon Aurora"></a>Amazon Aurora</h2><ul><li><p>Compatible API for PostgreSQL &#x2F; MySQL, separation of storage and compute</p><ul><li>Storage: data is stored in 6 replicas, across 3 AZ -highly available, self-healing, auto-scaling</li><li>Compute: Cluster of DB Instance across multiple AZ, auto-scaling of Read Replicas</li><li>Cluster: Custom endpoints for writer and reader DB instances</li><li>Same security &#x2F; monitoring&#x2F; maintenance features as RDS</li><li>Know the backup &amp; restore options for Aurora</li><li><strong>Aurora Serverless</strong> - for unpredictable &#x2F; intermittent workloads, no capacity planning</li><li><strong>Aurora Multi-Master</strong> - for continuous writes failover (high write availability)</li><li><strong>Aurora Global</strong>: up to 16 DB Read instances in each region, &lt; I second storage replication</li><li><strong>Aurora Machine Learning:</strong> perform ML using SageMaker &amp; Comprehend on Aurora</li><li><strong>Aurora Database Cloning</strong>: new cluster from existing one, faster than restoring a snapshot</li><li>Use case: same as RDS,but with less maintenance &#x2F; more flexibility &#x2F; more performance &#x2F; more features</li></ul><p>  <img src="/images/Untitled%2051.png" alt="Untitled">  </p></li><li><p>兼容的 PostgreSQL &#x2F; MySQL API，存储和计算分离</p></li><li><p>存储：数据存储在6个副本中，跨越3个可用区, 高可用、自我修复、自动扩展</p></li><li><p>计算：Cluster of DB Instance across multiple AZ,， auto-scaling of Read Replicas</p></li><li><p>集群:编写器和阅读器DB实例的自定义终端节点</p></li><li><p>与RDS相同的安全&#x2F;监控&#x2F;维护功能</p></li><li><p>了解Aurora的备份和恢复选项</p></li><li><p><strong>Aurora Serverless</strong> - 适用于不可预测&#x2F;<strong>间歇性</strong>工作负载，<strong>无需容量规划</strong></p></li><li><p><strong>Aurora Multi-Master</strong> - for continuous writes failover 用于连续写入故障转移（高写入可用性）</p></li><li><p><strong>Aurora Global</strong>：在每个区域中最多有16个DB读取实例，storage replication存储复制小于1秒</p></li><li><p><strong>Aurora Machine Learning</strong>：使用SageMaker和Comprehend在Aurora上执行ML</p></li><li><p><strong>Aurora Database Cloning</strong>：从现有集群创建新集群，比恢复快</p>  <aside>  🍋 use case：与RDS相同，但维护较少/更灵活/性能更好/具有更多功能AZ    </aside></li></ul><h2 id="Amazon-ElastiCache"><a href="#Amazon-ElastiCache" class="headerlink" title="Amazon ElastiCache"></a>Amazon ElastiCache</h2><ul><li><p>Managed Redis&#x2F; Memcached (similar offering as RDS, but for caches)</p><ul><li>In-memory data store, sub-millisecond latency</li><li>Must provision an EC2 instance type</li><li>Support for Clustering (Redis) and Multi AZ, Read Replicas (sharding)</li><li>Security through IAM, Security Groups, KMS, Redis Auth</li><li>Backup &#x2F; Snapshot &#x2F; Point in time restore feature</li><li>Managed and Scheduled maintenance</li><li><strong>Requires some application code changes to be leveraged</strong></li></ul>  <aside>  🍋 Use Case: Key/Value store, Frequent reads, less writes, cache results for DB queries, store session data for websites, cannot use SQL    </aside>  <p>  <img src="/images/Untitled%2052.png" alt="Untitled">  </p></li><li><p>内存数据存储，<strong>亚毫秒延迟sub-millisecond latency</strong></p></li><li><p>compatible with Redis or Memcached.</p></li><li><p>必须预配EC2实例类型</p></li><li><p>支持集群（Redis）和多AZ，读取副本（分片）Read Replicas (sharding)</p></li><li><p>通过IAM，Security Groups，KMS，Redis Auth实现安全性</p></li><li><p>备份&#x2F;快照&#x2F;时间点恢复功能</p></li><li><p>托管和计划维护</p></li><li><p><strong>需要更改应用程序代码才能利用</strong></p></li></ul><aside>🍋 用例：键/值存储，频繁读取，较少写入，缓存DB查询结果，存储网站会话数据，无法使用SQL</aside><h2 id="Amazon-DynamoDB"><a href="#Amazon-DynamoDB" class="headerlink" title="Amazon DynamoDB"></a>Amazon DynamoDB</h2><ul><li><p>AWS proprietary technology,managed serverless NoSOL database, milisecond latency</p><ul><li>Capacity modes: provisioned capacity with optional auto-scaling or on-demand capacity</li><li>Can replace ElastiCache as a key&#x2F;value store (storing session data for example, using TL feature)</li><li>Highly Available, Multi AZ by default, Read and Writes are decoupled, transaction capability</li><li>DAX cluster for read cache, microsecond read latency</li><li>Security authentication and authorization is done through IAM</li><li>Event Processing: DynamoDB Streams to integrate with AWS Lambda, or Kinesis Data Streams</li><li>Global Table feature; active -active setup</li><li>Autorated backups up to 35 days with PITR (restore to new table), or on demand backups Export to S3 without using RCU within the PITR, window, import from S3 without using WCU• Great to rapidly evolve schemas</li></ul>  <aside>  🍋 Use Case: Serverless applications development (small documents 100s KB), distributed serverless       cache, doesn't have SOL query language available    </aside>  <p>  <img src="/images/Untitled%2053.png" alt="Untitled"></p></li></ul><p><img src="/images/Untitled%2054.png" alt="Untitled"></p><ul><li>Amazon DynamoDB is a key-value, document, NoSQL database.</li><li>AWS专有技术，托管无服务器NoSQL数据库，毫秒级延迟 milisecond latency</li><li>容量模式：预置容量和可选自动扩展或按需容量</li><li>可以替换ElastiCache作为键&#x2F;值存储（例如存储会话数据，使用TL功能）</li><li>默认高可用性，多AZ，读写解耦，具有事务功能</li><li><strong>DAX集群用于读取缓存，微秒级读取延迟</strong></li><li>安全认证和授权通过IAM完成</li><li>事件处理：DynamoDB Streams与AWS Lambda或Kinesis Data Streams集成</li><li>全局表功能；<strong>主动-主动设置</strong></li><li>自动化备份长达35天，具有PITR（还原到新表）或按需备份，可在PITR窗口内无需使用RCU导出到S3，从S3导入无需使用WCU</li><li><strong>适用于快速演变的架构</strong></li></ul><aside>🍋 用例：无服务器应用程序开发（小型文档100 KB），分布式无服务器缓存，**doesn't have SOL query language available**</aside><h2 id="Amazon-S3"><a href="#Amazon-S3" class="headerlink" title="Amazon S3"></a>Amazon S3</h2><ul><li><p>S3 is a… key&#x2F; value store for objects</p><ul><li>Great for bigger objects, not so great for many small objects</li><li>Serverless, scales infinitely, max object size is 5 TB, versioning capability</li><li>Tiers: S3 Standard, S3 Infrequent Access, S3 Intelligent, S3 Glacier + lifecycle policy</li><li>Features: Versioning, Encryption, Replication, MFA-Delete, Access Logs…</li><li>Security. I&#x2F;AM, Bucket Palicies, ACL, Access Points, Object Lambda, CORS. Object&#x2F;aut Lock</li><li>Encryption: SSE-S3, SSE-KMS, SSE-C, client-side, TLS in transit, default encryption</li><li>Batch operations on objects using S3 Batch, listing files using S3 Inventory</li><li>Performance: Multi-part upload, S3 Transfer Acceleration, S3 Select</li><li>Automation: S3 Event Notifications (SNS, SOS, Lambda, EventBridge)</li><li>Use Cases; static files, key value store for big files, website hosting</li></ul><p>  <img src="/images/Untitled%2055.png" alt="Untitled">  </p></li><li><p>S3是一个用于object的<strong>键&#x2F;值存储系统</strong></p></li><li><p>非常适合存储大型对象，但对于<strong>大量</strong>小对象则不太适用</p></li><li><p><strong>无服务器</strong>架构，可无限扩展，单个对象最大大小为5TB，支持versioning</p></li><li><p>存储类型：S3 Standard, S3 Infrequent Access, S3 Intelligent, S3 Glacier + lifecycle policy</p></li><li><p>功能：版本控制、加密、复制、MFA-删除、访问日志等等</p></li><li><p>安全性：IAM、存储桶策略、ACL、访问点、对象Lambda、CORS、对象&#x2F;自动锁定</p></li><li><p>加密：SSE-S3、SSE-KMS、SSE-C、客户端加密、TLS in transit、默认加密</p></li><li><p>使用S3 Batch进行对象批量操作，使用S3 Inventory列出文件</p></li><li><p>性能：Multi-part upload, S3 Transfer Acceleration, S3 Select</p></li><li><p>自动化：S3事件通知（SNS、SOS、Lambda、EventBridge）</p></li></ul><aside>🍋 使用场景：静态文件存储static files、大文件的键值存储 key value store for big files、网站托管 website hosting</aside><h2 id="DocumentDB"><a href="#DocumentDB" class="headerlink" title="DocumentDB"></a>DocumentDB</h2><ul><li><p>documentDB</p><p>  <img src="/images/Untitled%2056.png" alt="Untitled"></p></li><li><p>Aurora是对PostgreSQL &#x2F; MySQL的AWS实现…</p></li><li><p><strong>DocumentDB是MongoDB的AWS实现（MongoDB是一种NoSQL数据库）</strong></p></li><li><p>MongoDB用于存储、查询和索引JSON数据</p></li><li><p>与Aurora类似的部署概念</p></li><li><p>完全托管，高可用性，跨3个可用区进行复制</p></li><li><p>Aurora存储会自动增长，每次增加10GB，最多可达64TB。</p></li><li><p>automatically scales to workloads with millions of request per seconds</p></li></ul><p>自动缩放以处理每秒数百万个请求的工作负载</p><h2 id="Neptune"><a href="#Neptune" class="headerlink" title="Neptune"></a>Neptune</h2><ul><li><p>neptune</p><p>  <img src="/images/Untitled%2057.png" alt="Untitled"></p></li></ul><p>Amazon Neptune is a <strong>fast, reliable, fully-managed graph database service</strong> that makes it easy to build and run applications that work with highly connected datasets</p><ul><li>Neptune是一个托管的图形数据库服务，用于构建图形数据应用程序。</li><li>支持图形数据库模型和图形查询语言，处理复杂的关系型数据。</li><li>完全托管的图形数据库</li><li>一个流行的图形数据集可以是一个社交网络<ul><li>用户拥有朋友</li><li>帖子有评论</li><li>评论有用户的喜欢</li><li>用户分享和喜欢帖子……</li></ul></li><li>在3个可用区内高可用性，最多支持15个读取副本</li><li>构建和运行与高度连接的数据集合一起工作的应用程序 - 为这些复杂和繁重的查询进行了优化</li><li>可以存储上百亿个关系并以毫秒级的延迟查询图</li><li>通过多个可用区进行复制来实现高可用性</li></ul><aside>🍋 适用于知识图谱（如维基百科）、欺诈检测、推荐引擎、社交网络等应用</aside><h2 id="Keyspaces："><a href="#Keyspaces：" class="headerlink" title="Keyspaces："></a>Keyspaces：</h2><ul><li><p>keyspaces</p><p>  <img src="/images/Untitled%2058.png" alt="Untitled"></p></li><li><p>用于Apache Cassandra）：</p></li><li><p>Apache Cassandra是一种开源的分布式NoSQL数据库。</p></li><li><p>这是一种托管的与Apache Cassandra兼容的数据库服务。</p></li><li><p>无服务器架构，可扩展，高可用性，由AWS全面托管。</p></li><li><p>根据应用程序的流量自动调整表格的规模。</p></li><li><p>表格在多个可用区内复制3次。</p></li><li><p>使用Cassandra查询语言（CQL）。</p></li><li><p>即使在大规模情况下，单位数毫秒的延迟，每秒数千个请求。</p></li><li><p>容量：按需模式或配额模式与自动扩展。</p></li><li><p>支持加密、备份和35天的按时间点恢复（PITR）</p></li></ul><aside>🍋 使用场景：存储物联网设备信息、时间序列数据等。</aside><ul><li>具有高度可扩展性和高性能，适用于处理海量的分布式数据。</li><li></li></ul><h2 id="QLDB（Quantum-Ledger-Database）："><a href="#QLDB（Quantum-Ledger-Database）：" class="headerlink" title="QLDB（Quantum Ledger Database）："></a>QLDB（Quantum Ledger Database）：</h2><ul><li><p>QLDB</p><p>  <img src="/images/Untitled%2059.png" alt="Untitled"></p></li><li><p>QLDB是一个全托管、不可变、透明的账本数据库。</p></li><li><p>Quantum Ledger Database-量子账本数据库</p></li><li><p>用于记录交易历史和变更，并保证数据的安全性和完整性。</p></li><li><p>账本是记录财务交易的记录册</p></li><li><p>完全托管、无服务器、高可用性，在3个可用区进行复制</p></li><li><p>用于查看应用程序数据的所有更改历史</p></li><li><p>不可变系统；任何条目都无法删除或修改，具有加密验证</p></li><li><p>使用SQL轻松操作数据，性能比常见的账本区块链框架提高2-3倍</p></li><li><p>与Amazon Managed Blockchain集成，提供强大的区块链功能</p></li></ul><h2 id="Timestream："><a href="#Timestream：" class="headerlink" title="Timestream："></a>Timestream：</h2><ul><li><p>timestream</p><p>  <img src="/images/Untitled%2060.png" alt="Untitled"></p></li><li><p>Timestream是一个全托管的时间序列数据库服务，用于存储和分析时间序列数据，如IoT传感器数据、应用程序日志等。</p></li><li><p>完全托管、快速、可扩展、无服务器的时间序列数据库</p></li><li><p>自动按需调整容量，实现自动扩缩容</p></li><li><p>可存储和分析每天数万亿个事件</p></li><li><p>比关系型数据库快1000倍，成本仅为其十分之一</p></li><li><p>支持定期查询、多指标记录、SQL兼容性</p></li><li><p>数据存储层次：近期数据保存在内存中，历史数据保存在成本优化的存储中</p></li><li><p>内置时间序列分析功能（帮助您在近实时中识别数据中的模式）</p></li><li><p>在传输和静态状态下进行加密</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;选择合适database&quot;&gt;&lt;a href=&quot;#选择合适database&quot; class=&quot;headerlink&quot; title=&quot;选择合适database&quot;&gt;&lt;/a&gt;选择合适database&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/images/Untitled%205</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>AWS-14【 网络】网络连接</title>
    <link href="https://sosocrown.github.io/2023/08/16/AWS-15%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"/>
    <id>https://sosocrown.github.io/2023/08/16/AWS-15%E3%80%90%20%E7%BD%91%E7%BB%9C%E3%80%91%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/</id>
    <published>2023-08-15T16:00:00.000Z</published>
    <updated>2025-05-07T02:38:21.351Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Internet-Gateway-IGW"><a href="#1-Internet-Gateway-IGW" class="headerlink" title="1. Internet Gateway (IGW)"></a>1. Internet Gateway (IGW)</h2><ul><li><strong>IGW（Internet gateway）是AWS提供的，用来实现VPC和Internet之间相互通信的高可用组件。</strong></li><li>IGW 是连接 VPC 内部<strong>私有子网</strong>和<strong>公共 Internet</strong> 的组件。</li><li>在公有子网中，IGW 允许实例与 Internet 通信，且可以使用公有 IP。</li><li>一个VPC只能连接到一个IGW，反之亦然</li></ul><h2 id="2-NAT"><a href="#2-NAT" class="headerlink" title="2. NAT"></a>2. NAT</h2><h3 id="NAT-Network-Address-Translation"><a href="#NAT-Network-Address-Translation" class="headerlink" title="NAT &#x3D; Network Address Translation"></a>NAT &#x3D; Network Address Translation</h3><p>NAT 网关主要用于<strong>私有子网中的实例</strong>访问互联网</p><p><strong><code>出站连接</code></strong></p><h3 id="NAT-instance"><a href="#NAT-instance" class="headerlink" title="NAT instance"></a><strong>NAT instance</strong></h3><p>需要手动配置，适用于小规模流量。Old, must be setup in a public subnet, disable Source &#x2F; Destination check flag</p><p><img src="/images/Untitled%20152.png" alt="Untitled"></p><h3 id="NAT-gateway"><a href="#NAT-gateway" class="headerlink" title="NAT gateway"></a>NAT gateway</h3><p>AWS 托管，适用于大规模流量和高可用性需求。</p><p>NAT Gateway由AWS管理，提供可扩展的IPv4私有EC2实例Internet访问。</p><p>性能和可用性较高，所以通常优于NAT Instance。</p><p><img src="/images/Untitled%20153.png" alt="Untitled"></p><h2 id="3-AWS-Direct-Connect-DX-直连"><a href="#3-AWS-Direct-Connect-DX-直连" class="headerlink" title="3. AWS Direct Connect (DX)-直连"></a>3. AWS Direct Connect (DX)-直连</h2><p><img src="/images/Untitled%20154.png" alt="Untitled"></p><ul><li><strong>专用的物理连接</strong></li><li>AWS Direct Connect 在您的本地部署网络和 AWS 之间建立专用网络连接。</li><li>可以实现更稳定、低延迟的连接，用于大数据传输和混合云架构。</li></ul><h2 id="Direct-Connect-DX"><a href="#Direct-Connect-DX" class="headerlink" title="Direct Connect (DX)"></a>Direct Connect (DX)</h2><ul><li>提供从远程网络到您的VPC的dedicated private专用私有连接。</li><li>Data Center and <em><strong>AWS Direct Connect locations</strong></em>之间设置专用连接。</li></ul><aside>💡 DX Location是AWS Direct Connect服务的实际物理位置，通过连接到这些位置，您可以建立专用的物理连接</aside><ul><li><p>可以在同一连接上访问公共资源（如S3）和私有资源（如EC2）。</p></li><li><p>支持IPv4和IPv6。</p><p>  <img src="/images/Untitled%20155.png" alt="Untitled"></p></li></ul><blockquote><p><strong>连接流程：</strong></p></blockquote><ol><li>您在AWS控制台中选择一个DX Location，这是您将要建立连接的物理位置。</li><li>在您的本地网络中，您配置一个CGW，以确保它能够连接到DX Location。</li><li>您在AWS中创建一个VGW，并分配一个公共IP地址。</li><li>您在CGW和VGW之间建立IPSec隧道，通过配置加密和认证参数，以建立安全的通信通道。</li><li>一旦隧道建立，数据可以通过VPN连接在CGW和VGW之间进行加密传输。</li></ol><h2 id="Direct-Connect-Gateway"><a href="#Direct-Connect-Gateway" class="headerlink" title="Direct Connect Gateway"></a>Direct Connect Gateway</h2><ul><li>如果您想要在许多不同的区域（同一账户）中设置与一个或多个VPC的Direct Connect连接，您必须使用Direct Connect网关。If you want to set up a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway</li><li>建立新连接需要一个月以上的时间。</li><li>在传输中的数据未加密，但是保持私密性。<ul><li>AWS Direct Connect + VPN提供了一个IPsec加密的私有连接。</li></ul></li><li>如果Direct Connect发生故障，您可以设置备份Direct Connect连接（费用较高），或者设置站点到站点VPN连接。In case Direct Connect fails, you can set up a backup Direct Connect connection (expensive), or a Site-to-Site VPN connection</li><li></li></ul><p><img src="/images/Untitled%20156.png" alt="Untitled"></p><p><img src="/images/Untitled%20157.png" alt="Untitled"></p><h2 id="4-Bastion-Hosts"><a href="#4-Bastion-Hosts" class="headerlink" title="4. Bastion Hosts"></a>4. Bastion Hosts</h2><ul><li>一个作为跳板的 EC2 instance</li><li>Bastion Host 是放置在公有子网中的实例，用于安全远程访问私有子网中的实例。</li><li>通常用于管理和维护私有子网中的实例，提供临时访问。</li></ul><p>访问跳板：在受保护的内部网络和外部网络之间进行访问的中间节点。</p><p>位于公共网络中</p><p>使用bastion hosts  to SSH into 私有EC2实例</p><p><img src="/images/Untitled%20158.png" alt="Untitled"></p><h2 id="5-Ephemeral-Ports"><a href="#5-Ephemeral-Ports" class="headerlink" title="5. Ephemeral Ports"></a>5. Ephemeral Ports</h2><p><code>临时端口，短暂端口或动态端口</code></p><ul><li>随机分配的临时端口</li><li>Ephemeral Ports（短暂端口）是客户端与服务器之间临时建立的端口，用于数据传输。</li><li>通常在连接时随机分配，并在连接终止后释放。</li><li>Clients connect to a defined port, and expect a response on this port</li></ul><h2 id="6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN"><a href="#6-AWS-VPN-CloudHub-和站点到站点-Site-to-Site-VPN" class="headerlink" title="6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN"></a>6. AWS VPN CloudHub 和站点到站点 (Site-to-Site) VPN</h2><h2 id="Site-to-Site-VPN"><a href="#Site-to-Site-VPN" class="headerlink" title="Site-to-Site VPN"></a>Site-to-Site VPN</h2><p>将本地数据中心与 VPC 直接连接的方法，作为备份连接方式。</p><p><strong>建立本地到VPC的连接：</strong> VPC站点到站点VPN允许您在VPC和本地数据中心之间建立一个加密的连接，使您的本地资源可以与VPC中的资源进行通信。</p><aside>💡 **VPN Gateway：** 在云服务中和本地网络中分别创建VPN Gateway：<aside>💡 VGW表示VPC侧的VPN设备</aside><aside>💡 LWG表示本地数据中心侧的VPN设备。</aside></aside><h3 id="VGW（Virtual-Private-Gateway）："><a href="#VGW（Virtual-Private-Gateway）：" class="headerlink" title="VGW（Virtual Private Gateway）："></a><strong>VGW（Virtual Private Gateway）：</strong></h3><ul><li>VGW是云服务提供商（如AWS）中的虚拟设备，用于建立VPN连接并处理数据的传入和传出。</li><li>VGW is created and attached to the VPC from which you want to create the Site-to-Site VPN connection</li></ul><h3 id="CGW（Customer-Gateway）："><a href="#CGW（Customer-Gateway）：" class="headerlink" title="CGW（Customer Gateway）："></a><strong>CGW（Customer Gateway）：</strong></h3><ul><li>本地网络中的物理设备或虚拟设备</li><li>与VGW之间建立IPSec隧道来实现安全通信。</li></ul><p><img src="/images/Untitled%20159.png" alt="Untitled"></p><h2 id="Site-to-Site-VPN-connection-as-a-backup"><a href="#Site-to-Site-VPN-connection-as-a-backup" class="headerlink" title="Site-to-Site VPN connection as a backup"></a>Site-to-Site VPN connection as a backup</h2><p><img src="/images/Untitled%20160.png" alt="Untitled"></p><h2 id="AWS-VPN-CloudHub"><a href="#AWS-VPN-CloudHub" class="headerlink" title="AWS VPN CloudHub"></a>AWS VPN CloudHub</h2><p>AWS VPN CloudHub 允许多个站点通过 VPN 连接到 AWS。</p><p>集中式的解决方案</p><ul><li>Provide secure communication between multiple sites, if you have multiple VPN connections</li><li>Low-cost hub-and-spoke model for primary or secondary network connectivity between different locations (VPN only)</li><li>It’s a VPN connection so it goes over the public Internet</li><li>如果有多个 VPN 连接，可以在多个站点之间提供安全通信</li><li>低成本的枢纽-辐射模型，用于不同位置之间的主要或次要网络连接 (仅限 VPN)</li><li>这是一种 VPN 连接，因此它经过公共互联网传输</li></ul><ol start="6"><li><strong>多站点连接：</strong> AWS VPN CloudHub支持同时连接多个远程站点。这些站点可以是不同地理位置的办公室、数据中心等。</li><li><strong>中心式架构：</strong> CloudHub采用中心式架构，其中AWS云中的一个VPC被用作中心（hub），连接到多个远程站点（spokes）。</li><li><strong>单一VPN连接：</strong> 在CloudHub配置中，每个远程站点与AWS云中的中心VPC之间只需要一个VPN连接。</li></ol><h2 id="7-Transit-Gateway-中转网关"><a href="#7-Transit-Gateway-中转网关" class="headerlink" title="7. Transit Gateway-中转网关"></a>7. Transit Gateway-<strong>中转网关</strong></h2><ul><li>Transit Gateway 是中心化的路由交换设备，用于连接多个 VPC、VPN 和 Direct Connect。</li><li>它简化了大规模 VPC 网络的管理和扩展。</li></ul><h2 id="Transit-Gateway（中转网关）"><a href="#Transit-Gateway（中转网关）" class="headerlink" title="Transit Gateway（中转网关）"></a><em><strong>Transit Gateway（中转网关）</strong></em></h2><p><strong>support  IP Multicast</strong></p><p>Transit Gateway是一种网络服务，用于在成千上万个VPC和本地网络之间建立具有<strong>传递性</strong>的中心式（星型）连接。以下是Transit Gateway的关键概念：</p><ul><li><strong>传递性对等连接：</strong> Transit Gateway允许在多个VPC和本地网络之间建立传递性的对等连接，形成一个中心枢纽连接。</li><li>Regional resource**：** Transit Gateway是region级别的资源，可以cross-region工作，实现不同AWS区域的连接。</li><li>Share cross-account contents using Resource Access Manager (RAM)</li><li>**使用RAM（Resource Access Manager）**Share cross-account contents</li></ul><p><img src="/images/Untitled%20161.png" alt="Untitled"></p><h3 id="Site-to-Site-VPN-ECMP"><a href="#Site-to-Site-VPN-ECMP" class="headerlink" title="Site-to-Site VPN ECMP"></a>Site-to-Site VPN ECMP</h3><ul><li>ECMP &#x3D; Equal-cost multi-path routing</li><li>Routing strategy to allow to forward a packet over multiple best path</li><li>Use case: create multiple Site-To-Site VPN connections to increase the bandwidth of your connection to AWS</li><li>站点对站点 VPN ECMP<ul><li>ECMP &#x3D; 等价多路径路由</li><li>转发数据包的路由策略，允许通过多个最佳路径</li><li>使用场景：创建多个站点对站点 VPN 连接，以增加到 AWS 的带宽</li></ul></li></ul><p><img src="/images/Untitled%20162.png" alt="Untitled"></p><p><img src="/images/Untitled%20163.png" alt="Untitled"></p><p><img src="/images/Untitled%20164.png" alt="Untitled"></p><h2 id="8-Traffic-Mirroring"><a href="#8-Traffic-Mirroring" class="headerlink" title="8. Traffic Mirroring"></a>8. Traffic Mirroring</h2><ul><li><strong>流量镜像：</strong> 通过使用流量镜像，您可以将来自<strong>生产 VPC</strong> 的流量镜像到特定的目标（例如 EC2 实例或另一个 VPC），然后在目标上执行流量<strong>检查和过滤</strong>。</li><li><strong>将流量路由到安全设备：</strong> 以进行内容检查、威胁监控、故障排除等操作。</li><li><strong>源和目标位置：</strong> 流量镜像的源和目标可以在同一VPC内或不同VPC之间（通过VPC Peering）。</li><li><strong>应用场景：</strong> 使用Transit Gateway的流量镜像功能可以用于内容检查、威胁监控、故障排除等场景。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-Internet-Gateway-IGW&quot;&gt;&lt;a href=&quot;#1-Internet-Gateway-IGW&quot; class=&quot;headerlink&quot; title=&quot;1. Internet Gateway (IGW)&quot;&gt;&lt;/a&gt;1. Internet Gatew</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>AWS-11【Storage Gateway】</title>
    <link href="https://sosocrown.github.io/2023/08/15/AWS-13%E3%80%90Storage%20Gateway%E3%80%91/"/>
    <id>https://sosocrown.github.io/2023/08/15/AWS-13%E3%80%90Storage%20Gateway%E3%80%91/</id>
    <published>2023-08-14T16:00:00.000Z</published>
    <updated>2025-05-07T02:38:12.553Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Storage-Gateway-混合存储"><a href="#Storage-Gateway-混合存储" class="headerlink" title="Storage Gateway-混合存储"></a><strong>Storage Gateway-混合存储</strong></h1><p><strong>Storage Gateway-混合存储</strong><br><img src="/images/Untitled%2038.png" alt="Untitled"></p><p><strong>在本地环境和AWS云存储之间建立连接</strong></p><p>AWS Storage Gateway充当本地应用和AWS云存储之间的桥梁，使您能够轻松<strong>扩展本地存储容量</strong>，将本地数据备份到AWS云中，并在本地应用和AWS云存储之间实现<strong>无缝的数据迁移</strong>。</p><p><img src="/images/Untitled%2039.png" alt="Untitled"></p><ul><li>文件网关接口：NFS 和 SMB。</li></ul><p>NFS和SMB都是用于文件共享的协议：</p><ol><li>NFS（Network File System）：NFS是一种用于在计算机网络中共享文件的协议，最初由Sun Microsystems开发。它允许不同操作系统的计算机之间通过网络访问和共享文件和目录。NFS主要在Unix和Linux系统中使用。</li><li>SMB（Server Message Block）：SMB是一种用于共享文件、打印机和其他资源的网络协议，最初由微软开发，后来被称为CIFS（Common Internet File System）。SMB&#x2F;CIFS协议通常用于Windows操作系统中的文件和打印机共享。</li></ol><p>在S3文件网关的情境中，NFS和SMB是用于创建本地网络共享，使得应用程序可以通过这些共享访问存储在Amazon S3中的数据。</p><h2 id="use-cases"><a href="#use-cases" class="headerlink" title="use cases"></a>use cases</h2><ol><li><strong>Backup &amp; recovery</strong></li><li><strong>Disaster Recovery</strong></li><li><strong>Local Storage Extension</strong></li><li><strong>tiered storage</strong></li><li><strong>Data Archiving and Long-Term Storage数据归档和长期存储</strong></li><li><strong>Cloud Backup and Data Migration云中备份和数据迁移</strong></li><li><strong>Hybrid Cloud Environments混合云环境</strong></li></ol><h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p><img src="/images/Untitled%2040.png" alt="Untitled"></p><h3 id="S3-File-Gateway："><a href="#S3-File-Gateway：" class="headerlink" title="S3 File Gateway："></a><strong>S3 File Gateway</strong>：</h3><p><strong>S3文件网关特点：</strong></p><ul><li>将S3文件网关部署在本地，作为本地文件系统和Amazon S3                                                                      之间的桥梁。</li><li>支持四种存储网关类型：文件、卷、缓存和虚拟带。</li><li>可以<strong>使用文件共享协议（NFS、SMB）访问存储在Amazon S3中的数据</strong>。</li><li>文件网关提供本地缓存，可以缓存频繁访问的数据，提供更快的访问速度。</li><li>支持数据在本地缓存和Amazon S3之间的自动传输。</li></ul><p><strong>适合使用场景：</strong></p><ul><li>需要在本地应用程序和Amazon S3之间建立文件共享的场景。</li><li>需要快速访问本地缓存数据和远程S3数据的应用程序，提高数据访问速度。</li><li>需要自动化数据传输，将本地数据定期或按需上传到Amazon S3中。</li><li>适用于文件备份、归档、协作等需要本地和云存储的场景。</li></ul><p><img src="/images/Untitled%2041.png" alt="Untitled"></p><h3 id="FSx-File-Gateway"><a href="#FSx-File-Gateway" class="headerlink" title="FSx  File Gateway"></a>FSx  <strong>File Gateway</strong></h3><p><img src="/images/Untitled%2042.png" alt="Untitled"></p><h3 id="Volume-Gateway-卷网关"><a href="#Volume-Gateway-卷网关" class="headerlink" title="Volume Gateway-卷网关"></a><strong>Volume Gateway-卷网关</strong></h3><ul><li><strong>缓存卷（Cached Volumes）</strong>：在<strong>本地缓存中保留常用数据</strong>，将数据异步上传到云中。适用于需要低延迟访问的应用程序。<ul><li>缓存卷的大小范围可以是 1 GiB 到 32 TiB</li></ul></li><li><strong>存储卷（Stored Volumes）</strong>：将<strong>数据完全保存在本地</strong>，并异步备份到云中。适用于需要在本地保留副本的应用程序。<ul><li>存储卷的大小范围从1gib到16tib</li></ul></li></ul><p><img src="/images/Untitled%2043.png" alt="Untitled"></p><p>卷网关允许您在本地创建iSCSI（Internet Small Computer System Interface）卷，将卷视为本地存储设备。然后，您可以通过卷网关将这些iSCSI卷的快照备份到AWS S3或AWS EBS（Elastic Block Store）卷中。</p><p>适用于将本地存储扩展到云中或进行数据备份和灾难恢复的场景。</p><ul><li>特点：提供iSCSI协议的块级别访问，允许在本地服务器上挂载虚拟卷。分为缓存卷和存储卷两种模式，数据可以部分或完全存储在云中。</li></ul><h3 id="Tape-Gateway-虚拟磁带库存储网关"><a href="#Tape-Gateway-虚拟磁带库存储网关" class="headerlink" title="**Tape Gateway-**虚拟磁带库存储网关"></a>**Tape Gateway-**虚拟磁带库存储网关</h3><p><img src="/images/Untitled%2044.png" alt="Untitled"></p><p>虚拟磁带库允许您在本地创建虚拟磁带库，将虚拟磁带视为磁带存储设备。您可以通过虚拟磁带库将磁带数据备份到AWS S3 Glacier或AWS S3 Glacier Deep Archive中，以实现长期数据归档和存储。</p><ul><li>特点：模拟磁带库，允许将备份和归档数据保存为虚拟磁带，并将其存储在Amazon S3中。<strong>适用于长期数据保留和归档</strong>。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Storage-Gateway-混合存储&quot;&gt;&lt;a href=&quot;#Storage-Gateway-混合存储&quot; class=&quot;headerlink&quot; title=&quot;Storage Gateway-混合存储&quot;&gt;&lt;/a&gt;&lt;strong&gt;Storage Gateway-混合</summary>
      
    
    
    
    <category term="lifelong learning" scheme="https://sosocrown.github.io/categories/lifelong-learning/"/>
    
    <category term="技术" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/categories/lifelong-learning/%E6%8A%80%E6%9C%AF/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="DevOps" scheme="https://sosocrown.github.io/tags/DevOps/"/>
    
    <category term="云原生" scheme="https://sosocrown.github.io/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
</feed>
